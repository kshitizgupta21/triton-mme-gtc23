{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7210102-aba1-42f4-a5f7-90bac19ac6b3",
   "metadata": {},
   "source": [
    "# Deploying AI Models from Multiple Frameworks on same GPU using MME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0edd954e",
   "metadata": {},
   "source": [
    "Amazon SageMaker multi-model endpoints(MME) provide a scalable and cost-effective way to deploy large number of deep learning models. Previously, customers had limited options to deploy 100s of deep learning models that need accelerated compute with GPUs. Now, customers can deploy 1000s of deep learning models on GPUs behind one SageMaker endpoint. MME will run multiple models on a GPU, share GPU instances behind an endpoint across multiple models and dynamically load/unload models based on the incoming traffic. With this, customers can significantly save cost and achieve the best price performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b308d276",
   "metadata": {},
   "source": [
    "In this section we show how MME on GPU allows you to deploy ML models from different frameworks like PyTorch, TensorRT, TensorFlow, ONNX, etc on the same GPU. In this example, we show the deployment of PyTorch and TensorRT DistilBERT models on same GPU using SageMaker MME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61a49a1",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"> ðŸ’¡ <strong> NOTE </strong>\n",
    "Set <strong> conda_python3 </strong> as kernel when prompted to set the kernel for this notebook. This notebook was tested with the <strong> conda_python3 </strong> kernel on an Amazon SageMaker notebook instance of type <strong> g5.xlarge </strong>.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66483eb5-f1ee-43ac-8f8b-3bc2a02a1fc3",
   "metadata": {},
   "source": [
    "### Installs <a class=\"anchor\" id=\"installs-and-set-up\"></a>\n",
    "\n",
    "Install required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e2956ae-e471-401e-9eb7-87a69df9c4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qU pip boto3 sagemaker awscli tritonclient[http] transformers datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b537a3-72b8-40d9-aed4-415efd008d09",
   "metadata": {},
   "source": [
    "### Imports and variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92279c0c-cd98-4928-8425-3530697fb9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "import time\n",
    "import random\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "from utils import print_safe\n",
    "\n",
    "# sagemaker variables\n",
    "prefix = \"nlp-mme-gpu\"\n",
    "role = get_execution_role()\n",
    "sm_client = boto3.client(service_name=\"sagemaker\")\n",
    "runtime_sm_client = boto3.client(\"sagemaker-runtime\")\n",
    "sagemaker_session = sagemaker.Session(boto_session=boto3.Session())\n",
    "bucket = sagemaker_session.default_bucket()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308dede4-e603-4e48-adb8-2d5a55b8f0d0",
   "metadata": {},
   "source": [
    "## Creating Model Artifacts <a class=\"anchor\" id=\"pytorch-efficientnet-model\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190a4d1d",
   "metadata": {},
   "source": [
    "This section presents overview of steps to prepare HuggingFace DistilBERT models to be deployed on SageMaker MME using Triton Inference server model configurations. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eeb7345-7bee-4ade-9213-1bd7082ca900",
   "metadata": {},
   "source": [
    "### Prepare PyTorch Model  <a class=\"anchor\" id=\"create-pytorch-model\"></a>\n",
    "\n",
    "\n",
    "* We load pre-trained PyTorch [Huggingface DistilBERT model](https://huggingface.co/bergum/xtremedistil-emotion) that was finetuned on emotion classification task. \n",
    "* Export it to Torchscript serialized format\n",
    "\n",
    "To perform these steps, we will be using our [pt_exporter.py](./workspace/pt_exporter.py) script and running it within the [PyTorch NGC](https://catalog.ngc.nvidia.com/orgs/nvidia/containers/pytorch) container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "633bfdf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./workspace/pt_exporter.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./workspace/pt_exporter.py\n",
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"bergum/xtremedistil-emotion\", torchscript=True)\n",
    "\n",
    "model = model.eval()\n",
    "model = model.to(device)\n",
    "\n",
    "bs = 224\n",
    "seq_len = 128\n",
    "dummy_inputs = [\n",
    "    torch.randint(1000, (bs, seq_len)).to(device),\n",
    "    torch.ones(bs, seq_len, dtype=torch.int).to(device),\n",
    "    torch.zeros(bs, seq_len, dtype=torch.int).to(device),\n",
    "]\n",
    "\n",
    "traced_model = torch.jit.trace(model, dummy_inputs)\n",
    "torch.jit.save(traced_model, \"model.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b290a97",
   "metadata": {},
   "source": [
    "Run the cell below to finish preparing the PyTorch DistilBERT model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f0dae16a-1bde-422b-9635-5b6e005e59c2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=============\n",
      "== PyTorch ==\n",
      "=============\n",
      "\n",
      "NVIDIA Release 22.12 (build 49968248)\n",
      "PyTorch Version 1.14.0a0+410ce96\n",
      "\n",
      "Container image Copyright (c) 2022, NVIDIA CORPORATION & AFFILIATES. All rights reserved.\n",
      "\n",
      "Copyright (c) 2014-2022 Facebook Inc.\n",
      "Copyright (c) 2011-2014 Idiap Research Institute (Ronan Collobert)\n",
      "Copyright (c) 2012-2014 Deepmind Technologies    (Koray Kavukcuoglu)\n",
      "Copyright (c) 2011-2012 NEC Laboratories America (Koray Kavukcuoglu)\n",
      "Copyright (c) 2011-2013 NYU                      (Clement Farabet)\n",
      "Copyright (c) 2006-2010 NEC Laboratories America (Ronan Collobert, Leon Bottou, Iain Melvin, Jason Weston)\n",
      "Copyright (c) 2006      Idiap Research Institute (Samy Bengio)\n",
      "Copyright (c) 2001-2004 Idiap Research Institute (Ronan Collobert, Samy Bengio, Johnny Mariethoz)\n",
      "Copyright (c) 2015      Google Inc.\n",
      "Copyright (c) 2015      Yangqing Jia\n",
      "Copyright (c) 2013-2016 The Caffe contributors\n",
      "All rights reserved.\n",
      "\n",
      "Various files include modifications (c) NVIDIA CORPORATION & AFFILIATES.  All rights reserved.\n",
      "\n",
      "This container image and its contents are governed by the NVIDIA Deep Learning Container License.\n",
      "By pulling and using the container, you accept the terms and conditions of this license:\n",
      "https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license\n",
      "\n",
      "NOTE: CUDA Forward Compatibility mode ENABLED.\n",
      "  Using CUDA 11.8 driver version 520.61.05 with kernel driver version 510.47.03.\n",
      "  See https://docs.nvidia.com/deploy/cuda-compatibility/ for details.\n",
      "\n",
      "Installing Transformers...\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 23.0 is available.\n",
      "You should consider upgrading via the '/usr/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Downloading xdistillbert model from HuggingFace...\n",
      "Exporting model to Torchscript...\n",
      "Downloading (â€¦)lve/main/config.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 991/991 [00:00<00:00, 256kB/s]\n",
      "Downloading (â€¦)\"pytorch_model.bin\";: 100%|â–ˆ| 51.1M/51.1M [00:01<00:00, 36.2MB/s]\n"
     ]
    }
   ],
   "source": [
    "!docker run --gpus=all --rm -it --ipc=host --ulimit memlock=-1 --ulimit stack=67108864 \\\n",
    "            -v `pwd`/workspace:/workspace -w /workspace nvcr.io/nvidia/pytorch:22.12-py3 \\\n",
    "            /bin/bash generate_model_pytorch.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff064e3",
   "metadata": {},
   "source": [
    "#### Setup PyTorch Model Repository\n",
    "\n",
    "Now that model artifact is ready we need to set up a model repository containing the model artifact we want to serve along with a [model configuration](https://github.com/triton-inference-server/server/blob/main/docs/model_configuration.md) file i.e. `config.pbtxt`. This is the expected structure of the model repository:\n",
    "```\n",
    "xdistilbert_pt\n",
    "â”œâ”€â”€ 1\n",
    "â”‚   â””â”€â”€ model.pt\n",
    "â””â”€â”€ config.pbtxt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e007176",
   "metadata": {},
   "source": [
    "#### PyTorch Model configuration <a class=\"anchor\" id=\"create-pytorch-model-config\"></a>\n",
    "\n",
    "Model configuration file `config.pbtxt` contains the following:  \n",
    "- `name`: xdistilbert_pt\n",
    "- `backend`: pytorch\n",
    "- `max_batch_size`: maximum batch size 224 that the model supports\n",
    "- `input` and `output` tensor shapes with the `data_type` \n",
    "\n",
    "Additionally, you can specify [instance_group](https://github.com/triton-inference-server/server/blob/main/docs/user_guide/model_configuration.md#instance-groups) and [dynamic_batching](https://github.com/triton-inference-server/server/blob/main/docs/user_guide/model_configuration.md#dynamic-batcher) properties to achieve high performance inference. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9a21ac8-012c-4e6c-8d17-27838295f507",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p model_repository/xdistilbert_pt/1\n",
    "!cp workspace/model.pt model_repository/xdistilbert_pt/1/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b45c395e-c52a-4a28-a18b-7baa746fc1b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting model_repository/xdistilbert_pt/config.pbtxt\n"
     ]
    }
   ],
   "source": [
    "%%writefile model_repository/xdistilbert_pt/config.pbtxt\n",
    "name: \"xdistilbert_pt\"\n",
    "backend: \"pytorch\"\n",
    "max_batch_size: 224\n",
    "input [\n",
    "  {\n",
    "    name: \"INPUT__0\"\n",
    "    data_type: TYPE_INT32\n",
    "    dims: [128]\n",
    "  },\n",
    "  {\n",
    "    name: \"INPUT__1\"\n",
    "    data_type: TYPE_INT32\n",
    "    dims: [128]\n",
    "  },\n",
    "    {\n",
    "    name: \"INPUT__2\"\n",
    "    data_type: TYPE_INT32\n",
    "    dims: [128]\n",
    "  }\n",
    "]\n",
    "output [\n",
    "  {\n",
    "    name: \"OUTPUT__0\"\n",
    "    data_type: TYPE_FP32\n",
    "    dims: [6]\n",
    "  }\n",
    "]\n",
    "instance_group {\n",
    "  count: 1\n",
    "  kind: KIND_GPU\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87036cb6-f830-495a-b2cc-9651ec93fe06",
   "metadata": {},
   "source": [
    "### Prepare TensorRT Model <a class=\"anchor\" id=\"create-tensorrt-model\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca98ddb-d90b-4095-b310-825d09774954",
   "metadata": {},
   "source": [
    "- We load pre-trained xdistilbert PyTorch model from Huggingface\n",
    "- Convert to onnx representation using torch onnx exporter.\n",
    "- Use TensorRT `trtexec` bash command to create the TensorRT model plan\n",
    "\n",
    "To perform these steps, we will be running the [generate_model_trt.sh](./workspace/generate_model_trt.sh) script inside the [PyTorch NGC](https://catalog.ngc.nvidia.com/orgs/nvidia/containers/pytorch) container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc3b292b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./workspace/generate_model_trt.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./workspace/generate_model_trt.sh\n",
    "\n",
    "echo \"Installing Transformers...\"\n",
    "pip -q install transformers[onnx]\n",
    "\n",
    "echo \"Exporting model to ONNX...\"\n",
    "python -m transformers.onnx --model=bergum/xtremedistil-emotion \\\n",
    "                            --feature=sequence-classification /workspace/onnx/\n",
    "\n",
    "export CUDA_MODULE_LOADING=LAZY\n",
    "echo \"Converting ONNX Model to TensorRT FP16 Plan...\"\n",
    "trtexec --onnx=/workspace/onnx/model.onnx \\\n",
    "        --saveEngine=/workspace/model.plan \\\n",
    "        --minShapes=input_ids:1x128,attention_mask:1x128,token_type_ids:1x128 \\\n",
    "        --optShapes=input_ids:16x128,attention_mask:16x128,token_type_ids:16x128 \\\n",
    "        --maxShapes=input_ids:224x128,attention_mask:224x128,token_type_ids:224x128 \\\n",
    "        --fp16 \\\n",
    "        --verbose \\\n",
    "        --memPoolSize=workspace:14000 | tee conversion_trt.txt\n",
    "\n",
    "echo \"Finished exporting all models...\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1a06fd",
   "metadata": {},
   "source": [
    "Execute the cell below to finish preparing the TensorRT DistilBERT model.\n",
    "\n",
    "**Note**:\n",
    "This TensorRT optimization step takes around 10 minutes to complete. While the step is running, feel free to check out the logs in the cell below and watch this [video](https://www.nvidia.com/en-us/on-demand/session/gtcspring22-s41306/?start=349) to learn more about the different TensorRT optimizations like *Kernel AutoTuning*, *Layer Fusion* and *Reduced Mixed Precision*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "daefd65d-f654-44b6-9569-0a1d5597a7f2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=============\n",
      "== PyTorch ==\n",
      "=============\n",
      "\n",
      "NVIDIA Release 22.12 (build 49968248)\n",
      "PyTorch Version 1.14.0a0+410ce96\n",
      "\n",
      "Container image Copyright (c) 2022, NVIDIA CORPORATION & AFFILIATES. All rights reserved.\n",
      "\n",
      "Copyright (c) 2014-2022 Facebook Inc.\n",
      "Copyright (c) 2011-2014 Idiap Research Institute (Ronan Collobert)\n",
      "Copyright (c) 2012-2014 Deepmind Technologies    (Koray Kavukcuoglu)\n",
      "Copyright (c) 2011-2012 NEC Laboratories America (Koray Kavukcuoglu)\n",
      "Copyright (c) 2011-2013 NYU                      (Clement Farabet)\n",
      "Copyright (c) 2006-2010 NEC Laboratories America (Ronan Collobert, Leon Bottou, Iain Melvin, Jason Weston)\n",
      "Copyright (c) 2006      Idiap Research Institute (Samy Bengio)\n",
      "Copyright (c) 2001-2004 Idiap Research Institute (Ronan Collobert, Samy Bengio, Johnny Mariethoz)\n",
      "Copyright (c) 2015      Google Inc.\n",
      "Copyright (c) 2015      Yangqing Jia\n",
      "Copyright (c) 2013-2016 The Caffe contributors\n",
      "All rights reserved.\n",
      "\n",
      "Various files include modifications (c) NVIDIA CORPORATION & AFFILIATES.  All rights reserved.\n",
      "\n",
      "This container image and its contents are governed by the NVIDIA Deep Learning Container License.\n",
      "By pulling and using the container, you accept the terms and conditions of this license:\n",
      "https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license\n",
      "\n",
      "NOTE: CUDA Forward Compatibility mode ENABLED.\n",
      "  Using CUDA 11.8 driver version 520.61.05 with kernel driver version 510.47.03.\n",
      "  See https://docs.nvidia.com/deploy/cuda-compatibility/ for details.\n",
      "\n",
      "Installing Transformers...\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 23.0 is available.\n",
      "You should consider upgrading via the '/usr/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Exporting model to ONNX...\n",
      "Framework not requested. Using torch to export to ONNX.\n",
      "Downloading (â€¦)lve/main/config.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 991/991 [00:00<00:00, 269kB/s]\n",
      "Downloading (â€¦)\"pytorch_model.bin\";: 100%|â–ˆ| 51.1M/51.1M [00:01<00:00, 41.1MB/s]\n",
      "Downloading (â€¦)okenizer_config.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 365/365 [00:00<00:00, 226kB/s]\n",
      "Downloading (â€¦)solve/main/vocab.txt: 100%|â–ˆâ–ˆâ–ˆâ–ˆ| 232k/232k [00:00<00:00, 934kB/s]\n",
      "Downloading (â€¦)/main/tokenizer.json: 100%|â–ˆâ–ˆâ–ˆ| 466k/466k [00:00<00:00, 1.51MB/s]\n",
      "Downloading (â€¦)cial_tokens_map.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 112/112 [00:00<00:00, 73.4kB/s]\n",
      "Using framework PyTorch: 1.14.0a0+410ce96\n",
      "Overriding 1 configuration item(s)\n",
      "\t- use_cache -> False\n",
      "Validating ONNX model...\n",
      "\t-[âœ“] ONNX model output names match reference model ({'logits'})\n",
      "\t- Validating ONNX Model output \"logits\":\n",
      "\t\t-[âœ“] (3, 6) matches (3, 6)\n",
      "\t\t-[âœ“] all values close (atol: 1e-05)\n",
      "All good, model saved at: /workspace/onnx/model.onnx\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/onnx/__main__.py:178: FutureWarning: The export was done by transformers.onnx which is deprecated and will be removed in v5. We recommend using optimum.exporters.onnx in future. You can find more information here: https://huggingface.co/docs/optimum/exporters/onnx/usage_guides/export_a_model.\n",
      "  warnings.warn(\n",
      "Converting ONNX Model to TensorRT FP16 Plan...\n",
      "&&&& RUNNING TensorRT.trtexec [TensorRT v8501] # trtexec --onnx=/workspace/onnx/model.onnx --saveEngine=/workspace/model.plan --minShapes=input_ids:1x128,attention_mask:1x128,token_type_ids:1x128 --optShapes=input_ids:16x128,attention_mask:16x128,token_type_ids:16x128 --maxShapes=input_ids:224x128,attention_mask:224x128,token_type_ids:224x128 --fp16 --verbose --memPoolSize=workspace:14000\n",
      "[02/02/2023-19:14:16] [I] === Model Options ===\n",
      "[02/02/2023-19:14:16] [I] Format: ONNX\n",
      "[02/02/2023-19:14:16] [I] Model: /workspace/onnx/model.onnx\n",
      "[02/02/2023-19:14:16] [I] Output:\n",
      "[02/02/2023-19:14:16] [I] === Build Options ===\n",
      "[02/02/2023-19:14:16] [I] Max batch: explicit batch\n",
      "[02/02/2023-19:14:16] [I] Memory Pools: workspace: 14000 MiB, dlaSRAM: default, dlaLocalDRAM: default, dlaGlobalDRAM: default\n",
      "[02/02/2023-19:14:16] [I] minTiming: 1\n",
      "[02/02/2023-19:14:16] [I] avgTiming: 8\n",
      "[02/02/2023-19:14:16] [I] Precision: FP32+FP16\n",
      "[02/02/2023-19:14:16] [I] LayerPrecisions: \n",
      "[02/02/2023-19:14:16] [I] Calibration: \n",
      "[02/02/2023-19:14:16] [I] Refit: Disabled\n",
      "[02/02/2023-19:14:16] [I] Sparsity: Disabled\n",
      "[02/02/2023-19:14:16] [I] Safe mode: Disabled\n",
      "[02/02/2023-19:14:16] [I] DirectIO mode: Disabled\n",
      "[02/02/2023-19:14:16] [I] Restricted mode: Disabled\n",
      "[02/02/2023-19:14:16] [I] Build only: Disabled\n",
      "[02/02/2023-19:14:16] [I] Save engine: /workspace/model.plan\n",
      "[02/02/2023-19:14:16] [I] Load engine: \n",
      "[02/02/2023-19:14:16] [I] Profiling verbosity: 0\n",
      "[02/02/2023-19:14:16] [I] Tactic sources: Using default tactic sources\n",
      "[02/02/2023-19:14:16] [I] timingCacheMode: local\n",
      "[02/02/2023-19:14:16] [I] timingCacheFile: \n",
      "[02/02/2023-19:14:16] [I] Heuristic: Disabled\n",
      "[02/02/2023-19:14:16] [I] Preview Features: Use default preview flags.\n",
      "[02/02/2023-19:14:16] [I] Input(s)s format: fp32:CHW\n",
      "[02/02/2023-19:14:16] [I] Output(s)s format: fp32:CHW\n",
      "[02/02/2023-19:14:16] [I] Input build shape: input_ids=1x128+16x128+224x128\n",
      "[02/02/2023-19:14:16] [I] Input build shape: attention_mask=1x128+16x128+224x128\n",
      "[02/02/2023-19:14:16] [I] Input build shape: token_type_ids=1x128+16x128+224x128\n",
      "[02/02/2023-19:14:16] [I] Input calibration shapes: model\n",
      "[02/02/2023-19:14:16] [I] === System Options ===\n",
      "[02/02/2023-19:14:16] [I] Device: 0\n",
      "[02/02/2023-19:14:16] [I] DLACore: \n",
      "[02/02/2023-19:14:16] [I] Plugins:\n",
      "[02/02/2023-19:14:16] [I] === Inference Options ===\n",
      "[02/02/2023-19:14:16] [I] Batch: Explicit\n",
      "[02/02/2023-19:14:16] [I] Input inference shape: token_type_ids=16x128\n",
      "[02/02/2023-19:14:16] [I] Input inference shape: attention_mask=16x128\n",
      "[02/02/2023-19:14:16] [I] Input inference shape: input_ids=16x128\n",
      "[02/02/2023-19:14:16] [I] Iterations: 10\n",
      "[02/02/2023-19:14:16] [I] Duration: 3s (+ 200ms warm up)\n",
      "[02/02/2023-19:14:16] [I] Sleep time: 0ms\n",
      "[02/02/2023-19:14:16] [I] Idle time: 0ms\n",
      "[02/02/2023-19:14:16] [I] Streams: 1\n",
      "[02/02/2023-19:14:16] [I] ExposeDMA: Disabled\n",
      "[02/02/2023-19:14:16] [I] Data transfers: Enabled\n",
      "[02/02/2023-19:14:16] [I] Spin-wait: Disabled\n",
      "[02/02/2023-19:14:16] [I] Multithreading: Disabled\n",
      "[02/02/2023-19:14:16] [I] CUDA Graph: Disabled\n",
      "[02/02/2023-19:14:16] [I] Separate profiling: Disabled\n",
      "[02/02/2023-19:14:16] [I] Time Deserialize: Disabled\n",
      "[02/02/2023-19:14:16] [I] Time Refit: Disabled\n",
      "[02/02/2023-19:14:16] [I] NVTX verbosity: 0\n",
      "[02/02/2023-19:14:16] [I] Persistent Cache Ratio: 0\n",
      "[02/02/2023-19:14:16] [I] Inputs:\n",
      "[02/02/2023-19:14:16] [I] === Reporting Options ===\n",
      "[02/02/2023-19:14:16] [I] Verbose: Enabled\n",
      "[02/02/2023-19:14:16] [I] Averages: 10 inferences\n",
      "[02/02/2023-19:14:16] [I] Percentiles: 90,95,99\n",
      "[02/02/2023-19:14:16] [I] Dump refittable layers:Disabled\n",
      "[02/02/2023-19:14:16] [I] Dump output: Disabled\n",
      "[02/02/2023-19:14:16] [I] Profile: Disabled\n",
      "[02/02/2023-19:14:16] [I] Export timing to JSON file: \n",
      "[02/02/2023-19:14:16] [I] Export output to JSON file: \n",
      "[02/02/2023-19:14:16] [I] Export profile to JSON file: \n",
      "[02/02/2023-19:14:16] [I] \n",
      "[02/02/2023-19:14:16] [I] === Device Information ===\n",
      "[02/02/2023-19:14:16] [I] Selected Device: NVIDIA A10G\n",
      "[02/02/2023-19:14:16] [I] Compute Capability: 8.6\n",
      "[02/02/2023-19:14:16] [I] SMs: 80\n",
      "[02/02/2023-19:14:16] [I] Compute Clock Rate: 1.71 GHz\n",
      "[02/02/2023-19:14:16] [I] Device Global Memory: 22731 MiB\n",
      "[02/02/2023-19:14:16] [I] Shared Memory per SM: 100 KiB\n",
      "[02/02/2023-19:14:16] [I] Memory Bus Width: 384 bits (ECC enabled)\n",
      "[02/02/2023-19:14:16] [I] Memory Clock Rate: 6.251 GHz\n",
      "[02/02/2023-19:14:16] [I] \n",
      "[02/02/2023-19:14:16] [I] TensorRT version: 8.5.1\n",
      "[02/02/2023-19:14:16] [V] [TRT] Registered plugin creator - ::BatchTilePlugin_TRT version 1\n",
      "[02/02/2023-19:14:16] [V] [TRT] Registered plugin creator - ::BatchedNMS_TRT version 1\n",
      "[02/02/2023-19:14:16] [V] [TRT] Registered plugin creator - ::BatchedNMSDynamic_TRT version 1\n",
      "[02/02/2023-19:14:16] [V] [TRT] Registered plugin creator - ::Clip_TRT version 1\n",
      "[02/02/2023-19:14:16] [V] [TRT] Registered plugin creator - ::CoordConvAC version 1\n",
      "[02/02/2023-19:14:16] [V] [TRT] Registered plugin creator - ::CropAndResize version 1\n",
      "[02/02/2023-19:14:16] [V] [TRT] Registered plugin creator - ::CropAndResizeDynamic version 1\n",
      "[02/02/2023-19:14:16] [V] [TRT] Registered plugin creator - ::DecodeBbox3DPlugin version 1\n",
      "[02/02/2023-19:14:16] [V] [TRT] Registered plugin creator - ::DetectionLayer_TRT version 1\n",
      "[02/02/2023-19:14:16] [V] [TRT] Registered plugin creator - ::EfficientNMS_TRT version 1\n",
      "[02/02/2023-19:14:16] [V] [TRT] Registered plugin creator - ::EfficientNMS_ONNX_TRT version 1\n",
      "[02/02/2023-19:14:16] [V] [TRT] Registered plugin creator - ::EfficientNMS_Explicit_TF_TRT version 1\n",
      "[02/02/2023-19:14:16] [V] [TRT] Registered plugin creator - ::EfficientNMS_Implicit_TF_TRT version 1\n",
      "[02/02/2023-19:14:16] [V] [TRT] Registered plugin creator - ::FlattenConcat_TRT version 1\n",
      "[02/02/2023-19:14:16] [V] [TRT] Registered plugin creator - ::GenerateDetection_TRT version 1\n",
      "[02/02/2023-19:14:16] [V] [TRT] Registered plugin creator - ::GridAnchor_TRT version 1\n",
      "[02/02/2023-19:14:16] [V] [TRT] Registered plugin creator - ::GridAnchorRect_TRT version 1\n",
      "[02/02/2023-19:14:16] [V] [TRT] Registered plugin creator - ::GroupNorm version 1\n",
      "[02/02/2023-19:14:16] [V] [TRT] Registered plugin creator - ::InstanceNormalization_TRT version 1\n",
      "[02/02/2023-19:14:16] [V] [TRT] Registered plugin creator - ::LayerNorm version 1\n",
      "[02/02/2023-19:14:16] [V] [TRT] Registered plugin creator - ::LReLU_TRT version 1\n",
      "[02/02/2023-19:14:16] [V] [TRT] Registered plugin creator - ::MultilevelCropAndResize_TRT version 1\n",
      "[02/02/2023-19:14:16] [V] [TRT] Registered plugin creator - ::MultilevelProposeROI_TRT version 1\n",
      "[02/02/2023-19:14:16] [V] [TRT] Registered plugin creator - ::MultiscaleDeformableAttnPlugin_TRT version 1\n",
      "[02/02/2023-19:14:16] [V] [TRT] Registered plugin creator - ::NMS_TRT version 1\n",
      "[02/02/2023-19:14:16] [V] [TRT] Registered plugin creator - ::NMSDynamic_TRT version 1\n",
      "[02/02/2023-19:14:16] [V] [TRT] Registered plugin creator - ::Normalize_TRT version 1\n",
      "[02/02/2023-19:14:16] [V] [TRT] Registered plugin creator - ::PillarScatterPlugin version 1\n",
      "[02/02/2023-19:14:16] [V] [TRT] Registered plugin creator - ::PriorBox_TRT version 1\n",
      "[02/02/2023-19:14:16] [V] [TRT] Registered plugin creator - ::ProposalLayer_TRT version 1\n",
      "[02/02/2023-19:14:16] [V] [TRT] Registered plugin creator - ::Proposal version 1\n",
      "[02/02/2023-19:14:16] [V] [TRT] Registered plugin creator - ::ProposalDynamic version 1\n",
      "[02/02/2023-19:14:16] [V] [TRT] Registered plugin creator - ::PyramidROIAlign_TRT version 1\n",
      "[02/02/2023-19:14:16] [V] [TRT] Registered plugin creator - ::Region_TRT version 1\n",
      "[02/02/2023-19:14:16] [V] [TRT] Registered plugin creator - ::Reorg_TRT version 1\n",
      "[02/02/2023-19:14:16] [V] [TRT] Registered plugin creator - ::ResizeNearest_TRT version 1\n",
      "[02/02/2023-19:14:16] [V] [TRT] Registered plugin creator - ::RPROI_TRT version 1\n",
      "[02/02/2023-19:14:16] [V] [TRT] Registered plugin creator - ::ROIAlign_TRT version 1\n",
      "[02/02/2023-19:14:16] [V] [TRT] Registered plugin creator - ::ScatterND version 1\n",
      "[02/02/2023-19:14:16] [V] [TRT] Registered plugin creator - ::SeqLen2Spatial version 1\n",
      "[02/02/2023-19:14:16] [V] [TRT] Registered plugin creator - ::SpecialSlice_TRT version 1\n",
      "[02/02/2023-19:14:16] [V] [TRT] Registered plugin creator - ::SplitGeLU version 1\n",
      "[02/02/2023-19:14:16] [V] [TRT] Registered plugin creator - ::Split version 1\n",
      "[02/02/2023-19:14:16] [V] [TRT] Registered plugin creator - ::VoxelGeneratorPlugin version 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02/02/2023-19:14:16] [I] [TRT] [MemUsageChange] Init CUDA: CPU +10, GPU +0, now: CPU 23, GPU 248 (MiB)\n",
      "[02/02/2023-19:14:16] [V] [TRT] Trying to load shared library libnvinfer_builder_resource.so.8.5.1\n",
      "[02/02/2023-19:14:16] [V] [TRT] Loaded shared library libnvinfer_builder_resource.so.8.5.1\n",
      "[02/02/2023-19:14:19] [I] [TRT] [MemUsageChange] Init builder kernel library: CPU +444, GPU +120, now: CPU 522, GPU 368 (MiB)\n",
      "[02/02/2023-19:14:19] [V] [TRT] CUDA lazy loading is enabled.\n",
      "[02/02/2023-19:14:19] [I] Start parsing network model\n",
      "[02/02/2023-19:14:19] [I] [TRT] ----------------------------------------------------------------\n",
      "[02/02/2023-19:14:19] [I] [TRT] Input filename:   /workspace/onnx/model.onnx\n",
      "[02/02/2023-19:14:19] [I] [TRT] ONNX IR version:  0.0.6\n",
      "[02/02/2023-19:14:19] [I] [TRT] Opset version:    11\n",
      "[02/02/2023-19:14:19] [I] [TRT] Producer name:    pytorch\n",
      "[02/02/2023-19:14:19] [I] [TRT] Producer version: 1.14.0\n",
      "[02/02/2023-19:14:19] [I] [TRT] Domain:           \n",
      "[02/02/2023-19:14:19] [I] [TRT] Model version:    0\n",
      "[02/02/2023-19:14:19] [I] [TRT] Doc string:       \n",
      "[02/02/2023-19:14:19] [I] [TRT] ----------------------------------------------------------------\n",
      "[02/02/2023-19:14:19] [V] [TRT] Plugin creator already registered - ::BatchTilePlugin_TRT version 1\n",
      "[02/02/2023-19:14:19] [V] [TRT] Plugin creator already registered - ::BatchedNMS_TRT version 1\n",
      "[02/02/2023-19:14:19] [V] [TRT] Plugin creator already registered - ::BatchedNMSDynamic_TRT version 1\n",
      "[02/02/2023-19:14:19] [V] [TRT] Plugin creator already registered - ::Clip_TRT version 1\n",
      "[02/02/2023-19:14:19] [V] [TRT] Plugin creator already registered - ::CoordConvAC version 1\n",
      "[02/02/2023-19:14:19] [V] [TRT] Plugin creator already registered - ::CropAndResize version 1\n",
      "[02/02/2023-19:14:19] [V] [TRT] Plugin creator already registered - ::CropAndResizeDynamic version 1\n",
      "[02/02/2023-19:14:19] [V] [TRT] Plugin creator already registered - ::DecodeBbox3DPlugin version 1\n",
      "[02/02/2023-19:14:19] [V] [TRT] Plugin creator already registered - ::DetectionLayer_TRT version 1\n",
      "[02/02/2023-19:14:19] [V] [TRT] Plugin creator already registered - ::EfficientNMS_TRT version 1\n",
      "[02/02/2023-19:14:19] [V] [TRT] Plugin creator already registered - ::EfficientNMS_ONNX_TRT version 1\n",
      "[02/02/2023-19:14:19] [V] [TRT] Plugin creator already registered - ::EfficientNMS_Explicit_TF_TRT version 1\n",
      "[02/02/2023-19:14:19] [V] [TRT] Plugin creator already registered - ::EfficientNMS_Implicit_TF_TRT version 1\n",
      "[02/02/2023-19:14:19] [V] [TRT] Plugin creator already registered - ::FlattenConcat_TRT version 1\n",
      "[02/02/2023-19:14:19] [V] [TRT] Plugin creator already registered - ::GenerateDetection_TRT version 1\n",
      "[02/02/2023-19:14:19] [V] [TRT] Plugin creator already registered - ::GridAnchor_TRT version 1\n",
      "[02/02/2023-19:14:19] [V] [TRT] Plugin creator already registered - ::GridAnchorRect_TRT version 1\n",
      "[02/02/2023-19:14:19] [V] [TRT] Plugin creator already registered - ::GroupNorm version 1\n",
      "[02/02/2023-19:14:19] [V] [TRT] Plugin creator already registered - ::InstanceNormalization_TRT version 1\n",
      "[02/02/2023-19:14:19] [V] [TRT] Plugin creator already registered - ::LayerNorm version 1\n",
      "[02/02/2023-19:14:19] [V] [TRT] Plugin creator already registered - ::LReLU_TRT version 1\n",
      "[02/02/2023-19:14:19] [V] [TRT] Plugin creator already registered - ::MultilevelCropAndResize_TRT version 1\n",
      "[02/02/2023-19:14:19] [V] [TRT] Plugin creator already registered - ::MultilevelProposeROI_TRT version 1\n",
      "[02/02/2023-19:14:19] [V] [TRT] Plugin creator already registered - ::MultiscaleDeformableAttnPlugin_TRT version 1\n",
      "[02/02/2023-19:14:19] [V] [TRT] Plugin creator already registered - ::NMS_TRT version 1\n",
      "[02/02/2023-19:14:19] [V] [TRT] Plugin creator already registered - ::NMSDynamic_TRT version 1\n",
      "[02/02/2023-19:14:19] [V] [TRT] Plugin creator already registered - ::Normalize_TRT version 1\n",
      "[02/02/2023-19:14:19] [V] [TRT] Plugin creator already registered - ::PillarScatterPlugin version 1\n",
      "[02/02/2023-19:14:19] [V] [TRT] Plugin creator already registered - ::PriorBox_TRT version 1\n",
      "[02/02/2023-19:14:19] [V] [TRT] Plugin creator already registered - ::ProposalLayer_TRT version 1\n",
      "[02/02/2023-19:14:19] [V] [TRT] Plugin creator already registered - ::Proposal version 1\n",
      "[02/02/2023-19:14:19] [V] [TRT] Plugin creator already registered - ::ProposalDynamic version 1\n",
      "[02/02/2023-19:14:19] [V] [TRT] Plugin creator already registered - ::PyramidROIAlign_TRT version 1\n",
      "[02/02/2023-19:14:19] [V] [TRT] Plugin creator already registered - ::Region_TRT version 1\n",
      "[02/02/2023-19:14:19] [V] [TRT] Plugin creator already registered - ::Reorg_TRT version 1\n",
      "[02/02/2023-19:14:19] [V] [TRT] Plugin creator already registered - ::ResizeNearest_TRT version 1\n",
      "[02/02/2023-19:14:19] [V] [TRT] Plugin creator already registered - ::RPROI_TRT version 1\n",
      "[02/02/2023-19:14:19] [V] [TRT] Plugin creator already registered - ::ROIAlign_TRT version 1\n",
      "[02/02/2023-19:14:19] [V] [TRT] Plugin creator already registered - ::ScatterND version 1\n",
      "[02/02/2023-19:14:19] [V] [TRT] Plugin creator already registered - ::SeqLen2Spatial version 1\n",
      "[02/02/2023-19:14:19] [V] [TRT] Plugin creator already registered - ::SpecialSlice_TRT version 1\n",
      "[02/02/2023-19:14:19] [V] [TRT] Plugin creator already registered - ::SplitGeLU version 1\n",
      "[02/02/2023-19:14:19] [V] [TRT] Plugin creator already registered - ::Split version 1\n",
      "[02/02/2023-19:14:19] [V] [TRT] Plugin creator already registered - ::VoxelGeneratorPlugin version 1\n",
      "[02/02/2023-19:14:19] [V] [TRT] Adding network input: input_ids with dtype: int32, dimensions: (-1, -1)\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: input_ids for ONNX tensor: input_ids\n",
      "[02/02/2023-19:14:19] [V] [TRT] Adding network input: attention_mask with dtype: int32, dimensions: (-1, -1)\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: attention_mask for ONNX tensor: attention_mask\n",
      "[02/02/2023-19:14:19] [V] [TRT] Adding network input: token_type_ids with dtype: int32, dimensions: (-1, -1)\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: token_type_ids for ONNX tensor: token_type_ids\n",
      "[02/02/2023-19:14:19] [V] [TRT] Importing initializer: bert.embeddings.position_ids\n",
      "[02/02/2023-19:14:19] [W] [TRT] parsers/onnx/onnx2trt_utils.cpp:375: Your ONNX model has been generated with INT64 weights, while TensorRT does not natively support INT64. Attempting to cast down to INT32.\n",
      "[02/02/2023-19:14:19] [V] [TRT] Importing initializer: bert.embeddings.word_embeddings.weight\n",
      "[02/02/2023-19:14:19] [V] [TRT] Importing initializer: bert.embeddings.position_embeddings.weight\n",
      "[02/02/2023-19:14:19] [V] [TRT] Importing initializer: bert.embeddings.token_type_embeddings.weight\n",
      "[02/02/2023-19:14:19] [V] [TRT] Importing initializer: bert.embeddings.LayerNorm.weight\n",
      "[02/02/2023-19:14:19] [V] [TRT] Importing initializer: bert.embeddings.LayerNorm.bias\n",
      "[02/02/2023-19:14:19] [V] [TRT] Importing initializer: bert.encoder.layer.0.attention.self.query.bias\n",
      "[02/02/2023-19:14:19] [V] [TRT] Importing initializer: bert.encoder.layer.0.attention.self.key.bias\n",
      "[02/02/2023-19:14:19] [V] [TRT] Importing initializer: bert.encoder.layer.0.attention.self.value.bias\n",
      "[02/02/2023-19:14:19] [V] [TRT] Importing initializer: bert.encoder.layer.0.attention.output.dense.bias\n",
      "[02/02/2023-19:14:19] [V] [TRT] Importing initializer: bert.encoder.layer.0.attention.output.LayerNorm.weight\n",
      "[02/02/2023-19:14:19] [V] [TRT] Importing initializer: bert.encoder.layer.0.attention.output.LayerNorm.bias\n",
      "[02/02/2023-19:14:19] [V] [TRT] Importing initializer: bert.encoder.layer.0.intermediate.dense.bias\n",
      "[02/02/2023-19:14:19] [V] [TRT] Importing initializer: bert.encoder.layer.0.output.dense.bias\n",
      "[02/02/2023-19:14:19] [V] [TRT] Importing initializer: bert.encoder.layer.0.output.LayerNorm.weight\n",
      "[02/02/2023-19:14:19] [V] [TRT] Importing initializer: bert.encoder.layer.0.output.LayerNorm.bias\n",
      "[02/02/2023-19:14:19] [V] [TRT] Importing initializer: bert.encoder.layer.1.attention.self.query.bias\n",
      "[02/02/2023-19:14:19] [V] [TRT] Importing initializer: bert.encoder.layer.1.attention.self.key.bias\n",
      "[02/02/2023-19:14:19] [V] [TRT] Importing initializer: bert.encoder.layer.1.attention.self.value.bias\n",
      "[02/02/2023-19:14:19] [V] [TRT] Importing initializer: bert.encoder.layer.1.attention.output.dense.bias\n",
      "[02/02/2023-19:14:19] [V] [TRT] Importing initializer: bert.encoder.layer.1.attention.output.LayerNorm.weight\n",
      "[02/02/2023-19:14:19] [V] [TRT] Importing initializer: bert.encoder.layer.1.attention.output.LayerNorm.bias\n",
      "[02/02/2023-19:14:19] [V] [TRT] Importing initializer: bert.encoder.layer.1.intermediate.dense.bias\n",
      "[02/02/2023-19:14:19] [V] [TRT] Importing initializer: bert.encoder.layer.1.output.dense.bias\n",
      "[02/02/2023-19:14:19] [V] [TRT] Importing initializer: bert.encoder.layer.1.output.LayerNorm.weight\n",
      "[02/02/2023-19:14:19] [V] [TRT] Importing initializer: bert.encoder.layer.1.output.LayerNorm.bias\n",
      "[02/02/2023-19:14:19] [V] [TRT] Importing initializer: bert.encoder.layer.2.attention.self.query.bias\n",
      "[02/02/2023-19:14:19] [V] [TRT] Importing initializer: bert.encoder.layer.2.attention.self.key.bias\n",
      "[02/02/2023-19:14:19] [V] [TRT] Importing initializer: bert.encoder.layer.2.attention.self.value.bias\n",
      "[02/02/2023-19:14:19] [V] [TRT] Importing initializer: bert.encoder.layer.2.attention.output.dense.bias\n",
      "[02/02/2023-19:14:19] [V] [TRT] Importing initializer: bert.encoder.layer.2.attention.output.LayerNorm.weight\n",
      "[02/02/2023-19:14:19] [V] [TRT] Importing initializer: bert.encoder.layer.2.attention.output.LayerNorm.bias\n",
      "[02/02/2023-19:14:19] [V] [TRT] Importing initializer: bert.encoder.layer.2.intermediate.dense.bias\n",
      "[02/02/2023-19:14:19] [V] [TRT] Importing initializer: bert.encoder.layer.2.output.dense.bias\n",
      "[02/02/2023-19:14:19] [V] [TRT] Importing initializer: bert.encoder.layer.2.output.LayerNorm.weight\n",
      "[02/02/2023-19:14:19] [V] [TRT] Importing initializer: bert.encoder.layer.2.output.LayerNorm.bias\n",
      "[02/02/2023-19:14:19] [V] [TRT] Importing initializer: bert.encoder.layer.3.attention.self.query.bias\n",
      "[02/02/2023-19:14:19] [V] [TRT] Importing initializer: bert.encoder.layer.3.attention.self.key.bias\n",
      "[02/02/2023-19:14:19] [V] [TRT] Importing initializer: bert.encoder.layer.3.attention.self.value.bias\n",
      "[02/02/2023-19:14:19] [V] [TRT] Importing initializer: bert.encoder.layer.3.attention.output.dense.bias\n",
      "[02/02/2023-19:14:19] [V] [TRT] Importing initializer: bert.encoder.layer.3.attention.output.LayerNorm.weight\n",
      "[02/02/2023-19:14:19] [V] [TRT] Importing initializer: bert.encoder.layer.3.attention.output.LayerNorm.bias\n",
      "[02/02/2023-19:14:19] [V] [TRT] Importing initializer: bert.encoder.layer.3.intermediate.dense.bias\n",
      "[02/02/2023-19:14:19] [V] [TRT] Importing initializer: bert.encoder.layer.3.output.dense.bias\n",
      "[02/02/2023-19:14:19] [V] [TRT] Importing initializer: bert.encoder.layer.3.output.LayerNorm.weight\n",
      "[02/02/2023-19:14:19] [V] [TRT] Importing initializer: bert.encoder.layer.3.output.LayerNorm.bias\n",
      "[02/02/2023-19:14:19] [V] [TRT] Importing initializer: bert.encoder.layer.4.attention.self.query.bias\n",
      "[02/02/2023-19:14:19] [V] [TRT] Importing initializer: bert.encoder.layer.4.attention.self.key.bias\n",
      "[02/02/2023-19:14:19] [V] [TRT] Importing initializer: bert.encoder.layer.4.attention.self.value.bias\n",
      "[02/02/2023-19:14:19] [V] [TRT] Importing initializer: bert.encoder.layer.4.attention.output.dense.bias\n",
      "[02/02/2023-19:14:19] [V] [TRT] Importing initializer: bert.encoder.layer.4.attention.output.LayerNorm.weight\n",
      "[02/02/2023-19:14:19] [V] [TRT] Importing initializer: bert.encoder.layer.4.attention.output.LayerNorm.bias\n",
      "[02/02/2023-19:14:19] [V] [TRT] Importing initializer: bert.encoder.layer.4.intermediate.dense.bias\n",
      "[02/02/2023-19:14:19] [V] [TRT] Importing initializer: bert.encoder.layer.4.output.dense.bias\n",
      "[02/02/2023-19:14:19] [V] [TRT] Importing initializer: bert.encoder.layer.4.output.LayerNorm.weight\n",
      "[02/02/2023-19:14:19] [V] [TRT] Importing initializer: bert.encoder.layer.4.output.LayerNorm.bias\n",
      "[02/02/2023-19:14:19] [V] [TRT] Importing initializer: bert.encoder.layer.5.attention.self.query.bias\n",
      "[02/02/2023-19:14:19] [V] [TRT] Importing initializer: bert.encoder.layer.5.attention.self.key.bias\n",
      "[02/02/2023-19:14:19] [V] [TRT] Importing initializer: bert.encoder.layer.5.attention.self.value.bias\n",
      "[02/02/2023-19:14:19] [V] [TRT] Importing initializer: bert.encoder.layer.5.attention.output.dense.bias\n",
      "[02/02/2023-19:14:19] [V] [TRT] Importing initializer: bert.encoder.layer.5.attention.output.LayerNorm.weight\n",
      "[02/02/2023-19:14:19] [V] [TRT] Importing initializer: bert.encoder.layer.5.attention.output.LayerNorm.bias\n",
      "[02/02/2023-19:14:19] [V] [TRT] Importing initializer: bert.encoder.layer.5.intermediate.dense.bias\n",
      "[02/02/2023-19:14:19] [V] [TRT] Importing initializer: bert.encoder.layer.5.output.dense.bias\n",
      "[02/02/2023-19:14:19] [V] [TRT] Importing initializer: bert.encoder.layer.5.output.LayerNorm.weight\n",
      "[02/02/2023-19:14:19] [V] [TRT] Importing initializer: bert.encoder.layer.5.output.LayerNorm.bias\n",
      "[02/02/2023-19:14:19] [V] [TRT] Importing initializer: bert.pooler.dense.weight\n",
      "[02/02/2023-19:14:19] [V] [TRT] Importing initializer: bert.pooler.dense.bias\n",
      "[02/02/2023-19:14:19] [V] [TRT] Importing initializer: classifier.weight\n",
      "[02/02/2023-19:14:19] [V] [TRT] Importing initializer: classifier.bias\n",
      "[02/02/2023-19:14:19] [V] [TRT] Importing initializer: onnx::MatMul_793\n",
      "[02/02/2023-19:14:19] [V] [TRT] Importing initializer: onnx::MatMul_794\n",
      "[02/02/2023-19:14:19] [V] [TRT] Importing initializer: onnx::MatMul_797\n",
      "[02/02/2023-19:14:19] [V] [TRT] Importing initializer: onnx::MatMul_803\n",
      "[02/02/2023-19:14:19] [V] [TRT] Importing initializer: onnx::MatMul_804\n",
      "[02/02/2023-19:14:19] [V] [TRT] Importing initializer: onnx::MatMul_805\n",
      "[02/02/2023-19:14:19] [V] [TRT] Importing initializer: onnx::MatMul_806\n",
      "[02/02/2023-19:14:19] [V] [TRT] Importing initializer: onnx::MatMul_807\n",
      "[02/02/2023-19:14:19] [V] [TRT] Importing initializer: onnx::MatMul_810\n",
      "[02/02/2023-19:14:19] [V] [TRT] Importing initializer: onnx::MatMul_816\n",
      "[02/02/2023-19:14:19] [V] [TRT] Importing initializer: onnx::MatMul_817\n",
      "[02/02/2023-19:14:19] [V] [TRT] Importing initializer: onnx::MatMul_818\n",
      "[02/02/2023-19:14:19] [V] [TRT] Importing initializer: onnx::MatMul_819\n",
      "[02/02/2023-19:14:19] [V] [TRT] Importing initializer: onnx::MatMul_820\n",
      "[02/02/2023-19:14:19] [V] [TRT] Importing initializer: onnx::MatMul_823\n",
      "[02/02/2023-19:14:19] [V] [TRT] Importing initializer: onnx::MatMul_829\n",
      "[02/02/2023-19:14:19] [V] [TRT] Importing initializer: onnx::MatMul_830\n",
      "[02/02/2023-19:14:19] [V] [TRT] Importing initializer: onnx::MatMul_831\n",
      "[02/02/2023-19:14:19] [V] [TRT] Importing initializer: onnx::MatMul_832\n",
      "[02/02/2023-19:14:19] [V] [TRT] Importing initializer: onnx::MatMul_833\n",
      "[02/02/2023-19:14:19] [V] [TRT] Importing initializer: onnx::MatMul_836\n",
      "[02/02/2023-19:14:19] [V] [TRT] Importing initializer: onnx::MatMul_842\n",
      "[02/02/2023-19:14:19] [V] [TRT] Importing initializer: onnx::MatMul_843\n",
      "[02/02/2023-19:14:19] [V] [TRT] Importing initializer: onnx::MatMul_844\n",
      "[02/02/2023-19:14:19] [V] [TRT] Importing initializer: onnx::MatMul_845\n",
      "[02/02/2023-19:14:19] [V] [TRT] Importing initializer: onnx::MatMul_846\n",
      "[02/02/2023-19:14:19] [V] [TRT] Importing initializer: onnx::MatMul_849\n",
      "[02/02/2023-19:14:19] [V] [TRT] Importing initializer: onnx::MatMul_855\n",
      "[02/02/2023-19:14:19] [V] [TRT] Importing initializer: onnx::MatMul_856\n",
      "[02/02/2023-19:14:19] [V] [TRT] Importing initializer: onnx::MatMul_857\n",
      "[02/02/2023-19:14:19] [V] [TRT] Importing initializer: onnx::MatMul_858\n",
      "[02/02/2023-19:14:19] [V] [TRT] Importing initializer: onnx::MatMul_859\n",
      "[02/02/2023-19:14:19] [V] [TRT] Importing initializer: onnx::MatMul_862\n",
      "[02/02/2023-19:14:19] [V] [TRT] Importing initializer: onnx::MatMul_868\n",
      "[02/02/2023-19:14:19] [V] [TRT] Importing initializer: onnx::MatMul_869\n",
      "[02/02/2023-19:14:19] [V] [TRT] Importing initializer: onnx::MatMul_870\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/Constant [Constant]\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/Constant [Constant] inputs: \n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/Constant [Constant] outputs: [/bert/Constant_output_0 -> ()[INT32]], \n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/Unsqueeze [Unsqueeze]\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: attention_mask\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/Unsqueeze [Unsqueeze] inputs: [attention_mask -> (-1, -1)[INT32]], \n",
      "[02/02/2023-19:14:19] [V] [TRT] Original shape: (_, _), unsqueezing to: (_, _, _)\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/Unsqueeze for ONNX node: /bert/Unsqueeze\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/Unsqueeze_output_0 for ONNX tensor: /bert/Unsqueeze_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/Unsqueeze [Unsqueeze] outputs: [/bert/Unsqueeze_output_0 -> (-1, 1, -1)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/Unsqueeze_1 [Unsqueeze]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/Unsqueeze_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/Unsqueeze_1 [Unsqueeze] inputs: [/bert/Unsqueeze_output_0 -> (-1, 1, -1)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Original shape: (_, 1, _), unsqueezing to: (_, _, _, _)\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/Unsqueeze_1 for ONNX node: /bert/Unsqueeze_1\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/Unsqueeze_1_output_0 for ONNX tensor: /bert/Unsqueeze_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/Unsqueeze_1 [Unsqueeze] outputs: [/bert/Unsqueeze_1_output_0 -> (-1, 1, 1, -1)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/Cast [Cast]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/Unsqueeze_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/Cast [Cast] inputs: [/bert/Unsqueeze_1_output_0 -> (-1, 1, 1, -1)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Casting to type: float32\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/Cast for ONNX node: /bert/Cast\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/Cast_output_0 for ONNX tensor: /bert/Cast_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/Cast [Cast] outputs: [/bert/Cast_output_0 -> (-1, 1, 1, -1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/Constant_1 [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/Constant_1 [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/Constant_1 [Constant] outputs: [/bert/Constant_1_output_0 -> ()[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/Sub [Sub]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/Constant_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/Cast_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/Sub [Sub] inputs: [/bert/Constant_1_output_0 -> ()[FLOAT]], [/bert/Cast_output_0 -> (-1, 1, 1, -1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/Constant_1_output_0 for ONNX node: /bert/Constant_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/Sub for ONNX node: /bert/Sub\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/Sub_output_0 for ONNX tensor: /bert/Sub_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/Sub [Sub] outputs: [/bert/Sub_output_0 -> (-1, 1, 1, -1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/Constant_2 [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/Constant_2 [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/Constant_2 [Constant] outputs: [/bert/Constant_2_output_0 -> ()[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/Mul [Mul]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/Sub_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/Constant_2_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/Mul [Mul] inputs: [/bert/Sub_output_0 -> (-1, 1, 1, -1)[FLOAT]], [/bert/Constant_2_output_0 -> ()[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/Constant_2_output_0 for ONNX node: /bert/Constant_2_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/Mul for ONNX node: /bert/Mul\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/Mul_output_0 for ONNX tensor: /bert/Mul_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/Mul [Mul] outputs: [/bert/Mul_output_0 -> (-1, 1, 1, -1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/embeddings/Shape [Shape]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: input_ids\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/embeddings/Shape [Shape] inputs: [input_ids -> (-1, -1)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/embeddings/Shape for ONNX node: /bert/embeddings/Shape\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/embeddings/Shape_output_0 for ONNX tensor: /bert/embeddings/Shape_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/embeddings/Shape [Shape] outputs: [/bert/embeddings/Shape_output_0 -> (2)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/embeddings/Constant [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/embeddings/Constant [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/embeddings/Constant [Constant] outputs: [/bert/embeddings/Constant_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/embeddings/Gather [Gather]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/embeddings/Shape_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/embeddings/Constant_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/embeddings/Gather [Gather] inputs: [/bert/embeddings/Shape_output_0 -> (2)[INT32]], [/bert/embeddings/Constant_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/embeddings/Constant_output_0 for ONNX node: /bert/embeddings/Constant_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Using Gather axis: 0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/embeddings/Gather for ONNX node: /bert/embeddings/Gather\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/embeddings/Gather_output_0 for ONNX tensor: /bert/embeddings/Gather_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/embeddings/Gather [Gather] outputs: [/bert/embeddings/Gather_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/embeddings/Constant_1 [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/embeddings/Constant_1 [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/embeddings/Constant_1 [Constant] outputs: [/bert/embeddings/Constant_1_output_0 -> (1)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/embeddings/Unsqueeze [Unsqueeze]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/embeddings/Gather_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/embeddings/Unsqueeze [Unsqueeze] inputs: [/bert/embeddings/Gather_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Original shape: (), unsqueezing to: (1,)\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/embeddings/Unsqueeze for ONNX node: /bert/embeddings/Unsqueeze\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/embeddings/Unsqueeze_output_0 for ONNX tensor: /bert/embeddings/Unsqueeze_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/embeddings/Unsqueeze [Unsqueeze] outputs: [/bert/embeddings/Unsqueeze_output_0 -> (1)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/embeddings/Constant_2 [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/embeddings/Constant_2 [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/embeddings/Constant_2 [Constant] outputs: [/bert/embeddings/Constant_2_output_0 -> (1)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/embeddings/Constant_3 [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/embeddings/Constant_3 [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/embeddings/Constant_3 [Constant] outputs: [/bert/embeddings/Constant_3_output_0 -> (1)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/embeddings/Slice [Slice]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: bert.embeddings.position_ids\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/embeddings/Constant_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/embeddings/Unsqueeze_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/embeddings/Constant_2_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/embeddings/Constant_3_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/embeddings/Slice [Slice] inputs: [bert.embeddings.position_ids -> (1, 512)[INT32]], [/bert/embeddings/Constant_1_output_0 -> (1)[INT32]], [/bert/embeddings/Unsqueeze_output_0 -> (1)[INT32]], [/bert/embeddings/Constant_2_output_0 -> (1)[INT32]], [/bert/embeddings/Constant_3_output_0 -> (1)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: bert.embeddings.position_ids for ONNX node: bert.embeddings.position_ids\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/embeddings/Slice for ONNX node: /bert/embeddings/Slice\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/embeddings/Slice_output_0 for ONNX tensor: /bert/embeddings/Slice_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/embeddings/Slice [Slice] outputs: [/bert/embeddings/Slice_output_0 -> (1, -1)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/embeddings/word_embeddings/Gather [Gather]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: bert.embeddings.word_embeddings.weight\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: input_ids\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/embeddings/word_embeddings/Gather [Gather] inputs: [bert.embeddings.word_embeddings.weight -> (30522, 256)[FLOAT]], [input_ids -> (-1, -1)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: bert.embeddings.word_embeddings.weight for ONNX node: bert.embeddings.word_embeddings.weight\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Using Gather axis: 0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/embeddings/word_embeddings/Gather for ONNX node: /bert/embeddings/word_embeddings/Gather\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/embeddings/word_embeddings/Gather_output_0 for ONNX tensor: /bert/embeddings/word_embeddings/Gather_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/embeddings/word_embeddings/Gather [Gather] outputs: [/bert/embeddings/word_embeddings/Gather_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/embeddings/token_type_embeddings/Gather [Gather]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: bert.embeddings.token_type_embeddings.weight\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: token_type_ids\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/embeddings/token_type_embeddings/Gather [Gather] inputs: [bert.embeddings.token_type_embeddings.weight -> (2, 256)[FLOAT]], [token_type_ids -> (-1, -1)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: bert.embeddings.token_type_embeddings.weight for ONNX node: bert.embeddings.token_type_embeddings.weight\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Using Gather axis: 0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/embeddings/token_type_embeddings/Gather for ONNX node: /bert/embeddings/token_type_embeddings/Gather\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/embeddings/token_type_embeddings/Gather_output_0 for ONNX tensor: /bert/embeddings/token_type_embeddings/Gather_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/embeddings/token_type_embeddings/Gather [Gather] outputs: [/bert/embeddings/token_type_embeddings/Gather_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/embeddings/Add [Add]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/embeddings/word_embeddings/Gather_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/embeddings/token_type_embeddings/Gather_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/embeddings/Add [Add] inputs: [/bert/embeddings/word_embeddings/Gather_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/embeddings/token_type_embeddings/Gather_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/embeddings/Add for ONNX node: /bert/embeddings/Add\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/embeddings/Add_output_0 for ONNX tensor: /bert/embeddings/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/embeddings/Add [Add] outputs: [/bert/embeddings/Add_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/embeddings/position_embeddings/Gather [Gather]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: bert.embeddings.position_embeddings.weight\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/embeddings/Slice_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/embeddings/position_embeddings/Gather [Gather] inputs: [bert.embeddings.position_embeddings.weight -> (512, 256)[FLOAT]], [/bert/embeddings/Slice_output_0 -> (1, -1)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: bert.embeddings.position_embeddings.weight for ONNX node: bert.embeddings.position_embeddings.weight\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Using Gather axis: 0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/embeddings/position_embeddings/Gather for ONNX node: /bert/embeddings/position_embeddings/Gather\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/embeddings/position_embeddings/Gather_output_0 for ONNX tensor: /bert/embeddings/position_embeddings/Gather_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/embeddings/position_embeddings/Gather [Gather] outputs: [/bert/embeddings/position_embeddings/Gather_output_0 -> (1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/embeddings/Add_1 [Add]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/embeddings/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/embeddings/position_embeddings/Gather_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/embeddings/Add_1 [Add] inputs: [/bert/embeddings/Add_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/embeddings/position_embeddings/Gather_output_0 -> (1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/embeddings/Add_1 for ONNX node: /bert/embeddings/Add_1\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/embeddings/Add_1_output_0 for ONNX tensor: /bert/embeddings/Add_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/embeddings/Add_1 [Add] outputs: [/bert/embeddings/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/embeddings/LayerNorm/ReduceMean [ReduceMean]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/embeddings/Add_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/embeddings/LayerNorm/ReduceMean [ReduceMean] inputs: [/bert/embeddings/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/embeddings/LayerNorm/ReduceMean for ONNX node: /bert/embeddings/LayerNorm/ReduceMean\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/embeddings/LayerNorm/ReduceMean_output_0 for ONNX tensor: /bert/embeddings/LayerNorm/ReduceMean_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/embeddings/LayerNorm/ReduceMean [ReduceMean] outputs: [/bert/embeddings/LayerNorm/ReduceMean_output_0 -> (-1, -1, 1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/embeddings/LayerNorm/Sub [Sub]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/embeddings/Add_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/embeddings/LayerNorm/ReduceMean_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/embeddings/LayerNorm/Sub [Sub] inputs: [/bert/embeddings/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/embeddings/LayerNorm/ReduceMean_output_0 -> (-1, -1, 1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/embeddings/LayerNorm/Sub for ONNX node: /bert/embeddings/LayerNorm/Sub\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/embeddings/LayerNorm/Sub_output_0 for ONNX tensor: /bert/embeddings/LayerNorm/Sub_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/embeddings/LayerNorm/Sub [Sub] outputs: [/bert/embeddings/LayerNorm/Sub_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/embeddings/LayerNorm/Constant [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/embeddings/LayerNorm/Constant [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/embeddings/LayerNorm/Constant [Constant] outputs: [/bert/embeddings/LayerNorm/Constant_output_0 -> ()[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/embeddings/LayerNorm/Pow [Pow]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/embeddings/LayerNorm/Sub_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/embeddings/LayerNorm/Constant_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/embeddings/LayerNorm/Pow [Pow] inputs: [/bert/embeddings/LayerNorm/Sub_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/embeddings/LayerNorm/Constant_output_0 -> ()[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/embeddings/LayerNorm/Constant_output_0 for ONNX node: /bert/embeddings/LayerNorm/Constant_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/embeddings/LayerNorm/Pow for ONNX node: /bert/embeddings/LayerNorm/Pow\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/embeddings/LayerNorm/Pow_output_0 for ONNX tensor: /bert/embeddings/LayerNorm/Pow_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/embeddings/LayerNorm/Pow [Pow] outputs: [/bert/embeddings/LayerNorm/Pow_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/embeddings/LayerNorm/ReduceMean_1 [ReduceMean]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/embeddings/LayerNorm/Pow_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/embeddings/LayerNorm/ReduceMean_1 [ReduceMean] inputs: [/bert/embeddings/LayerNorm/Pow_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/embeddings/LayerNorm/ReduceMean_1 for ONNX node: /bert/embeddings/LayerNorm/ReduceMean_1\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/embeddings/LayerNorm/ReduceMean_1_output_0 for ONNX tensor: /bert/embeddings/LayerNorm/ReduceMean_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/embeddings/LayerNorm/ReduceMean_1 [ReduceMean] outputs: [/bert/embeddings/LayerNorm/ReduceMean_1_output_0 -> (-1, -1, 1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/embeddings/LayerNorm/Constant_1 [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/embeddings/LayerNorm/Constant_1 [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/embeddings/LayerNorm/Constant_1 [Constant] outputs: [/bert/embeddings/LayerNorm/Constant_1_output_0 -> ()[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/embeddings/LayerNorm/Add [Add]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/embeddings/LayerNorm/ReduceMean_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/embeddings/LayerNorm/Constant_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/embeddings/LayerNorm/Add [Add] inputs: [/bert/embeddings/LayerNorm/ReduceMean_1_output_0 -> (-1, -1, 1)[FLOAT]], [/bert/embeddings/LayerNorm/Constant_1_output_0 -> ()[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/embeddings/LayerNorm/Constant_1_output_0 for ONNX node: /bert/embeddings/LayerNorm/Constant_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/embeddings/LayerNorm/Add for ONNX node: /bert/embeddings/LayerNorm/Add\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/embeddings/LayerNorm/Add_output_0 for ONNX tensor: /bert/embeddings/LayerNorm/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/embeddings/LayerNorm/Add [Add] outputs: [/bert/embeddings/LayerNorm/Add_output_0 -> (-1, -1, 1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/embeddings/LayerNorm/Sqrt [Sqrt]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/embeddings/LayerNorm/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/embeddings/LayerNorm/Sqrt [Sqrt] inputs: [/bert/embeddings/LayerNorm/Add_output_0 -> (-1, -1, 1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/embeddings/LayerNorm/Sqrt for ONNX node: /bert/embeddings/LayerNorm/Sqrt\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/embeddings/LayerNorm/Sqrt_output_0 for ONNX tensor: /bert/embeddings/LayerNorm/Sqrt_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/embeddings/LayerNorm/Sqrt [Sqrt] outputs: [/bert/embeddings/LayerNorm/Sqrt_output_0 -> (-1, -1, 1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/embeddings/LayerNorm/Div [Div]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/embeddings/LayerNorm/Sub_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/embeddings/LayerNorm/Sqrt_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/embeddings/LayerNorm/Div [Div] inputs: [/bert/embeddings/LayerNorm/Sub_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/embeddings/LayerNorm/Sqrt_output_0 -> (-1, -1, 1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/embeddings/LayerNorm/Div for ONNX node: /bert/embeddings/LayerNorm/Div\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/embeddings/LayerNorm/Div_output_0 for ONNX tensor: /bert/embeddings/LayerNorm/Div_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/embeddings/LayerNorm/Div [Div] outputs: [/bert/embeddings/LayerNorm/Div_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/embeddings/LayerNorm/Mul [Mul]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/embeddings/LayerNorm/Div_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: bert.embeddings.LayerNorm.weight\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/embeddings/LayerNorm/Mul [Mul] inputs: [/bert/embeddings/LayerNorm/Div_output_0 -> (-1, -1, 256)[FLOAT]], [bert.embeddings.LayerNorm.weight -> (256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: bert.embeddings.LayerNorm.weight for ONNX node: bert.embeddings.LayerNorm.weight\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/embeddings/LayerNorm/Mul for ONNX node: /bert/embeddings/LayerNorm/Mul\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/embeddings/LayerNorm/Mul_output_0 for ONNX tensor: /bert/embeddings/LayerNorm/Mul_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/embeddings/LayerNorm/Mul [Mul] outputs: [/bert/embeddings/LayerNorm/Mul_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/embeddings/LayerNorm/Add_1 [Add]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/embeddings/LayerNorm/Mul_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: bert.embeddings.LayerNorm.bias\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/embeddings/LayerNorm/Add_1 [Add] inputs: [/bert/embeddings/LayerNorm/Mul_output_0 -> (-1, -1, 256)[FLOAT]], [bert.embeddings.LayerNorm.bias -> (256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: bert.embeddings.LayerNorm.bias for ONNX node: bert.embeddings.LayerNorm.bias\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/embeddings/LayerNorm/Add_1 for ONNX node: /bert/embeddings/LayerNorm/Add_1\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/embeddings/LayerNorm/Add_1_output_0 for ONNX tensor: /bert/embeddings/LayerNorm/Add_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/embeddings/LayerNorm/Add_1 [Add] outputs: [/bert/embeddings/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/query/MatMul [MatMul]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/embeddings/LayerNorm/Add_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: onnx::MatMul_793\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/self/query/MatMul [MatMul] inputs: [/bert/embeddings/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], [onnx::MatMul_793 -> (256, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: onnx::MatMul_793 for ONNX node: onnx::MatMul_793\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/query/MatMul for ONNX node: /bert/encoder/layer.0/attention/self/query/MatMul\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/query/MatMul_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/query/MatMul_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/self/query/MatMul [MatMul] outputs: [/bert/encoder/layer.0/attention/self/query/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/query/Add [Add]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: bert.encoder.layer.0.attention.self.query.bias\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/query/MatMul_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/self/query/Add [Add] inputs: [bert.encoder.layer.0.attention.self.query.bias -> (256)[FLOAT]], [/bert/encoder/layer.0/attention/self/query/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: bert.encoder.layer.0.attention.self.query.bias for ONNX node: bert.encoder.layer.0.attention.self.query.bias\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/query/Add for ONNX node: /bert/encoder/layer.0/attention/self/query/Add\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/query/Add_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/query/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/self/query/Add [Add] outputs: [/bert/encoder/layer.0/attention/self/query/Add_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/key/MatMul [MatMul]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/embeddings/LayerNorm/Add_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: onnx::MatMul_794\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/self/key/MatMul [MatMul] inputs: [/bert/embeddings/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], [onnx::MatMul_794 -> (256, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: onnx::MatMul_794 for ONNX node: onnx::MatMul_794\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/key/MatMul for ONNX node: /bert/encoder/layer.0/attention/self/key/MatMul\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/key/MatMul_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/key/MatMul_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/self/key/MatMul [MatMul] outputs: [/bert/encoder/layer.0/attention/self/key/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/key/Add [Add]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: bert.encoder.layer.0.attention.self.key.bias\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/key/MatMul_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/self/key/Add [Add] inputs: [bert.encoder.layer.0.attention.self.key.bias -> (256)[FLOAT]], [/bert/encoder/layer.0/attention/self/key/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: bert.encoder.layer.0.attention.self.key.bias for ONNX node: bert.encoder.layer.0.attention.self.key.bias\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/key/Add for ONNX node: /bert/encoder/layer.0/attention/self/key/Add\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/key/Add_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/key/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/self/key/Add [Add] outputs: [/bert/encoder/layer.0/attention/self/key/Add_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Shape [Shape]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/key/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/self/Shape [Shape] inputs: [/bert/encoder/layer.0/attention/self/key/Add_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Shape for ONNX node: /bert/encoder/layer.0/attention/self/Shape\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/Shape_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/Shape_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/self/Shape [Shape] outputs: [/bert/encoder/layer.0/attention/self/Shape_output_0 -> (3)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Constant [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/self/Constant [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/self/Constant [Constant] outputs: [/bert/encoder/layer.0/attention/self/Constant_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Gather [Gather]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Shape_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Constant_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/self/Gather [Gather] inputs: [/bert/encoder/layer.0/attention/self/Shape_output_0 -> (3)[INT32]], [/bert/encoder/layer.0/attention/self/Constant_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Constant_output_0 for ONNX node: /bert/encoder/layer.0/attention/self/Constant_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Using Gather axis: 0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Gather for ONNX node: /bert/encoder/layer.0/attention/self/Gather\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/Gather_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/Gather_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/self/Gather [Gather] outputs: [/bert/encoder/layer.0/attention/self/Gather_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Shape_1 [Shape]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/key/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/self/Shape_1 [Shape] inputs: [/bert/encoder/layer.0/attention/self/key/Add_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Shape_1 for ONNX node: /bert/encoder/layer.0/attention/self/Shape_1\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/Shape_1_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/Shape_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/self/Shape_1 [Shape] outputs: [/bert/encoder/layer.0/attention/self/Shape_1_output_0 -> (3)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Constant_1 [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/self/Constant_1 [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/self/Constant_1 [Constant] outputs: [/bert/encoder/layer.0/attention/self/Constant_1_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Gather_1 [Gather]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Shape_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Constant_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/self/Gather_1 [Gather] inputs: [/bert/encoder/layer.0/attention/self/Shape_1_output_0 -> (3)[INT32]], [/bert/encoder/layer.0/attention/self/Constant_1_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Constant_1_output_0 for ONNX node: /bert/encoder/layer.0/attention/self/Constant_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Using Gather axis: 0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Gather_1 for ONNX node: /bert/encoder/layer.0/attention/self/Gather_1\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/Gather_1_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/Gather_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/self/Gather_1 [Gather] outputs: [/bert/encoder/layer.0/attention/self/Gather_1_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Unsqueeze [Unsqueeze]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Gather_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/self/Unsqueeze [Unsqueeze] inputs: [/bert/encoder/layer.0/attention/self/Gather_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Original shape: (), unsqueezing to: (1,)\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Unsqueeze for ONNX node: /bert/encoder/layer.0/attention/self/Unsqueeze\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/Unsqueeze_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/Unsqueeze_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/self/Unsqueeze [Unsqueeze] outputs: [/bert/encoder/layer.0/attention/self/Unsqueeze_output_0 -> (1)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Unsqueeze_1 [Unsqueeze]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Gather_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/self/Unsqueeze_1 [Unsqueeze] inputs: [/bert/encoder/layer.0/attention/self/Gather_1_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Original shape: (), unsqueezing to: (1,)\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Unsqueeze_1 for ONNX node: /bert/encoder/layer.0/attention/self/Unsqueeze_1\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/Unsqueeze_1_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/Unsqueeze_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/self/Unsqueeze_1 [Unsqueeze] outputs: [/bert/encoder/layer.0/attention/self/Unsqueeze_1_output_0 -> (1)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Constant_2 [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/self/Constant_2 [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/self/Constant_2 [Constant] outputs: [/bert/encoder/layer.0/attention/self/Constant_2_output_0 -> (1)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Constant_3 [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/self/Constant_3 [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/self/Constant_3 [Constant] outputs: [/bert/encoder/layer.0/attention/self/Constant_3_output_0 -> (1)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Concat [Concat]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Unsqueeze_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Unsqueeze_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Constant_2_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Constant_3_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/self/Concat [Concat] inputs: [/bert/encoder/layer.0/attention/self/Unsqueeze_output_0 -> (1)[INT32]], [/bert/encoder/layer.0/attention/self/Unsqueeze_1_output_0 -> (1)[INT32]], [/bert/encoder/layer.0/attention/self/Constant_2_output_0 -> (1)[INT32]], [/bert/encoder/layer.0/attention/self/Constant_3_output_0 -> (1)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Constant_2_output_0 for ONNX node: /bert/encoder/layer.0/attention/self/Constant_2_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Constant_3_output_0 for ONNX node: /bert/encoder/layer.0/attention/self/Constant_3_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Concat for ONNX node: /bert/encoder/layer.0/attention/self/Concat\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/Concat_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/Concat_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/self/Concat [Concat] outputs: [/bert/encoder/layer.0/attention/self/Concat_output_0 -> (4)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Reshape [Reshape]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/key/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Concat_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/self/Reshape [Reshape] inputs: [/bert/encoder/layer.0/attention/self/key/Add_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.0/attention/self/Concat_output_0 -> (4)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Reshape for ONNX node: /bert/encoder/layer.0/attention/self/Reshape\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/Reshape_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/Reshape_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/self/Reshape [Reshape] outputs: [/bert/encoder/layer.0/attention/self/Reshape_output_0 -> (-1, -1, 8, 32)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/value/MatMul [MatMul]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/embeddings/LayerNorm/Add_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: onnx::MatMul_797\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/self/value/MatMul [MatMul] inputs: [/bert/embeddings/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], [onnx::MatMul_797 -> (256, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: onnx::MatMul_797 for ONNX node: onnx::MatMul_797\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/value/MatMul for ONNX node: /bert/encoder/layer.0/attention/self/value/MatMul\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/value/MatMul_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/value/MatMul_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/self/value/MatMul [MatMul] outputs: [/bert/encoder/layer.0/attention/self/value/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/value/Add [Add]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: bert.encoder.layer.0.attention.self.value.bias\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/value/MatMul_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/self/value/Add [Add] inputs: [bert.encoder.layer.0.attention.self.value.bias -> (256)[FLOAT]], [/bert/encoder/layer.0/attention/self/value/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: bert.encoder.layer.0.attention.self.value.bias for ONNX node: bert.encoder.layer.0.attention.self.value.bias\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/value/Add for ONNX node: /bert/encoder/layer.0/attention/self/value/Add\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/value/Add_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/value/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/self/value/Add [Add] outputs: [/bert/encoder/layer.0/attention/self/value/Add_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Shape_2 [Shape]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/value/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/self/Shape_2 [Shape] inputs: [/bert/encoder/layer.0/attention/self/value/Add_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Shape_2 for ONNX node: /bert/encoder/layer.0/attention/self/Shape_2\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/Shape_2_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/Shape_2_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/self/Shape_2 [Shape] outputs: [/bert/encoder/layer.0/attention/self/Shape_2_output_0 -> (3)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Constant_4 [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/self/Constant_4 [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/self/Constant_4 [Constant] outputs: [/bert/encoder/layer.0/attention/self/Constant_4_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Gather_2 [Gather]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Shape_2_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Constant_4_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/self/Gather_2 [Gather] inputs: [/bert/encoder/layer.0/attention/self/Shape_2_output_0 -> (3)[INT32]], [/bert/encoder/layer.0/attention/self/Constant_4_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Constant_4_output_0 for ONNX node: /bert/encoder/layer.0/attention/self/Constant_4_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Using Gather axis: 0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Gather_2 for ONNX node: /bert/encoder/layer.0/attention/self/Gather_2\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/Gather_2_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/Gather_2_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/self/Gather_2 [Gather] outputs: [/bert/encoder/layer.0/attention/self/Gather_2_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Shape_3 [Shape]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/value/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/self/Shape_3 [Shape] inputs: [/bert/encoder/layer.0/attention/self/value/Add_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Shape_3 for ONNX node: /bert/encoder/layer.0/attention/self/Shape_3\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/Shape_3_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/Shape_3_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/self/Shape_3 [Shape] outputs: [/bert/encoder/layer.0/attention/self/Shape_3_output_0 -> (3)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Constant_5 [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/self/Constant_5 [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/self/Constant_5 [Constant] outputs: [/bert/encoder/layer.0/attention/self/Constant_5_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Gather_3 [Gather]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Shape_3_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Constant_5_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/self/Gather_3 [Gather] inputs: [/bert/encoder/layer.0/attention/self/Shape_3_output_0 -> (3)[INT32]], [/bert/encoder/layer.0/attention/self/Constant_5_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Constant_5_output_0 for ONNX node: /bert/encoder/layer.0/attention/self/Constant_5_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Using Gather axis: 0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Gather_3 for ONNX node: /bert/encoder/layer.0/attention/self/Gather_3\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/Gather_3_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/Gather_3_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/self/Gather_3 [Gather] outputs: [/bert/encoder/layer.0/attention/self/Gather_3_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Unsqueeze_2 [Unsqueeze]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Gather_2_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/self/Unsqueeze_2 [Unsqueeze] inputs: [/bert/encoder/layer.0/attention/self/Gather_2_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Original shape: (), unsqueezing to: (1,)\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Unsqueeze_2 for ONNX node: /bert/encoder/layer.0/attention/self/Unsqueeze_2\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/Unsqueeze_2_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/Unsqueeze_2_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/self/Unsqueeze_2 [Unsqueeze] outputs: [/bert/encoder/layer.0/attention/self/Unsqueeze_2_output_0 -> (1)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Unsqueeze_3 [Unsqueeze]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Gather_3_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/self/Unsqueeze_3 [Unsqueeze] inputs: [/bert/encoder/layer.0/attention/self/Gather_3_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Original shape: (), unsqueezing to: (1,)\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Unsqueeze_3 for ONNX node: /bert/encoder/layer.0/attention/self/Unsqueeze_3\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/Unsqueeze_3_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/Unsqueeze_3_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/self/Unsqueeze_3 [Unsqueeze] outputs: [/bert/encoder/layer.0/attention/self/Unsqueeze_3_output_0 -> (1)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Constant_6 [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/self/Constant_6 [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/self/Constant_6 [Constant] outputs: [/bert/encoder/layer.0/attention/self/Constant_6_output_0 -> (1)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Constant_7 [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/self/Constant_7 [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/self/Constant_7 [Constant] outputs: [/bert/encoder/layer.0/attention/self/Constant_7_output_0 -> (1)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Concat_1 [Concat]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Unsqueeze_2_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Unsqueeze_3_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Constant_6_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Constant_7_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/self/Concat_1 [Concat] inputs: [/bert/encoder/layer.0/attention/self/Unsqueeze_2_output_0 -> (1)[INT32]], [/bert/encoder/layer.0/attention/self/Unsqueeze_3_output_0 -> (1)[INT32]], [/bert/encoder/layer.0/attention/self/Constant_6_output_0 -> (1)[INT32]], [/bert/encoder/layer.0/attention/self/Constant_7_output_0 -> (1)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Constant_6_output_0 for ONNX node: /bert/encoder/layer.0/attention/self/Constant_6_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Constant_7_output_0 for ONNX node: /bert/encoder/layer.0/attention/self/Constant_7_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Concat_1 for ONNX node: /bert/encoder/layer.0/attention/self/Concat_1\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/Concat_1_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/Concat_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/self/Concat_1 [Concat] outputs: [/bert/encoder/layer.0/attention/self/Concat_1_output_0 -> (4)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Reshape_1 [Reshape]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/value/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Concat_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/self/Reshape_1 [Reshape] inputs: [/bert/encoder/layer.0/attention/self/value/Add_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.0/attention/self/Concat_1_output_0 -> (4)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Reshape_1 for ONNX node: /bert/encoder/layer.0/attention/self/Reshape_1\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/Reshape_1_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/Reshape_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/self/Reshape_1 [Reshape] outputs: [/bert/encoder/layer.0/attention/self/Reshape_1_output_0 -> (-1, -1, 8, 32)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Transpose [Transpose]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Reshape_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/self/Transpose [Transpose] inputs: [/bert/encoder/layer.0/attention/self/Reshape_1_output_0 -> (-1, -1, 8, 32)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Transpose for ONNX node: /bert/encoder/layer.0/attention/self/Transpose\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/Transpose_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/Transpose_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/self/Transpose [Transpose] outputs: [/bert/encoder/layer.0/attention/self/Transpose_output_0 -> (-1, 8, -1, 32)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Shape_4 [Shape]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/query/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/self/Shape_4 [Shape] inputs: [/bert/encoder/layer.0/attention/self/query/Add_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Shape_4 for ONNX node: /bert/encoder/layer.0/attention/self/Shape_4\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/Shape_4_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/Shape_4_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/self/Shape_4 [Shape] outputs: [/bert/encoder/layer.0/attention/self/Shape_4_output_0 -> (3)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Constant_8 [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/self/Constant_8 [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/self/Constant_8 [Constant] outputs: [/bert/encoder/layer.0/attention/self/Constant_8_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Gather_4 [Gather]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Shape_4_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Constant_8_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/self/Gather_4 [Gather] inputs: [/bert/encoder/layer.0/attention/self/Shape_4_output_0 -> (3)[INT32]], [/bert/encoder/layer.0/attention/self/Constant_8_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Constant_8_output_0 for ONNX node: /bert/encoder/layer.0/attention/self/Constant_8_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Using Gather axis: 0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Gather_4 for ONNX node: /bert/encoder/layer.0/attention/self/Gather_4\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/Gather_4_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/Gather_4_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/self/Gather_4 [Gather] outputs: [/bert/encoder/layer.0/attention/self/Gather_4_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Shape_5 [Shape]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/query/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/self/Shape_5 [Shape] inputs: [/bert/encoder/layer.0/attention/self/query/Add_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Shape_5 for ONNX node: /bert/encoder/layer.0/attention/self/Shape_5\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/Shape_5_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/Shape_5_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/self/Shape_5 [Shape] outputs: [/bert/encoder/layer.0/attention/self/Shape_5_output_0 -> (3)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Constant_9 [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/self/Constant_9 [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/self/Constant_9 [Constant] outputs: [/bert/encoder/layer.0/attention/self/Constant_9_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Gather_5 [Gather]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Shape_5_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Constant_9_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/self/Gather_5 [Gather] inputs: [/bert/encoder/layer.0/attention/self/Shape_5_output_0 -> (3)[INT32]], [/bert/encoder/layer.0/attention/self/Constant_9_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Constant_9_output_0 for ONNX node: /bert/encoder/layer.0/attention/self/Constant_9_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Using Gather axis: 0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Gather_5 for ONNX node: /bert/encoder/layer.0/attention/self/Gather_5\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/Gather_5_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/Gather_5_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/self/Gather_5 [Gather] outputs: [/bert/encoder/layer.0/attention/self/Gather_5_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Unsqueeze_4 [Unsqueeze]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Gather_4_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/self/Unsqueeze_4 [Unsqueeze] inputs: [/bert/encoder/layer.0/attention/self/Gather_4_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Original shape: (), unsqueezing to: (1,)\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Unsqueeze_4 for ONNX node: /bert/encoder/layer.0/attention/self/Unsqueeze_4\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/Unsqueeze_4_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/Unsqueeze_4_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/self/Unsqueeze_4 [Unsqueeze] outputs: [/bert/encoder/layer.0/attention/self/Unsqueeze_4_output_0 -> (1)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Unsqueeze_5 [Unsqueeze]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Gather_5_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/self/Unsqueeze_5 [Unsqueeze] inputs: [/bert/encoder/layer.0/attention/self/Gather_5_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Original shape: (), unsqueezing to: (1,)\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Unsqueeze_5 for ONNX node: /bert/encoder/layer.0/attention/self/Unsqueeze_5\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/Unsqueeze_5_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/Unsqueeze_5_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/self/Unsqueeze_5 [Unsqueeze] outputs: [/bert/encoder/layer.0/attention/self/Unsqueeze_5_output_0 -> (1)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Constant_10 [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/self/Constant_10 [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/self/Constant_10 [Constant] outputs: [/bert/encoder/layer.0/attention/self/Constant_10_output_0 -> (1)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Constant_11 [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/self/Constant_11 [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/self/Constant_11 [Constant] outputs: [/bert/encoder/layer.0/attention/self/Constant_11_output_0 -> (1)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Concat_2 [Concat]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Unsqueeze_4_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Unsqueeze_5_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Constant_10_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Constant_11_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/self/Concat_2 [Concat] inputs: [/bert/encoder/layer.0/attention/self/Unsqueeze_4_output_0 -> (1)[INT32]], [/bert/encoder/layer.0/attention/self/Unsqueeze_5_output_0 -> (1)[INT32]], [/bert/encoder/layer.0/attention/self/Constant_10_output_0 -> (1)[INT32]], [/bert/encoder/layer.0/attention/self/Constant_11_output_0 -> (1)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Constant_10_output_0 for ONNX node: /bert/encoder/layer.0/attention/self/Constant_10_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Constant_11_output_0 for ONNX node: /bert/encoder/layer.0/attention/self/Constant_11_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Concat_2 for ONNX node: /bert/encoder/layer.0/attention/self/Concat_2\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/Concat_2_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/Concat_2_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/self/Concat_2 [Concat] outputs: [/bert/encoder/layer.0/attention/self/Concat_2_output_0 -> (4)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Reshape_2 [Reshape]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/query/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Concat_2_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/self/Reshape_2 [Reshape] inputs: [/bert/encoder/layer.0/attention/self/query/Add_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.0/attention/self/Concat_2_output_0 -> (4)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Reshape_2 for ONNX node: /bert/encoder/layer.0/attention/self/Reshape_2\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/Reshape_2_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/Reshape_2_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/self/Reshape_2 [Reshape] outputs: [/bert/encoder/layer.0/attention/self/Reshape_2_output_0 -> (-1, -1, 8, 32)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Transpose_1 [Transpose]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Reshape_2_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/self/Transpose_1 [Transpose] inputs: [/bert/encoder/layer.0/attention/self/Reshape_2_output_0 -> (-1, -1, 8, 32)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Transpose_1 for ONNX node: /bert/encoder/layer.0/attention/self/Transpose_1\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/Transpose_1_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/Transpose_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/self/Transpose_1 [Transpose] outputs: [/bert/encoder/layer.0/attention/self/Transpose_1_output_0 -> (-1, 8, -1, 32)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Transpose_2 [Transpose]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Reshape_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/self/Transpose_2 [Transpose] inputs: [/bert/encoder/layer.0/attention/self/Reshape_output_0 -> (-1, -1, 8, 32)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Transpose_2 for ONNX node: /bert/encoder/layer.0/attention/self/Transpose_2\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/Transpose_2_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/Transpose_2_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/self/Transpose_2 [Transpose] outputs: [/bert/encoder/layer.0/attention/self/Transpose_2_output_0 -> (-1, 8, 32, -1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/MatMul [MatMul]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Transpose_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Transpose_2_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/self/MatMul [MatMul] inputs: [/bert/encoder/layer.0/attention/self/Transpose_1_output_0 -> (-1, 8, -1, 32)[FLOAT]], [/bert/encoder/layer.0/attention/self/Transpose_2_output_0 -> (-1, 8, 32, -1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/MatMul for ONNX node: /bert/encoder/layer.0/attention/self/MatMul\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/MatMul_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/MatMul_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/self/MatMul [MatMul] outputs: [/bert/encoder/layer.0/attention/self/MatMul_output_0 -> (-1, 8, -1, -1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Constant_12 [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/self/Constant_12 [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/self/Constant_12 [Constant] outputs: [/bert/encoder/layer.0/attention/self/Constant_12_output_0 -> ()[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Div [Div]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/MatMul_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Constant_12_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/self/Div [Div] inputs: [/bert/encoder/layer.0/attention/self/MatMul_output_0 -> (-1, 8, -1, -1)[FLOAT]], [/bert/encoder/layer.0/attention/self/Constant_12_output_0 -> ()[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Constant_12_output_0 for ONNX node: /bert/encoder/layer.0/attention/self/Constant_12_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Div for ONNX node: /bert/encoder/layer.0/attention/self/Div\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/Div_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/Div_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/self/Div [Div] outputs: [/bert/encoder/layer.0/attention/self/Div_output_0 -> (-1, 8, -1, -1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Add [Add]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Div_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/Mul_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/self/Add [Add] inputs: [/bert/encoder/layer.0/attention/self/Div_output_0 -> (-1, 8, -1, -1)[FLOAT]], [/bert/Mul_output_0 -> (-1, 1, 1, -1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Add for ONNX node: /bert/encoder/layer.0/attention/self/Add\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/Add_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/self/Add [Add] outputs: [/bert/encoder/layer.0/attention/self/Add_output_0 -> (-1, 8, -1, -1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Softmax [Softmax]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/self/Softmax [Softmax] inputs: [/bert/encoder/layer.0/attention/self/Add_output_0 -> (-1, 8, -1, -1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Softmax for ONNX node: /bert/encoder/layer.0/attention/self/Softmax\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/Softmax_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/Softmax_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/self/Softmax [Softmax] outputs: [/bert/encoder/layer.0/attention/self/Softmax_output_0 -> (-1, 8, -1, -1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/MatMul_1 [MatMul]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Softmax_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Transpose_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/self/MatMul_1 [MatMul] inputs: [/bert/encoder/layer.0/attention/self/Softmax_output_0 -> (-1, 8, -1, -1)[FLOAT]], [/bert/encoder/layer.0/attention/self/Transpose_output_0 -> (-1, 8, -1, 32)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/MatMul_1 for ONNX node: /bert/encoder/layer.0/attention/self/MatMul_1\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/MatMul_1_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/MatMul_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/self/MatMul_1 [MatMul] outputs: [/bert/encoder/layer.0/attention/self/MatMul_1_output_0 -> (-1, 8, -1, 32)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Transpose_3 [Transpose]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/MatMul_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/self/Transpose_3 [Transpose] inputs: [/bert/encoder/layer.0/attention/self/MatMul_1_output_0 -> (-1, 8, -1, 32)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Transpose_3 for ONNX node: /bert/encoder/layer.0/attention/self/Transpose_3\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/Transpose_3_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/Transpose_3_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/self/Transpose_3 [Transpose] outputs: [/bert/encoder/layer.0/attention/self/Transpose_3_output_0 -> (-1, -1, 8, 32)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Shape_6 [Shape]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Transpose_3_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/self/Shape_6 [Shape] inputs: [/bert/encoder/layer.0/attention/self/Transpose_3_output_0 -> (-1, -1, 8, 32)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Shape_6 for ONNX node: /bert/encoder/layer.0/attention/self/Shape_6\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/Shape_6_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/Shape_6_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/self/Shape_6 [Shape] outputs: [/bert/encoder/layer.0/attention/self/Shape_6_output_0 -> (4)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Constant_13 [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/self/Constant_13 [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/self/Constant_13 [Constant] outputs: [/bert/encoder/layer.0/attention/self/Constant_13_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Gather_6 [Gather]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Shape_6_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Constant_13_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/self/Gather_6 [Gather] inputs: [/bert/encoder/layer.0/attention/self/Shape_6_output_0 -> (4)[INT32]], [/bert/encoder/layer.0/attention/self/Constant_13_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Constant_13_output_0 for ONNX node: /bert/encoder/layer.0/attention/self/Constant_13_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Using Gather axis: 0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Gather_6 for ONNX node: /bert/encoder/layer.0/attention/self/Gather_6\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/Gather_6_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/Gather_6_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/self/Gather_6 [Gather] outputs: [/bert/encoder/layer.0/attention/self/Gather_6_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Shape_7 [Shape]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Transpose_3_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/self/Shape_7 [Shape] inputs: [/bert/encoder/layer.0/attention/self/Transpose_3_output_0 -> (-1, -1, 8, 32)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Shape_7 for ONNX node: /bert/encoder/layer.0/attention/self/Shape_7\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/Shape_7_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/Shape_7_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/self/Shape_7 [Shape] outputs: [/bert/encoder/layer.0/attention/self/Shape_7_output_0 -> (4)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Constant_14 [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/self/Constant_14 [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/self/Constant_14 [Constant] outputs: [/bert/encoder/layer.0/attention/self/Constant_14_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Gather_7 [Gather]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Shape_7_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Constant_14_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/self/Gather_7 [Gather] inputs: [/bert/encoder/layer.0/attention/self/Shape_7_output_0 -> (4)[INT32]], [/bert/encoder/layer.0/attention/self/Constant_14_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Constant_14_output_0 for ONNX node: /bert/encoder/layer.0/attention/self/Constant_14_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Using Gather axis: 0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Gather_7 for ONNX node: /bert/encoder/layer.0/attention/self/Gather_7\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/Gather_7_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/Gather_7_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/self/Gather_7 [Gather] outputs: [/bert/encoder/layer.0/attention/self/Gather_7_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Unsqueeze_6 [Unsqueeze]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Gather_6_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/self/Unsqueeze_6 [Unsqueeze] inputs: [/bert/encoder/layer.0/attention/self/Gather_6_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Original shape: (), unsqueezing to: (1,)\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Unsqueeze_6 for ONNX node: /bert/encoder/layer.0/attention/self/Unsqueeze_6\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/Unsqueeze_6_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/Unsqueeze_6_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/self/Unsqueeze_6 [Unsqueeze] outputs: [/bert/encoder/layer.0/attention/self/Unsqueeze_6_output_0 -> (1)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Unsqueeze_7 [Unsqueeze]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Gather_7_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/self/Unsqueeze_7 [Unsqueeze] inputs: [/bert/encoder/layer.0/attention/self/Gather_7_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Original shape: (), unsqueezing to: (1,)\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Unsqueeze_7 for ONNX node: /bert/encoder/layer.0/attention/self/Unsqueeze_7\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/Unsqueeze_7_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/Unsqueeze_7_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/self/Unsqueeze_7 [Unsqueeze] outputs: [/bert/encoder/layer.0/attention/self/Unsqueeze_7_output_0 -> (1)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Constant_15 [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/self/Constant_15 [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/self/Constant_15 [Constant] outputs: [/bert/encoder/layer.0/attention/self/Constant_15_output_0 -> (1)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Concat_3 [Concat]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Unsqueeze_6_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Unsqueeze_7_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Constant_15_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/self/Concat_3 [Concat] inputs: [/bert/encoder/layer.0/attention/self/Unsqueeze_6_output_0 -> (1)[INT32]], [/bert/encoder/layer.0/attention/self/Unsqueeze_7_output_0 -> (1)[INT32]], [/bert/encoder/layer.0/attention/self/Constant_15_output_0 -> (1)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Constant_15_output_0 for ONNX node: /bert/encoder/layer.0/attention/self/Constant_15_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Concat_3 for ONNX node: /bert/encoder/layer.0/attention/self/Concat_3\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/Concat_3_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/Concat_3_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/self/Concat_3 [Concat] outputs: [/bert/encoder/layer.0/attention/self/Concat_3_output_0 -> (3)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Reshape_3 [Reshape]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Transpose_3_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Concat_3_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/self/Reshape_3 [Reshape] inputs: [/bert/encoder/layer.0/attention/self/Transpose_3_output_0 -> (-1, -1, 8, 32)[FLOAT]], [/bert/encoder/layer.0/attention/self/Concat_3_output_0 -> (3)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Reshape_3 for ONNX node: /bert/encoder/layer.0/attention/self/Reshape_3\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/Reshape_3_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/Reshape_3_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/self/Reshape_3 [Reshape] outputs: [/bert/encoder/layer.0/attention/self/Reshape_3_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/output/dense/MatMul [MatMul]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Reshape_3_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: onnx::MatMul_803\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/output/dense/MatMul [MatMul] inputs: [/bert/encoder/layer.0/attention/self/Reshape_3_output_0 -> (-1, -1, 256)[FLOAT]], [onnx::MatMul_803 -> (256, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: onnx::MatMul_803 for ONNX node: onnx::MatMul_803\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/output/dense/MatMul for ONNX node: /bert/encoder/layer.0/attention/output/dense/MatMul\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/output/dense/MatMul_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/output/dense/MatMul_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/output/dense/MatMul [MatMul] outputs: [/bert/encoder/layer.0/attention/output/dense/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/output/dense/Add [Add]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: bert.encoder.layer.0.attention.output.dense.bias\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/output/dense/MatMul_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/output/dense/Add [Add] inputs: [bert.encoder.layer.0.attention.output.dense.bias -> (256)[FLOAT]], [/bert/encoder/layer.0/attention/output/dense/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: bert.encoder.layer.0.attention.output.dense.bias for ONNX node: bert.encoder.layer.0.attention.output.dense.bias\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/output/dense/Add for ONNX node: /bert/encoder/layer.0/attention/output/dense/Add\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/output/dense/Add_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/output/dense/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/output/dense/Add [Add] outputs: [/bert/encoder/layer.0/attention/output/dense/Add_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/output/Add [Add]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/output/dense/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/embeddings/LayerNorm/Add_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/output/Add [Add] inputs: [/bert/encoder/layer.0/attention/output/dense/Add_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/embeddings/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/output/Add for ONNX node: /bert/encoder/layer.0/attention/output/Add\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/output/Add_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/output/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/output/Add [Add] outputs: [/bert/encoder/layer.0/attention/output/Add_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/output/LayerNorm/ReduceMean [ReduceMean]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/output/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/output/LayerNorm/ReduceMean [ReduceMean] inputs: [/bert/encoder/layer.0/attention/output/Add_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/output/LayerNorm/ReduceMean for ONNX node: /bert/encoder/layer.0/attention/output/LayerNorm/ReduceMean\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/output/LayerNorm/ReduceMean_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/output/LayerNorm/ReduceMean_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/output/LayerNorm/ReduceMean [ReduceMean] outputs: [/bert/encoder/layer.0/attention/output/LayerNorm/ReduceMean_output_0 -> (-1, -1, 1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/output/LayerNorm/Sub [Sub]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/output/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/output/LayerNorm/ReduceMean_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/output/LayerNorm/Sub [Sub] inputs: [/bert/encoder/layer.0/attention/output/Add_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.0/attention/output/LayerNorm/ReduceMean_output_0 -> (-1, -1, 1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/output/LayerNorm/Sub for ONNX node: /bert/encoder/layer.0/attention/output/LayerNorm/Sub\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/output/LayerNorm/Sub_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/output/LayerNorm/Sub_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/output/LayerNorm/Sub [Sub] outputs: [/bert/encoder/layer.0/attention/output/LayerNorm/Sub_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/output/LayerNorm/Constant [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/output/LayerNorm/Constant [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/output/LayerNorm/Constant [Constant] outputs: [/bert/encoder/layer.0/attention/output/LayerNorm/Constant_output_0 -> ()[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/output/LayerNorm/Pow [Pow]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/output/LayerNorm/Sub_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/output/LayerNorm/Constant_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/output/LayerNorm/Pow [Pow] inputs: [/bert/encoder/layer.0/attention/output/LayerNorm/Sub_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.0/attention/output/LayerNorm/Constant_output_0 -> ()[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/output/LayerNorm/Constant_output_0 for ONNX node: /bert/encoder/layer.0/attention/output/LayerNorm/Constant_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/output/LayerNorm/Pow for ONNX node: /bert/encoder/layer.0/attention/output/LayerNorm/Pow\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/output/LayerNorm/Pow_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/output/LayerNorm/Pow_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/output/LayerNorm/Pow [Pow] outputs: [/bert/encoder/layer.0/attention/output/LayerNorm/Pow_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/output/LayerNorm/ReduceMean_1 [ReduceMean]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/output/LayerNorm/Pow_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/output/LayerNorm/ReduceMean_1 [ReduceMean] inputs: [/bert/encoder/layer.0/attention/output/LayerNorm/Pow_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/output/LayerNorm/ReduceMean_1 for ONNX node: /bert/encoder/layer.0/attention/output/LayerNorm/ReduceMean_1\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/output/LayerNorm/ReduceMean_1_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/output/LayerNorm/ReduceMean_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/output/LayerNorm/ReduceMean_1 [ReduceMean] outputs: [/bert/encoder/layer.0/attention/output/LayerNorm/ReduceMean_1_output_0 -> (-1, -1, 1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/output/LayerNorm/Constant_1 [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/output/LayerNorm/Constant_1 [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/output/LayerNorm/Constant_1 [Constant] outputs: [/bert/encoder/layer.0/attention/output/LayerNorm/Constant_1_output_0 -> ()[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/output/LayerNorm/Add [Add]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/output/LayerNorm/ReduceMean_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/output/LayerNorm/Constant_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/output/LayerNorm/Add [Add] inputs: [/bert/encoder/layer.0/attention/output/LayerNorm/ReduceMean_1_output_0 -> (-1, -1, 1)[FLOAT]], [/bert/encoder/layer.0/attention/output/LayerNorm/Constant_1_output_0 -> ()[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/output/LayerNorm/Constant_1_output_0 for ONNX node: /bert/encoder/layer.0/attention/output/LayerNorm/Constant_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/output/LayerNorm/Add for ONNX node: /bert/encoder/layer.0/attention/output/LayerNorm/Add\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/output/LayerNorm/Add_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/output/LayerNorm/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/output/LayerNorm/Add [Add] outputs: [/bert/encoder/layer.0/attention/output/LayerNorm/Add_output_0 -> (-1, -1, 1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/output/LayerNorm/Sqrt [Sqrt]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/output/LayerNorm/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/output/LayerNorm/Sqrt [Sqrt] inputs: [/bert/encoder/layer.0/attention/output/LayerNorm/Add_output_0 -> (-1, -1, 1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/output/LayerNorm/Sqrt for ONNX node: /bert/encoder/layer.0/attention/output/LayerNorm/Sqrt\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/output/LayerNorm/Sqrt_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/output/LayerNorm/Sqrt_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/output/LayerNorm/Sqrt [Sqrt] outputs: [/bert/encoder/layer.0/attention/output/LayerNorm/Sqrt_output_0 -> (-1, -1, 1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/output/LayerNorm/Div [Div]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/output/LayerNorm/Sub_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/output/LayerNorm/Sqrt_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/output/LayerNorm/Div [Div] inputs: [/bert/encoder/layer.0/attention/output/LayerNorm/Sub_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.0/attention/output/LayerNorm/Sqrt_output_0 -> (-1, -1, 1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/output/LayerNorm/Div for ONNX node: /bert/encoder/layer.0/attention/output/LayerNorm/Div\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/output/LayerNorm/Div_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/output/LayerNorm/Div_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/output/LayerNorm/Div [Div] outputs: [/bert/encoder/layer.0/attention/output/LayerNorm/Div_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/output/LayerNorm/Mul [Mul]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/output/LayerNorm/Div_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: bert.encoder.layer.0.attention.output.LayerNorm.weight\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/output/LayerNorm/Mul [Mul] inputs: [/bert/encoder/layer.0/attention/output/LayerNorm/Div_output_0 -> (-1, -1, 256)[FLOAT]], [bert.encoder.layer.0.attention.output.LayerNorm.weight -> (256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: bert.encoder.layer.0.attention.output.LayerNorm.weight for ONNX node: bert.encoder.layer.0.attention.output.LayerNorm.weight\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/output/LayerNorm/Mul for ONNX node: /bert/encoder/layer.0/attention/output/LayerNorm/Mul\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/output/LayerNorm/Mul_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/output/LayerNorm/Mul_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/output/LayerNorm/Mul [Mul] outputs: [/bert/encoder/layer.0/attention/output/LayerNorm/Mul_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/output/LayerNorm/Add_1 [Add]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/output/LayerNorm/Mul_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: bert.encoder.layer.0.attention.output.LayerNorm.bias\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/output/LayerNorm/Add_1 [Add] inputs: [/bert/encoder/layer.0/attention/output/LayerNorm/Mul_output_0 -> (-1, -1, 256)[FLOAT]], [bert.encoder.layer.0.attention.output.LayerNorm.bias -> (256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: bert.encoder.layer.0.attention.output.LayerNorm.bias for ONNX node: bert.encoder.layer.0.attention.output.LayerNorm.bias\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/output/LayerNorm/Add_1 for ONNX node: /bert/encoder/layer.0/attention/output/LayerNorm/Add_1\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/output/LayerNorm/Add_1_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/output/LayerNorm/Add_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/attention/output/LayerNorm/Add_1 [Add] outputs: [/bert/encoder/layer.0/attention/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.0/intermediate/dense/MatMul [MatMul]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/output/LayerNorm/Add_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: onnx::MatMul_804\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/intermediate/dense/MatMul [MatMul] inputs: [/bert/encoder/layer.0/attention/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], [onnx::MatMul_804 -> (256, 1024)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: onnx::MatMul_804 for ONNX node: onnx::MatMul_804\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.0/intermediate/dense/MatMul for ONNX node: /bert/encoder/layer.0/intermediate/dense/MatMul\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.0/intermediate/dense/MatMul_output_0 for ONNX tensor: /bert/encoder/layer.0/intermediate/dense/MatMul_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/intermediate/dense/MatMul [MatMul] outputs: [/bert/encoder/layer.0/intermediate/dense/MatMul_output_0 -> (-1, -1, 1024)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.0/intermediate/dense/Add [Add]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: bert.encoder.layer.0.intermediate.dense.bias\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.0/intermediate/dense/MatMul_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/intermediate/dense/Add [Add] inputs: [bert.encoder.layer.0.intermediate.dense.bias -> (1024)[FLOAT]], [/bert/encoder/layer.0/intermediate/dense/MatMul_output_0 -> (-1, -1, 1024)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: bert.encoder.layer.0.intermediate.dense.bias for ONNX node: bert.encoder.layer.0.intermediate.dense.bias\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.0/intermediate/dense/Add for ONNX node: /bert/encoder/layer.0/intermediate/dense/Add\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.0/intermediate/dense/Add_output_0 for ONNX tensor: /bert/encoder/layer.0/intermediate/dense/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/intermediate/dense/Add [Add] outputs: [/bert/encoder/layer.0/intermediate/dense/Add_output_0 -> (-1, -1, 1024)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.0/intermediate/intermediate_act_fn/Constant [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/intermediate/intermediate_act_fn/Constant [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/intermediate/intermediate_act_fn/Constant [Constant] outputs: [/bert/encoder/layer.0/intermediate/intermediate_act_fn/Constant_output_0 -> ()[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.0/intermediate/intermediate_act_fn/Div [Div]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.0/intermediate/dense/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.0/intermediate/intermediate_act_fn/Constant_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/intermediate/intermediate_act_fn/Div [Div] inputs: [/bert/encoder/layer.0/intermediate/dense/Add_output_0 -> (-1, -1, 1024)[FLOAT]], [/bert/encoder/layer.0/intermediate/intermediate_act_fn/Constant_output_0 -> ()[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.0/intermediate/intermediate_act_fn/Constant_output_0 for ONNX node: /bert/encoder/layer.0/intermediate/intermediate_act_fn/Constant_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.0/intermediate/intermediate_act_fn/Div for ONNX node: /bert/encoder/layer.0/intermediate/intermediate_act_fn/Div\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.0/intermediate/intermediate_act_fn/Div_output_0 for ONNX tensor: /bert/encoder/layer.0/intermediate/intermediate_act_fn/Div_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/intermediate/intermediate_act_fn/Div [Div] outputs: [/bert/encoder/layer.0/intermediate/intermediate_act_fn/Div_output_0 -> (-1, -1, 1024)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.0/intermediate/intermediate_act_fn/Erf [Erf]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.0/intermediate/intermediate_act_fn/Div_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/intermediate/intermediate_act_fn/Erf [Erf] inputs: [/bert/encoder/layer.0/intermediate/intermediate_act_fn/Div_output_0 -> (-1, -1, 1024)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.0/intermediate/intermediate_act_fn/Erf for ONNX node: /bert/encoder/layer.0/intermediate/intermediate_act_fn/Erf\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.0/intermediate/intermediate_act_fn/Erf_output_0 for ONNX tensor: /bert/encoder/layer.0/intermediate/intermediate_act_fn/Erf_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/intermediate/intermediate_act_fn/Erf [Erf] outputs: [/bert/encoder/layer.0/intermediate/intermediate_act_fn/Erf_output_0 -> (-1, -1, 1024)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.0/intermediate/intermediate_act_fn/Constant_1 [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/intermediate/intermediate_act_fn/Constant_1 [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/intermediate/intermediate_act_fn/Constant_1 [Constant] outputs: [/bert/encoder/layer.0/intermediate/intermediate_act_fn/Constant_1_output_0 -> ()[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.0/intermediate/intermediate_act_fn/Add [Add]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.0/intermediate/intermediate_act_fn/Erf_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.0/intermediate/intermediate_act_fn/Constant_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/intermediate/intermediate_act_fn/Add [Add] inputs: [/bert/encoder/layer.0/intermediate/intermediate_act_fn/Erf_output_0 -> (-1, -1, 1024)[FLOAT]], [/bert/encoder/layer.0/intermediate/intermediate_act_fn/Constant_1_output_0 -> ()[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.0/intermediate/intermediate_act_fn/Constant_1_output_0 for ONNX node: /bert/encoder/layer.0/intermediate/intermediate_act_fn/Constant_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.0/intermediate/intermediate_act_fn/Add for ONNX node: /bert/encoder/layer.0/intermediate/intermediate_act_fn/Add\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.0/intermediate/intermediate_act_fn/Add_output_0 for ONNX tensor: /bert/encoder/layer.0/intermediate/intermediate_act_fn/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/intermediate/intermediate_act_fn/Add [Add] outputs: [/bert/encoder/layer.0/intermediate/intermediate_act_fn/Add_output_0 -> (-1, -1, 1024)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.0/intermediate/intermediate_act_fn/Mul [Mul]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.0/intermediate/dense/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.0/intermediate/intermediate_act_fn/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/intermediate/intermediate_act_fn/Mul [Mul] inputs: [/bert/encoder/layer.0/intermediate/dense/Add_output_0 -> (-1, -1, 1024)[FLOAT]], [/bert/encoder/layer.0/intermediate/intermediate_act_fn/Add_output_0 -> (-1, -1, 1024)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.0/intermediate/intermediate_act_fn/Mul for ONNX node: /bert/encoder/layer.0/intermediate/intermediate_act_fn/Mul\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.0/intermediate/intermediate_act_fn/Mul_output_0 for ONNX tensor: /bert/encoder/layer.0/intermediate/intermediate_act_fn/Mul_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/intermediate/intermediate_act_fn/Mul [Mul] outputs: [/bert/encoder/layer.0/intermediate/intermediate_act_fn/Mul_output_0 -> (-1, -1, 1024)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.0/intermediate/intermediate_act_fn/Constant_2 [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/intermediate/intermediate_act_fn/Constant_2 [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/intermediate/intermediate_act_fn/Constant_2 [Constant] outputs: [/bert/encoder/layer.0/intermediate/intermediate_act_fn/Constant_2_output_0 -> ()[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.0/intermediate/intermediate_act_fn/Mul_1 [Mul]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.0/intermediate/intermediate_act_fn/Mul_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.0/intermediate/intermediate_act_fn/Constant_2_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/intermediate/intermediate_act_fn/Mul_1 [Mul] inputs: [/bert/encoder/layer.0/intermediate/intermediate_act_fn/Mul_output_0 -> (-1, -1, 1024)[FLOAT]], [/bert/encoder/layer.0/intermediate/intermediate_act_fn/Constant_2_output_0 -> ()[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.0/intermediate/intermediate_act_fn/Constant_2_output_0 for ONNX node: /bert/encoder/layer.0/intermediate/intermediate_act_fn/Constant_2_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.0/intermediate/intermediate_act_fn/Mul_1 for ONNX node: /bert/encoder/layer.0/intermediate/intermediate_act_fn/Mul_1\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.0/intermediate/intermediate_act_fn/Mul_1_output_0 for ONNX tensor: /bert/encoder/layer.0/intermediate/intermediate_act_fn/Mul_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/intermediate/intermediate_act_fn/Mul_1 [Mul] outputs: [/bert/encoder/layer.0/intermediate/intermediate_act_fn/Mul_1_output_0 -> (-1, -1, 1024)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.0/output/dense/MatMul [MatMul]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.0/intermediate/intermediate_act_fn/Mul_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: onnx::MatMul_805\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/output/dense/MatMul [MatMul] inputs: [/bert/encoder/layer.0/intermediate/intermediate_act_fn/Mul_1_output_0 -> (-1, -1, 1024)[FLOAT]], [onnx::MatMul_805 -> (1024, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: onnx::MatMul_805 for ONNX node: onnx::MatMul_805\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.0/output/dense/MatMul for ONNX node: /bert/encoder/layer.0/output/dense/MatMul\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.0/output/dense/MatMul_output_0 for ONNX tensor: /bert/encoder/layer.0/output/dense/MatMul_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/output/dense/MatMul [MatMul] outputs: [/bert/encoder/layer.0/output/dense/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.0/output/dense/Add [Add]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: bert.encoder.layer.0.output.dense.bias\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.0/output/dense/MatMul_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/output/dense/Add [Add] inputs: [bert.encoder.layer.0.output.dense.bias -> (256)[FLOAT]], [/bert/encoder/layer.0/output/dense/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: bert.encoder.layer.0.output.dense.bias for ONNX node: bert.encoder.layer.0.output.dense.bias\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.0/output/dense/Add for ONNX node: /bert/encoder/layer.0/output/dense/Add\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.0/output/dense/Add_output_0 for ONNX tensor: /bert/encoder/layer.0/output/dense/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/output/dense/Add [Add] outputs: [/bert/encoder/layer.0/output/dense/Add_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.0/output/Add [Add]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.0/output/dense/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/output/LayerNorm/Add_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/output/Add [Add] inputs: [/bert/encoder/layer.0/output/dense/Add_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.0/attention/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.0/output/Add for ONNX node: /bert/encoder/layer.0/output/Add\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.0/output/Add_output_0 for ONNX tensor: /bert/encoder/layer.0/output/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/output/Add [Add] outputs: [/bert/encoder/layer.0/output/Add_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.0/output/LayerNorm/ReduceMean [ReduceMean]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.0/output/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/output/LayerNorm/ReduceMean [ReduceMean] inputs: [/bert/encoder/layer.0/output/Add_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.0/output/LayerNorm/ReduceMean for ONNX node: /bert/encoder/layer.0/output/LayerNorm/ReduceMean\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.0/output/LayerNorm/ReduceMean_output_0 for ONNX tensor: /bert/encoder/layer.0/output/LayerNorm/ReduceMean_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/output/LayerNorm/ReduceMean [ReduceMean] outputs: [/bert/encoder/layer.0/output/LayerNorm/ReduceMean_output_0 -> (-1, -1, 1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.0/output/LayerNorm/Sub [Sub]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.0/output/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.0/output/LayerNorm/ReduceMean_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/output/LayerNorm/Sub [Sub] inputs: [/bert/encoder/layer.0/output/Add_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.0/output/LayerNorm/ReduceMean_output_0 -> (-1, -1, 1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.0/output/LayerNorm/Sub for ONNX node: /bert/encoder/layer.0/output/LayerNorm/Sub\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.0/output/LayerNorm/Sub_output_0 for ONNX tensor: /bert/encoder/layer.0/output/LayerNorm/Sub_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/output/LayerNorm/Sub [Sub] outputs: [/bert/encoder/layer.0/output/LayerNorm/Sub_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.0/output/LayerNorm/Constant [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/output/LayerNorm/Constant [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/output/LayerNorm/Constant [Constant] outputs: [/bert/encoder/layer.0/output/LayerNorm/Constant_output_0 -> ()[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.0/output/LayerNorm/Pow [Pow]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.0/output/LayerNorm/Sub_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.0/output/LayerNorm/Constant_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/output/LayerNorm/Pow [Pow] inputs: [/bert/encoder/layer.0/output/LayerNorm/Sub_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.0/output/LayerNorm/Constant_output_0 -> ()[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.0/output/LayerNorm/Constant_output_0 for ONNX node: /bert/encoder/layer.0/output/LayerNorm/Constant_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.0/output/LayerNorm/Pow for ONNX node: /bert/encoder/layer.0/output/LayerNorm/Pow\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.0/output/LayerNorm/Pow_output_0 for ONNX tensor: /bert/encoder/layer.0/output/LayerNorm/Pow_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/output/LayerNorm/Pow [Pow] outputs: [/bert/encoder/layer.0/output/LayerNorm/Pow_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.0/output/LayerNorm/ReduceMean_1 [ReduceMean]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.0/output/LayerNorm/Pow_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/output/LayerNorm/ReduceMean_1 [ReduceMean] inputs: [/bert/encoder/layer.0/output/LayerNorm/Pow_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.0/output/LayerNorm/ReduceMean_1 for ONNX node: /bert/encoder/layer.0/output/LayerNorm/ReduceMean_1\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.0/output/LayerNorm/ReduceMean_1_output_0 for ONNX tensor: /bert/encoder/layer.0/output/LayerNorm/ReduceMean_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/output/LayerNorm/ReduceMean_1 [ReduceMean] outputs: [/bert/encoder/layer.0/output/LayerNorm/ReduceMean_1_output_0 -> (-1, -1, 1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.0/output/LayerNorm/Constant_1 [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/output/LayerNorm/Constant_1 [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/output/LayerNorm/Constant_1 [Constant] outputs: [/bert/encoder/layer.0/output/LayerNorm/Constant_1_output_0 -> ()[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.0/output/LayerNorm/Add [Add]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.0/output/LayerNorm/ReduceMean_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.0/output/LayerNorm/Constant_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/output/LayerNorm/Add [Add] inputs: [/bert/encoder/layer.0/output/LayerNorm/ReduceMean_1_output_0 -> (-1, -1, 1)[FLOAT]], [/bert/encoder/layer.0/output/LayerNorm/Constant_1_output_0 -> ()[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.0/output/LayerNorm/Constant_1_output_0 for ONNX node: /bert/encoder/layer.0/output/LayerNorm/Constant_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.0/output/LayerNorm/Add for ONNX node: /bert/encoder/layer.0/output/LayerNorm/Add\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.0/output/LayerNorm/Add_output_0 for ONNX tensor: /bert/encoder/layer.0/output/LayerNorm/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/output/LayerNorm/Add [Add] outputs: [/bert/encoder/layer.0/output/LayerNorm/Add_output_0 -> (-1, -1, 1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.0/output/LayerNorm/Sqrt [Sqrt]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.0/output/LayerNorm/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/output/LayerNorm/Sqrt [Sqrt] inputs: [/bert/encoder/layer.0/output/LayerNorm/Add_output_0 -> (-1, -1, 1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.0/output/LayerNorm/Sqrt for ONNX node: /bert/encoder/layer.0/output/LayerNorm/Sqrt\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.0/output/LayerNorm/Sqrt_output_0 for ONNX tensor: /bert/encoder/layer.0/output/LayerNorm/Sqrt_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/output/LayerNorm/Sqrt [Sqrt] outputs: [/bert/encoder/layer.0/output/LayerNorm/Sqrt_output_0 -> (-1, -1, 1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.0/output/LayerNorm/Div [Div]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.0/output/LayerNorm/Sub_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.0/output/LayerNorm/Sqrt_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/output/LayerNorm/Div [Div] inputs: [/bert/encoder/layer.0/output/LayerNorm/Sub_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.0/output/LayerNorm/Sqrt_output_0 -> (-1, -1, 1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.0/output/LayerNorm/Div for ONNX node: /bert/encoder/layer.0/output/LayerNorm/Div\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.0/output/LayerNorm/Div_output_0 for ONNX tensor: /bert/encoder/layer.0/output/LayerNorm/Div_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/output/LayerNorm/Div [Div] outputs: [/bert/encoder/layer.0/output/LayerNorm/Div_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.0/output/LayerNorm/Mul [Mul]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.0/output/LayerNorm/Div_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: bert.encoder.layer.0.output.LayerNorm.weight\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/output/LayerNorm/Mul [Mul] inputs: [/bert/encoder/layer.0/output/LayerNorm/Div_output_0 -> (-1, -1, 256)[FLOAT]], [bert.encoder.layer.0.output.LayerNorm.weight -> (256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: bert.encoder.layer.0.output.LayerNorm.weight for ONNX node: bert.encoder.layer.0.output.LayerNorm.weight\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.0/output/LayerNorm/Mul for ONNX node: /bert/encoder/layer.0/output/LayerNorm/Mul\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.0/output/LayerNorm/Mul_output_0 for ONNX tensor: /bert/encoder/layer.0/output/LayerNorm/Mul_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/output/LayerNorm/Mul [Mul] outputs: [/bert/encoder/layer.0/output/LayerNorm/Mul_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.0/output/LayerNorm/Add_1 [Add]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.0/output/LayerNorm/Mul_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: bert.encoder.layer.0.output.LayerNorm.bias\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/output/LayerNorm/Add_1 [Add] inputs: [/bert/encoder/layer.0/output/LayerNorm/Mul_output_0 -> (-1, -1, 256)[FLOAT]], [bert.encoder.layer.0.output.LayerNorm.bias -> (256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: bert.encoder.layer.0.output.LayerNorm.bias for ONNX node: bert.encoder.layer.0.output.LayerNorm.bias\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.0/output/LayerNorm/Add_1 for ONNX node: /bert/encoder/layer.0/output/LayerNorm/Add_1\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.0/output/LayerNorm/Add_1_output_0 for ONNX tensor: /bert/encoder/layer.0/output/LayerNorm/Add_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.0/output/LayerNorm/Add_1 [Add] outputs: [/bert/encoder/layer.0/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/query/MatMul [MatMul]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.0/output/LayerNorm/Add_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: onnx::MatMul_806\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/self/query/MatMul [MatMul] inputs: [/bert/encoder/layer.0/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], [onnx::MatMul_806 -> (256, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: onnx::MatMul_806 for ONNX node: onnx::MatMul_806\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/query/MatMul for ONNX node: /bert/encoder/layer.1/attention/self/query/MatMul\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/query/MatMul_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/query/MatMul_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/self/query/MatMul [MatMul] outputs: [/bert/encoder/layer.1/attention/self/query/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/query/Add [Add]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: bert.encoder.layer.1.attention.self.query.bias\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/query/MatMul_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/self/query/Add [Add] inputs: [bert.encoder.layer.1.attention.self.query.bias -> (256)[FLOAT]], [/bert/encoder/layer.1/attention/self/query/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: bert.encoder.layer.1.attention.self.query.bias for ONNX node: bert.encoder.layer.1.attention.self.query.bias\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/query/Add for ONNX node: /bert/encoder/layer.1/attention/self/query/Add\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/query/Add_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/query/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/self/query/Add [Add] outputs: [/bert/encoder/layer.1/attention/self/query/Add_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/key/MatMul [MatMul]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.0/output/LayerNorm/Add_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: onnx::MatMul_807\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/self/key/MatMul [MatMul] inputs: [/bert/encoder/layer.0/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], [onnx::MatMul_807 -> (256, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: onnx::MatMul_807 for ONNX node: onnx::MatMul_807\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/key/MatMul for ONNX node: /bert/encoder/layer.1/attention/self/key/MatMul\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/key/MatMul_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/key/MatMul_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/self/key/MatMul [MatMul] outputs: [/bert/encoder/layer.1/attention/self/key/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/key/Add [Add]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: bert.encoder.layer.1.attention.self.key.bias\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/key/MatMul_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/self/key/Add [Add] inputs: [bert.encoder.layer.1.attention.self.key.bias -> (256)[FLOAT]], [/bert/encoder/layer.1/attention/self/key/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: bert.encoder.layer.1.attention.self.key.bias for ONNX node: bert.encoder.layer.1.attention.self.key.bias\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/key/Add for ONNX node: /bert/encoder/layer.1/attention/self/key/Add\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/key/Add_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/key/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/self/key/Add [Add] outputs: [/bert/encoder/layer.1/attention/self/key/Add_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Shape [Shape]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/key/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/self/Shape [Shape] inputs: [/bert/encoder/layer.1/attention/self/key/Add_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Shape for ONNX node: /bert/encoder/layer.1/attention/self/Shape\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/Shape_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/Shape_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/self/Shape [Shape] outputs: [/bert/encoder/layer.1/attention/self/Shape_output_0 -> (3)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Constant [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/self/Constant [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/self/Constant [Constant] outputs: [/bert/encoder/layer.1/attention/self/Constant_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Gather [Gather]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Shape_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Constant_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/self/Gather [Gather] inputs: [/bert/encoder/layer.1/attention/self/Shape_output_0 -> (3)[INT32]], [/bert/encoder/layer.1/attention/self/Constant_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Constant_output_0 for ONNX node: /bert/encoder/layer.1/attention/self/Constant_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Using Gather axis: 0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Gather for ONNX node: /bert/encoder/layer.1/attention/self/Gather\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/Gather_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/Gather_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/self/Gather [Gather] outputs: [/bert/encoder/layer.1/attention/self/Gather_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Shape_1 [Shape]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/key/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/self/Shape_1 [Shape] inputs: [/bert/encoder/layer.1/attention/self/key/Add_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Shape_1 for ONNX node: /bert/encoder/layer.1/attention/self/Shape_1\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/Shape_1_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/Shape_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/self/Shape_1 [Shape] outputs: [/bert/encoder/layer.1/attention/self/Shape_1_output_0 -> (3)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Constant_1 [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/self/Constant_1 [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/self/Constant_1 [Constant] outputs: [/bert/encoder/layer.1/attention/self/Constant_1_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Gather_1 [Gather]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Shape_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Constant_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/self/Gather_1 [Gather] inputs: [/bert/encoder/layer.1/attention/self/Shape_1_output_0 -> (3)[INT32]], [/bert/encoder/layer.1/attention/self/Constant_1_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Constant_1_output_0 for ONNX node: /bert/encoder/layer.1/attention/self/Constant_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Using Gather axis: 0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Gather_1 for ONNX node: /bert/encoder/layer.1/attention/self/Gather_1\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/Gather_1_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/Gather_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/self/Gather_1 [Gather] outputs: [/bert/encoder/layer.1/attention/self/Gather_1_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Unsqueeze [Unsqueeze]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Gather_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/self/Unsqueeze [Unsqueeze] inputs: [/bert/encoder/layer.1/attention/self/Gather_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Original shape: (), unsqueezing to: (1,)\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Unsqueeze for ONNX node: /bert/encoder/layer.1/attention/self/Unsqueeze\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/Unsqueeze_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/Unsqueeze_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/self/Unsqueeze [Unsqueeze] outputs: [/bert/encoder/layer.1/attention/self/Unsqueeze_output_0 -> (1)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Unsqueeze_1 [Unsqueeze]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Gather_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/self/Unsqueeze_1 [Unsqueeze] inputs: [/bert/encoder/layer.1/attention/self/Gather_1_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Original shape: (), unsqueezing to: (1,)\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Unsqueeze_1 for ONNX node: /bert/encoder/layer.1/attention/self/Unsqueeze_1\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/Unsqueeze_1_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/Unsqueeze_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/self/Unsqueeze_1 [Unsqueeze] outputs: [/bert/encoder/layer.1/attention/self/Unsqueeze_1_output_0 -> (1)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Constant_2 [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/self/Constant_2 [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/self/Constant_2 [Constant] outputs: [/bert/encoder/layer.1/attention/self/Constant_2_output_0 -> (1)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Constant_3 [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/self/Constant_3 [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/self/Constant_3 [Constant] outputs: [/bert/encoder/layer.1/attention/self/Constant_3_output_0 -> (1)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Concat [Concat]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Unsqueeze_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Unsqueeze_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Constant_2_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Constant_3_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/self/Concat [Concat] inputs: [/bert/encoder/layer.1/attention/self/Unsqueeze_output_0 -> (1)[INT32]], [/bert/encoder/layer.1/attention/self/Unsqueeze_1_output_0 -> (1)[INT32]], [/bert/encoder/layer.1/attention/self/Constant_2_output_0 -> (1)[INT32]], [/bert/encoder/layer.1/attention/self/Constant_3_output_0 -> (1)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Constant_2_output_0 for ONNX node: /bert/encoder/layer.1/attention/self/Constant_2_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Constant_3_output_0 for ONNX node: /bert/encoder/layer.1/attention/self/Constant_3_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Concat for ONNX node: /bert/encoder/layer.1/attention/self/Concat\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/Concat_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/Concat_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/self/Concat [Concat] outputs: [/bert/encoder/layer.1/attention/self/Concat_output_0 -> (4)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Reshape [Reshape]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/key/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Concat_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/self/Reshape [Reshape] inputs: [/bert/encoder/layer.1/attention/self/key/Add_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.1/attention/self/Concat_output_0 -> (4)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Reshape for ONNX node: /bert/encoder/layer.1/attention/self/Reshape\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/Reshape_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/Reshape_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/self/Reshape [Reshape] outputs: [/bert/encoder/layer.1/attention/self/Reshape_output_0 -> (-1, -1, 8, 32)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/value/MatMul [MatMul]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.0/output/LayerNorm/Add_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: onnx::MatMul_810\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/self/value/MatMul [MatMul] inputs: [/bert/encoder/layer.0/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], [onnx::MatMul_810 -> (256, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: onnx::MatMul_810 for ONNX node: onnx::MatMul_810\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/value/MatMul for ONNX node: /bert/encoder/layer.1/attention/self/value/MatMul\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/value/MatMul_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/value/MatMul_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/self/value/MatMul [MatMul] outputs: [/bert/encoder/layer.1/attention/self/value/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/value/Add [Add]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: bert.encoder.layer.1.attention.self.value.bias\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/value/MatMul_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/self/value/Add [Add] inputs: [bert.encoder.layer.1.attention.self.value.bias -> (256)[FLOAT]], [/bert/encoder/layer.1/attention/self/value/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: bert.encoder.layer.1.attention.self.value.bias for ONNX node: bert.encoder.layer.1.attention.self.value.bias\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/value/Add for ONNX node: /bert/encoder/layer.1/attention/self/value/Add\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/value/Add_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/value/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/self/value/Add [Add] outputs: [/bert/encoder/layer.1/attention/self/value/Add_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Shape_2 [Shape]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/value/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/self/Shape_2 [Shape] inputs: [/bert/encoder/layer.1/attention/self/value/Add_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Shape_2 for ONNX node: /bert/encoder/layer.1/attention/self/Shape_2\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/Shape_2_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/Shape_2_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/self/Shape_2 [Shape] outputs: [/bert/encoder/layer.1/attention/self/Shape_2_output_0 -> (3)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Constant_4 [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/self/Constant_4 [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/self/Constant_4 [Constant] outputs: [/bert/encoder/layer.1/attention/self/Constant_4_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Gather_2 [Gather]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Shape_2_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Constant_4_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/self/Gather_2 [Gather] inputs: [/bert/encoder/layer.1/attention/self/Shape_2_output_0 -> (3)[INT32]], [/bert/encoder/layer.1/attention/self/Constant_4_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Constant_4_output_0 for ONNX node: /bert/encoder/layer.1/attention/self/Constant_4_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Using Gather axis: 0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Gather_2 for ONNX node: /bert/encoder/layer.1/attention/self/Gather_2\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/Gather_2_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/Gather_2_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/self/Gather_2 [Gather] outputs: [/bert/encoder/layer.1/attention/self/Gather_2_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Shape_3 [Shape]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/value/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/self/Shape_3 [Shape] inputs: [/bert/encoder/layer.1/attention/self/value/Add_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Shape_3 for ONNX node: /bert/encoder/layer.1/attention/self/Shape_3\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/Shape_3_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/Shape_3_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/self/Shape_3 [Shape] outputs: [/bert/encoder/layer.1/attention/self/Shape_3_output_0 -> (3)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Constant_5 [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/self/Constant_5 [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/self/Constant_5 [Constant] outputs: [/bert/encoder/layer.1/attention/self/Constant_5_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Gather_3 [Gather]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Shape_3_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Constant_5_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/self/Gather_3 [Gather] inputs: [/bert/encoder/layer.1/attention/self/Shape_3_output_0 -> (3)[INT32]], [/bert/encoder/layer.1/attention/self/Constant_5_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Constant_5_output_0 for ONNX node: /bert/encoder/layer.1/attention/self/Constant_5_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Using Gather axis: 0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Gather_3 for ONNX node: /bert/encoder/layer.1/attention/self/Gather_3\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/Gather_3_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/Gather_3_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/self/Gather_3 [Gather] outputs: [/bert/encoder/layer.1/attention/self/Gather_3_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Unsqueeze_2 [Unsqueeze]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Gather_2_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/self/Unsqueeze_2 [Unsqueeze] inputs: [/bert/encoder/layer.1/attention/self/Gather_2_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Original shape: (), unsqueezing to: (1,)\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Unsqueeze_2 for ONNX node: /bert/encoder/layer.1/attention/self/Unsqueeze_2\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/Unsqueeze_2_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/Unsqueeze_2_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/self/Unsqueeze_2 [Unsqueeze] outputs: [/bert/encoder/layer.1/attention/self/Unsqueeze_2_output_0 -> (1)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Unsqueeze_3 [Unsqueeze]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Gather_3_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/self/Unsqueeze_3 [Unsqueeze] inputs: [/bert/encoder/layer.1/attention/self/Gather_3_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Original shape: (), unsqueezing to: (1,)\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Unsqueeze_3 for ONNX node: /bert/encoder/layer.1/attention/self/Unsqueeze_3\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/Unsqueeze_3_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/Unsqueeze_3_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/self/Unsqueeze_3 [Unsqueeze] outputs: [/bert/encoder/layer.1/attention/self/Unsqueeze_3_output_0 -> (1)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Constant_6 [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/self/Constant_6 [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/self/Constant_6 [Constant] outputs: [/bert/encoder/layer.1/attention/self/Constant_6_output_0 -> (1)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Constant_7 [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/self/Constant_7 [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/self/Constant_7 [Constant] outputs: [/bert/encoder/layer.1/attention/self/Constant_7_output_0 -> (1)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Concat_1 [Concat]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Unsqueeze_2_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Unsqueeze_3_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Constant_6_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Constant_7_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/self/Concat_1 [Concat] inputs: [/bert/encoder/layer.1/attention/self/Unsqueeze_2_output_0 -> (1)[INT32]], [/bert/encoder/layer.1/attention/self/Unsqueeze_3_output_0 -> (1)[INT32]], [/bert/encoder/layer.1/attention/self/Constant_6_output_0 -> (1)[INT32]], [/bert/encoder/layer.1/attention/self/Constant_7_output_0 -> (1)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Constant_6_output_0 for ONNX node: /bert/encoder/layer.1/attention/self/Constant_6_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Constant_7_output_0 for ONNX node: /bert/encoder/layer.1/attention/self/Constant_7_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Concat_1 for ONNX node: /bert/encoder/layer.1/attention/self/Concat_1\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/Concat_1_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/Concat_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/self/Concat_1 [Concat] outputs: [/bert/encoder/layer.1/attention/self/Concat_1_output_0 -> (4)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Reshape_1 [Reshape]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/value/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Concat_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/self/Reshape_1 [Reshape] inputs: [/bert/encoder/layer.1/attention/self/value/Add_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.1/attention/self/Concat_1_output_0 -> (4)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Reshape_1 for ONNX node: /bert/encoder/layer.1/attention/self/Reshape_1\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/Reshape_1_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/Reshape_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/self/Reshape_1 [Reshape] outputs: [/bert/encoder/layer.1/attention/self/Reshape_1_output_0 -> (-1, -1, 8, 32)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Transpose [Transpose]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Reshape_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/self/Transpose [Transpose] inputs: [/bert/encoder/layer.1/attention/self/Reshape_1_output_0 -> (-1, -1, 8, 32)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Transpose for ONNX node: /bert/encoder/layer.1/attention/self/Transpose\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/Transpose_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/Transpose_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/self/Transpose [Transpose] outputs: [/bert/encoder/layer.1/attention/self/Transpose_output_0 -> (-1, 8, -1, 32)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Shape_4 [Shape]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/query/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/self/Shape_4 [Shape] inputs: [/bert/encoder/layer.1/attention/self/query/Add_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Shape_4 for ONNX node: /bert/encoder/layer.1/attention/self/Shape_4\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/Shape_4_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/Shape_4_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/self/Shape_4 [Shape] outputs: [/bert/encoder/layer.1/attention/self/Shape_4_output_0 -> (3)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Constant_8 [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/self/Constant_8 [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/self/Constant_8 [Constant] outputs: [/bert/encoder/layer.1/attention/self/Constant_8_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Gather_4 [Gather]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Shape_4_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Constant_8_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/self/Gather_4 [Gather] inputs: [/bert/encoder/layer.1/attention/self/Shape_4_output_0 -> (3)[INT32]], [/bert/encoder/layer.1/attention/self/Constant_8_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Constant_8_output_0 for ONNX node: /bert/encoder/layer.1/attention/self/Constant_8_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Using Gather axis: 0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Gather_4 for ONNX node: /bert/encoder/layer.1/attention/self/Gather_4\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/Gather_4_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/Gather_4_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/self/Gather_4 [Gather] outputs: [/bert/encoder/layer.1/attention/self/Gather_4_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Shape_5 [Shape]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/query/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/self/Shape_5 [Shape] inputs: [/bert/encoder/layer.1/attention/self/query/Add_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Shape_5 for ONNX node: /bert/encoder/layer.1/attention/self/Shape_5\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/Shape_5_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/Shape_5_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/self/Shape_5 [Shape] outputs: [/bert/encoder/layer.1/attention/self/Shape_5_output_0 -> (3)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Constant_9 [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/self/Constant_9 [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/self/Constant_9 [Constant] outputs: [/bert/encoder/layer.1/attention/self/Constant_9_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Gather_5 [Gather]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Shape_5_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Constant_9_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/self/Gather_5 [Gather] inputs: [/bert/encoder/layer.1/attention/self/Shape_5_output_0 -> (3)[INT32]], [/bert/encoder/layer.1/attention/self/Constant_9_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Constant_9_output_0 for ONNX node: /bert/encoder/layer.1/attention/self/Constant_9_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Using Gather axis: 0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Gather_5 for ONNX node: /bert/encoder/layer.1/attention/self/Gather_5\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/Gather_5_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/Gather_5_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/self/Gather_5 [Gather] outputs: [/bert/encoder/layer.1/attention/self/Gather_5_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Unsqueeze_4 [Unsqueeze]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Gather_4_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/self/Unsqueeze_4 [Unsqueeze] inputs: [/bert/encoder/layer.1/attention/self/Gather_4_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Original shape: (), unsqueezing to: (1,)\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Unsqueeze_4 for ONNX node: /bert/encoder/layer.1/attention/self/Unsqueeze_4\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/Unsqueeze_4_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/Unsqueeze_4_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/self/Unsqueeze_4 [Unsqueeze] outputs: [/bert/encoder/layer.1/attention/self/Unsqueeze_4_output_0 -> (1)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Unsqueeze_5 [Unsqueeze]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Gather_5_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/self/Unsqueeze_5 [Unsqueeze] inputs: [/bert/encoder/layer.1/attention/self/Gather_5_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Original shape: (), unsqueezing to: (1,)\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Unsqueeze_5 for ONNX node: /bert/encoder/layer.1/attention/self/Unsqueeze_5\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/Unsqueeze_5_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/Unsqueeze_5_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/self/Unsqueeze_5 [Unsqueeze] outputs: [/bert/encoder/layer.1/attention/self/Unsqueeze_5_output_0 -> (1)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Constant_10 [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/self/Constant_10 [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/self/Constant_10 [Constant] outputs: [/bert/encoder/layer.1/attention/self/Constant_10_output_0 -> (1)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Constant_11 [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/self/Constant_11 [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/self/Constant_11 [Constant] outputs: [/bert/encoder/layer.1/attention/self/Constant_11_output_0 -> (1)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Concat_2 [Concat]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Unsqueeze_4_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Unsqueeze_5_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Constant_10_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Constant_11_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/self/Concat_2 [Concat] inputs: [/bert/encoder/layer.1/attention/self/Unsqueeze_4_output_0 -> (1)[INT32]], [/bert/encoder/layer.1/attention/self/Unsqueeze_5_output_0 -> (1)[INT32]], [/bert/encoder/layer.1/attention/self/Constant_10_output_0 -> (1)[INT32]], [/bert/encoder/layer.1/attention/self/Constant_11_output_0 -> (1)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Constant_10_output_0 for ONNX node: /bert/encoder/layer.1/attention/self/Constant_10_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Constant_11_output_0 for ONNX node: /bert/encoder/layer.1/attention/self/Constant_11_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Concat_2 for ONNX node: /bert/encoder/layer.1/attention/self/Concat_2\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/Concat_2_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/Concat_2_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/self/Concat_2 [Concat] outputs: [/bert/encoder/layer.1/attention/self/Concat_2_output_0 -> (4)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Reshape_2 [Reshape]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/query/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Concat_2_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/self/Reshape_2 [Reshape] inputs: [/bert/encoder/layer.1/attention/self/query/Add_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.1/attention/self/Concat_2_output_0 -> (4)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Reshape_2 for ONNX node: /bert/encoder/layer.1/attention/self/Reshape_2\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/Reshape_2_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/Reshape_2_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/self/Reshape_2 [Reshape] outputs: [/bert/encoder/layer.1/attention/self/Reshape_2_output_0 -> (-1, -1, 8, 32)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Transpose_1 [Transpose]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Reshape_2_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/self/Transpose_1 [Transpose] inputs: [/bert/encoder/layer.1/attention/self/Reshape_2_output_0 -> (-1, -1, 8, 32)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Transpose_1 for ONNX node: /bert/encoder/layer.1/attention/self/Transpose_1\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/Transpose_1_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/Transpose_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/self/Transpose_1 [Transpose] outputs: [/bert/encoder/layer.1/attention/self/Transpose_1_output_0 -> (-1, 8, -1, 32)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Transpose_2 [Transpose]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Reshape_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/self/Transpose_2 [Transpose] inputs: [/bert/encoder/layer.1/attention/self/Reshape_output_0 -> (-1, -1, 8, 32)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Transpose_2 for ONNX node: /bert/encoder/layer.1/attention/self/Transpose_2\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/Transpose_2_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/Transpose_2_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/self/Transpose_2 [Transpose] outputs: [/bert/encoder/layer.1/attention/self/Transpose_2_output_0 -> (-1, 8, 32, -1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/MatMul [MatMul]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Transpose_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Transpose_2_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/self/MatMul [MatMul] inputs: [/bert/encoder/layer.1/attention/self/Transpose_1_output_0 -> (-1, 8, -1, 32)[FLOAT]], [/bert/encoder/layer.1/attention/self/Transpose_2_output_0 -> (-1, 8, 32, -1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/MatMul for ONNX node: /bert/encoder/layer.1/attention/self/MatMul\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/MatMul_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/MatMul_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/self/MatMul [MatMul] outputs: [/bert/encoder/layer.1/attention/self/MatMul_output_0 -> (-1, 8, -1, -1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Constant_12 [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/self/Constant_12 [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/self/Constant_12 [Constant] outputs: [/bert/encoder/layer.1/attention/self/Constant_12_output_0 -> ()[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Div [Div]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/MatMul_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Constant_12_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/self/Div [Div] inputs: [/bert/encoder/layer.1/attention/self/MatMul_output_0 -> (-1, 8, -1, -1)[FLOAT]], [/bert/encoder/layer.1/attention/self/Constant_12_output_0 -> ()[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Constant_12_output_0 for ONNX node: /bert/encoder/layer.1/attention/self/Constant_12_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Div for ONNX node: /bert/encoder/layer.1/attention/self/Div\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/Div_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/Div_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/self/Div [Div] outputs: [/bert/encoder/layer.1/attention/self/Div_output_0 -> (-1, 8, -1, -1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Add [Add]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Div_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/Mul_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/self/Add [Add] inputs: [/bert/encoder/layer.1/attention/self/Div_output_0 -> (-1, 8, -1, -1)[FLOAT]], [/bert/Mul_output_0 -> (-1, 1, 1, -1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Add for ONNX node: /bert/encoder/layer.1/attention/self/Add\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/Add_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/self/Add [Add] outputs: [/bert/encoder/layer.1/attention/self/Add_output_0 -> (-1, 8, -1, -1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Softmax [Softmax]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/self/Softmax [Softmax] inputs: [/bert/encoder/layer.1/attention/self/Add_output_0 -> (-1, 8, -1, -1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Softmax for ONNX node: /bert/encoder/layer.1/attention/self/Softmax\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/Softmax_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/Softmax_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/self/Softmax [Softmax] outputs: [/bert/encoder/layer.1/attention/self/Softmax_output_0 -> (-1, 8, -1, -1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/MatMul_1 [MatMul]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Softmax_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Transpose_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/self/MatMul_1 [MatMul] inputs: [/bert/encoder/layer.1/attention/self/Softmax_output_0 -> (-1, 8, -1, -1)[FLOAT]], [/bert/encoder/layer.1/attention/self/Transpose_output_0 -> (-1, 8, -1, 32)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/MatMul_1 for ONNX node: /bert/encoder/layer.1/attention/self/MatMul_1\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/MatMul_1_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/MatMul_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/self/MatMul_1 [MatMul] outputs: [/bert/encoder/layer.1/attention/self/MatMul_1_output_0 -> (-1, 8, -1, 32)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Transpose_3 [Transpose]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/MatMul_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/self/Transpose_3 [Transpose] inputs: [/bert/encoder/layer.1/attention/self/MatMul_1_output_0 -> (-1, 8, -1, 32)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Transpose_3 for ONNX node: /bert/encoder/layer.1/attention/self/Transpose_3\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/Transpose_3_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/Transpose_3_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/self/Transpose_3 [Transpose] outputs: [/bert/encoder/layer.1/attention/self/Transpose_3_output_0 -> (-1, -1, 8, 32)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Shape_6 [Shape]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Transpose_3_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/self/Shape_6 [Shape] inputs: [/bert/encoder/layer.1/attention/self/Transpose_3_output_0 -> (-1, -1, 8, 32)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Shape_6 for ONNX node: /bert/encoder/layer.1/attention/self/Shape_6\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/Shape_6_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/Shape_6_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/self/Shape_6 [Shape] outputs: [/bert/encoder/layer.1/attention/self/Shape_6_output_0 -> (4)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Constant_13 [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/self/Constant_13 [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/self/Constant_13 [Constant] outputs: [/bert/encoder/layer.1/attention/self/Constant_13_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Gather_6 [Gather]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Shape_6_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Constant_13_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/self/Gather_6 [Gather] inputs: [/bert/encoder/layer.1/attention/self/Shape_6_output_0 -> (4)[INT32]], [/bert/encoder/layer.1/attention/self/Constant_13_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Constant_13_output_0 for ONNX node: /bert/encoder/layer.1/attention/self/Constant_13_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Using Gather axis: 0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Gather_6 for ONNX node: /bert/encoder/layer.1/attention/self/Gather_6\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/Gather_6_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/Gather_6_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/self/Gather_6 [Gather] outputs: [/bert/encoder/layer.1/attention/self/Gather_6_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Shape_7 [Shape]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Transpose_3_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/self/Shape_7 [Shape] inputs: [/bert/encoder/layer.1/attention/self/Transpose_3_output_0 -> (-1, -1, 8, 32)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Shape_7 for ONNX node: /bert/encoder/layer.1/attention/self/Shape_7\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/Shape_7_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/Shape_7_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/self/Shape_7 [Shape] outputs: [/bert/encoder/layer.1/attention/self/Shape_7_output_0 -> (4)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Constant_14 [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/self/Constant_14 [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/self/Constant_14 [Constant] outputs: [/bert/encoder/layer.1/attention/self/Constant_14_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Gather_7 [Gather]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Shape_7_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Constant_14_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/self/Gather_7 [Gather] inputs: [/bert/encoder/layer.1/attention/self/Shape_7_output_0 -> (4)[INT32]], [/bert/encoder/layer.1/attention/self/Constant_14_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Constant_14_output_0 for ONNX node: /bert/encoder/layer.1/attention/self/Constant_14_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Using Gather axis: 0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Gather_7 for ONNX node: /bert/encoder/layer.1/attention/self/Gather_7\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/Gather_7_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/Gather_7_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/self/Gather_7 [Gather] outputs: [/bert/encoder/layer.1/attention/self/Gather_7_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Unsqueeze_6 [Unsqueeze]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Gather_6_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/self/Unsqueeze_6 [Unsqueeze] inputs: [/bert/encoder/layer.1/attention/self/Gather_6_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Original shape: (), unsqueezing to: (1,)\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Unsqueeze_6 for ONNX node: /bert/encoder/layer.1/attention/self/Unsqueeze_6\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/Unsqueeze_6_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/Unsqueeze_6_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/self/Unsqueeze_6 [Unsqueeze] outputs: [/bert/encoder/layer.1/attention/self/Unsqueeze_6_output_0 -> (1)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Unsqueeze_7 [Unsqueeze]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Gather_7_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/self/Unsqueeze_7 [Unsqueeze] inputs: [/bert/encoder/layer.1/attention/self/Gather_7_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Original shape: (), unsqueezing to: (1,)\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Unsqueeze_7 for ONNX node: /bert/encoder/layer.1/attention/self/Unsqueeze_7\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/Unsqueeze_7_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/Unsqueeze_7_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/self/Unsqueeze_7 [Unsqueeze] outputs: [/bert/encoder/layer.1/attention/self/Unsqueeze_7_output_0 -> (1)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Constant_15 [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/self/Constant_15 [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/self/Constant_15 [Constant] outputs: [/bert/encoder/layer.1/attention/self/Constant_15_output_0 -> (1)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Concat_3 [Concat]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Unsqueeze_6_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Unsqueeze_7_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Constant_15_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/self/Concat_3 [Concat] inputs: [/bert/encoder/layer.1/attention/self/Unsqueeze_6_output_0 -> (1)[INT32]], [/bert/encoder/layer.1/attention/self/Unsqueeze_7_output_0 -> (1)[INT32]], [/bert/encoder/layer.1/attention/self/Constant_15_output_0 -> (1)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Constant_15_output_0 for ONNX node: /bert/encoder/layer.1/attention/self/Constant_15_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Concat_3 for ONNX node: /bert/encoder/layer.1/attention/self/Concat_3\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/Concat_3_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/Concat_3_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/self/Concat_3 [Concat] outputs: [/bert/encoder/layer.1/attention/self/Concat_3_output_0 -> (3)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Reshape_3 [Reshape]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Transpose_3_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Concat_3_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/self/Reshape_3 [Reshape] inputs: [/bert/encoder/layer.1/attention/self/Transpose_3_output_0 -> (-1, -1, 8, 32)[FLOAT]], [/bert/encoder/layer.1/attention/self/Concat_3_output_0 -> (3)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Reshape_3 for ONNX node: /bert/encoder/layer.1/attention/self/Reshape_3\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/Reshape_3_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/Reshape_3_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/self/Reshape_3 [Reshape] outputs: [/bert/encoder/layer.1/attention/self/Reshape_3_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/output/dense/MatMul [MatMul]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Reshape_3_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: onnx::MatMul_816\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/output/dense/MatMul [MatMul] inputs: [/bert/encoder/layer.1/attention/self/Reshape_3_output_0 -> (-1, -1, 256)[FLOAT]], [onnx::MatMul_816 -> (256, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: onnx::MatMul_816 for ONNX node: onnx::MatMul_816\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/output/dense/MatMul for ONNX node: /bert/encoder/layer.1/attention/output/dense/MatMul\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/output/dense/MatMul_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/output/dense/MatMul_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/output/dense/MatMul [MatMul] outputs: [/bert/encoder/layer.1/attention/output/dense/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/output/dense/Add [Add]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: bert.encoder.layer.1.attention.output.dense.bias\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/output/dense/MatMul_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/output/dense/Add [Add] inputs: [bert.encoder.layer.1.attention.output.dense.bias -> (256)[FLOAT]], [/bert/encoder/layer.1/attention/output/dense/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: bert.encoder.layer.1.attention.output.dense.bias for ONNX node: bert.encoder.layer.1.attention.output.dense.bias\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/output/dense/Add for ONNX node: /bert/encoder/layer.1/attention/output/dense/Add\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/output/dense/Add_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/output/dense/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/output/dense/Add [Add] outputs: [/bert/encoder/layer.1/attention/output/dense/Add_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/output/Add [Add]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/output/dense/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.0/output/LayerNorm/Add_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/output/Add [Add] inputs: [/bert/encoder/layer.1/attention/output/dense/Add_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.0/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/output/Add for ONNX node: /bert/encoder/layer.1/attention/output/Add\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/output/Add_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/output/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/output/Add [Add] outputs: [/bert/encoder/layer.1/attention/output/Add_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/output/LayerNorm/ReduceMean [ReduceMean]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/output/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/output/LayerNorm/ReduceMean [ReduceMean] inputs: [/bert/encoder/layer.1/attention/output/Add_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/output/LayerNorm/ReduceMean for ONNX node: /bert/encoder/layer.1/attention/output/LayerNorm/ReduceMean\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/output/LayerNorm/ReduceMean_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/output/LayerNorm/ReduceMean_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/output/LayerNorm/ReduceMean [ReduceMean] outputs: [/bert/encoder/layer.1/attention/output/LayerNorm/ReduceMean_output_0 -> (-1, -1, 1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/output/LayerNorm/Sub [Sub]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/output/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/output/LayerNorm/ReduceMean_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/output/LayerNorm/Sub [Sub] inputs: [/bert/encoder/layer.1/attention/output/Add_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.1/attention/output/LayerNorm/ReduceMean_output_0 -> (-1, -1, 1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/output/LayerNorm/Sub for ONNX node: /bert/encoder/layer.1/attention/output/LayerNorm/Sub\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/output/LayerNorm/Sub_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/output/LayerNorm/Sub_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/output/LayerNorm/Sub [Sub] outputs: [/bert/encoder/layer.1/attention/output/LayerNorm/Sub_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/output/LayerNorm/Constant [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/output/LayerNorm/Constant [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/output/LayerNorm/Constant [Constant] outputs: [/bert/encoder/layer.1/attention/output/LayerNorm/Constant_output_0 -> ()[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/output/LayerNorm/Pow [Pow]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/output/LayerNorm/Sub_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/output/LayerNorm/Constant_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/output/LayerNorm/Pow [Pow] inputs: [/bert/encoder/layer.1/attention/output/LayerNorm/Sub_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.1/attention/output/LayerNorm/Constant_output_0 -> ()[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/output/LayerNorm/Constant_output_0 for ONNX node: /bert/encoder/layer.1/attention/output/LayerNorm/Constant_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/output/LayerNorm/Pow for ONNX node: /bert/encoder/layer.1/attention/output/LayerNorm/Pow\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/output/LayerNorm/Pow_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/output/LayerNorm/Pow_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/output/LayerNorm/Pow [Pow] outputs: [/bert/encoder/layer.1/attention/output/LayerNorm/Pow_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/output/LayerNorm/ReduceMean_1 [ReduceMean]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/output/LayerNorm/Pow_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/output/LayerNorm/ReduceMean_1 [ReduceMean] inputs: [/bert/encoder/layer.1/attention/output/LayerNorm/Pow_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/output/LayerNorm/ReduceMean_1 for ONNX node: /bert/encoder/layer.1/attention/output/LayerNorm/ReduceMean_1\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/output/LayerNorm/ReduceMean_1_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/output/LayerNorm/ReduceMean_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/output/LayerNorm/ReduceMean_1 [ReduceMean] outputs: [/bert/encoder/layer.1/attention/output/LayerNorm/ReduceMean_1_output_0 -> (-1, -1, 1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/output/LayerNorm/Constant_1 [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/output/LayerNorm/Constant_1 [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/output/LayerNorm/Constant_1 [Constant] outputs: [/bert/encoder/layer.1/attention/output/LayerNorm/Constant_1_output_0 -> ()[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/output/LayerNorm/Add [Add]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/output/LayerNorm/ReduceMean_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/output/LayerNorm/Constant_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/output/LayerNorm/Add [Add] inputs: [/bert/encoder/layer.1/attention/output/LayerNorm/ReduceMean_1_output_0 -> (-1, -1, 1)[FLOAT]], [/bert/encoder/layer.1/attention/output/LayerNorm/Constant_1_output_0 -> ()[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/output/LayerNorm/Constant_1_output_0 for ONNX node: /bert/encoder/layer.1/attention/output/LayerNorm/Constant_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/output/LayerNorm/Add for ONNX node: /bert/encoder/layer.1/attention/output/LayerNorm/Add\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/output/LayerNorm/Add_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/output/LayerNorm/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/output/LayerNorm/Add [Add] outputs: [/bert/encoder/layer.1/attention/output/LayerNorm/Add_output_0 -> (-1, -1, 1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/output/LayerNorm/Sqrt [Sqrt]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/output/LayerNorm/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/output/LayerNorm/Sqrt [Sqrt] inputs: [/bert/encoder/layer.1/attention/output/LayerNorm/Add_output_0 -> (-1, -1, 1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/output/LayerNorm/Sqrt for ONNX node: /bert/encoder/layer.1/attention/output/LayerNorm/Sqrt\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/output/LayerNorm/Sqrt_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/output/LayerNorm/Sqrt_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/output/LayerNorm/Sqrt [Sqrt] outputs: [/bert/encoder/layer.1/attention/output/LayerNorm/Sqrt_output_0 -> (-1, -1, 1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/output/LayerNorm/Div [Div]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/output/LayerNorm/Sub_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/output/LayerNorm/Sqrt_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/output/LayerNorm/Div [Div] inputs: [/bert/encoder/layer.1/attention/output/LayerNorm/Sub_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.1/attention/output/LayerNorm/Sqrt_output_0 -> (-1, -1, 1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/output/LayerNorm/Div for ONNX node: /bert/encoder/layer.1/attention/output/LayerNorm/Div\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/output/LayerNorm/Div_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/output/LayerNorm/Div_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/output/LayerNorm/Div [Div] outputs: [/bert/encoder/layer.1/attention/output/LayerNorm/Div_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/output/LayerNorm/Mul [Mul]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/output/LayerNorm/Div_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: bert.encoder.layer.1.attention.output.LayerNorm.weight\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/output/LayerNorm/Mul [Mul] inputs: [/bert/encoder/layer.1/attention/output/LayerNorm/Div_output_0 -> (-1, -1, 256)[FLOAT]], [bert.encoder.layer.1.attention.output.LayerNorm.weight -> (256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: bert.encoder.layer.1.attention.output.LayerNorm.weight for ONNX node: bert.encoder.layer.1.attention.output.LayerNorm.weight\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/output/LayerNorm/Mul for ONNX node: /bert/encoder/layer.1/attention/output/LayerNorm/Mul\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/output/LayerNorm/Mul_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/output/LayerNorm/Mul_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/output/LayerNorm/Mul [Mul] outputs: [/bert/encoder/layer.1/attention/output/LayerNorm/Mul_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/output/LayerNorm/Add_1 [Add]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/output/LayerNorm/Mul_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: bert.encoder.layer.1.attention.output.LayerNorm.bias\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/output/LayerNorm/Add_1 [Add] inputs: [/bert/encoder/layer.1/attention/output/LayerNorm/Mul_output_0 -> (-1, -1, 256)[FLOAT]], [bert.encoder.layer.1.attention.output.LayerNorm.bias -> (256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: bert.encoder.layer.1.attention.output.LayerNorm.bias for ONNX node: bert.encoder.layer.1.attention.output.LayerNorm.bias\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/output/LayerNorm/Add_1 for ONNX node: /bert/encoder/layer.1/attention/output/LayerNorm/Add_1\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/output/LayerNorm/Add_1_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/output/LayerNorm/Add_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/attention/output/LayerNorm/Add_1 [Add] outputs: [/bert/encoder/layer.1/attention/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.1/intermediate/dense/MatMul [MatMul]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/output/LayerNorm/Add_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: onnx::MatMul_817\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/intermediate/dense/MatMul [MatMul] inputs: [/bert/encoder/layer.1/attention/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], [onnx::MatMul_817 -> (256, 1024)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: onnx::MatMul_817 for ONNX node: onnx::MatMul_817\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.1/intermediate/dense/MatMul for ONNX node: /bert/encoder/layer.1/intermediate/dense/MatMul\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.1/intermediate/dense/MatMul_output_0 for ONNX tensor: /bert/encoder/layer.1/intermediate/dense/MatMul_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/intermediate/dense/MatMul [MatMul] outputs: [/bert/encoder/layer.1/intermediate/dense/MatMul_output_0 -> (-1, -1, 1024)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.1/intermediate/dense/Add [Add]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: bert.encoder.layer.1.intermediate.dense.bias\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.1/intermediate/dense/MatMul_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/intermediate/dense/Add [Add] inputs: [bert.encoder.layer.1.intermediate.dense.bias -> (1024)[FLOAT]], [/bert/encoder/layer.1/intermediate/dense/MatMul_output_0 -> (-1, -1, 1024)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: bert.encoder.layer.1.intermediate.dense.bias for ONNX node: bert.encoder.layer.1.intermediate.dense.bias\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.1/intermediate/dense/Add for ONNX node: /bert/encoder/layer.1/intermediate/dense/Add\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.1/intermediate/dense/Add_output_0 for ONNX tensor: /bert/encoder/layer.1/intermediate/dense/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/intermediate/dense/Add [Add] outputs: [/bert/encoder/layer.1/intermediate/dense/Add_output_0 -> (-1, -1, 1024)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.1/intermediate/intermediate_act_fn/Constant [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/intermediate/intermediate_act_fn/Constant [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/intermediate/intermediate_act_fn/Constant [Constant] outputs: [/bert/encoder/layer.1/intermediate/intermediate_act_fn/Constant_output_0 -> ()[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.1/intermediate/intermediate_act_fn/Div [Div]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.1/intermediate/dense/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.1/intermediate/intermediate_act_fn/Constant_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/intermediate/intermediate_act_fn/Div [Div] inputs: [/bert/encoder/layer.1/intermediate/dense/Add_output_0 -> (-1, -1, 1024)[FLOAT]], [/bert/encoder/layer.1/intermediate/intermediate_act_fn/Constant_output_0 -> ()[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.1/intermediate/intermediate_act_fn/Constant_output_0 for ONNX node: /bert/encoder/layer.1/intermediate/intermediate_act_fn/Constant_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.1/intermediate/intermediate_act_fn/Div for ONNX node: /bert/encoder/layer.1/intermediate/intermediate_act_fn/Div\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.1/intermediate/intermediate_act_fn/Div_output_0 for ONNX tensor: /bert/encoder/layer.1/intermediate/intermediate_act_fn/Div_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/intermediate/intermediate_act_fn/Div [Div] outputs: [/bert/encoder/layer.1/intermediate/intermediate_act_fn/Div_output_0 -> (-1, -1, 1024)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.1/intermediate/intermediate_act_fn/Erf [Erf]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.1/intermediate/intermediate_act_fn/Div_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/intermediate/intermediate_act_fn/Erf [Erf] inputs: [/bert/encoder/layer.1/intermediate/intermediate_act_fn/Div_output_0 -> (-1, -1, 1024)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.1/intermediate/intermediate_act_fn/Erf for ONNX node: /bert/encoder/layer.1/intermediate/intermediate_act_fn/Erf\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.1/intermediate/intermediate_act_fn/Erf_output_0 for ONNX tensor: /bert/encoder/layer.1/intermediate/intermediate_act_fn/Erf_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/intermediate/intermediate_act_fn/Erf [Erf] outputs: [/bert/encoder/layer.1/intermediate/intermediate_act_fn/Erf_output_0 -> (-1, -1, 1024)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.1/intermediate/intermediate_act_fn/Constant_1 [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/intermediate/intermediate_act_fn/Constant_1 [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/intermediate/intermediate_act_fn/Constant_1 [Constant] outputs: [/bert/encoder/layer.1/intermediate/intermediate_act_fn/Constant_1_output_0 -> ()[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.1/intermediate/intermediate_act_fn/Add [Add]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.1/intermediate/intermediate_act_fn/Erf_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.1/intermediate/intermediate_act_fn/Constant_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/intermediate/intermediate_act_fn/Add [Add] inputs: [/bert/encoder/layer.1/intermediate/intermediate_act_fn/Erf_output_0 -> (-1, -1, 1024)[FLOAT]], [/bert/encoder/layer.1/intermediate/intermediate_act_fn/Constant_1_output_0 -> ()[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.1/intermediate/intermediate_act_fn/Constant_1_output_0 for ONNX node: /bert/encoder/layer.1/intermediate/intermediate_act_fn/Constant_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.1/intermediate/intermediate_act_fn/Add for ONNX node: /bert/encoder/layer.1/intermediate/intermediate_act_fn/Add\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.1/intermediate/intermediate_act_fn/Add_output_0 for ONNX tensor: /bert/encoder/layer.1/intermediate/intermediate_act_fn/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/intermediate/intermediate_act_fn/Add [Add] outputs: [/bert/encoder/layer.1/intermediate/intermediate_act_fn/Add_output_0 -> (-1, -1, 1024)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.1/intermediate/intermediate_act_fn/Mul [Mul]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.1/intermediate/dense/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.1/intermediate/intermediate_act_fn/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/intermediate/intermediate_act_fn/Mul [Mul] inputs: [/bert/encoder/layer.1/intermediate/dense/Add_output_0 -> (-1, -1, 1024)[FLOAT]], [/bert/encoder/layer.1/intermediate/intermediate_act_fn/Add_output_0 -> (-1, -1, 1024)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.1/intermediate/intermediate_act_fn/Mul for ONNX node: /bert/encoder/layer.1/intermediate/intermediate_act_fn/Mul\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.1/intermediate/intermediate_act_fn/Mul_output_0 for ONNX tensor: /bert/encoder/layer.1/intermediate/intermediate_act_fn/Mul_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/intermediate/intermediate_act_fn/Mul [Mul] outputs: [/bert/encoder/layer.1/intermediate/intermediate_act_fn/Mul_output_0 -> (-1, -1, 1024)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.1/intermediate/intermediate_act_fn/Constant_2 [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/intermediate/intermediate_act_fn/Constant_2 [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/intermediate/intermediate_act_fn/Constant_2 [Constant] outputs: [/bert/encoder/layer.1/intermediate/intermediate_act_fn/Constant_2_output_0 -> ()[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.1/intermediate/intermediate_act_fn/Mul_1 [Mul]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.1/intermediate/intermediate_act_fn/Mul_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.1/intermediate/intermediate_act_fn/Constant_2_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/intermediate/intermediate_act_fn/Mul_1 [Mul] inputs: [/bert/encoder/layer.1/intermediate/intermediate_act_fn/Mul_output_0 -> (-1, -1, 1024)[FLOAT]], [/bert/encoder/layer.1/intermediate/intermediate_act_fn/Constant_2_output_0 -> ()[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.1/intermediate/intermediate_act_fn/Constant_2_output_0 for ONNX node: /bert/encoder/layer.1/intermediate/intermediate_act_fn/Constant_2_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.1/intermediate/intermediate_act_fn/Mul_1 for ONNX node: /bert/encoder/layer.1/intermediate/intermediate_act_fn/Mul_1\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.1/intermediate/intermediate_act_fn/Mul_1_output_0 for ONNX tensor: /bert/encoder/layer.1/intermediate/intermediate_act_fn/Mul_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/intermediate/intermediate_act_fn/Mul_1 [Mul] outputs: [/bert/encoder/layer.1/intermediate/intermediate_act_fn/Mul_1_output_0 -> (-1, -1, 1024)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.1/output/dense/MatMul [MatMul]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.1/intermediate/intermediate_act_fn/Mul_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: onnx::MatMul_818\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/output/dense/MatMul [MatMul] inputs: [/bert/encoder/layer.1/intermediate/intermediate_act_fn/Mul_1_output_0 -> (-1, -1, 1024)[FLOAT]], [onnx::MatMul_818 -> (1024, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: onnx::MatMul_818 for ONNX node: onnx::MatMul_818\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.1/output/dense/MatMul for ONNX node: /bert/encoder/layer.1/output/dense/MatMul\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.1/output/dense/MatMul_output_0 for ONNX tensor: /bert/encoder/layer.1/output/dense/MatMul_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/output/dense/MatMul [MatMul] outputs: [/bert/encoder/layer.1/output/dense/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.1/output/dense/Add [Add]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: bert.encoder.layer.1.output.dense.bias\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.1/output/dense/MatMul_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/output/dense/Add [Add] inputs: [bert.encoder.layer.1.output.dense.bias -> (256)[FLOAT]], [/bert/encoder/layer.1/output/dense/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: bert.encoder.layer.1.output.dense.bias for ONNX node: bert.encoder.layer.1.output.dense.bias\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.1/output/dense/Add for ONNX node: /bert/encoder/layer.1/output/dense/Add\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.1/output/dense/Add_output_0 for ONNX tensor: /bert/encoder/layer.1/output/dense/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/output/dense/Add [Add] outputs: [/bert/encoder/layer.1/output/dense/Add_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.1/output/Add [Add]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.1/output/dense/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/output/LayerNorm/Add_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/output/Add [Add] inputs: [/bert/encoder/layer.1/output/dense/Add_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.1/attention/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.1/output/Add for ONNX node: /bert/encoder/layer.1/output/Add\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.1/output/Add_output_0 for ONNX tensor: /bert/encoder/layer.1/output/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/output/Add [Add] outputs: [/bert/encoder/layer.1/output/Add_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.1/output/LayerNorm/ReduceMean [ReduceMean]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.1/output/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/output/LayerNorm/ReduceMean [ReduceMean] inputs: [/bert/encoder/layer.1/output/Add_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.1/output/LayerNorm/ReduceMean for ONNX node: /bert/encoder/layer.1/output/LayerNorm/ReduceMean\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.1/output/LayerNorm/ReduceMean_output_0 for ONNX tensor: /bert/encoder/layer.1/output/LayerNorm/ReduceMean_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/output/LayerNorm/ReduceMean [ReduceMean] outputs: [/bert/encoder/layer.1/output/LayerNorm/ReduceMean_output_0 -> (-1, -1, 1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.1/output/LayerNorm/Sub [Sub]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.1/output/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.1/output/LayerNorm/ReduceMean_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/output/LayerNorm/Sub [Sub] inputs: [/bert/encoder/layer.1/output/Add_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.1/output/LayerNorm/ReduceMean_output_0 -> (-1, -1, 1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.1/output/LayerNorm/Sub for ONNX node: /bert/encoder/layer.1/output/LayerNorm/Sub\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.1/output/LayerNorm/Sub_output_0 for ONNX tensor: /bert/encoder/layer.1/output/LayerNorm/Sub_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/output/LayerNorm/Sub [Sub] outputs: [/bert/encoder/layer.1/output/LayerNorm/Sub_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.1/output/LayerNorm/Constant [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/output/LayerNorm/Constant [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/output/LayerNorm/Constant [Constant] outputs: [/bert/encoder/layer.1/output/LayerNorm/Constant_output_0 -> ()[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.1/output/LayerNorm/Pow [Pow]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.1/output/LayerNorm/Sub_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.1/output/LayerNorm/Constant_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/output/LayerNorm/Pow [Pow] inputs: [/bert/encoder/layer.1/output/LayerNorm/Sub_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.1/output/LayerNorm/Constant_output_0 -> ()[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.1/output/LayerNorm/Constant_output_0 for ONNX node: /bert/encoder/layer.1/output/LayerNorm/Constant_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.1/output/LayerNorm/Pow for ONNX node: /bert/encoder/layer.1/output/LayerNorm/Pow\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.1/output/LayerNorm/Pow_output_0 for ONNX tensor: /bert/encoder/layer.1/output/LayerNorm/Pow_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/output/LayerNorm/Pow [Pow] outputs: [/bert/encoder/layer.1/output/LayerNorm/Pow_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.1/output/LayerNorm/ReduceMean_1 [ReduceMean]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.1/output/LayerNorm/Pow_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/output/LayerNorm/ReduceMean_1 [ReduceMean] inputs: [/bert/encoder/layer.1/output/LayerNorm/Pow_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.1/output/LayerNorm/ReduceMean_1 for ONNX node: /bert/encoder/layer.1/output/LayerNorm/ReduceMean_1\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.1/output/LayerNorm/ReduceMean_1_output_0 for ONNX tensor: /bert/encoder/layer.1/output/LayerNorm/ReduceMean_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/output/LayerNorm/ReduceMean_1 [ReduceMean] outputs: [/bert/encoder/layer.1/output/LayerNorm/ReduceMean_1_output_0 -> (-1, -1, 1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.1/output/LayerNorm/Constant_1 [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/output/LayerNorm/Constant_1 [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/output/LayerNorm/Constant_1 [Constant] outputs: [/bert/encoder/layer.1/output/LayerNorm/Constant_1_output_0 -> ()[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.1/output/LayerNorm/Add [Add]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.1/output/LayerNorm/ReduceMean_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.1/output/LayerNorm/Constant_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/output/LayerNorm/Add [Add] inputs: [/bert/encoder/layer.1/output/LayerNorm/ReduceMean_1_output_0 -> (-1, -1, 1)[FLOAT]], [/bert/encoder/layer.1/output/LayerNorm/Constant_1_output_0 -> ()[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.1/output/LayerNorm/Constant_1_output_0 for ONNX node: /bert/encoder/layer.1/output/LayerNorm/Constant_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.1/output/LayerNorm/Add for ONNX node: /bert/encoder/layer.1/output/LayerNorm/Add\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.1/output/LayerNorm/Add_output_0 for ONNX tensor: /bert/encoder/layer.1/output/LayerNorm/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/output/LayerNorm/Add [Add] outputs: [/bert/encoder/layer.1/output/LayerNorm/Add_output_0 -> (-1, -1, 1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.1/output/LayerNorm/Sqrt [Sqrt]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.1/output/LayerNorm/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/output/LayerNorm/Sqrt [Sqrt] inputs: [/bert/encoder/layer.1/output/LayerNorm/Add_output_0 -> (-1, -1, 1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.1/output/LayerNorm/Sqrt for ONNX node: /bert/encoder/layer.1/output/LayerNorm/Sqrt\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.1/output/LayerNorm/Sqrt_output_0 for ONNX tensor: /bert/encoder/layer.1/output/LayerNorm/Sqrt_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/output/LayerNorm/Sqrt [Sqrt] outputs: [/bert/encoder/layer.1/output/LayerNorm/Sqrt_output_0 -> (-1, -1, 1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.1/output/LayerNorm/Div [Div]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.1/output/LayerNorm/Sub_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.1/output/LayerNorm/Sqrt_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/output/LayerNorm/Div [Div] inputs: [/bert/encoder/layer.1/output/LayerNorm/Sub_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.1/output/LayerNorm/Sqrt_output_0 -> (-1, -1, 1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.1/output/LayerNorm/Div for ONNX node: /bert/encoder/layer.1/output/LayerNorm/Div\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.1/output/LayerNorm/Div_output_0 for ONNX tensor: /bert/encoder/layer.1/output/LayerNorm/Div_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/output/LayerNorm/Div [Div] outputs: [/bert/encoder/layer.1/output/LayerNorm/Div_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.1/output/LayerNorm/Mul [Mul]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.1/output/LayerNorm/Div_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: bert.encoder.layer.1.output.LayerNorm.weight\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/output/LayerNorm/Mul [Mul] inputs: [/bert/encoder/layer.1/output/LayerNorm/Div_output_0 -> (-1, -1, 256)[FLOAT]], [bert.encoder.layer.1.output.LayerNorm.weight -> (256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: bert.encoder.layer.1.output.LayerNorm.weight for ONNX node: bert.encoder.layer.1.output.LayerNorm.weight\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.1/output/LayerNorm/Mul for ONNX node: /bert/encoder/layer.1/output/LayerNorm/Mul\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.1/output/LayerNorm/Mul_output_0 for ONNX tensor: /bert/encoder/layer.1/output/LayerNorm/Mul_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/output/LayerNorm/Mul [Mul] outputs: [/bert/encoder/layer.1/output/LayerNorm/Mul_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.1/output/LayerNorm/Add_1 [Add]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.1/output/LayerNorm/Mul_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: bert.encoder.layer.1.output.LayerNorm.bias\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/output/LayerNorm/Add_1 [Add] inputs: [/bert/encoder/layer.1/output/LayerNorm/Mul_output_0 -> (-1, -1, 256)[FLOAT]], [bert.encoder.layer.1.output.LayerNorm.bias -> (256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: bert.encoder.layer.1.output.LayerNorm.bias for ONNX node: bert.encoder.layer.1.output.LayerNorm.bias\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.1/output/LayerNorm/Add_1 for ONNX node: /bert/encoder/layer.1/output/LayerNorm/Add_1\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.1/output/LayerNorm/Add_1_output_0 for ONNX tensor: /bert/encoder/layer.1/output/LayerNorm/Add_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.1/output/LayerNorm/Add_1 [Add] outputs: [/bert/encoder/layer.1/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/query/MatMul [MatMul]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.1/output/LayerNorm/Add_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: onnx::MatMul_819\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/self/query/MatMul [MatMul] inputs: [/bert/encoder/layer.1/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], [onnx::MatMul_819 -> (256, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: onnx::MatMul_819 for ONNX node: onnx::MatMul_819\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/query/MatMul for ONNX node: /bert/encoder/layer.2/attention/self/query/MatMul\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/query/MatMul_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/query/MatMul_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/self/query/MatMul [MatMul] outputs: [/bert/encoder/layer.2/attention/self/query/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/query/Add [Add]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: bert.encoder.layer.2.attention.self.query.bias\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/query/MatMul_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/self/query/Add [Add] inputs: [bert.encoder.layer.2.attention.self.query.bias -> (256)[FLOAT]], [/bert/encoder/layer.2/attention/self/query/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: bert.encoder.layer.2.attention.self.query.bias for ONNX node: bert.encoder.layer.2.attention.self.query.bias\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/query/Add for ONNX node: /bert/encoder/layer.2/attention/self/query/Add\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/query/Add_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/query/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/self/query/Add [Add] outputs: [/bert/encoder/layer.2/attention/self/query/Add_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/key/MatMul [MatMul]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.1/output/LayerNorm/Add_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: onnx::MatMul_820\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/self/key/MatMul [MatMul] inputs: [/bert/encoder/layer.1/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], [onnx::MatMul_820 -> (256, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: onnx::MatMul_820 for ONNX node: onnx::MatMul_820\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/key/MatMul for ONNX node: /bert/encoder/layer.2/attention/self/key/MatMul\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/key/MatMul_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/key/MatMul_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/self/key/MatMul [MatMul] outputs: [/bert/encoder/layer.2/attention/self/key/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/key/Add [Add]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: bert.encoder.layer.2.attention.self.key.bias\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/key/MatMul_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/self/key/Add [Add] inputs: [bert.encoder.layer.2.attention.self.key.bias -> (256)[FLOAT]], [/bert/encoder/layer.2/attention/self/key/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: bert.encoder.layer.2.attention.self.key.bias for ONNX node: bert.encoder.layer.2.attention.self.key.bias\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/key/Add for ONNX node: /bert/encoder/layer.2/attention/self/key/Add\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/key/Add_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/key/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/self/key/Add [Add] outputs: [/bert/encoder/layer.2/attention/self/key/Add_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Shape [Shape]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/key/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/self/Shape [Shape] inputs: [/bert/encoder/layer.2/attention/self/key/Add_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Shape for ONNX node: /bert/encoder/layer.2/attention/self/Shape\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/Shape_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/Shape_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/self/Shape [Shape] outputs: [/bert/encoder/layer.2/attention/self/Shape_output_0 -> (3)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Constant [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/self/Constant [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/self/Constant [Constant] outputs: [/bert/encoder/layer.2/attention/self/Constant_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Gather [Gather]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Shape_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Constant_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/self/Gather [Gather] inputs: [/bert/encoder/layer.2/attention/self/Shape_output_0 -> (3)[INT32]], [/bert/encoder/layer.2/attention/self/Constant_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Constant_output_0 for ONNX node: /bert/encoder/layer.2/attention/self/Constant_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Using Gather axis: 0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Gather for ONNX node: /bert/encoder/layer.2/attention/self/Gather\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/Gather_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/Gather_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/self/Gather [Gather] outputs: [/bert/encoder/layer.2/attention/self/Gather_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Shape_1 [Shape]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/key/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/self/Shape_1 [Shape] inputs: [/bert/encoder/layer.2/attention/self/key/Add_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Shape_1 for ONNX node: /bert/encoder/layer.2/attention/self/Shape_1\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/Shape_1_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/Shape_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/self/Shape_1 [Shape] outputs: [/bert/encoder/layer.2/attention/self/Shape_1_output_0 -> (3)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Constant_1 [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/self/Constant_1 [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/self/Constant_1 [Constant] outputs: [/bert/encoder/layer.2/attention/self/Constant_1_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Gather_1 [Gather]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Shape_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Constant_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/self/Gather_1 [Gather] inputs: [/bert/encoder/layer.2/attention/self/Shape_1_output_0 -> (3)[INT32]], [/bert/encoder/layer.2/attention/self/Constant_1_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Constant_1_output_0 for ONNX node: /bert/encoder/layer.2/attention/self/Constant_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Using Gather axis: 0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Gather_1 for ONNX node: /bert/encoder/layer.2/attention/self/Gather_1\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/Gather_1_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/Gather_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/self/Gather_1 [Gather] outputs: [/bert/encoder/layer.2/attention/self/Gather_1_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Unsqueeze [Unsqueeze]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Gather_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/self/Unsqueeze [Unsqueeze] inputs: [/bert/encoder/layer.2/attention/self/Gather_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Original shape: (), unsqueezing to: (1,)\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Unsqueeze for ONNX node: /bert/encoder/layer.2/attention/self/Unsqueeze\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/Unsqueeze_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/Unsqueeze_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/self/Unsqueeze [Unsqueeze] outputs: [/bert/encoder/layer.2/attention/self/Unsqueeze_output_0 -> (1)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Unsqueeze_1 [Unsqueeze]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Gather_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/self/Unsqueeze_1 [Unsqueeze] inputs: [/bert/encoder/layer.2/attention/self/Gather_1_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Original shape: (), unsqueezing to: (1,)\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Unsqueeze_1 for ONNX node: /bert/encoder/layer.2/attention/self/Unsqueeze_1\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/Unsqueeze_1_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/Unsqueeze_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/self/Unsqueeze_1 [Unsqueeze] outputs: [/bert/encoder/layer.2/attention/self/Unsqueeze_1_output_0 -> (1)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Constant_2 [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/self/Constant_2 [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/self/Constant_2 [Constant] outputs: [/bert/encoder/layer.2/attention/self/Constant_2_output_0 -> (1)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Constant_3 [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/self/Constant_3 [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/self/Constant_3 [Constant] outputs: [/bert/encoder/layer.2/attention/self/Constant_3_output_0 -> (1)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Concat [Concat]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Unsqueeze_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Unsqueeze_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Constant_2_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Constant_3_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/self/Concat [Concat] inputs: [/bert/encoder/layer.2/attention/self/Unsqueeze_output_0 -> (1)[INT32]], [/bert/encoder/layer.2/attention/self/Unsqueeze_1_output_0 -> (1)[INT32]], [/bert/encoder/layer.2/attention/self/Constant_2_output_0 -> (1)[INT32]], [/bert/encoder/layer.2/attention/self/Constant_3_output_0 -> (1)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Constant_2_output_0 for ONNX node: /bert/encoder/layer.2/attention/self/Constant_2_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Constant_3_output_0 for ONNX node: /bert/encoder/layer.2/attention/self/Constant_3_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Concat for ONNX node: /bert/encoder/layer.2/attention/self/Concat\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/Concat_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/Concat_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/self/Concat [Concat] outputs: [/bert/encoder/layer.2/attention/self/Concat_output_0 -> (4)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Reshape [Reshape]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/key/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Concat_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/self/Reshape [Reshape] inputs: [/bert/encoder/layer.2/attention/self/key/Add_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.2/attention/self/Concat_output_0 -> (4)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Reshape for ONNX node: /bert/encoder/layer.2/attention/self/Reshape\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/Reshape_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/Reshape_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/self/Reshape [Reshape] outputs: [/bert/encoder/layer.2/attention/self/Reshape_output_0 -> (-1, -1, 8, 32)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/value/MatMul [MatMul]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.1/output/LayerNorm/Add_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: onnx::MatMul_823\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/self/value/MatMul [MatMul] inputs: [/bert/encoder/layer.1/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], [onnx::MatMul_823 -> (256, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: onnx::MatMul_823 for ONNX node: onnx::MatMul_823\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/value/MatMul for ONNX node: /bert/encoder/layer.2/attention/self/value/MatMul\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/value/MatMul_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/value/MatMul_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/self/value/MatMul [MatMul] outputs: [/bert/encoder/layer.2/attention/self/value/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/value/Add [Add]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: bert.encoder.layer.2.attention.self.value.bias\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/value/MatMul_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/self/value/Add [Add] inputs: [bert.encoder.layer.2.attention.self.value.bias -> (256)[FLOAT]], [/bert/encoder/layer.2/attention/self/value/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: bert.encoder.layer.2.attention.self.value.bias for ONNX node: bert.encoder.layer.2.attention.self.value.bias\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/value/Add for ONNX node: /bert/encoder/layer.2/attention/self/value/Add\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/value/Add_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/value/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/self/value/Add [Add] outputs: [/bert/encoder/layer.2/attention/self/value/Add_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Shape_2 [Shape]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/value/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/self/Shape_2 [Shape] inputs: [/bert/encoder/layer.2/attention/self/value/Add_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Shape_2 for ONNX node: /bert/encoder/layer.2/attention/self/Shape_2\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/Shape_2_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/Shape_2_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/self/Shape_2 [Shape] outputs: [/bert/encoder/layer.2/attention/self/Shape_2_output_0 -> (3)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Constant_4 [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/self/Constant_4 [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/self/Constant_4 [Constant] outputs: [/bert/encoder/layer.2/attention/self/Constant_4_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Gather_2 [Gather]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Shape_2_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Constant_4_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/self/Gather_2 [Gather] inputs: [/bert/encoder/layer.2/attention/self/Shape_2_output_0 -> (3)[INT32]], [/bert/encoder/layer.2/attention/self/Constant_4_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Constant_4_output_0 for ONNX node: /bert/encoder/layer.2/attention/self/Constant_4_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Using Gather axis: 0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Gather_2 for ONNX node: /bert/encoder/layer.2/attention/self/Gather_2\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/Gather_2_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/Gather_2_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/self/Gather_2 [Gather] outputs: [/bert/encoder/layer.2/attention/self/Gather_2_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Shape_3 [Shape]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/value/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/self/Shape_3 [Shape] inputs: [/bert/encoder/layer.2/attention/self/value/Add_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Shape_3 for ONNX node: /bert/encoder/layer.2/attention/self/Shape_3\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/Shape_3_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/Shape_3_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/self/Shape_3 [Shape] outputs: [/bert/encoder/layer.2/attention/self/Shape_3_output_0 -> (3)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Constant_5 [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/self/Constant_5 [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/self/Constant_5 [Constant] outputs: [/bert/encoder/layer.2/attention/self/Constant_5_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Gather_3 [Gather]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Shape_3_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Constant_5_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/self/Gather_3 [Gather] inputs: [/bert/encoder/layer.2/attention/self/Shape_3_output_0 -> (3)[INT32]], [/bert/encoder/layer.2/attention/self/Constant_5_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Constant_5_output_0 for ONNX node: /bert/encoder/layer.2/attention/self/Constant_5_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Using Gather axis: 0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Gather_3 for ONNX node: /bert/encoder/layer.2/attention/self/Gather_3\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/Gather_3_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/Gather_3_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/self/Gather_3 [Gather] outputs: [/bert/encoder/layer.2/attention/self/Gather_3_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Unsqueeze_2 [Unsqueeze]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Gather_2_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/self/Unsqueeze_2 [Unsqueeze] inputs: [/bert/encoder/layer.2/attention/self/Gather_2_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Original shape: (), unsqueezing to: (1,)\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Unsqueeze_2 for ONNX node: /bert/encoder/layer.2/attention/self/Unsqueeze_2\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/Unsqueeze_2_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/Unsqueeze_2_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/self/Unsqueeze_2 [Unsqueeze] outputs: [/bert/encoder/layer.2/attention/self/Unsqueeze_2_output_0 -> (1)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Unsqueeze_3 [Unsqueeze]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Gather_3_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/self/Unsqueeze_3 [Unsqueeze] inputs: [/bert/encoder/layer.2/attention/self/Gather_3_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Original shape: (), unsqueezing to: (1,)\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Unsqueeze_3 for ONNX node: /bert/encoder/layer.2/attention/self/Unsqueeze_3\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/Unsqueeze_3_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/Unsqueeze_3_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/self/Unsqueeze_3 [Unsqueeze] outputs: [/bert/encoder/layer.2/attention/self/Unsqueeze_3_output_0 -> (1)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Constant_6 [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/self/Constant_6 [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/self/Constant_6 [Constant] outputs: [/bert/encoder/layer.2/attention/self/Constant_6_output_0 -> (1)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Constant_7 [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/self/Constant_7 [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/self/Constant_7 [Constant] outputs: [/bert/encoder/layer.2/attention/self/Constant_7_output_0 -> (1)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Concat_1 [Concat]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Unsqueeze_2_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Unsqueeze_3_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Constant_6_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Constant_7_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/self/Concat_1 [Concat] inputs: [/bert/encoder/layer.2/attention/self/Unsqueeze_2_output_0 -> (1)[INT32]], [/bert/encoder/layer.2/attention/self/Unsqueeze_3_output_0 -> (1)[INT32]], [/bert/encoder/layer.2/attention/self/Constant_6_output_0 -> (1)[INT32]], [/bert/encoder/layer.2/attention/self/Constant_7_output_0 -> (1)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Constant_6_output_0 for ONNX node: /bert/encoder/layer.2/attention/self/Constant_6_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Constant_7_output_0 for ONNX node: /bert/encoder/layer.2/attention/self/Constant_7_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Concat_1 for ONNX node: /bert/encoder/layer.2/attention/self/Concat_1\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/Concat_1_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/Concat_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/self/Concat_1 [Concat] outputs: [/bert/encoder/layer.2/attention/self/Concat_1_output_0 -> (4)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Reshape_1 [Reshape]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/value/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Concat_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/self/Reshape_1 [Reshape] inputs: [/bert/encoder/layer.2/attention/self/value/Add_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.2/attention/self/Concat_1_output_0 -> (4)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Reshape_1 for ONNX node: /bert/encoder/layer.2/attention/self/Reshape_1\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/Reshape_1_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/Reshape_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/self/Reshape_1 [Reshape] outputs: [/bert/encoder/layer.2/attention/self/Reshape_1_output_0 -> (-1, -1, 8, 32)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Transpose [Transpose]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Reshape_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/self/Transpose [Transpose] inputs: [/bert/encoder/layer.2/attention/self/Reshape_1_output_0 -> (-1, -1, 8, 32)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Transpose for ONNX node: /bert/encoder/layer.2/attention/self/Transpose\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/Transpose_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/Transpose_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/self/Transpose [Transpose] outputs: [/bert/encoder/layer.2/attention/self/Transpose_output_0 -> (-1, 8, -1, 32)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Shape_4 [Shape]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/query/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/self/Shape_4 [Shape] inputs: [/bert/encoder/layer.2/attention/self/query/Add_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Shape_4 for ONNX node: /bert/encoder/layer.2/attention/self/Shape_4\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/Shape_4_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/Shape_4_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/self/Shape_4 [Shape] outputs: [/bert/encoder/layer.2/attention/self/Shape_4_output_0 -> (3)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Constant_8 [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/self/Constant_8 [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/self/Constant_8 [Constant] outputs: [/bert/encoder/layer.2/attention/self/Constant_8_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Gather_4 [Gather]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Shape_4_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Constant_8_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/self/Gather_4 [Gather] inputs: [/bert/encoder/layer.2/attention/self/Shape_4_output_0 -> (3)[INT32]], [/bert/encoder/layer.2/attention/self/Constant_8_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Constant_8_output_0 for ONNX node: /bert/encoder/layer.2/attention/self/Constant_8_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Using Gather axis: 0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Gather_4 for ONNX node: /bert/encoder/layer.2/attention/self/Gather_4\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/Gather_4_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/Gather_4_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/self/Gather_4 [Gather] outputs: [/bert/encoder/layer.2/attention/self/Gather_4_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Shape_5 [Shape]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/query/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/self/Shape_5 [Shape] inputs: [/bert/encoder/layer.2/attention/self/query/Add_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Shape_5 for ONNX node: /bert/encoder/layer.2/attention/self/Shape_5\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/Shape_5_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/Shape_5_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/self/Shape_5 [Shape] outputs: [/bert/encoder/layer.2/attention/self/Shape_5_output_0 -> (3)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Constant_9 [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/self/Constant_9 [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/self/Constant_9 [Constant] outputs: [/bert/encoder/layer.2/attention/self/Constant_9_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Gather_5 [Gather]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Shape_5_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Constant_9_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/self/Gather_5 [Gather] inputs: [/bert/encoder/layer.2/attention/self/Shape_5_output_0 -> (3)[INT32]], [/bert/encoder/layer.2/attention/self/Constant_9_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Constant_9_output_0 for ONNX node: /bert/encoder/layer.2/attention/self/Constant_9_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Using Gather axis: 0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Gather_5 for ONNX node: /bert/encoder/layer.2/attention/self/Gather_5\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/Gather_5_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/Gather_5_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/self/Gather_5 [Gather] outputs: [/bert/encoder/layer.2/attention/self/Gather_5_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Unsqueeze_4 [Unsqueeze]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Gather_4_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/self/Unsqueeze_4 [Unsqueeze] inputs: [/bert/encoder/layer.2/attention/self/Gather_4_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Original shape: (), unsqueezing to: (1,)\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Unsqueeze_4 for ONNX node: /bert/encoder/layer.2/attention/self/Unsqueeze_4\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/Unsqueeze_4_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/Unsqueeze_4_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/self/Unsqueeze_4 [Unsqueeze] outputs: [/bert/encoder/layer.2/attention/self/Unsqueeze_4_output_0 -> (1)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Unsqueeze_5 [Unsqueeze]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Gather_5_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/self/Unsqueeze_5 [Unsqueeze] inputs: [/bert/encoder/layer.2/attention/self/Gather_5_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Original shape: (), unsqueezing to: (1,)\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Unsqueeze_5 for ONNX node: /bert/encoder/layer.2/attention/self/Unsqueeze_5\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/Unsqueeze_5_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/Unsqueeze_5_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/self/Unsqueeze_5 [Unsqueeze] outputs: [/bert/encoder/layer.2/attention/self/Unsqueeze_5_output_0 -> (1)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Constant_10 [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/self/Constant_10 [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/self/Constant_10 [Constant] outputs: [/bert/encoder/layer.2/attention/self/Constant_10_output_0 -> (1)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Constant_11 [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/self/Constant_11 [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/self/Constant_11 [Constant] outputs: [/bert/encoder/layer.2/attention/self/Constant_11_output_0 -> (1)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Concat_2 [Concat]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Unsqueeze_4_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Unsqueeze_5_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Constant_10_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Constant_11_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/self/Concat_2 [Concat] inputs: [/bert/encoder/layer.2/attention/self/Unsqueeze_4_output_0 -> (1)[INT32]], [/bert/encoder/layer.2/attention/self/Unsqueeze_5_output_0 -> (1)[INT32]], [/bert/encoder/layer.2/attention/self/Constant_10_output_0 -> (1)[INT32]], [/bert/encoder/layer.2/attention/self/Constant_11_output_0 -> (1)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Constant_10_output_0 for ONNX node: /bert/encoder/layer.2/attention/self/Constant_10_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Constant_11_output_0 for ONNX node: /bert/encoder/layer.2/attention/self/Constant_11_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Concat_2 for ONNX node: /bert/encoder/layer.2/attention/self/Concat_2\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/Concat_2_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/Concat_2_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/self/Concat_2 [Concat] outputs: [/bert/encoder/layer.2/attention/self/Concat_2_output_0 -> (4)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Reshape_2 [Reshape]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/query/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Concat_2_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/self/Reshape_2 [Reshape] inputs: [/bert/encoder/layer.2/attention/self/query/Add_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.2/attention/self/Concat_2_output_0 -> (4)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Reshape_2 for ONNX node: /bert/encoder/layer.2/attention/self/Reshape_2\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/Reshape_2_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/Reshape_2_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/self/Reshape_2 [Reshape] outputs: [/bert/encoder/layer.2/attention/self/Reshape_2_output_0 -> (-1, -1, 8, 32)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Transpose_1 [Transpose]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Reshape_2_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/self/Transpose_1 [Transpose] inputs: [/bert/encoder/layer.2/attention/self/Reshape_2_output_0 -> (-1, -1, 8, 32)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Transpose_1 for ONNX node: /bert/encoder/layer.2/attention/self/Transpose_1\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/Transpose_1_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/Transpose_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/self/Transpose_1 [Transpose] outputs: [/bert/encoder/layer.2/attention/self/Transpose_1_output_0 -> (-1, 8, -1, 32)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Transpose_2 [Transpose]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Reshape_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/self/Transpose_2 [Transpose] inputs: [/bert/encoder/layer.2/attention/self/Reshape_output_0 -> (-1, -1, 8, 32)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Transpose_2 for ONNX node: /bert/encoder/layer.2/attention/self/Transpose_2\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/Transpose_2_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/Transpose_2_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/self/Transpose_2 [Transpose] outputs: [/bert/encoder/layer.2/attention/self/Transpose_2_output_0 -> (-1, 8, 32, -1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/MatMul [MatMul]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Transpose_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Transpose_2_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/self/MatMul [MatMul] inputs: [/bert/encoder/layer.2/attention/self/Transpose_1_output_0 -> (-1, 8, -1, 32)[FLOAT]], [/bert/encoder/layer.2/attention/self/Transpose_2_output_0 -> (-1, 8, 32, -1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/MatMul for ONNX node: /bert/encoder/layer.2/attention/self/MatMul\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/MatMul_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/MatMul_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/self/MatMul [MatMul] outputs: [/bert/encoder/layer.2/attention/self/MatMul_output_0 -> (-1, 8, -1, -1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Constant_12 [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/self/Constant_12 [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/self/Constant_12 [Constant] outputs: [/bert/encoder/layer.2/attention/self/Constant_12_output_0 -> ()[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Div [Div]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/MatMul_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Constant_12_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/self/Div [Div] inputs: [/bert/encoder/layer.2/attention/self/MatMul_output_0 -> (-1, 8, -1, -1)[FLOAT]], [/bert/encoder/layer.2/attention/self/Constant_12_output_0 -> ()[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Constant_12_output_0 for ONNX node: /bert/encoder/layer.2/attention/self/Constant_12_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Div for ONNX node: /bert/encoder/layer.2/attention/self/Div\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/Div_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/Div_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/self/Div [Div] outputs: [/bert/encoder/layer.2/attention/self/Div_output_0 -> (-1, 8, -1, -1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Add [Add]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Div_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/Mul_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/self/Add [Add] inputs: [/bert/encoder/layer.2/attention/self/Div_output_0 -> (-1, 8, -1, -1)[FLOAT]], [/bert/Mul_output_0 -> (-1, 1, 1, -1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Add for ONNX node: /bert/encoder/layer.2/attention/self/Add\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/Add_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/self/Add [Add] outputs: [/bert/encoder/layer.2/attention/self/Add_output_0 -> (-1, 8, -1, -1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Softmax [Softmax]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/self/Softmax [Softmax] inputs: [/bert/encoder/layer.2/attention/self/Add_output_0 -> (-1, 8, -1, -1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Softmax for ONNX node: /bert/encoder/layer.2/attention/self/Softmax\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/Softmax_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/Softmax_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/self/Softmax [Softmax] outputs: [/bert/encoder/layer.2/attention/self/Softmax_output_0 -> (-1, 8, -1, -1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/MatMul_1 [MatMul]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Softmax_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Transpose_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/self/MatMul_1 [MatMul] inputs: [/bert/encoder/layer.2/attention/self/Softmax_output_0 -> (-1, 8, -1, -1)[FLOAT]], [/bert/encoder/layer.2/attention/self/Transpose_output_0 -> (-1, 8, -1, 32)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/MatMul_1 for ONNX node: /bert/encoder/layer.2/attention/self/MatMul_1\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/MatMul_1_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/MatMul_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/self/MatMul_1 [MatMul] outputs: [/bert/encoder/layer.2/attention/self/MatMul_1_output_0 -> (-1, 8, -1, 32)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Transpose_3 [Transpose]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/MatMul_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/self/Transpose_3 [Transpose] inputs: [/bert/encoder/layer.2/attention/self/MatMul_1_output_0 -> (-1, 8, -1, 32)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Transpose_3 for ONNX node: /bert/encoder/layer.2/attention/self/Transpose_3\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/Transpose_3_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/Transpose_3_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/self/Transpose_3 [Transpose] outputs: [/bert/encoder/layer.2/attention/self/Transpose_3_output_0 -> (-1, -1, 8, 32)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Shape_6 [Shape]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Transpose_3_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/self/Shape_6 [Shape] inputs: [/bert/encoder/layer.2/attention/self/Transpose_3_output_0 -> (-1, -1, 8, 32)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Shape_6 for ONNX node: /bert/encoder/layer.2/attention/self/Shape_6\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/Shape_6_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/Shape_6_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/self/Shape_6 [Shape] outputs: [/bert/encoder/layer.2/attention/self/Shape_6_output_0 -> (4)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Constant_13 [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/self/Constant_13 [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/self/Constant_13 [Constant] outputs: [/bert/encoder/layer.2/attention/self/Constant_13_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Gather_6 [Gather]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Shape_6_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Constant_13_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/self/Gather_6 [Gather] inputs: [/bert/encoder/layer.2/attention/self/Shape_6_output_0 -> (4)[INT32]], [/bert/encoder/layer.2/attention/self/Constant_13_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Constant_13_output_0 for ONNX node: /bert/encoder/layer.2/attention/self/Constant_13_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Using Gather axis: 0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Gather_6 for ONNX node: /bert/encoder/layer.2/attention/self/Gather_6\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/Gather_6_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/Gather_6_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/self/Gather_6 [Gather] outputs: [/bert/encoder/layer.2/attention/self/Gather_6_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Shape_7 [Shape]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Transpose_3_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/self/Shape_7 [Shape] inputs: [/bert/encoder/layer.2/attention/self/Transpose_3_output_0 -> (-1, -1, 8, 32)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Shape_7 for ONNX node: /bert/encoder/layer.2/attention/self/Shape_7\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/Shape_7_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/Shape_7_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/self/Shape_7 [Shape] outputs: [/bert/encoder/layer.2/attention/self/Shape_7_output_0 -> (4)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Constant_14 [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/self/Constant_14 [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/self/Constant_14 [Constant] outputs: [/bert/encoder/layer.2/attention/self/Constant_14_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Gather_7 [Gather]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Shape_7_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Constant_14_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/self/Gather_7 [Gather] inputs: [/bert/encoder/layer.2/attention/self/Shape_7_output_0 -> (4)[INT32]], [/bert/encoder/layer.2/attention/self/Constant_14_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Constant_14_output_0 for ONNX node: /bert/encoder/layer.2/attention/self/Constant_14_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Using Gather axis: 0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Gather_7 for ONNX node: /bert/encoder/layer.2/attention/self/Gather_7\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/Gather_7_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/Gather_7_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/self/Gather_7 [Gather] outputs: [/bert/encoder/layer.2/attention/self/Gather_7_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Unsqueeze_6 [Unsqueeze]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Gather_6_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/self/Unsqueeze_6 [Unsqueeze] inputs: [/bert/encoder/layer.2/attention/self/Gather_6_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Original shape: (), unsqueezing to: (1,)\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Unsqueeze_6 for ONNX node: /bert/encoder/layer.2/attention/self/Unsqueeze_6\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/Unsqueeze_6_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/Unsqueeze_6_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/self/Unsqueeze_6 [Unsqueeze] outputs: [/bert/encoder/layer.2/attention/self/Unsqueeze_6_output_0 -> (1)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Unsqueeze_7 [Unsqueeze]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Gather_7_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/self/Unsqueeze_7 [Unsqueeze] inputs: [/bert/encoder/layer.2/attention/self/Gather_7_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Original shape: (), unsqueezing to: (1,)\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Unsqueeze_7 for ONNX node: /bert/encoder/layer.2/attention/self/Unsqueeze_7\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/Unsqueeze_7_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/Unsqueeze_7_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/self/Unsqueeze_7 [Unsqueeze] outputs: [/bert/encoder/layer.2/attention/self/Unsqueeze_7_output_0 -> (1)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Constant_15 [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/self/Constant_15 [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/self/Constant_15 [Constant] outputs: [/bert/encoder/layer.2/attention/self/Constant_15_output_0 -> (1)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Concat_3 [Concat]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Unsqueeze_6_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Unsqueeze_7_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Constant_15_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/self/Concat_3 [Concat] inputs: [/bert/encoder/layer.2/attention/self/Unsqueeze_6_output_0 -> (1)[INT32]], [/bert/encoder/layer.2/attention/self/Unsqueeze_7_output_0 -> (1)[INT32]], [/bert/encoder/layer.2/attention/self/Constant_15_output_0 -> (1)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Constant_15_output_0 for ONNX node: /bert/encoder/layer.2/attention/self/Constant_15_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Concat_3 for ONNX node: /bert/encoder/layer.2/attention/self/Concat_3\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/Concat_3_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/Concat_3_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/self/Concat_3 [Concat] outputs: [/bert/encoder/layer.2/attention/self/Concat_3_output_0 -> (3)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Reshape_3 [Reshape]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Transpose_3_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Concat_3_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/self/Reshape_3 [Reshape] inputs: [/bert/encoder/layer.2/attention/self/Transpose_3_output_0 -> (-1, -1, 8, 32)[FLOAT]], [/bert/encoder/layer.2/attention/self/Concat_3_output_0 -> (3)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Reshape_3 for ONNX node: /bert/encoder/layer.2/attention/self/Reshape_3\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/Reshape_3_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/Reshape_3_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/self/Reshape_3 [Reshape] outputs: [/bert/encoder/layer.2/attention/self/Reshape_3_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/output/dense/MatMul [MatMul]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Reshape_3_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: onnx::MatMul_829\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/output/dense/MatMul [MatMul] inputs: [/bert/encoder/layer.2/attention/self/Reshape_3_output_0 -> (-1, -1, 256)[FLOAT]], [onnx::MatMul_829 -> (256, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: onnx::MatMul_829 for ONNX node: onnx::MatMul_829\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/output/dense/MatMul for ONNX node: /bert/encoder/layer.2/attention/output/dense/MatMul\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/output/dense/MatMul_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/output/dense/MatMul_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/output/dense/MatMul [MatMul] outputs: [/bert/encoder/layer.2/attention/output/dense/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/output/dense/Add [Add]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: bert.encoder.layer.2.attention.output.dense.bias\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/output/dense/MatMul_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/output/dense/Add [Add] inputs: [bert.encoder.layer.2.attention.output.dense.bias -> (256)[FLOAT]], [/bert/encoder/layer.2/attention/output/dense/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: bert.encoder.layer.2.attention.output.dense.bias for ONNX node: bert.encoder.layer.2.attention.output.dense.bias\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/output/dense/Add for ONNX node: /bert/encoder/layer.2/attention/output/dense/Add\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/output/dense/Add_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/output/dense/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/output/dense/Add [Add] outputs: [/bert/encoder/layer.2/attention/output/dense/Add_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/output/Add [Add]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/output/dense/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.1/output/LayerNorm/Add_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/output/Add [Add] inputs: [/bert/encoder/layer.2/attention/output/dense/Add_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.1/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/output/Add for ONNX node: /bert/encoder/layer.2/attention/output/Add\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/output/Add_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/output/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/output/Add [Add] outputs: [/bert/encoder/layer.2/attention/output/Add_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/output/LayerNorm/ReduceMean [ReduceMean]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/output/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/output/LayerNorm/ReduceMean [ReduceMean] inputs: [/bert/encoder/layer.2/attention/output/Add_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/output/LayerNorm/ReduceMean for ONNX node: /bert/encoder/layer.2/attention/output/LayerNorm/ReduceMean\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/output/LayerNorm/ReduceMean_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/output/LayerNorm/ReduceMean_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/output/LayerNorm/ReduceMean [ReduceMean] outputs: [/bert/encoder/layer.2/attention/output/LayerNorm/ReduceMean_output_0 -> (-1, -1, 1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/output/LayerNorm/Sub [Sub]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/output/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/output/LayerNorm/ReduceMean_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/output/LayerNorm/Sub [Sub] inputs: [/bert/encoder/layer.2/attention/output/Add_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.2/attention/output/LayerNorm/ReduceMean_output_0 -> (-1, -1, 1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/output/LayerNorm/Sub for ONNX node: /bert/encoder/layer.2/attention/output/LayerNorm/Sub\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/output/LayerNorm/Sub_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/output/LayerNorm/Sub_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/output/LayerNorm/Sub [Sub] outputs: [/bert/encoder/layer.2/attention/output/LayerNorm/Sub_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/output/LayerNorm/Constant [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/output/LayerNorm/Constant [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/output/LayerNorm/Constant [Constant] outputs: [/bert/encoder/layer.2/attention/output/LayerNorm/Constant_output_0 -> ()[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/output/LayerNorm/Pow [Pow]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/output/LayerNorm/Sub_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/output/LayerNorm/Constant_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/output/LayerNorm/Pow [Pow] inputs: [/bert/encoder/layer.2/attention/output/LayerNorm/Sub_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.2/attention/output/LayerNorm/Constant_output_0 -> ()[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/output/LayerNorm/Constant_output_0 for ONNX node: /bert/encoder/layer.2/attention/output/LayerNorm/Constant_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/output/LayerNorm/Pow for ONNX node: /bert/encoder/layer.2/attention/output/LayerNorm/Pow\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/output/LayerNorm/Pow_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/output/LayerNorm/Pow_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/output/LayerNorm/Pow [Pow] outputs: [/bert/encoder/layer.2/attention/output/LayerNorm/Pow_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/output/LayerNorm/ReduceMean_1 [ReduceMean]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/output/LayerNorm/Pow_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/output/LayerNorm/ReduceMean_1 [ReduceMean] inputs: [/bert/encoder/layer.2/attention/output/LayerNorm/Pow_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/output/LayerNorm/ReduceMean_1 for ONNX node: /bert/encoder/layer.2/attention/output/LayerNorm/ReduceMean_1\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/output/LayerNorm/ReduceMean_1_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/output/LayerNorm/ReduceMean_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/output/LayerNorm/ReduceMean_1 [ReduceMean] outputs: [/bert/encoder/layer.2/attention/output/LayerNorm/ReduceMean_1_output_0 -> (-1, -1, 1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/output/LayerNorm/Constant_1 [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/output/LayerNorm/Constant_1 [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/output/LayerNorm/Constant_1 [Constant] outputs: [/bert/encoder/layer.2/attention/output/LayerNorm/Constant_1_output_0 -> ()[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/output/LayerNorm/Add [Add]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/output/LayerNorm/ReduceMean_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/output/LayerNorm/Constant_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/output/LayerNorm/Add [Add] inputs: [/bert/encoder/layer.2/attention/output/LayerNorm/ReduceMean_1_output_0 -> (-1, -1, 1)[FLOAT]], [/bert/encoder/layer.2/attention/output/LayerNorm/Constant_1_output_0 -> ()[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/output/LayerNorm/Constant_1_output_0 for ONNX node: /bert/encoder/layer.2/attention/output/LayerNorm/Constant_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/output/LayerNorm/Add for ONNX node: /bert/encoder/layer.2/attention/output/LayerNorm/Add\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/output/LayerNorm/Add_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/output/LayerNorm/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/output/LayerNorm/Add [Add] outputs: [/bert/encoder/layer.2/attention/output/LayerNorm/Add_output_0 -> (-1, -1, 1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/output/LayerNorm/Sqrt [Sqrt]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/output/LayerNorm/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/output/LayerNorm/Sqrt [Sqrt] inputs: [/bert/encoder/layer.2/attention/output/LayerNorm/Add_output_0 -> (-1, -1, 1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/output/LayerNorm/Sqrt for ONNX node: /bert/encoder/layer.2/attention/output/LayerNorm/Sqrt\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/output/LayerNorm/Sqrt_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/output/LayerNorm/Sqrt_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/output/LayerNorm/Sqrt [Sqrt] outputs: [/bert/encoder/layer.2/attention/output/LayerNorm/Sqrt_output_0 -> (-1, -1, 1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/output/LayerNorm/Div [Div]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/output/LayerNorm/Sub_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/output/LayerNorm/Sqrt_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/output/LayerNorm/Div [Div] inputs: [/bert/encoder/layer.2/attention/output/LayerNorm/Sub_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.2/attention/output/LayerNorm/Sqrt_output_0 -> (-1, -1, 1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/output/LayerNorm/Div for ONNX node: /bert/encoder/layer.2/attention/output/LayerNorm/Div\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/output/LayerNorm/Div_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/output/LayerNorm/Div_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/output/LayerNorm/Div [Div] outputs: [/bert/encoder/layer.2/attention/output/LayerNorm/Div_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/output/LayerNorm/Mul [Mul]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/output/LayerNorm/Div_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: bert.encoder.layer.2.attention.output.LayerNorm.weight\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/output/LayerNorm/Mul [Mul] inputs: [/bert/encoder/layer.2/attention/output/LayerNorm/Div_output_0 -> (-1, -1, 256)[FLOAT]], [bert.encoder.layer.2.attention.output.LayerNorm.weight -> (256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: bert.encoder.layer.2.attention.output.LayerNorm.weight for ONNX node: bert.encoder.layer.2.attention.output.LayerNorm.weight\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/output/LayerNorm/Mul for ONNX node: /bert/encoder/layer.2/attention/output/LayerNorm/Mul\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/output/LayerNorm/Mul_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/output/LayerNorm/Mul_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/output/LayerNorm/Mul [Mul] outputs: [/bert/encoder/layer.2/attention/output/LayerNorm/Mul_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/output/LayerNorm/Add_1 [Add]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/output/LayerNorm/Mul_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: bert.encoder.layer.2.attention.output.LayerNorm.bias\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/output/LayerNorm/Add_1 [Add] inputs: [/bert/encoder/layer.2/attention/output/LayerNorm/Mul_output_0 -> (-1, -1, 256)[FLOAT]], [bert.encoder.layer.2.attention.output.LayerNorm.bias -> (256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: bert.encoder.layer.2.attention.output.LayerNorm.bias for ONNX node: bert.encoder.layer.2.attention.output.LayerNorm.bias\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/output/LayerNorm/Add_1 for ONNX node: /bert/encoder/layer.2/attention/output/LayerNorm/Add_1\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/output/LayerNorm/Add_1_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/output/LayerNorm/Add_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/attention/output/LayerNorm/Add_1 [Add] outputs: [/bert/encoder/layer.2/attention/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.2/intermediate/dense/MatMul [MatMul]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/output/LayerNorm/Add_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: onnx::MatMul_830\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/intermediate/dense/MatMul [MatMul] inputs: [/bert/encoder/layer.2/attention/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], [onnx::MatMul_830 -> (256, 1024)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: onnx::MatMul_830 for ONNX node: onnx::MatMul_830\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.2/intermediate/dense/MatMul for ONNX node: /bert/encoder/layer.2/intermediate/dense/MatMul\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.2/intermediate/dense/MatMul_output_0 for ONNX tensor: /bert/encoder/layer.2/intermediate/dense/MatMul_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/intermediate/dense/MatMul [MatMul] outputs: [/bert/encoder/layer.2/intermediate/dense/MatMul_output_0 -> (-1, -1, 1024)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.2/intermediate/dense/Add [Add]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: bert.encoder.layer.2.intermediate.dense.bias\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.2/intermediate/dense/MatMul_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/intermediate/dense/Add [Add] inputs: [bert.encoder.layer.2.intermediate.dense.bias -> (1024)[FLOAT]], [/bert/encoder/layer.2/intermediate/dense/MatMul_output_0 -> (-1, -1, 1024)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: bert.encoder.layer.2.intermediate.dense.bias for ONNX node: bert.encoder.layer.2.intermediate.dense.bias\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.2/intermediate/dense/Add for ONNX node: /bert/encoder/layer.2/intermediate/dense/Add\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.2/intermediate/dense/Add_output_0 for ONNX tensor: /bert/encoder/layer.2/intermediate/dense/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/intermediate/dense/Add [Add] outputs: [/bert/encoder/layer.2/intermediate/dense/Add_output_0 -> (-1, -1, 1024)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.2/intermediate/intermediate_act_fn/Constant [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/intermediate/intermediate_act_fn/Constant [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/intermediate/intermediate_act_fn/Constant [Constant] outputs: [/bert/encoder/layer.2/intermediate/intermediate_act_fn/Constant_output_0 -> ()[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.2/intermediate/intermediate_act_fn/Div [Div]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.2/intermediate/dense/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.2/intermediate/intermediate_act_fn/Constant_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/intermediate/intermediate_act_fn/Div [Div] inputs: [/bert/encoder/layer.2/intermediate/dense/Add_output_0 -> (-1, -1, 1024)[FLOAT]], [/bert/encoder/layer.2/intermediate/intermediate_act_fn/Constant_output_0 -> ()[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.2/intermediate/intermediate_act_fn/Constant_output_0 for ONNX node: /bert/encoder/layer.2/intermediate/intermediate_act_fn/Constant_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.2/intermediate/intermediate_act_fn/Div for ONNX node: /bert/encoder/layer.2/intermediate/intermediate_act_fn/Div\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.2/intermediate/intermediate_act_fn/Div_output_0 for ONNX tensor: /bert/encoder/layer.2/intermediate/intermediate_act_fn/Div_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/intermediate/intermediate_act_fn/Div [Div] outputs: [/bert/encoder/layer.2/intermediate/intermediate_act_fn/Div_output_0 -> (-1, -1, 1024)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.2/intermediate/intermediate_act_fn/Erf [Erf]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.2/intermediate/intermediate_act_fn/Div_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/intermediate/intermediate_act_fn/Erf [Erf] inputs: [/bert/encoder/layer.2/intermediate/intermediate_act_fn/Div_output_0 -> (-1, -1, 1024)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.2/intermediate/intermediate_act_fn/Erf for ONNX node: /bert/encoder/layer.2/intermediate/intermediate_act_fn/Erf\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.2/intermediate/intermediate_act_fn/Erf_output_0 for ONNX tensor: /bert/encoder/layer.2/intermediate/intermediate_act_fn/Erf_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/intermediate/intermediate_act_fn/Erf [Erf] outputs: [/bert/encoder/layer.2/intermediate/intermediate_act_fn/Erf_output_0 -> (-1, -1, 1024)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.2/intermediate/intermediate_act_fn/Constant_1 [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/intermediate/intermediate_act_fn/Constant_1 [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/intermediate/intermediate_act_fn/Constant_1 [Constant] outputs: [/bert/encoder/layer.2/intermediate/intermediate_act_fn/Constant_1_output_0 -> ()[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.2/intermediate/intermediate_act_fn/Add [Add]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.2/intermediate/intermediate_act_fn/Erf_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.2/intermediate/intermediate_act_fn/Constant_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/intermediate/intermediate_act_fn/Add [Add] inputs: [/bert/encoder/layer.2/intermediate/intermediate_act_fn/Erf_output_0 -> (-1, -1, 1024)[FLOAT]], [/bert/encoder/layer.2/intermediate/intermediate_act_fn/Constant_1_output_0 -> ()[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.2/intermediate/intermediate_act_fn/Constant_1_output_0 for ONNX node: /bert/encoder/layer.2/intermediate/intermediate_act_fn/Constant_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.2/intermediate/intermediate_act_fn/Add for ONNX node: /bert/encoder/layer.2/intermediate/intermediate_act_fn/Add\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.2/intermediate/intermediate_act_fn/Add_output_0 for ONNX tensor: /bert/encoder/layer.2/intermediate/intermediate_act_fn/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/intermediate/intermediate_act_fn/Add [Add] outputs: [/bert/encoder/layer.2/intermediate/intermediate_act_fn/Add_output_0 -> (-1, -1, 1024)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.2/intermediate/intermediate_act_fn/Mul [Mul]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.2/intermediate/dense/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.2/intermediate/intermediate_act_fn/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/intermediate/intermediate_act_fn/Mul [Mul] inputs: [/bert/encoder/layer.2/intermediate/dense/Add_output_0 -> (-1, -1, 1024)[FLOAT]], [/bert/encoder/layer.2/intermediate/intermediate_act_fn/Add_output_0 -> (-1, -1, 1024)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.2/intermediate/intermediate_act_fn/Mul for ONNX node: /bert/encoder/layer.2/intermediate/intermediate_act_fn/Mul\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.2/intermediate/intermediate_act_fn/Mul_output_0 for ONNX tensor: /bert/encoder/layer.2/intermediate/intermediate_act_fn/Mul_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/intermediate/intermediate_act_fn/Mul [Mul] outputs: [/bert/encoder/layer.2/intermediate/intermediate_act_fn/Mul_output_0 -> (-1, -1, 1024)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.2/intermediate/intermediate_act_fn/Constant_2 [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/intermediate/intermediate_act_fn/Constant_2 [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/intermediate/intermediate_act_fn/Constant_2 [Constant] outputs: [/bert/encoder/layer.2/intermediate/intermediate_act_fn/Constant_2_output_0 -> ()[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.2/intermediate/intermediate_act_fn/Mul_1 [Mul]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.2/intermediate/intermediate_act_fn/Mul_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.2/intermediate/intermediate_act_fn/Constant_2_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/intermediate/intermediate_act_fn/Mul_1 [Mul] inputs: [/bert/encoder/layer.2/intermediate/intermediate_act_fn/Mul_output_0 -> (-1, -1, 1024)[FLOAT]], [/bert/encoder/layer.2/intermediate/intermediate_act_fn/Constant_2_output_0 -> ()[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.2/intermediate/intermediate_act_fn/Constant_2_output_0 for ONNX node: /bert/encoder/layer.2/intermediate/intermediate_act_fn/Constant_2_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.2/intermediate/intermediate_act_fn/Mul_1 for ONNX node: /bert/encoder/layer.2/intermediate/intermediate_act_fn/Mul_1\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.2/intermediate/intermediate_act_fn/Mul_1_output_0 for ONNX tensor: /bert/encoder/layer.2/intermediate/intermediate_act_fn/Mul_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/intermediate/intermediate_act_fn/Mul_1 [Mul] outputs: [/bert/encoder/layer.2/intermediate/intermediate_act_fn/Mul_1_output_0 -> (-1, -1, 1024)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.2/output/dense/MatMul [MatMul]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.2/intermediate/intermediate_act_fn/Mul_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: onnx::MatMul_831\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/output/dense/MatMul [MatMul] inputs: [/bert/encoder/layer.2/intermediate/intermediate_act_fn/Mul_1_output_0 -> (-1, -1, 1024)[FLOAT]], [onnx::MatMul_831 -> (1024, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: onnx::MatMul_831 for ONNX node: onnx::MatMul_831\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.2/output/dense/MatMul for ONNX node: /bert/encoder/layer.2/output/dense/MatMul\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.2/output/dense/MatMul_output_0 for ONNX tensor: /bert/encoder/layer.2/output/dense/MatMul_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/output/dense/MatMul [MatMul] outputs: [/bert/encoder/layer.2/output/dense/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.2/output/dense/Add [Add]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: bert.encoder.layer.2.output.dense.bias\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.2/output/dense/MatMul_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/output/dense/Add [Add] inputs: [bert.encoder.layer.2.output.dense.bias -> (256)[FLOAT]], [/bert/encoder/layer.2/output/dense/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: bert.encoder.layer.2.output.dense.bias for ONNX node: bert.encoder.layer.2.output.dense.bias\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.2/output/dense/Add for ONNX node: /bert/encoder/layer.2/output/dense/Add\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.2/output/dense/Add_output_0 for ONNX tensor: /bert/encoder/layer.2/output/dense/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/output/dense/Add [Add] outputs: [/bert/encoder/layer.2/output/dense/Add_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.2/output/Add [Add]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.2/output/dense/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/output/LayerNorm/Add_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/output/Add [Add] inputs: [/bert/encoder/layer.2/output/dense/Add_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.2/attention/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.2/output/Add for ONNX node: /bert/encoder/layer.2/output/Add\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.2/output/Add_output_0 for ONNX tensor: /bert/encoder/layer.2/output/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/output/Add [Add] outputs: [/bert/encoder/layer.2/output/Add_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.2/output/LayerNorm/ReduceMean [ReduceMean]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.2/output/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/output/LayerNorm/ReduceMean [ReduceMean] inputs: [/bert/encoder/layer.2/output/Add_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.2/output/LayerNorm/ReduceMean for ONNX node: /bert/encoder/layer.2/output/LayerNorm/ReduceMean\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.2/output/LayerNorm/ReduceMean_output_0 for ONNX tensor: /bert/encoder/layer.2/output/LayerNorm/ReduceMean_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/output/LayerNorm/ReduceMean [ReduceMean] outputs: [/bert/encoder/layer.2/output/LayerNorm/ReduceMean_output_0 -> (-1, -1, 1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.2/output/LayerNorm/Sub [Sub]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.2/output/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.2/output/LayerNorm/ReduceMean_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/output/LayerNorm/Sub [Sub] inputs: [/bert/encoder/layer.2/output/Add_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.2/output/LayerNorm/ReduceMean_output_0 -> (-1, -1, 1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.2/output/LayerNorm/Sub for ONNX node: /bert/encoder/layer.2/output/LayerNorm/Sub\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.2/output/LayerNorm/Sub_output_0 for ONNX tensor: /bert/encoder/layer.2/output/LayerNorm/Sub_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/output/LayerNorm/Sub [Sub] outputs: [/bert/encoder/layer.2/output/LayerNorm/Sub_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.2/output/LayerNorm/Constant [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/output/LayerNorm/Constant [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/output/LayerNorm/Constant [Constant] outputs: [/bert/encoder/layer.2/output/LayerNorm/Constant_output_0 -> ()[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.2/output/LayerNorm/Pow [Pow]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.2/output/LayerNorm/Sub_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.2/output/LayerNorm/Constant_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/output/LayerNorm/Pow [Pow] inputs: [/bert/encoder/layer.2/output/LayerNorm/Sub_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.2/output/LayerNorm/Constant_output_0 -> ()[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.2/output/LayerNorm/Constant_output_0 for ONNX node: /bert/encoder/layer.2/output/LayerNorm/Constant_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.2/output/LayerNorm/Pow for ONNX node: /bert/encoder/layer.2/output/LayerNorm/Pow\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.2/output/LayerNorm/Pow_output_0 for ONNX tensor: /bert/encoder/layer.2/output/LayerNorm/Pow_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/output/LayerNorm/Pow [Pow] outputs: [/bert/encoder/layer.2/output/LayerNorm/Pow_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.2/output/LayerNorm/ReduceMean_1 [ReduceMean]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.2/output/LayerNorm/Pow_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/output/LayerNorm/ReduceMean_1 [ReduceMean] inputs: [/bert/encoder/layer.2/output/LayerNorm/Pow_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.2/output/LayerNorm/ReduceMean_1 for ONNX node: /bert/encoder/layer.2/output/LayerNorm/ReduceMean_1\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.2/output/LayerNorm/ReduceMean_1_output_0 for ONNX tensor: /bert/encoder/layer.2/output/LayerNorm/ReduceMean_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/output/LayerNorm/ReduceMean_1 [ReduceMean] outputs: [/bert/encoder/layer.2/output/LayerNorm/ReduceMean_1_output_0 -> (-1, -1, 1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.2/output/LayerNorm/Constant_1 [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/output/LayerNorm/Constant_1 [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/output/LayerNorm/Constant_1 [Constant] outputs: [/bert/encoder/layer.2/output/LayerNorm/Constant_1_output_0 -> ()[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.2/output/LayerNorm/Add [Add]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.2/output/LayerNorm/ReduceMean_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.2/output/LayerNorm/Constant_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/output/LayerNorm/Add [Add] inputs: [/bert/encoder/layer.2/output/LayerNorm/ReduceMean_1_output_0 -> (-1, -1, 1)[FLOAT]], [/bert/encoder/layer.2/output/LayerNorm/Constant_1_output_0 -> ()[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.2/output/LayerNorm/Constant_1_output_0 for ONNX node: /bert/encoder/layer.2/output/LayerNorm/Constant_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.2/output/LayerNorm/Add for ONNX node: /bert/encoder/layer.2/output/LayerNorm/Add\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.2/output/LayerNorm/Add_output_0 for ONNX tensor: /bert/encoder/layer.2/output/LayerNorm/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/output/LayerNorm/Add [Add] outputs: [/bert/encoder/layer.2/output/LayerNorm/Add_output_0 -> (-1, -1, 1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.2/output/LayerNorm/Sqrt [Sqrt]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.2/output/LayerNorm/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/output/LayerNorm/Sqrt [Sqrt] inputs: [/bert/encoder/layer.2/output/LayerNorm/Add_output_0 -> (-1, -1, 1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.2/output/LayerNorm/Sqrt for ONNX node: /bert/encoder/layer.2/output/LayerNorm/Sqrt\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.2/output/LayerNorm/Sqrt_output_0 for ONNX tensor: /bert/encoder/layer.2/output/LayerNorm/Sqrt_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/output/LayerNorm/Sqrt [Sqrt] outputs: [/bert/encoder/layer.2/output/LayerNorm/Sqrt_output_0 -> (-1, -1, 1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.2/output/LayerNorm/Div [Div]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.2/output/LayerNorm/Sub_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.2/output/LayerNorm/Sqrt_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/output/LayerNorm/Div [Div] inputs: [/bert/encoder/layer.2/output/LayerNorm/Sub_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.2/output/LayerNorm/Sqrt_output_0 -> (-1, -1, 1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.2/output/LayerNorm/Div for ONNX node: /bert/encoder/layer.2/output/LayerNorm/Div\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.2/output/LayerNorm/Div_output_0 for ONNX tensor: /bert/encoder/layer.2/output/LayerNorm/Div_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/output/LayerNorm/Div [Div] outputs: [/bert/encoder/layer.2/output/LayerNorm/Div_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.2/output/LayerNorm/Mul [Mul]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.2/output/LayerNorm/Div_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: bert.encoder.layer.2.output.LayerNorm.weight\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/output/LayerNorm/Mul [Mul] inputs: [/bert/encoder/layer.2/output/LayerNorm/Div_output_0 -> (-1, -1, 256)[FLOAT]], [bert.encoder.layer.2.output.LayerNorm.weight -> (256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: bert.encoder.layer.2.output.LayerNorm.weight for ONNX node: bert.encoder.layer.2.output.LayerNorm.weight\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.2/output/LayerNorm/Mul for ONNX node: /bert/encoder/layer.2/output/LayerNorm/Mul\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.2/output/LayerNorm/Mul_output_0 for ONNX tensor: /bert/encoder/layer.2/output/LayerNorm/Mul_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/output/LayerNorm/Mul [Mul] outputs: [/bert/encoder/layer.2/output/LayerNorm/Mul_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.2/output/LayerNorm/Add_1 [Add]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.2/output/LayerNorm/Mul_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: bert.encoder.layer.2.output.LayerNorm.bias\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/output/LayerNorm/Add_1 [Add] inputs: [/bert/encoder/layer.2/output/LayerNorm/Mul_output_0 -> (-1, -1, 256)[FLOAT]], [bert.encoder.layer.2.output.LayerNorm.bias -> (256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: bert.encoder.layer.2.output.LayerNorm.bias for ONNX node: bert.encoder.layer.2.output.LayerNorm.bias\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.2/output/LayerNorm/Add_1 for ONNX node: /bert/encoder/layer.2/output/LayerNorm/Add_1\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.2/output/LayerNorm/Add_1_output_0 for ONNX tensor: /bert/encoder/layer.2/output/LayerNorm/Add_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.2/output/LayerNorm/Add_1 [Add] outputs: [/bert/encoder/layer.2/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/query/MatMul [MatMul]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.2/output/LayerNorm/Add_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: onnx::MatMul_832\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/self/query/MatMul [MatMul] inputs: [/bert/encoder/layer.2/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], [onnx::MatMul_832 -> (256, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: onnx::MatMul_832 for ONNX node: onnx::MatMul_832\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/query/MatMul for ONNX node: /bert/encoder/layer.3/attention/self/query/MatMul\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/query/MatMul_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/query/MatMul_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/self/query/MatMul [MatMul] outputs: [/bert/encoder/layer.3/attention/self/query/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/query/Add [Add]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: bert.encoder.layer.3.attention.self.query.bias\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/query/MatMul_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/self/query/Add [Add] inputs: [bert.encoder.layer.3.attention.self.query.bias -> (256)[FLOAT]], [/bert/encoder/layer.3/attention/self/query/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: bert.encoder.layer.3.attention.self.query.bias for ONNX node: bert.encoder.layer.3.attention.self.query.bias\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/query/Add for ONNX node: /bert/encoder/layer.3/attention/self/query/Add\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/query/Add_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/query/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/self/query/Add [Add] outputs: [/bert/encoder/layer.3/attention/self/query/Add_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/key/MatMul [MatMul]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.2/output/LayerNorm/Add_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: onnx::MatMul_833\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/self/key/MatMul [MatMul] inputs: [/bert/encoder/layer.2/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], [onnx::MatMul_833 -> (256, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: onnx::MatMul_833 for ONNX node: onnx::MatMul_833\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/key/MatMul for ONNX node: /bert/encoder/layer.3/attention/self/key/MatMul\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/key/MatMul_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/key/MatMul_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/self/key/MatMul [MatMul] outputs: [/bert/encoder/layer.3/attention/self/key/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/key/Add [Add]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: bert.encoder.layer.3.attention.self.key.bias\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/key/MatMul_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/self/key/Add [Add] inputs: [bert.encoder.layer.3.attention.self.key.bias -> (256)[FLOAT]], [/bert/encoder/layer.3/attention/self/key/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: bert.encoder.layer.3.attention.self.key.bias for ONNX node: bert.encoder.layer.3.attention.self.key.bias\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/key/Add for ONNX node: /bert/encoder/layer.3/attention/self/key/Add\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/key/Add_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/key/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/self/key/Add [Add] outputs: [/bert/encoder/layer.3/attention/self/key/Add_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Shape [Shape]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/key/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/self/Shape [Shape] inputs: [/bert/encoder/layer.3/attention/self/key/Add_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Shape for ONNX node: /bert/encoder/layer.3/attention/self/Shape\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/Shape_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/Shape_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/self/Shape [Shape] outputs: [/bert/encoder/layer.3/attention/self/Shape_output_0 -> (3)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Constant [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/self/Constant [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/self/Constant [Constant] outputs: [/bert/encoder/layer.3/attention/self/Constant_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Gather [Gather]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Shape_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Constant_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/self/Gather [Gather] inputs: [/bert/encoder/layer.3/attention/self/Shape_output_0 -> (3)[INT32]], [/bert/encoder/layer.3/attention/self/Constant_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Constant_output_0 for ONNX node: /bert/encoder/layer.3/attention/self/Constant_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Using Gather axis: 0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Gather for ONNX node: /bert/encoder/layer.3/attention/self/Gather\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/Gather_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/Gather_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/self/Gather [Gather] outputs: [/bert/encoder/layer.3/attention/self/Gather_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Shape_1 [Shape]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/key/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/self/Shape_1 [Shape] inputs: [/bert/encoder/layer.3/attention/self/key/Add_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Shape_1 for ONNX node: /bert/encoder/layer.3/attention/self/Shape_1\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/Shape_1_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/Shape_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/self/Shape_1 [Shape] outputs: [/bert/encoder/layer.3/attention/self/Shape_1_output_0 -> (3)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Constant_1 [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/self/Constant_1 [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/self/Constant_1 [Constant] outputs: [/bert/encoder/layer.3/attention/self/Constant_1_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Gather_1 [Gather]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Shape_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Constant_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/self/Gather_1 [Gather] inputs: [/bert/encoder/layer.3/attention/self/Shape_1_output_0 -> (3)[INT32]], [/bert/encoder/layer.3/attention/self/Constant_1_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Constant_1_output_0 for ONNX node: /bert/encoder/layer.3/attention/self/Constant_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Using Gather axis: 0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Gather_1 for ONNX node: /bert/encoder/layer.3/attention/self/Gather_1\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/Gather_1_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/Gather_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/self/Gather_1 [Gather] outputs: [/bert/encoder/layer.3/attention/self/Gather_1_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Unsqueeze [Unsqueeze]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Gather_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/self/Unsqueeze [Unsqueeze] inputs: [/bert/encoder/layer.3/attention/self/Gather_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Original shape: (), unsqueezing to: (1,)\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Unsqueeze for ONNX node: /bert/encoder/layer.3/attention/self/Unsqueeze\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/Unsqueeze_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/Unsqueeze_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/self/Unsqueeze [Unsqueeze] outputs: [/bert/encoder/layer.3/attention/self/Unsqueeze_output_0 -> (1)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Unsqueeze_1 [Unsqueeze]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Gather_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/self/Unsqueeze_1 [Unsqueeze] inputs: [/bert/encoder/layer.3/attention/self/Gather_1_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Original shape: (), unsqueezing to: (1,)\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Unsqueeze_1 for ONNX node: /bert/encoder/layer.3/attention/self/Unsqueeze_1\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/Unsqueeze_1_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/Unsqueeze_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/self/Unsqueeze_1 [Unsqueeze] outputs: [/bert/encoder/layer.3/attention/self/Unsqueeze_1_output_0 -> (1)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Constant_2 [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/self/Constant_2 [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/self/Constant_2 [Constant] outputs: [/bert/encoder/layer.3/attention/self/Constant_2_output_0 -> (1)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Constant_3 [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/self/Constant_3 [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/self/Constant_3 [Constant] outputs: [/bert/encoder/layer.3/attention/self/Constant_3_output_0 -> (1)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Concat [Concat]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Unsqueeze_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Unsqueeze_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Constant_2_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Constant_3_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/self/Concat [Concat] inputs: [/bert/encoder/layer.3/attention/self/Unsqueeze_output_0 -> (1)[INT32]], [/bert/encoder/layer.3/attention/self/Unsqueeze_1_output_0 -> (1)[INT32]], [/bert/encoder/layer.3/attention/self/Constant_2_output_0 -> (1)[INT32]], [/bert/encoder/layer.3/attention/self/Constant_3_output_0 -> (1)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Constant_2_output_0 for ONNX node: /bert/encoder/layer.3/attention/self/Constant_2_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Constant_3_output_0 for ONNX node: /bert/encoder/layer.3/attention/self/Constant_3_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Concat for ONNX node: /bert/encoder/layer.3/attention/self/Concat\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/Concat_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/Concat_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/self/Concat [Concat] outputs: [/bert/encoder/layer.3/attention/self/Concat_output_0 -> (4)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Reshape [Reshape]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/key/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Concat_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/self/Reshape [Reshape] inputs: [/bert/encoder/layer.3/attention/self/key/Add_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.3/attention/self/Concat_output_0 -> (4)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Reshape for ONNX node: /bert/encoder/layer.3/attention/self/Reshape\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/Reshape_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/Reshape_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/self/Reshape [Reshape] outputs: [/bert/encoder/layer.3/attention/self/Reshape_output_0 -> (-1, -1, 8, 32)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/value/MatMul [MatMul]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.2/output/LayerNorm/Add_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: onnx::MatMul_836\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/self/value/MatMul [MatMul] inputs: [/bert/encoder/layer.2/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], [onnx::MatMul_836 -> (256, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: onnx::MatMul_836 for ONNX node: onnx::MatMul_836\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/value/MatMul for ONNX node: /bert/encoder/layer.3/attention/self/value/MatMul\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/value/MatMul_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/value/MatMul_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/self/value/MatMul [MatMul] outputs: [/bert/encoder/layer.3/attention/self/value/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/value/Add [Add]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: bert.encoder.layer.3.attention.self.value.bias\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/value/MatMul_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/self/value/Add [Add] inputs: [bert.encoder.layer.3.attention.self.value.bias -> (256)[FLOAT]], [/bert/encoder/layer.3/attention/self/value/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: bert.encoder.layer.3.attention.self.value.bias for ONNX node: bert.encoder.layer.3.attention.self.value.bias\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/value/Add for ONNX node: /bert/encoder/layer.3/attention/self/value/Add\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/value/Add_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/value/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/self/value/Add [Add] outputs: [/bert/encoder/layer.3/attention/self/value/Add_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Shape_2 [Shape]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/value/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/self/Shape_2 [Shape] inputs: [/bert/encoder/layer.3/attention/self/value/Add_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Shape_2 for ONNX node: /bert/encoder/layer.3/attention/self/Shape_2\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/Shape_2_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/Shape_2_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/self/Shape_2 [Shape] outputs: [/bert/encoder/layer.3/attention/self/Shape_2_output_0 -> (3)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Constant_4 [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/self/Constant_4 [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/self/Constant_4 [Constant] outputs: [/bert/encoder/layer.3/attention/self/Constant_4_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Gather_2 [Gather]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Shape_2_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Constant_4_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/self/Gather_2 [Gather] inputs: [/bert/encoder/layer.3/attention/self/Shape_2_output_0 -> (3)[INT32]], [/bert/encoder/layer.3/attention/self/Constant_4_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Constant_4_output_0 for ONNX node: /bert/encoder/layer.3/attention/self/Constant_4_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Using Gather axis: 0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Gather_2 for ONNX node: /bert/encoder/layer.3/attention/self/Gather_2\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/Gather_2_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/Gather_2_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/self/Gather_2 [Gather] outputs: [/bert/encoder/layer.3/attention/self/Gather_2_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Shape_3 [Shape]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/value/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/self/Shape_3 [Shape] inputs: [/bert/encoder/layer.3/attention/self/value/Add_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Shape_3 for ONNX node: /bert/encoder/layer.3/attention/self/Shape_3\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/Shape_3_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/Shape_3_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/self/Shape_3 [Shape] outputs: [/bert/encoder/layer.3/attention/self/Shape_3_output_0 -> (3)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Constant_5 [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/self/Constant_5 [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/self/Constant_5 [Constant] outputs: [/bert/encoder/layer.3/attention/self/Constant_5_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Gather_3 [Gather]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Shape_3_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Constant_5_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/self/Gather_3 [Gather] inputs: [/bert/encoder/layer.3/attention/self/Shape_3_output_0 -> (3)[INT32]], [/bert/encoder/layer.3/attention/self/Constant_5_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Constant_5_output_0 for ONNX node: /bert/encoder/layer.3/attention/self/Constant_5_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Using Gather axis: 0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Gather_3 for ONNX node: /bert/encoder/layer.3/attention/self/Gather_3\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/Gather_3_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/Gather_3_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/self/Gather_3 [Gather] outputs: [/bert/encoder/layer.3/attention/self/Gather_3_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Unsqueeze_2 [Unsqueeze]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Gather_2_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/self/Unsqueeze_2 [Unsqueeze] inputs: [/bert/encoder/layer.3/attention/self/Gather_2_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Original shape: (), unsqueezing to: (1,)\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Unsqueeze_2 for ONNX node: /bert/encoder/layer.3/attention/self/Unsqueeze_2\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/Unsqueeze_2_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/Unsqueeze_2_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/self/Unsqueeze_2 [Unsqueeze] outputs: [/bert/encoder/layer.3/attention/self/Unsqueeze_2_output_0 -> (1)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Unsqueeze_3 [Unsqueeze]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Gather_3_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/self/Unsqueeze_3 [Unsqueeze] inputs: [/bert/encoder/layer.3/attention/self/Gather_3_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Original shape: (), unsqueezing to: (1,)\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Unsqueeze_3 for ONNX node: /bert/encoder/layer.3/attention/self/Unsqueeze_3\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/Unsqueeze_3_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/Unsqueeze_3_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/self/Unsqueeze_3 [Unsqueeze] outputs: [/bert/encoder/layer.3/attention/self/Unsqueeze_3_output_0 -> (1)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Constant_6 [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/self/Constant_6 [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/self/Constant_6 [Constant] outputs: [/bert/encoder/layer.3/attention/self/Constant_6_output_0 -> (1)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Constant_7 [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/self/Constant_7 [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/self/Constant_7 [Constant] outputs: [/bert/encoder/layer.3/attention/self/Constant_7_output_0 -> (1)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Concat_1 [Concat]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Unsqueeze_2_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Unsqueeze_3_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Constant_6_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Constant_7_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/self/Concat_1 [Concat] inputs: [/bert/encoder/layer.3/attention/self/Unsqueeze_2_output_0 -> (1)[INT32]], [/bert/encoder/layer.3/attention/self/Unsqueeze_3_output_0 -> (1)[INT32]], [/bert/encoder/layer.3/attention/self/Constant_6_output_0 -> (1)[INT32]], [/bert/encoder/layer.3/attention/self/Constant_7_output_0 -> (1)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Constant_6_output_0 for ONNX node: /bert/encoder/layer.3/attention/self/Constant_6_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Constant_7_output_0 for ONNX node: /bert/encoder/layer.3/attention/self/Constant_7_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Concat_1 for ONNX node: /bert/encoder/layer.3/attention/self/Concat_1\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/Concat_1_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/Concat_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/self/Concat_1 [Concat] outputs: [/bert/encoder/layer.3/attention/self/Concat_1_output_0 -> (4)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Reshape_1 [Reshape]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/value/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Concat_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/self/Reshape_1 [Reshape] inputs: [/bert/encoder/layer.3/attention/self/value/Add_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.3/attention/self/Concat_1_output_0 -> (4)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Reshape_1 for ONNX node: /bert/encoder/layer.3/attention/self/Reshape_1\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/Reshape_1_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/Reshape_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/self/Reshape_1 [Reshape] outputs: [/bert/encoder/layer.3/attention/self/Reshape_1_output_0 -> (-1, -1, 8, 32)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Transpose [Transpose]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Reshape_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/self/Transpose [Transpose] inputs: [/bert/encoder/layer.3/attention/self/Reshape_1_output_0 -> (-1, -1, 8, 32)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Transpose for ONNX node: /bert/encoder/layer.3/attention/self/Transpose\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/Transpose_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/Transpose_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/self/Transpose [Transpose] outputs: [/bert/encoder/layer.3/attention/self/Transpose_output_0 -> (-1, 8, -1, 32)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Shape_4 [Shape]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/query/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/self/Shape_4 [Shape] inputs: [/bert/encoder/layer.3/attention/self/query/Add_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Shape_4 for ONNX node: /bert/encoder/layer.3/attention/self/Shape_4\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/Shape_4_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/Shape_4_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/self/Shape_4 [Shape] outputs: [/bert/encoder/layer.3/attention/self/Shape_4_output_0 -> (3)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Constant_8 [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/self/Constant_8 [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/self/Constant_8 [Constant] outputs: [/bert/encoder/layer.3/attention/self/Constant_8_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Gather_4 [Gather]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Shape_4_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Constant_8_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/self/Gather_4 [Gather] inputs: [/bert/encoder/layer.3/attention/self/Shape_4_output_0 -> (3)[INT32]], [/bert/encoder/layer.3/attention/self/Constant_8_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Constant_8_output_0 for ONNX node: /bert/encoder/layer.3/attention/self/Constant_8_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Using Gather axis: 0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Gather_4 for ONNX node: /bert/encoder/layer.3/attention/self/Gather_4\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/Gather_4_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/Gather_4_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/self/Gather_4 [Gather] outputs: [/bert/encoder/layer.3/attention/self/Gather_4_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Shape_5 [Shape]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/query/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/self/Shape_5 [Shape] inputs: [/bert/encoder/layer.3/attention/self/query/Add_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Shape_5 for ONNX node: /bert/encoder/layer.3/attention/self/Shape_5\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/Shape_5_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/Shape_5_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/self/Shape_5 [Shape] outputs: [/bert/encoder/layer.3/attention/self/Shape_5_output_0 -> (3)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Constant_9 [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/self/Constant_9 [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/self/Constant_9 [Constant] outputs: [/bert/encoder/layer.3/attention/self/Constant_9_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Gather_5 [Gather]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Shape_5_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Constant_9_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/self/Gather_5 [Gather] inputs: [/bert/encoder/layer.3/attention/self/Shape_5_output_0 -> (3)[INT32]], [/bert/encoder/layer.3/attention/self/Constant_9_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Constant_9_output_0 for ONNX node: /bert/encoder/layer.3/attention/self/Constant_9_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Using Gather axis: 0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Gather_5 for ONNX node: /bert/encoder/layer.3/attention/self/Gather_5\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/Gather_5_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/Gather_5_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/self/Gather_5 [Gather] outputs: [/bert/encoder/layer.3/attention/self/Gather_5_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Unsqueeze_4 [Unsqueeze]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Gather_4_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/self/Unsqueeze_4 [Unsqueeze] inputs: [/bert/encoder/layer.3/attention/self/Gather_4_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Original shape: (), unsqueezing to: (1,)\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Unsqueeze_4 for ONNX node: /bert/encoder/layer.3/attention/self/Unsqueeze_4\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/Unsqueeze_4_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/Unsqueeze_4_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/self/Unsqueeze_4 [Unsqueeze] outputs: [/bert/encoder/layer.3/attention/self/Unsqueeze_4_output_0 -> (1)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Unsqueeze_5 [Unsqueeze]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Gather_5_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/self/Unsqueeze_5 [Unsqueeze] inputs: [/bert/encoder/layer.3/attention/self/Gather_5_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Original shape: (), unsqueezing to: (1,)\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Unsqueeze_5 for ONNX node: /bert/encoder/layer.3/attention/self/Unsqueeze_5\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/Unsqueeze_5_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/Unsqueeze_5_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/self/Unsqueeze_5 [Unsqueeze] outputs: [/bert/encoder/layer.3/attention/self/Unsqueeze_5_output_0 -> (1)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Constant_10 [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/self/Constant_10 [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/self/Constant_10 [Constant] outputs: [/bert/encoder/layer.3/attention/self/Constant_10_output_0 -> (1)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Constant_11 [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/self/Constant_11 [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/self/Constant_11 [Constant] outputs: [/bert/encoder/layer.3/attention/self/Constant_11_output_0 -> (1)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Concat_2 [Concat]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Unsqueeze_4_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Unsqueeze_5_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Constant_10_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Constant_11_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/self/Concat_2 [Concat] inputs: [/bert/encoder/layer.3/attention/self/Unsqueeze_4_output_0 -> (1)[INT32]], [/bert/encoder/layer.3/attention/self/Unsqueeze_5_output_0 -> (1)[INT32]], [/bert/encoder/layer.3/attention/self/Constant_10_output_0 -> (1)[INT32]], [/bert/encoder/layer.3/attention/self/Constant_11_output_0 -> (1)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Constant_10_output_0 for ONNX node: /bert/encoder/layer.3/attention/self/Constant_10_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Constant_11_output_0 for ONNX node: /bert/encoder/layer.3/attention/self/Constant_11_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Concat_2 for ONNX node: /bert/encoder/layer.3/attention/self/Concat_2\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/Concat_2_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/Concat_2_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/self/Concat_2 [Concat] outputs: [/bert/encoder/layer.3/attention/self/Concat_2_output_0 -> (4)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Reshape_2 [Reshape]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/query/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Concat_2_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/self/Reshape_2 [Reshape] inputs: [/bert/encoder/layer.3/attention/self/query/Add_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.3/attention/self/Concat_2_output_0 -> (4)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Reshape_2 for ONNX node: /bert/encoder/layer.3/attention/self/Reshape_2\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/Reshape_2_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/Reshape_2_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/self/Reshape_2 [Reshape] outputs: [/bert/encoder/layer.3/attention/self/Reshape_2_output_0 -> (-1, -1, 8, 32)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Transpose_1 [Transpose]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Reshape_2_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/self/Transpose_1 [Transpose] inputs: [/bert/encoder/layer.3/attention/self/Reshape_2_output_0 -> (-1, -1, 8, 32)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Transpose_1 for ONNX node: /bert/encoder/layer.3/attention/self/Transpose_1\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/Transpose_1_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/Transpose_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/self/Transpose_1 [Transpose] outputs: [/bert/encoder/layer.3/attention/self/Transpose_1_output_0 -> (-1, 8, -1, 32)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Transpose_2 [Transpose]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Reshape_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/self/Transpose_2 [Transpose] inputs: [/bert/encoder/layer.3/attention/self/Reshape_output_0 -> (-1, -1, 8, 32)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Transpose_2 for ONNX node: /bert/encoder/layer.3/attention/self/Transpose_2\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/Transpose_2_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/Transpose_2_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/self/Transpose_2 [Transpose] outputs: [/bert/encoder/layer.3/attention/self/Transpose_2_output_0 -> (-1, 8, 32, -1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/MatMul [MatMul]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Transpose_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Transpose_2_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/self/MatMul [MatMul] inputs: [/bert/encoder/layer.3/attention/self/Transpose_1_output_0 -> (-1, 8, -1, 32)[FLOAT]], [/bert/encoder/layer.3/attention/self/Transpose_2_output_0 -> (-1, 8, 32, -1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/MatMul for ONNX node: /bert/encoder/layer.3/attention/self/MatMul\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/MatMul_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/MatMul_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/self/MatMul [MatMul] outputs: [/bert/encoder/layer.3/attention/self/MatMul_output_0 -> (-1, 8, -1, -1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Constant_12 [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/self/Constant_12 [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/self/Constant_12 [Constant] outputs: [/bert/encoder/layer.3/attention/self/Constant_12_output_0 -> ()[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Div [Div]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/MatMul_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Constant_12_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/self/Div [Div] inputs: [/bert/encoder/layer.3/attention/self/MatMul_output_0 -> (-1, 8, -1, -1)[FLOAT]], [/bert/encoder/layer.3/attention/self/Constant_12_output_0 -> ()[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Constant_12_output_0 for ONNX node: /bert/encoder/layer.3/attention/self/Constant_12_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Div for ONNX node: /bert/encoder/layer.3/attention/self/Div\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/Div_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/Div_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/self/Div [Div] outputs: [/bert/encoder/layer.3/attention/self/Div_output_0 -> (-1, 8, -1, -1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Add [Add]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Div_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/Mul_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/self/Add [Add] inputs: [/bert/encoder/layer.3/attention/self/Div_output_0 -> (-1, 8, -1, -1)[FLOAT]], [/bert/Mul_output_0 -> (-1, 1, 1, -1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Add for ONNX node: /bert/encoder/layer.3/attention/self/Add\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/Add_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/self/Add [Add] outputs: [/bert/encoder/layer.3/attention/self/Add_output_0 -> (-1, 8, -1, -1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Softmax [Softmax]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/self/Softmax [Softmax] inputs: [/bert/encoder/layer.3/attention/self/Add_output_0 -> (-1, 8, -1, -1)[FLOAT]], \r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Softmax for ONNX node: /bert/encoder/layer.3/attention/self/Softmax\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/Softmax_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/Softmax_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/self/Softmax [Softmax] outputs: [/bert/encoder/layer.3/attention/self/Softmax_output_0 -> (-1, 8, -1, -1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/MatMul_1 [MatMul]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Softmax_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Transpose_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/self/MatMul_1 [MatMul] inputs: [/bert/encoder/layer.3/attention/self/Softmax_output_0 -> (-1, 8, -1, -1)[FLOAT]], [/bert/encoder/layer.3/attention/self/Transpose_output_0 -> (-1, 8, -1, 32)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/MatMul_1 for ONNX node: /bert/encoder/layer.3/attention/self/MatMul_1\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/MatMul_1_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/MatMul_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/self/MatMul_1 [MatMul] outputs: [/bert/encoder/layer.3/attention/self/MatMul_1_output_0 -> (-1, 8, -1, 32)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Transpose_3 [Transpose]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/MatMul_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/self/Transpose_3 [Transpose] inputs: [/bert/encoder/layer.3/attention/self/MatMul_1_output_0 -> (-1, 8, -1, 32)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Transpose_3 for ONNX node: /bert/encoder/layer.3/attention/self/Transpose_3\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/Transpose_3_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/Transpose_3_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/self/Transpose_3 [Transpose] outputs: [/bert/encoder/layer.3/attention/self/Transpose_3_output_0 -> (-1, -1, 8, 32)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Shape_6 [Shape]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Transpose_3_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/self/Shape_6 [Shape] inputs: [/bert/encoder/layer.3/attention/self/Transpose_3_output_0 -> (-1, -1, 8, 32)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Shape_6 for ONNX node: /bert/encoder/layer.3/attention/self/Shape_6\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/Shape_6_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/Shape_6_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/self/Shape_6 [Shape] outputs: [/bert/encoder/layer.3/attention/self/Shape_6_output_0 -> (4)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Constant_13 [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/self/Constant_13 [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/self/Constant_13 [Constant] outputs: [/bert/encoder/layer.3/attention/self/Constant_13_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Gather_6 [Gather]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Shape_6_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Constant_13_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/self/Gather_6 [Gather] inputs: [/bert/encoder/layer.3/attention/self/Shape_6_output_0 -> (4)[INT32]], [/bert/encoder/layer.3/attention/self/Constant_13_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Constant_13_output_0 for ONNX node: /bert/encoder/layer.3/attention/self/Constant_13_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Using Gather axis: 0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Gather_6 for ONNX node: /bert/encoder/layer.3/attention/self/Gather_6\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/Gather_6_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/Gather_6_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/self/Gather_6 [Gather] outputs: [/bert/encoder/layer.3/attention/self/Gather_6_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Shape_7 [Shape]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Transpose_3_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/self/Shape_7 [Shape] inputs: [/bert/encoder/layer.3/attention/self/Transpose_3_output_0 -> (-1, -1, 8, 32)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Shape_7 for ONNX node: /bert/encoder/layer.3/attention/self/Shape_7\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/Shape_7_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/Shape_7_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/self/Shape_7 [Shape] outputs: [/bert/encoder/layer.3/attention/self/Shape_7_output_0 -> (4)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Constant_14 [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/self/Constant_14 [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/self/Constant_14 [Constant] outputs: [/bert/encoder/layer.3/attention/self/Constant_14_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Gather_7 [Gather]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Shape_7_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Constant_14_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/self/Gather_7 [Gather] inputs: [/bert/encoder/layer.3/attention/self/Shape_7_output_0 -> (4)[INT32]], [/bert/encoder/layer.3/attention/self/Constant_14_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Constant_14_output_0 for ONNX node: /bert/encoder/layer.3/attention/self/Constant_14_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Using Gather axis: 0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Gather_7 for ONNX node: /bert/encoder/layer.3/attention/self/Gather_7\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/Gather_7_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/Gather_7_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/self/Gather_7 [Gather] outputs: [/bert/encoder/layer.3/attention/self/Gather_7_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Unsqueeze_6 [Unsqueeze]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Gather_6_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/self/Unsqueeze_6 [Unsqueeze] inputs: [/bert/encoder/layer.3/attention/self/Gather_6_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Original shape: (), unsqueezing to: (1,)\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Unsqueeze_6 for ONNX node: /bert/encoder/layer.3/attention/self/Unsqueeze_6\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/Unsqueeze_6_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/Unsqueeze_6_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/self/Unsqueeze_6 [Unsqueeze] outputs: [/bert/encoder/layer.3/attention/self/Unsqueeze_6_output_0 -> (1)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Unsqueeze_7 [Unsqueeze]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Gather_7_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/self/Unsqueeze_7 [Unsqueeze] inputs: [/bert/encoder/layer.3/attention/self/Gather_7_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Original shape: (), unsqueezing to: (1,)\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Unsqueeze_7 for ONNX node: /bert/encoder/layer.3/attention/self/Unsqueeze_7\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/Unsqueeze_7_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/Unsqueeze_7_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/self/Unsqueeze_7 [Unsqueeze] outputs: [/bert/encoder/layer.3/attention/self/Unsqueeze_7_output_0 -> (1)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Constant_15 [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/self/Constant_15 [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/self/Constant_15 [Constant] outputs: [/bert/encoder/layer.3/attention/self/Constant_15_output_0 -> (1)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Concat_3 [Concat]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Unsqueeze_6_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Unsqueeze_7_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Constant_15_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/self/Concat_3 [Concat] inputs: [/bert/encoder/layer.3/attention/self/Unsqueeze_6_output_0 -> (1)[INT32]], [/bert/encoder/layer.3/attention/self/Unsqueeze_7_output_0 -> (1)[INT32]], [/bert/encoder/layer.3/attention/self/Constant_15_output_0 -> (1)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Constant_15_output_0 for ONNX node: /bert/encoder/layer.3/attention/self/Constant_15_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Concat_3 for ONNX node: /bert/encoder/layer.3/attention/self/Concat_3\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/Concat_3_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/Concat_3_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/self/Concat_3 [Concat] outputs: [/bert/encoder/layer.3/attention/self/Concat_3_output_0 -> (3)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Reshape_3 [Reshape]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Transpose_3_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Concat_3_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/self/Reshape_3 [Reshape] inputs: [/bert/encoder/layer.3/attention/self/Transpose_3_output_0 -> (-1, -1, 8, 32)[FLOAT]], [/bert/encoder/layer.3/attention/self/Concat_3_output_0 -> (3)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Reshape_3 for ONNX node: /bert/encoder/layer.3/attention/self/Reshape_3\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/Reshape_3_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/Reshape_3_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/self/Reshape_3 [Reshape] outputs: [/bert/encoder/layer.3/attention/self/Reshape_3_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/output/dense/MatMul [MatMul]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Reshape_3_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: onnx::MatMul_842\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/output/dense/MatMul [MatMul] inputs: [/bert/encoder/layer.3/attention/self/Reshape_3_output_0 -> (-1, -1, 256)[FLOAT]], [onnx::MatMul_842 -> (256, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: onnx::MatMul_842 for ONNX node: onnx::MatMul_842\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/output/dense/MatMul for ONNX node: /bert/encoder/layer.3/attention/output/dense/MatMul\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/output/dense/MatMul_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/output/dense/MatMul_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/output/dense/MatMul [MatMul] outputs: [/bert/encoder/layer.3/attention/output/dense/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/output/dense/Add [Add]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: bert.encoder.layer.3.attention.output.dense.bias\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/output/dense/MatMul_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/output/dense/Add [Add] inputs: [bert.encoder.layer.3.attention.output.dense.bias -> (256)[FLOAT]], [/bert/encoder/layer.3/attention/output/dense/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: bert.encoder.layer.3.attention.output.dense.bias for ONNX node: bert.encoder.layer.3.attention.output.dense.bias\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/output/dense/Add for ONNX node: /bert/encoder/layer.3/attention/output/dense/Add\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/output/dense/Add_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/output/dense/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/output/dense/Add [Add] outputs: [/bert/encoder/layer.3/attention/output/dense/Add_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/output/Add [Add]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/output/dense/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.2/output/LayerNorm/Add_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/output/Add [Add] inputs: [/bert/encoder/layer.3/attention/output/dense/Add_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.2/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/output/Add for ONNX node: /bert/encoder/layer.3/attention/output/Add\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/output/Add_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/output/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/output/Add [Add] outputs: [/bert/encoder/layer.3/attention/output/Add_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/output/LayerNorm/ReduceMean [ReduceMean]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/output/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/output/LayerNorm/ReduceMean [ReduceMean] inputs: [/bert/encoder/layer.3/attention/output/Add_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/output/LayerNorm/ReduceMean for ONNX node: /bert/encoder/layer.3/attention/output/LayerNorm/ReduceMean\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/output/LayerNorm/ReduceMean_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/output/LayerNorm/ReduceMean_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/output/LayerNorm/ReduceMean [ReduceMean] outputs: [/bert/encoder/layer.3/attention/output/LayerNorm/ReduceMean_output_0 -> (-1, -1, 1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/output/LayerNorm/Sub [Sub]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/output/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/output/LayerNorm/ReduceMean_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/output/LayerNorm/Sub [Sub] inputs: [/bert/encoder/layer.3/attention/output/Add_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.3/attention/output/LayerNorm/ReduceMean_output_0 -> (-1, -1, 1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/output/LayerNorm/Sub for ONNX node: /bert/encoder/layer.3/attention/output/LayerNorm/Sub\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/output/LayerNorm/Sub_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/output/LayerNorm/Sub_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/output/LayerNorm/Sub [Sub] outputs: [/bert/encoder/layer.3/attention/output/LayerNorm/Sub_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/output/LayerNorm/Constant [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/output/LayerNorm/Constant [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/output/LayerNorm/Constant [Constant] outputs: [/bert/encoder/layer.3/attention/output/LayerNorm/Constant_output_0 -> ()[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/output/LayerNorm/Pow [Pow]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/output/LayerNorm/Sub_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/output/LayerNorm/Constant_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/output/LayerNorm/Pow [Pow] inputs: [/bert/encoder/layer.3/attention/output/LayerNorm/Sub_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.3/attention/output/LayerNorm/Constant_output_0 -> ()[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/output/LayerNorm/Constant_output_0 for ONNX node: /bert/encoder/layer.3/attention/output/LayerNorm/Constant_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/output/LayerNorm/Pow for ONNX node: /bert/encoder/layer.3/attention/output/LayerNorm/Pow\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/output/LayerNorm/Pow_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/output/LayerNorm/Pow_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/output/LayerNorm/Pow [Pow] outputs: [/bert/encoder/layer.3/attention/output/LayerNorm/Pow_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/output/LayerNorm/ReduceMean_1 [ReduceMean]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/output/LayerNorm/Pow_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/output/LayerNorm/ReduceMean_1 [ReduceMean] inputs: [/bert/encoder/layer.3/attention/output/LayerNorm/Pow_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/output/LayerNorm/ReduceMean_1 for ONNX node: /bert/encoder/layer.3/attention/output/LayerNorm/ReduceMean_1\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/output/LayerNorm/ReduceMean_1_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/output/LayerNorm/ReduceMean_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/output/LayerNorm/ReduceMean_1 [ReduceMean] outputs: [/bert/encoder/layer.3/attention/output/LayerNorm/ReduceMean_1_output_0 -> (-1, -1, 1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/output/LayerNorm/Constant_1 [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/output/LayerNorm/Constant_1 [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/output/LayerNorm/Constant_1 [Constant] outputs: [/bert/encoder/layer.3/attention/output/LayerNorm/Constant_1_output_0 -> ()[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/output/LayerNorm/Add [Add]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/output/LayerNorm/ReduceMean_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/output/LayerNorm/Constant_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/output/LayerNorm/Add [Add] inputs: [/bert/encoder/layer.3/attention/output/LayerNorm/ReduceMean_1_output_0 -> (-1, -1, 1)[FLOAT]], [/bert/encoder/layer.3/attention/output/LayerNorm/Constant_1_output_0 -> ()[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/output/LayerNorm/Constant_1_output_0 for ONNX node: /bert/encoder/layer.3/attention/output/LayerNorm/Constant_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/output/LayerNorm/Add for ONNX node: /bert/encoder/layer.3/attention/output/LayerNorm/Add\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/output/LayerNorm/Add_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/output/LayerNorm/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/output/LayerNorm/Add [Add] outputs: [/bert/encoder/layer.3/attention/output/LayerNorm/Add_output_0 -> (-1, -1, 1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/output/LayerNorm/Sqrt [Sqrt]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/output/LayerNorm/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/output/LayerNorm/Sqrt [Sqrt] inputs: [/bert/encoder/layer.3/attention/output/LayerNorm/Add_output_0 -> (-1, -1, 1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/output/LayerNorm/Sqrt for ONNX node: /bert/encoder/layer.3/attention/output/LayerNorm/Sqrt\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/output/LayerNorm/Sqrt_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/output/LayerNorm/Sqrt_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/output/LayerNorm/Sqrt [Sqrt] outputs: [/bert/encoder/layer.3/attention/output/LayerNorm/Sqrt_output_0 -> (-1, -1, 1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/output/LayerNorm/Div [Div]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/output/LayerNorm/Sub_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/output/LayerNorm/Sqrt_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/output/LayerNorm/Div [Div] inputs: [/bert/encoder/layer.3/attention/output/LayerNorm/Sub_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.3/attention/output/LayerNorm/Sqrt_output_0 -> (-1, -1, 1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/output/LayerNorm/Div for ONNX node: /bert/encoder/layer.3/attention/output/LayerNorm/Div\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/output/LayerNorm/Div_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/output/LayerNorm/Div_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/output/LayerNorm/Div [Div] outputs: [/bert/encoder/layer.3/attention/output/LayerNorm/Div_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/output/LayerNorm/Mul [Mul]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/output/LayerNorm/Div_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: bert.encoder.layer.3.attention.output.LayerNorm.weight\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/output/LayerNorm/Mul [Mul] inputs: [/bert/encoder/layer.3/attention/output/LayerNorm/Div_output_0 -> (-1, -1, 256)[FLOAT]], [bert.encoder.layer.3.attention.output.LayerNorm.weight -> (256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: bert.encoder.layer.3.attention.output.LayerNorm.weight for ONNX node: bert.encoder.layer.3.attention.output.LayerNorm.weight\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/output/LayerNorm/Mul for ONNX node: /bert/encoder/layer.3/attention/output/LayerNorm/Mul\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/output/LayerNorm/Mul_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/output/LayerNorm/Mul_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/output/LayerNorm/Mul [Mul] outputs: [/bert/encoder/layer.3/attention/output/LayerNorm/Mul_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/output/LayerNorm/Add_1 [Add]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/output/LayerNorm/Mul_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: bert.encoder.layer.3.attention.output.LayerNorm.bias\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/output/LayerNorm/Add_1 [Add] inputs: [/bert/encoder/layer.3/attention/output/LayerNorm/Mul_output_0 -> (-1, -1, 256)[FLOAT]], [bert.encoder.layer.3.attention.output.LayerNorm.bias -> (256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: bert.encoder.layer.3.attention.output.LayerNorm.bias for ONNX node: bert.encoder.layer.3.attention.output.LayerNorm.bias\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/output/LayerNorm/Add_1 for ONNX node: /bert/encoder/layer.3/attention/output/LayerNorm/Add_1\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/output/LayerNorm/Add_1_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/output/LayerNorm/Add_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/attention/output/LayerNorm/Add_1 [Add] outputs: [/bert/encoder/layer.3/attention/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.3/intermediate/dense/MatMul [MatMul]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/output/LayerNorm/Add_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: onnx::MatMul_843\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/intermediate/dense/MatMul [MatMul] inputs: [/bert/encoder/layer.3/attention/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], [onnx::MatMul_843 -> (256, 1024)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: onnx::MatMul_843 for ONNX node: onnx::MatMul_843\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.3/intermediate/dense/MatMul for ONNX node: /bert/encoder/layer.3/intermediate/dense/MatMul\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.3/intermediate/dense/MatMul_output_0 for ONNX tensor: /bert/encoder/layer.3/intermediate/dense/MatMul_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/intermediate/dense/MatMul [MatMul] outputs: [/bert/encoder/layer.3/intermediate/dense/MatMul_output_0 -> (-1, -1, 1024)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.3/intermediate/dense/Add [Add]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: bert.encoder.layer.3.intermediate.dense.bias\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.3/intermediate/dense/MatMul_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/intermediate/dense/Add [Add] inputs: [bert.encoder.layer.3.intermediate.dense.bias -> (1024)[FLOAT]], [/bert/encoder/layer.3/intermediate/dense/MatMul_output_0 -> (-1, -1, 1024)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: bert.encoder.layer.3.intermediate.dense.bias for ONNX node: bert.encoder.layer.3.intermediate.dense.bias\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.3/intermediate/dense/Add for ONNX node: /bert/encoder/layer.3/intermediate/dense/Add\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.3/intermediate/dense/Add_output_0 for ONNX tensor: /bert/encoder/layer.3/intermediate/dense/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/intermediate/dense/Add [Add] outputs: [/bert/encoder/layer.3/intermediate/dense/Add_output_0 -> (-1, -1, 1024)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.3/intermediate/intermediate_act_fn/Constant [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/intermediate/intermediate_act_fn/Constant [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/intermediate/intermediate_act_fn/Constant [Constant] outputs: [/bert/encoder/layer.3/intermediate/intermediate_act_fn/Constant_output_0 -> ()[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.3/intermediate/intermediate_act_fn/Div [Div]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.3/intermediate/dense/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.3/intermediate/intermediate_act_fn/Constant_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/intermediate/intermediate_act_fn/Div [Div] inputs: [/bert/encoder/layer.3/intermediate/dense/Add_output_0 -> (-1, -1, 1024)[FLOAT]], [/bert/encoder/layer.3/intermediate/intermediate_act_fn/Constant_output_0 -> ()[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.3/intermediate/intermediate_act_fn/Constant_output_0 for ONNX node: /bert/encoder/layer.3/intermediate/intermediate_act_fn/Constant_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.3/intermediate/intermediate_act_fn/Div for ONNX node: /bert/encoder/layer.3/intermediate/intermediate_act_fn/Div\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.3/intermediate/intermediate_act_fn/Div_output_0 for ONNX tensor: /bert/encoder/layer.3/intermediate/intermediate_act_fn/Div_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/intermediate/intermediate_act_fn/Div [Div] outputs: [/bert/encoder/layer.3/intermediate/intermediate_act_fn/Div_output_0 -> (-1, -1, 1024)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.3/intermediate/intermediate_act_fn/Erf [Erf]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.3/intermediate/intermediate_act_fn/Div_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/intermediate/intermediate_act_fn/Erf [Erf] inputs: [/bert/encoder/layer.3/intermediate/intermediate_act_fn/Div_output_0 -> (-1, -1, 1024)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.3/intermediate/intermediate_act_fn/Erf for ONNX node: /bert/encoder/layer.3/intermediate/intermediate_act_fn/Erf\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.3/intermediate/intermediate_act_fn/Erf_output_0 for ONNX tensor: /bert/encoder/layer.3/intermediate/intermediate_act_fn/Erf_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/intermediate/intermediate_act_fn/Erf [Erf] outputs: [/bert/encoder/layer.3/intermediate/intermediate_act_fn/Erf_output_0 -> (-1, -1, 1024)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.3/intermediate/intermediate_act_fn/Constant_1 [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/intermediate/intermediate_act_fn/Constant_1 [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/intermediate/intermediate_act_fn/Constant_1 [Constant] outputs: [/bert/encoder/layer.3/intermediate/intermediate_act_fn/Constant_1_output_0 -> ()[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.3/intermediate/intermediate_act_fn/Add [Add]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.3/intermediate/intermediate_act_fn/Erf_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.3/intermediate/intermediate_act_fn/Constant_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/intermediate/intermediate_act_fn/Add [Add] inputs: [/bert/encoder/layer.3/intermediate/intermediate_act_fn/Erf_output_0 -> (-1, -1, 1024)[FLOAT]], [/bert/encoder/layer.3/intermediate/intermediate_act_fn/Constant_1_output_0 -> ()[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.3/intermediate/intermediate_act_fn/Constant_1_output_0 for ONNX node: /bert/encoder/layer.3/intermediate/intermediate_act_fn/Constant_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.3/intermediate/intermediate_act_fn/Add for ONNX node: /bert/encoder/layer.3/intermediate/intermediate_act_fn/Add\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.3/intermediate/intermediate_act_fn/Add_output_0 for ONNX tensor: /bert/encoder/layer.3/intermediate/intermediate_act_fn/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/intermediate/intermediate_act_fn/Add [Add] outputs: [/bert/encoder/layer.3/intermediate/intermediate_act_fn/Add_output_0 -> (-1, -1, 1024)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.3/intermediate/intermediate_act_fn/Mul [Mul]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.3/intermediate/dense/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.3/intermediate/intermediate_act_fn/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/intermediate/intermediate_act_fn/Mul [Mul] inputs: [/bert/encoder/layer.3/intermediate/dense/Add_output_0 -> (-1, -1, 1024)[FLOAT]], [/bert/encoder/layer.3/intermediate/intermediate_act_fn/Add_output_0 -> (-1, -1, 1024)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.3/intermediate/intermediate_act_fn/Mul for ONNX node: /bert/encoder/layer.3/intermediate/intermediate_act_fn/Mul\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.3/intermediate/intermediate_act_fn/Mul_output_0 for ONNX tensor: /bert/encoder/layer.3/intermediate/intermediate_act_fn/Mul_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/intermediate/intermediate_act_fn/Mul [Mul] outputs: [/bert/encoder/layer.3/intermediate/intermediate_act_fn/Mul_output_0 -> (-1, -1, 1024)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.3/intermediate/intermediate_act_fn/Constant_2 [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/intermediate/intermediate_act_fn/Constant_2 [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/intermediate/intermediate_act_fn/Constant_2 [Constant] outputs: [/bert/encoder/layer.3/intermediate/intermediate_act_fn/Constant_2_output_0 -> ()[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.3/intermediate/intermediate_act_fn/Mul_1 [Mul]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.3/intermediate/intermediate_act_fn/Mul_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.3/intermediate/intermediate_act_fn/Constant_2_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/intermediate/intermediate_act_fn/Mul_1 [Mul] inputs: [/bert/encoder/layer.3/intermediate/intermediate_act_fn/Mul_output_0 -> (-1, -1, 1024)[FLOAT]], [/bert/encoder/layer.3/intermediate/intermediate_act_fn/Constant_2_output_0 -> ()[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.3/intermediate/intermediate_act_fn/Constant_2_output_0 for ONNX node: /bert/encoder/layer.3/intermediate/intermediate_act_fn/Constant_2_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.3/intermediate/intermediate_act_fn/Mul_1 for ONNX node: /bert/encoder/layer.3/intermediate/intermediate_act_fn/Mul_1\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.3/intermediate/intermediate_act_fn/Mul_1_output_0 for ONNX tensor: /bert/encoder/layer.3/intermediate/intermediate_act_fn/Mul_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/intermediate/intermediate_act_fn/Mul_1 [Mul] outputs: [/bert/encoder/layer.3/intermediate/intermediate_act_fn/Mul_1_output_0 -> (-1, -1, 1024)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.3/output/dense/MatMul [MatMul]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.3/intermediate/intermediate_act_fn/Mul_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: onnx::MatMul_844\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/output/dense/MatMul [MatMul] inputs: [/bert/encoder/layer.3/intermediate/intermediate_act_fn/Mul_1_output_0 -> (-1, -1, 1024)[FLOAT]], [onnx::MatMul_844 -> (1024, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: onnx::MatMul_844 for ONNX node: onnx::MatMul_844\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.3/output/dense/MatMul for ONNX node: /bert/encoder/layer.3/output/dense/MatMul\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.3/output/dense/MatMul_output_0 for ONNX tensor: /bert/encoder/layer.3/output/dense/MatMul_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/output/dense/MatMul [MatMul] outputs: [/bert/encoder/layer.3/output/dense/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.3/output/dense/Add [Add]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: bert.encoder.layer.3.output.dense.bias\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.3/output/dense/MatMul_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/output/dense/Add [Add] inputs: [bert.encoder.layer.3.output.dense.bias -> (256)[FLOAT]], [/bert/encoder/layer.3/output/dense/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: bert.encoder.layer.3.output.dense.bias for ONNX node: bert.encoder.layer.3.output.dense.bias\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.3/output/dense/Add for ONNX node: /bert/encoder/layer.3/output/dense/Add\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.3/output/dense/Add_output_0 for ONNX tensor: /bert/encoder/layer.3/output/dense/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/output/dense/Add [Add] outputs: [/bert/encoder/layer.3/output/dense/Add_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.3/output/Add [Add]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.3/output/dense/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/output/LayerNorm/Add_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/output/Add [Add] inputs: [/bert/encoder/layer.3/output/dense/Add_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.3/attention/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.3/output/Add for ONNX node: /bert/encoder/layer.3/output/Add\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.3/output/Add_output_0 for ONNX tensor: /bert/encoder/layer.3/output/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/output/Add [Add] outputs: [/bert/encoder/layer.3/output/Add_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.3/output/LayerNorm/ReduceMean [ReduceMean]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.3/output/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/output/LayerNorm/ReduceMean [ReduceMean] inputs: [/bert/encoder/layer.3/output/Add_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.3/output/LayerNorm/ReduceMean for ONNX node: /bert/encoder/layer.3/output/LayerNorm/ReduceMean\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.3/output/LayerNorm/ReduceMean_output_0 for ONNX tensor: /bert/encoder/layer.3/output/LayerNorm/ReduceMean_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/output/LayerNorm/ReduceMean [ReduceMean] outputs: [/bert/encoder/layer.3/output/LayerNorm/ReduceMean_output_0 -> (-1, -1, 1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.3/output/LayerNorm/Sub [Sub]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.3/output/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.3/output/LayerNorm/ReduceMean_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/output/LayerNorm/Sub [Sub] inputs: [/bert/encoder/layer.3/output/Add_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.3/output/LayerNorm/ReduceMean_output_0 -> (-1, -1, 1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.3/output/LayerNorm/Sub for ONNX node: /bert/encoder/layer.3/output/LayerNorm/Sub\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.3/output/LayerNorm/Sub_output_0 for ONNX tensor: /bert/encoder/layer.3/output/LayerNorm/Sub_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/output/LayerNorm/Sub [Sub] outputs: [/bert/encoder/layer.3/output/LayerNorm/Sub_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.3/output/LayerNorm/Constant [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/output/LayerNorm/Constant [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/output/LayerNorm/Constant [Constant] outputs: [/bert/encoder/layer.3/output/LayerNorm/Constant_output_0 -> ()[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.3/output/LayerNorm/Pow [Pow]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.3/output/LayerNorm/Sub_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.3/output/LayerNorm/Constant_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/output/LayerNorm/Pow [Pow] inputs: [/bert/encoder/layer.3/output/LayerNorm/Sub_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.3/output/LayerNorm/Constant_output_0 -> ()[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.3/output/LayerNorm/Constant_output_0 for ONNX node: /bert/encoder/layer.3/output/LayerNorm/Constant_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.3/output/LayerNorm/Pow for ONNX node: /bert/encoder/layer.3/output/LayerNorm/Pow\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.3/output/LayerNorm/Pow_output_0 for ONNX tensor: /bert/encoder/layer.3/output/LayerNorm/Pow_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/output/LayerNorm/Pow [Pow] outputs: [/bert/encoder/layer.3/output/LayerNorm/Pow_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.3/output/LayerNorm/ReduceMean_1 [ReduceMean]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.3/output/LayerNorm/Pow_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/output/LayerNorm/ReduceMean_1 [ReduceMean] inputs: [/bert/encoder/layer.3/output/LayerNorm/Pow_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.3/output/LayerNorm/ReduceMean_1 for ONNX node: /bert/encoder/layer.3/output/LayerNorm/ReduceMean_1\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.3/output/LayerNorm/ReduceMean_1_output_0 for ONNX tensor: /bert/encoder/layer.3/output/LayerNorm/ReduceMean_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/output/LayerNorm/ReduceMean_1 [ReduceMean] outputs: [/bert/encoder/layer.3/output/LayerNorm/ReduceMean_1_output_0 -> (-1, -1, 1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.3/output/LayerNorm/Constant_1 [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/output/LayerNorm/Constant_1 [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/output/LayerNorm/Constant_1 [Constant] outputs: [/bert/encoder/layer.3/output/LayerNorm/Constant_1_output_0 -> ()[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.3/output/LayerNorm/Add [Add]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.3/output/LayerNorm/ReduceMean_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.3/output/LayerNorm/Constant_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/output/LayerNorm/Add [Add] inputs: [/bert/encoder/layer.3/output/LayerNorm/ReduceMean_1_output_0 -> (-1, -1, 1)[FLOAT]], [/bert/encoder/layer.3/output/LayerNorm/Constant_1_output_0 -> ()[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.3/output/LayerNorm/Constant_1_output_0 for ONNX node: /bert/encoder/layer.3/output/LayerNorm/Constant_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.3/output/LayerNorm/Add for ONNX node: /bert/encoder/layer.3/output/LayerNorm/Add\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.3/output/LayerNorm/Add_output_0 for ONNX tensor: /bert/encoder/layer.3/output/LayerNorm/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/output/LayerNorm/Add [Add] outputs: [/bert/encoder/layer.3/output/LayerNorm/Add_output_0 -> (-1, -1, 1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.3/output/LayerNorm/Sqrt [Sqrt]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.3/output/LayerNorm/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/output/LayerNorm/Sqrt [Sqrt] inputs: [/bert/encoder/layer.3/output/LayerNorm/Add_output_0 -> (-1, -1, 1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.3/output/LayerNorm/Sqrt for ONNX node: /bert/encoder/layer.3/output/LayerNorm/Sqrt\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.3/output/LayerNorm/Sqrt_output_0 for ONNX tensor: /bert/encoder/layer.3/output/LayerNorm/Sqrt_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/output/LayerNorm/Sqrt [Sqrt] outputs: [/bert/encoder/layer.3/output/LayerNorm/Sqrt_output_0 -> (-1, -1, 1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.3/output/LayerNorm/Div [Div]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.3/output/LayerNorm/Sub_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.3/output/LayerNorm/Sqrt_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/output/LayerNorm/Div [Div] inputs: [/bert/encoder/layer.3/output/LayerNorm/Sub_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.3/output/LayerNorm/Sqrt_output_0 -> (-1, -1, 1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.3/output/LayerNorm/Div for ONNX node: /bert/encoder/layer.3/output/LayerNorm/Div\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.3/output/LayerNorm/Div_output_0 for ONNX tensor: /bert/encoder/layer.3/output/LayerNorm/Div_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/output/LayerNorm/Div [Div] outputs: [/bert/encoder/layer.3/output/LayerNorm/Div_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.3/output/LayerNorm/Mul [Mul]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.3/output/LayerNorm/Div_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: bert.encoder.layer.3.output.LayerNorm.weight\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/output/LayerNorm/Mul [Mul] inputs: [/bert/encoder/layer.3/output/LayerNorm/Div_output_0 -> (-1, -1, 256)[FLOAT]], [bert.encoder.layer.3.output.LayerNorm.weight -> (256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: bert.encoder.layer.3.output.LayerNorm.weight for ONNX node: bert.encoder.layer.3.output.LayerNorm.weight\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.3/output/LayerNorm/Mul for ONNX node: /bert/encoder/layer.3/output/LayerNorm/Mul\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.3/output/LayerNorm/Mul_output_0 for ONNX tensor: /bert/encoder/layer.3/output/LayerNorm/Mul_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/output/LayerNorm/Mul [Mul] outputs: [/bert/encoder/layer.3/output/LayerNorm/Mul_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.3/output/LayerNorm/Add_1 [Add]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.3/output/LayerNorm/Mul_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: bert.encoder.layer.3.output.LayerNorm.bias\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/output/LayerNorm/Add_1 [Add] inputs: [/bert/encoder/layer.3/output/LayerNorm/Mul_output_0 -> (-1, -1, 256)[FLOAT]], [bert.encoder.layer.3.output.LayerNorm.bias -> (256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: bert.encoder.layer.3.output.LayerNorm.bias for ONNX node: bert.encoder.layer.3.output.LayerNorm.bias\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.3/output/LayerNorm/Add_1 for ONNX node: /bert/encoder/layer.3/output/LayerNorm/Add_1\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.3/output/LayerNorm/Add_1_output_0 for ONNX tensor: /bert/encoder/layer.3/output/LayerNorm/Add_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.3/output/LayerNorm/Add_1 [Add] outputs: [/bert/encoder/layer.3/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/query/MatMul [MatMul]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.3/output/LayerNorm/Add_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: onnx::MatMul_845\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/self/query/MatMul [MatMul] inputs: [/bert/encoder/layer.3/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], [onnx::MatMul_845 -> (256, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: onnx::MatMul_845 for ONNX node: onnx::MatMul_845\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/query/MatMul for ONNX node: /bert/encoder/layer.4/attention/self/query/MatMul\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/query/MatMul_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/query/MatMul_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/self/query/MatMul [MatMul] outputs: [/bert/encoder/layer.4/attention/self/query/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/query/Add [Add]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: bert.encoder.layer.4.attention.self.query.bias\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/query/MatMul_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/self/query/Add [Add] inputs: [bert.encoder.layer.4.attention.self.query.bias -> (256)[FLOAT]], [/bert/encoder/layer.4/attention/self/query/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: bert.encoder.layer.4.attention.self.query.bias for ONNX node: bert.encoder.layer.4.attention.self.query.bias\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/query/Add for ONNX node: /bert/encoder/layer.4/attention/self/query/Add\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/query/Add_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/query/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/self/query/Add [Add] outputs: [/bert/encoder/layer.4/attention/self/query/Add_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/key/MatMul [MatMul]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.3/output/LayerNorm/Add_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: onnx::MatMul_846\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/self/key/MatMul [MatMul] inputs: [/bert/encoder/layer.3/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], [onnx::MatMul_846 -> (256, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: onnx::MatMul_846 for ONNX node: onnx::MatMul_846\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/key/MatMul for ONNX node: /bert/encoder/layer.4/attention/self/key/MatMul\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/key/MatMul_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/key/MatMul_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/self/key/MatMul [MatMul] outputs: [/bert/encoder/layer.4/attention/self/key/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/key/Add [Add]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: bert.encoder.layer.4.attention.self.key.bias\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/key/MatMul_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/self/key/Add [Add] inputs: [bert.encoder.layer.4.attention.self.key.bias -> (256)[FLOAT]], [/bert/encoder/layer.4/attention/self/key/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: bert.encoder.layer.4.attention.self.key.bias for ONNX node: bert.encoder.layer.4.attention.self.key.bias\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/key/Add for ONNX node: /bert/encoder/layer.4/attention/self/key/Add\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/key/Add_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/key/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/self/key/Add [Add] outputs: [/bert/encoder/layer.4/attention/self/key/Add_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Shape [Shape]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/key/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/self/Shape [Shape] inputs: [/bert/encoder/layer.4/attention/self/key/Add_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Shape for ONNX node: /bert/encoder/layer.4/attention/self/Shape\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/Shape_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/Shape_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/self/Shape [Shape] outputs: [/bert/encoder/layer.4/attention/self/Shape_output_0 -> (3)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Constant [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/self/Constant [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/self/Constant [Constant] outputs: [/bert/encoder/layer.4/attention/self/Constant_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Gather [Gather]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Shape_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Constant_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/self/Gather [Gather] inputs: [/bert/encoder/layer.4/attention/self/Shape_output_0 -> (3)[INT32]], [/bert/encoder/layer.4/attention/self/Constant_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Constant_output_0 for ONNX node: /bert/encoder/layer.4/attention/self/Constant_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Using Gather axis: 0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Gather for ONNX node: /bert/encoder/layer.4/attention/self/Gather\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/Gather_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/Gather_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/self/Gather [Gather] outputs: [/bert/encoder/layer.4/attention/self/Gather_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Shape_1 [Shape]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/key/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/self/Shape_1 [Shape] inputs: [/bert/encoder/layer.4/attention/self/key/Add_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Shape_1 for ONNX node: /bert/encoder/layer.4/attention/self/Shape_1\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/Shape_1_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/Shape_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/self/Shape_1 [Shape] outputs: [/bert/encoder/layer.4/attention/self/Shape_1_output_0 -> (3)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Constant_1 [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/self/Constant_1 [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/self/Constant_1 [Constant] outputs: [/bert/encoder/layer.4/attention/self/Constant_1_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Gather_1 [Gather]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Shape_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Constant_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/self/Gather_1 [Gather] inputs: [/bert/encoder/layer.4/attention/self/Shape_1_output_0 -> (3)[INT32]], [/bert/encoder/layer.4/attention/self/Constant_1_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Constant_1_output_0 for ONNX node: /bert/encoder/layer.4/attention/self/Constant_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Using Gather axis: 0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Gather_1 for ONNX node: /bert/encoder/layer.4/attention/self/Gather_1\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/Gather_1_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/Gather_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/self/Gather_1 [Gather] outputs: [/bert/encoder/layer.4/attention/self/Gather_1_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Unsqueeze [Unsqueeze]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Gather_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/self/Unsqueeze [Unsqueeze] inputs: [/bert/encoder/layer.4/attention/self/Gather_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Original shape: (), unsqueezing to: (1,)\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Unsqueeze for ONNX node: /bert/encoder/layer.4/attention/self/Unsqueeze\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/Unsqueeze_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/Unsqueeze_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/self/Unsqueeze [Unsqueeze] outputs: [/bert/encoder/layer.4/attention/self/Unsqueeze_output_0 -> (1)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Unsqueeze_1 [Unsqueeze]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Gather_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/self/Unsqueeze_1 [Unsqueeze] inputs: [/bert/encoder/layer.4/attention/self/Gather_1_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Original shape: (), unsqueezing to: (1,)\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Unsqueeze_1 for ONNX node: /bert/encoder/layer.4/attention/self/Unsqueeze_1\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/Unsqueeze_1_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/Unsqueeze_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/self/Unsqueeze_1 [Unsqueeze] outputs: [/bert/encoder/layer.4/attention/self/Unsqueeze_1_output_0 -> (1)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Constant_2 [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/self/Constant_2 [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/self/Constant_2 [Constant] outputs: [/bert/encoder/layer.4/attention/self/Constant_2_output_0 -> (1)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Constant_3 [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/self/Constant_3 [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/self/Constant_3 [Constant] outputs: [/bert/encoder/layer.4/attention/self/Constant_3_output_0 -> (1)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Concat [Concat]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Unsqueeze_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Unsqueeze_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Constant_2_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Constant_3_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/self/Concat [Concat] inputs: [/bert/encoder/layer.4/attention/self/Unsqueeze_output_0 -> (1)[INT32]], [/bert/encoder/layer.4/attention/self/Unsqueeze_1_output_0 -> (1)[INT32]], [/bert/encoder/layer.4/attention/self/Constant_2_output_0 -> (1)[INT32]], [/bert/encoder/layer.4/attention/self/Constant_3_output_0 -> (1)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Constant_2_output_0 for ONNX node: /bert/encoder/layer.4/attention/self/Constant_2_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Constant_3_output_0 for ONNX node: /bert/encoder/layer.4/attention/self/Constant_3_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Concat for ONNX node: /bert/encoder/layer.4/attention/self/Concat\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/Concat_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/Concat_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/self/Concat [Concat] outputs: [/bert/encoder/layer.4/attention/self/Concat_output_0 -> (4)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Reshape [Reshape]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/key/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Concat_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/self/Reshape [Reshape] inputs: [/bert/encoder/layer.4/attention/self/key/Add_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.4/attention/self/Concat_output_0 -> (4)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Reshape for ONNX node: /bert/encoder/layer.4/attention/self/Reshape\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/Reshape_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/Reshape_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/self/Reshape [Reshape] outputs: [/bert/encoder/layer.4/attention/self/Reshape_output_0 -> (-1, -1, 8, 32)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/value/MatMul [MatMul]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.3/output/LayerNorm/Add_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: onnx::MatMul_849\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/self/value/MatMul [MatMul] inputs: [/bert/encoder/layer.3/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], [onnx::MatMul_849 -> (256, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: onnx::MatMul_849 for ONNX node: onnx::MatMul_849\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/value/MatMul for ONNX node: /bert/encoder/layer.4/attention/self/value/MatMul\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/value/MatMul_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/value/MatMul_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/self/value/MatMul [MatMul] outputs: [/bert/encoder/layer.4/attention/self/value/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/value/Add [Add]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: bert.encoder.layer.4.attention.self.value.bias\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/value/MatMul_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/self/value/Add [Add] inputs: [bert.encoder.layer.4.attention.self.value.bias -> (256)[FLOAT]], [/bert/encoder/layer.4/attention/self/value/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: bert.encoder.layer.4.attention.self.value.bias for ONNX node: bert.encoder.layer.4.attention.self.value.bias\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/value/Add for ONNX node: /bert/encoder/layer.4/attention/self/value/Add\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/value/Add_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/value/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/self/value/Add [Add] outputs: [/bert/encoder/layer.4/attention/self/value/Add_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Shape_2 [Shape]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/value/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/self/Shape_2 [Shape] inputs: [/bert/encoder/layer.4/attention/self/value/Add_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Shape_2 for ONNX node: /bert/encoder/layer.4/attention/self/Shape_2\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/Shape_2_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/Shape_2_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/self/Shape_2 [Shape] outputs: [/bert/encoder/layer.4/attention/self/Shape_2_output_0 -> (3)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Constant_4 [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/self/Constant_4 [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/self/Constant_4 [Constant] outputs: [/bert/encoder/layer.4/attention/self/Constant_4_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Gather_2 [Gather]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Shape_2_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Constant_4_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/self/Gather_2 [Gather] inputs: [/bert/encoder/layer.4/attention/self/Shape_2_output_0 -> (3)[INT32]], [/bert/encoder/layer.4/attention/self/Constant_4_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Constant_4_output_0 for ONNX node: /bert/encoder/layer.4/attention/self/Constant_4_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Using Gather axis: 0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Gather_2 for ONNX node: /bert/encoder/layer.4/attention/self/Gather_2\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/Gather_2_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/Gather_2_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/self/Gather_2 [Gather] outputs: [/bert/encoder/layer.4/attention/self/Gather_2_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Shape_3 [Shape]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/value/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/self/Shape_3 [Shape] inputs: [/bert/encoder/layer.4/attention/self/value/Add_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Shape_3 for ONNX node: /bert/encoder/layer.4/attention/self/Shape_3\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/Shape_3_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/Shape_3_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/self/Shape_3 [Shape] outputs: [/bert/encoder/layer.4/attention/self/Shape_3_output_0 -> (3)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Constant_5 [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/self/Constant_5 [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/self/Constant_5 [Constant] outputs: [/bert/encoder/layer.4/attention/self/Constant_5_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Gather_3 [Gather]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Shape_3_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Constant_5_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/self/Gather_3 [Gather] inputs: [/bert/encoder/layer.4/attention/self/Shape_3_output_0 -> (3)[INT32]], [/bert/encoder/layer.4/attention/self/Constant_5_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Constant_5_output_0 for ONNX node: /bert/encoder/layer.4/attention/self/Constant_5_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Using Gather axis: 0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Gather_3 for ONNX node: /bert/encoder/layer.4/attention/self/Gather_3\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/Gather_3_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/Gather_3_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/self/Gather_3 [Gather] outputs: [/bert/encoder/layer.4/attention/self/Gather_3_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Unsqueeze_2 [Unsqueeze]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Gather_2_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/self/Unsqueeze_2 [Unsqueeze] inputs: [/bert/encoder/layer.4/attention/self/Gather_2_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Original shape: (), unsqueezing to: (1,)\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Unsqueeze_2 for ONNX node: /bert/encoder/layer.4/attention/self/Unsqueeze_2\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/Unsqueeze_2_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/Unsqueeze_2_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/self/Unsqueeze_2 [Unsqueeze] outputs: [/bert/encoder/layer.4/attention/self/Unsqueeze_2_output_0 -> (1)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Unsqueeze_3 [Unsqueeze]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Gather_3_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/self/Unsqueeze_3 [Unsqueeze] inputs: [/bert/encoder/layer.4/attention/self/Gather_3_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Original shape: (), unsqueezing to: (1,)\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Unsqueeze_3 for ONNX node: /bert/encoder/layer.4/attention/self/Unsqueeze_3\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/Unsqueeze_3_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/Unsqueeze_3_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/self/Unsqueeze_3 [Unsqueeze] outputs: [/bert/encoder/layer.4/attention/self/Unsqueeze_3_output_0 -> (1)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Constant_6 [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/self/Constant_6 [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/self/Constant_6 [Constant] outputs: [/bert/encoder/layer.4/attention/self/Constant_6_output_0 -> (1)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Constant_7 [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/self/Constant_7 [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/self/Constant_7 [Constant] outputs: [/bert/encoder/layer.4/attention/self/Constant_7_output_0 -> (1)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Concat_1 [Concat]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Unsqueeze_2_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Unsqueeze_3_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Constant_6_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Constant_7_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/self/Concat_1 [Concat] inputs: [/bert/encoder/layer.4/attention/self/Unsqueeze_2_output_0 -> (1)[INT32]], [/bert/encoder/layer.4/attention/self/Unsqueeze_3_output_0 -> (1)[INT32]], [/bert/encoder/layer.4/attention/self/Constant_6_output_0 -> (1)[INT32]], [/bert/encoder/layer.4/attention/self/Constant_7_output_0 -> (1)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Constant_6_output_0 for ONNX node: /bert/encoder/layer.4/attention/self/Constant_6_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Constant_7_output_0 for ONNX node: /bert/encoder/layer.4/attention/self/Constant_7_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Concat_1 for ONNX node: /bert/encoder/layer.4/attention/self/Concat_1\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/Concat_1_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/Concat_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/self/Concat_1 [Concat] outputs: [/bert/encoder/layer.4/attention/self/Concat_1_output_0 -> (4)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Reshape_1 [Reshape]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/value/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Concat_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/self/Reshape_1 [Reshape] inputs: [/bert/encoder/layer.4/attention/self/value/Add_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.4/attention/self/Concat_1_output_0 -> (4)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Reshape_1 for ONNX node: /bert/encoder/layer.4/attention/self/Reshape_1\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/Reshape_1_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/Reshape_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/self/Reshape_1 [Reshape] outputs: [/bert/encoder/layer.4/attention/self/Reshape_1_output_0 -> (-1, -1, 8, 32)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Transpose [Transpose]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Reshape_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/self/Transpose [Transpose] inputs: [/bert/encoder/layer.4/attention/self/Reshape_1_output_0 -> (-1, -1, 8, 32)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Transpose for ONNX node: /bert/encoder/layer.4/attention/self/Transpose\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/Transpose_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/Transpose_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/self/Transpose [Transpose] outputs: [/bert/encoder/layer.4/attention/self/Transpose_output_0 -> (-1, 8, -1, 32)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Shape_4 [Shape]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/query/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/self/Shape_4 [Shape] inputs: [/bert/encoder/layer.4/attention/self/query/Add_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Shape_4 for ONNX node: /bert/encoder/layer.4/attention/self/Shape_4\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/Shape_4_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/Shape_4_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/self/Shape_4 [Shape] outputs: [/bert/encoder/layer.4/attention/self/Shape_4_output_0 -> (3)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Constant_8 [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/self/Constant_8 [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/self/Constant_8 [Constant] outputs: [/bert/encoder/layer.4/attention/self/Constant_8_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Gather_4 [Gather]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Shape_4_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Constant_8_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/self/Gather_4 [Gather] inputs: [/bert/encoder/layer.4/attention/self/Shape_4_output_0 -> (3)[INT32]], [/bert/encoder/layer.4/attention/self/Constant_8_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Constant_8_output_0 for ONNX node: /bert/encoder/layer.4/attention/self/Constant_8_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Using Gather axis: 0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Gather_4 for ONNX node: /bert/encoder/layer.4/attention/self/Gather_4\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/Gather_4_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/Gather_4_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/self/Gather_4 [Gather] outputs: [/bert/encoder/layer.4/attention/self/Gather_4_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Shape_5 [Shape]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/query/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/self/Shape_5 [Shape] inputs: [/bert/encoder/layer.4/attention/self/query/Add_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Shape_5 for ONNX node: /bert/encoder/layer.4/attention/self/Shape_5\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/Shape_5_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/Shape_5_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/self/Shape_5 [Shape] outputs: [/bert/encoder/layer.4/attention/self/Shape_5_output_0 -> (3)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Constant_9 [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/self/Constant_9 [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/self/Constant_9 [Constant] outputs: [/bert/encoder/layer.4/attention/self/Constant_9_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Gather_5 [Gather]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Shape_5_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Constant_9_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/self/Gather_5 [Gather] inputs: [/bert/encoder/layer.4/attention/self/Shape_5_output_0 -> (3)[INT32]], [/bert/encoder/layer.4/attention/self/Constant_9_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Constant_9_output_0 for ONNX node: /bert/encoder/layer.4/attention/self/Constant_9_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Using Gather axis: 0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Gather_5 for ONNX node: /bert/encoder/layer.4/attention/self/Gather_5\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/Gather_5_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/Gather_5_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/self/Gather_5 [Gather] outputs: [/bert/encoder/layer.4/attention/self/Gather_5_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Unsqueeze_4 [Unsqueeze]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Gather_4_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/self/Unsqueeze_4 [Unsqueeze] inputs: [/bert/encoder/layer.4/attention/self/Gather_4_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Original shape: (), unsqueezing to: (1,)\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Unsqueeze_4 for ONNX node: /bert/encoder/layer.4/attention/self/Unsqueeze_4\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/Unsqueeze_4_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/Unsqueeze_4_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/self/Unsqueeze_4 [Unsqueeze] outputs: [/bert/encoder/layer.4/attention/self/Unsqueeze_4_output_0 -> (1)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Unsqueeze_5 [Unsqueeze]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Gather_5_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/self/Unsqueeze_5 [Unsqueeze] inputs: [/bert/encoder/layer.4/attention/self/Gather_5_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Original shape: (), unsqueezing to: (1,)\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Unsqueeze_5 for ONNX node: /bert/encoder/layer.4/attention/self/Unsqueeze_5\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/Unsqueeze_5_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/Unsqueeze_5_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/self/Unsqueeze_5 [Unsqueeze] outputs: [/bert/encoder/layer.4/attention/self/Unsqueeze_5_output_0 -> (1)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Constant_10 [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/self/Constant_10 [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/self/Constant_10 [Constant] outputs: [/bert/encoder/layer.4/attention/self/Constant_10_output_0 -> (1)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Constant_11 [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/self/Constant_11 [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/self/Constant_11 [Constant] outputs: [/bert/encoder/layer.4/attention/self/Constant_11_output_0 -> (1)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Concat_2 [Concat]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Unsqueeze_4_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Unsqueeze_5_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Constant_10_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Constant_11_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/self/Concat_2 [Concat] inputs: [/bert/encoder/layer.4/attention/self/Unsqueeze_4_output_0 -> (1)[INT32]], [/bert/encoder/layer.4/attention/self/Unsqueeze_5_output_0 -> (1)[INT32]], [/bert/encoder/layer.4/attention/self/Constant_10_output_0 -> (1)[INT32]], [/bert/encoder/layer.4/attention/self/Constant_11_output_0 -> (1)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Constant_10_output_0 for ONNX node: /bert/encoder/layer.4/attention/self/Constant_10_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Constant_11_output_0 for ONNX node: /bert/encoder/layer.4/attention/self/Constant_11_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Concat_2 for ONNX node: /bert/encoder/layer.4/attention/self/Concat_2\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/Concat_2_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/Concat_2_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/self/Concat_2 [Concat] outputs: [/bert/encoder/layer.4/attention/self/Concat_2_output_0 -> (4)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Reshape_2 [Reshape]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/query/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Concat_2_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/self/Reshape_2 [Reshape] inputs: [/bert/encoder/layer.4/attention/self/query/Add_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.4/attention/self/Concat_2_output_0 -> (4)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Reshape_2 for ONNX node: /bert/encoder/layer.4/attention/self/Reshape_2\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/Reshape_2_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/Reshape_2_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/self/Reshape_2 [Reshape] outputs: [/bert/encoder/layer.4/attention/self/Reshape_2_output_0 -> (-1, -1, 8, 32)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Transpose_1 [Transpose]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Reshape_2_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/self/Transpose_1 [Transpose] inputs: [/bert/encoder/layer.4/attention/self/Reshape_2_output_0 -> (-1, -1, 8, 32)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Transpose_1 for ONNX node: /bert/encoder/layer.4/attention/self/Transpose_1\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/Transpose_1_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/Transpose_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/self/Transpose_1 [Transpose] outputs: [/bert/encoder/layer.4/attention/self/Transpose_1_output_0 -> (-1, 8, -1, 32)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Transpose_2 [Transpose]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Reshape_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/self/Transpose_2 [Transpose] inputs: [/bert/encoder/layer.4/attention/self/Reshape_output_0 -> (-1, -1, 8, 32)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Transpose_2 for ONNX node: /bert/encoder/layer.4/attention/self/Transpose_2\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/Transpose_2_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/Transpose_2_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/self/Transpose_2 [Transpose] outputs: [/bert/encoder/layer.4/attention/self/Transpose_2_output_0 -> (-1, 8, 32, -1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/MatMul [MatMul]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Transpose_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Transpose_2_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/self/MatMul [MatMul] inputs: [/bert/encoder/layer.4/attention/self/Transpose_1_output_0 -> (-1, 8, -1, 32)[FLOAT]], [/bert/encoder/layer.4/attention/self/Transpose_2_output_0 -> (-1, 8, 32, -1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/MatMul for ONNX node: /bert/encoder/layer.4/attention/self/MatMul\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/MatMul_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/MatMul_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/self/MatMul [MatMul] outputs: [/bert/encoder/layer.4/attention/self/MatMul_output_0 -> (-1, 8, -1, -1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Constant_12 [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/self/Constant_12 [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/self/Constant_12 [Constant] outputs: [/bert/encoder/layer.4/attention/self/Constant_12_output_0 -> ()[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Div [Div]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/MatMul_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Constant_12_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/self/Div [Div] inputs: [/bert/encoder/layer.4/attention/self/MatMul_output_0 -> (-1, 8, -1, -1)[FLOAT]], [/bert/encoder/layer.4/attention/self/Constant_12_output_0 -> ()[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Constant_12_output_0 for ONNX node: /bert/encoder/layer.4/attention/self/Constant_12_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Div for ONNX node: /bert/encoder/layer.4/attention/self/Div\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/Div_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/Div_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/self/Div [Div] outputs: [/bert/encoder/layer.4/attention/self/Div_output_0 -> (-1, 8, -1, -1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Add [Add]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Div_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/Mul_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/self/Add [Add] inputs: [/bert/encoder/layer.4/attention/self/Div_output_0 -> (-1, 8, -1, -1)[FLOAT]], [/bert/Mul_output_0 -> (-1, 1, 1, -1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Add for ONNX node: /bert/encoder/layer.4/attention/self/Add\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/Add_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/self/Add [Add] outputs: [/bert/encoder/layer.4/attention/self/Add_output_0 -> (-1, 8, -1, -1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Softmax [Softmax]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/self/Softmax [Softmax] inputs: [/bert/encoder/layer.4/attention/self/Add_output_0 -> (-1, 8, -1, -1)[FLOAT]], \r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Softmax for ONNX node: /bert/encoder/layer.4/attention/self/Softmax\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/Softmax_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/Softmax_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/self/Softmax [Softmax] outputs: [/bert/encoder/layer.4/attention/self/Softmax_output_0 -> (-1, 8, -1, -1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/MatMul_1 [MatMul]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Softmax_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Transpose_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/self/MatMul_1 [MatMul] inputs: [/bert/encoder/layer.4/attention/self/Softmax_output_0 -> (-1, 8, -1, -1)[FLOAT]], [/bert/encoder/layer.4/attention/self/Transpose_output_0 -> (-1, 8, -1, 32)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/MatMul_1 for ONNX node: /bert/encoder/layer.4/attention/self/MatMul_1\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/MatMul_1_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/MatMul_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/self/MatMul_1 [MatMul] outputs: [/bert/encoder/layer.4/attention/self/MatMul_1_output_0 -> (-1, 8, -1, 32)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Transpose_3 [Transpose]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/MatMul_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/self/Transpose_3 [Transpose] inputs: [/bert/encoder/layer.4/attention/self/MatMul_1_output_0 -> (-1, 8, -1, 32)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Transpose_3 for ONNX node: /bert/encoder/layer.4/attention/self/Transpose_3\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/Transpose_3_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/Transpose_3_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/self/Transpose_3 [Transpose] outputs: [/bert/encoder/layer.4/attention/self/Transpose_3_output_0 -> (-1, -1, 8, 32)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Shape_6 [Shape]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Transpose_3_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/self/Shape_6 [Shape] inputs: [/bert/encoder/layer.4/attention/self/Transpose_3_output_0 -> (-1, -1, 8, 32)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Shape_6 for ONNX node: /bert/encoder/layer.4/attention/self/Shape_6\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/Shape_6_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/Shape_6_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/self/Shape_6 [Shape] outputs: [/bert/encoder/layer.4/attention/self/Shape_6_output_0 -> (4)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Constant_13 [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/self/Constant_13 [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/self/Constant_13 [Constant] outputs: [/bert/encoder/layer.4/attention/self/Constant_13_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Gather_6 [Gather]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Shape_6_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Constant_13_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/self/Gather_6 [Gather] inputs: [/bert/encoder/layer.4/attention/self/Shape_6_output_0 -> (4)[INT32]], [/bert/encoder/layer.4/attention/self/Constant_13_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Constant_13_output_0 for ONNX node: /bert/encoder/layer.4/attention/self/Constant_13_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Using Gather axis: 0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Gather_6 for ONNX node: /bert/encoder/layer.4/attention/self/Gather_6\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/Gather_6_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/Gather_6_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/self/Gather_6 [Gather] outputs: [/bert/encoder/layer.4/attention/self/Gather_6_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Shape_7 [Shape]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Transpose_3_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/self/Shape_7 [Shape] inputs: [/bert/encoder/layer.4/attention/self/Transpose_3_output_0 -> (-1, -1, 8, 32)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Shape_7 for ONNX node: /bert/encoder/layer.4/attention/self/Shape_7\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/Shape_7_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/Shape_7_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/self/Shape_7 [Shape] outputs: [/bert/encoder/layer.4/attention/self/Shape_7_output_0 -> (4)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Constant_14 [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/self/Constant_14 [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/self/Constant_14 [Constant] outputs: [/bert/encoder/layer.4/attention/self/Constant_14_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Gather_7 [Gather]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Shape_7_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Constant_14_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/self/Gather_7 [Gather] inputs: [/bert/encoder/layer.4/attention/self/Shape_7_output_0 -> (4)[INT32]], [/bert/encoder/layer.4/attention/self/Constant_14_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Constant_14_output_0 for ONNX node: /bert/encoder/layer.4/attention/self/Constant_14_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Using Gather axis: 0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Gather_7 for ONNX node: /bert/encoder/layer.4/attention/self/Gather_7\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/Gather_7_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/Gather_7_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/self/Gather_7 [Gather] outputs: [/bert/encoder/layer.4/attention/self/Gather_7_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Unsqueeze_6 [Unsqueeze]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Gather_6_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/self/Unsqueeze_6 [Unsqueeze] inputs: [/bert/encoder/layer.4/attention/self/Gather_6_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Original shape: (), unsqueezing to: (1,)\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Unsqueeze_6 for ONNX node: /bert/encoder/layer.4/attention/self/Unsqueeze_6\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/Unsqueeze_6_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/Unsqueeze_6_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/self/Unsqueeze_6 [Unsqueeze] outputs: [/bert/encoder/layer.4/attention/self/Unsqueeze_6_output_0 -> (1)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Unsqueeze_7 [Unsqueeze]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Gather_7_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/self/Unsqueeze_7 [Unsqueeze] inputs: [/bert/encoder/layer.4/attention/self/Gather_7_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Original shape: (), unsqueezing to: (1,)\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Unsqueeze_7 for ONNX node: /bert/encoder/layer.4/attention/self/Unsqueeze_7\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/Unsqueeze_7_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/Unsqueeze_7_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/self/Unsqueeze_7 [Unsqueeze] outputs: [/bert/encoder/layer.4/attention/self/Unsqueeze_7_output_0 -> (1)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Constant_15 [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/self/Constant_15 [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/self/Constant_15 [Constant] outputs: [/bert/encoder/layer.4/attention/self/Constant_15_output_0 -> (1)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Concat_3 [Concat]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Unsqueeze_6_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Unsqueeze_7_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Constant_15_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/self/Concat_3 [Concat] inputs: [/bert/encoder/layer.4/attention/self/Unsqueeze_6_output_0 -> (1)[INT32]], [/bert/encoder/layer.4/attention/self/Unsqueeze_7_output_0 -> (1)[INT32]], [/bert/encoder/layer.4/attention/self/Constant_15_output_0 -> (1)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Constant_15_output_0 for ONNX node: /bert/encoder/layer.4/attention/self/Constant_15_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Concat_3 for ONNX node: /bert/encoder/layer.4/attention/self/Concat_3\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/Concat_3_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/Concat_3_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/self/Concat_3 [Concat] outputs: [/bert/encoder/layer.4/attention/self/Concat_3_output_0 -> (3)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Reshape_3 [Reshape]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Transpose_3_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Concat_3_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/self/Reshape_3 [Reshape] inputs: [/bert/encoder/layer.4/attention/self/Transpose_3_output_0 -> (-1, -1, 8, 32)[FLOAT]], [/bert/encoder/layer.4/attention/self/Concat_3_output_0 -> (3)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Reshape_3 for ONNX node: /bert/encoder/layer.4/attention/self/Reshape_3\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/Reshape_3_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/Reshape_3_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/self/Reshape_3 [Reshape] outputs: [/bert/encoder/layer.4/attention/self/Reshape_3_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/output/dense/MatMul [MatMul]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Reshape_3_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: onnx::MatMul_855\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/output/dense/MatMul [MatMul] inputs: [/bert/encoder/layer.4/attention/self/Reshape_3_output_0 -> (-1, -1, 256)[FLOAT]], [onnx::MatMul_855 -> (256, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: onnx::MatMul_855 for ONNX node: onnx::MatMul_855\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/output/dense/MatMul for ONNX node: /bert/encoder/layer.4/attention/output/dense/MatMul\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/output/dense/MatMul_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/output/dense/MatMul_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/output/dense/MatMul [MatMul] outputs: [/bert/encoder/layer.4/attention/output/dense/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/output/dense/Add [Add]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: bert.encoder.layer.4.attention.output.dense.bias\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/output/dense/MatMul_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/output/dense/Add [Add] inputs: [bert.encoder.layer.4.attention.output.dense.bias -> (256)[FLOAT]], [/bert/encoder/layer.4/attention/output/dense/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: bert.encoder.layer.4.attention.output.dense.bias for ONNX node: bert.encoder.layer.4.attention.output.dense.bias\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/output/dense/Add for ONNX node: /bert/encoder/layer.4/attention/output/dense/Add\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/output/dense/Add_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/output/dense/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/output/dense/Add [Add] outputs: [/bert/encoder/layer.4/attention/output/dense/Add_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/output/Add [Add]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/output/dense/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.3/output/LayerNorm/Add_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/output/Add [Add] inputs: [/bert/encoder/layer.4/attention/output/dense/Add_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.3/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/output/Add for ONNX node: /bert/encoder/layer.4/attention/output/Add\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/output/Add_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/output/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/output/Add [Add] outputs: [/bert/encoder/layer.4/attention/output/Add_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/output/LayerNorm/ReduceMean [ReduceMean]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/output/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/output/LayerNorm/ReduceMean [ReduceMean] inputs: [/bert/encoder/layer.4/attention/output/Add_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/output/LayerNorm/ReduceMean for ONNX node: /bert/encoder/layer.4/attention/output/LayerNorm/ReduceMean\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/output/LayerNorm/ReduceMean_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/output/LayerNorm/ReduceMean_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/output/LayerNorm/ReduceMean [ReduceMean] outputs: [/bert/encoder/layer.4/attention/output/LayerNorm/ReduceMean_output_0 -> (-1, -1, 1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/output/LayerNorm/Sub [Sub]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/output/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/output/LayerNorm/ReduceMean_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/output/LayerNorm/Sub [Sub] inputs: [/bert/encoder/layer.4/attention/output/Add_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.4/attention/output/LayerNorm/ReduceMean_output_0 -> (-1, -1, 1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/output/LayerNorm/Sub for ONNX node: /bert/encoder/layer.4/attention/output/LayerNorm/Sub\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/output/LayerNorm/Sub_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/output/LayerNorm/Sub_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/output/LayerNorm/Sub [Sub] outputs: [/bert/encoder/layer.4/attention/output/LayerNorm/Sub_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/output/LayerNorm/Constant [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/output/LayerNorm/Constant [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/output/LayerNorm/Constant [Constant] outputs: [/bert/encoder/layer.4/attention/output/LayerNorm/Constant_output_0 -> ()[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/output/LayerNorm/Pow [Pow]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/output/LayerNorm/Sub_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/output/LayerNorm/Constant_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/output/LayerNorm/Pow [Pow] inputs: [/bert/encoder/layer.4/attention/output/LayerNorm/Sub_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.4/attention/output/LayerNorm/Constant_output_0 -> ()[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/output/LayerNorm/Constant_output_0 for ONNX node: /bert/encoder/layer.4/attention/output/LayerNorm/Constant_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/output/LayerNorm/Pow for ONNX node: /bert/encoder/layer.4/attention/output/LayerNorm/Pow\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/output/LayerNorm/Pow_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/output/LayerNorm/Pow_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/output/LayerNorm/Pow [Pow] outputs: [/bert/encoder/layer.4/attention/output/LayerNorm/Pow_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/output/LayerNorm/ReduceMean_1 [ReduceMean]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/output/LayerNorm/Pow_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/output/LayerNorm/ReduceMean_1 [ReduceMean] inputs: [/bert/encoder/layer.4/attention/output/LayerNorm/Pow_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/output/LayerNorm/ReduceMean_1 for ONNX node: /bert/encoder/layer.4/attention/output/LayerNorm/ReduceMean_1\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/output/LayerNorm/ReduceMean_1_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/output/LayerNorm/ReduceMean_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/output/LayerNorm/ReduceMean_1 [ReduceMean] outputs: [/bert/encoder/layer.4/attention/output/LayerNorm/ReduceMean_1_output_0 -> (-1, -1, 1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/output/LayerNorm/Constant_1 [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/output/LayerNorm/Constant_1 [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/output/LayerNorm/Constant_1 [Constant] outputs: [/bert/encoder/layer.4/attention/output/LayerNorm/Constant_1_output_0 -> ()[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/output/LayerNorm/Add [Add]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/output/LayerNorm/ReduceMean_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/output/LayerNorm/Constant_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/output/LayerNorm/Add [Add] inputs: [/bert/encoder/layer.4/attention/output/LayerNorm/ReduceMean_1_output_0 -> (-1, -1, 1)[FLOAT]], [/bert/encoder/layer.4/attention/output/LayerNorm/Constant_1_output_0 -> ()[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/output/LayerNorm/Constant_1_output_0 for ONNX node: /bert/encoder/layer.4/attention/output/LayerNorm/Constant_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/output/LayerNorm/Add for ONNX node: /bert/encoder/layer.4/attention/output/LayerNorm/Add\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/output/LayerNorm/Add_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/output/LayerNorm/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/output/LayerNorm/Add [Add] outputs: [/bert/encoder/layer.4/attention/output/LayerNorm/Add_output_0 -> (-1, -1, 1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/output/LayerNorm/Sqrt [Sqrt]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/output/LayerNorm/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/output/LayerNorm/Sqrt [Sqrt] inputs: [/bert/encoder/layer.4/attention/output/LayerNorm/Add_output_0 -> (-1, -1, 1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/output/LayerNorm/Sqrt for ONNX node: /bert/encoder/layer.4/attention/output/LayerNorm/Sqrt\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/output/LayerNorm/Sqrt_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/output/LayerNorm/Sqrt_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/output/LayerNorm/Sqrt [Sqrt] outputs: [/bert/encoder/layer.4/attention/output/LayerNorm/Sqrt_output_0 -> (-1, -1, 1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/output/LayerNorm/Div [Div]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/output/LayerNorm/Sub_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/output/LayerNorm/Sqrt_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/output/LayerNorm/Div [Div] inputs: [/bert/encoder/layer.4/attention/output/LayerNorm/Sub_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.4/attention/output/LayerNorm/Sqrt_output_0 -> (-1, -1, 1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/output/LayerNorm/Div for ONNX node: /bert/encoder/layer.4/attention/output/LayerNorm/Div\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/output/LayerNorm/Div_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/output/LayerNorm/Div_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/output/LayerNorm/Div [Div] outputs: [/bert/encoder/layer.4/attention/output/LayerNorm/Div_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/output/LayerNorm/Mul [Mul]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/output/LayerNorm/Div_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: bert.encoder.layer.4.attention.output.LayerNorm.weight\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/output/LayerNorm/Mul [Mul] inputs: [/bert/encoder/layer.4/attention/output/LayerNorm/Div_output_0 -> (-1, -1, 256)[FLOAT]], [bert.encoder.layer.4.attention.output.LayerNorm.weight -> (256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: bert.encoder.layer.4.attention.output.LayerNorm.weight for ONNX node: bert.encoder.layer.4.attention.output.LayerNorm.weight\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/output/LayerNorm/Mul for ONNX node: /bert/encoder/layer.4/attention/output/LayerNorm/Mul\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/output/LayerNorm/Mul_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/output/LayerNorm/Mul_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/output/LayerNorm/Mul [Mul] outputs: [/bert/encoder/layer.4/attention/output/LayerNorm/Mul_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/output/LayerNorm/Add_1 [Add]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/output/LayerNorm/Mul_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: bert.encoder.layer.4.attention.output.LayerNorm.bias\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/output/LayerNorm/Add_1 [Add] inputs: [/bert/encoder/layer.4/attention/output/LayerNorm/Mul_output_0 -> (-1, -1, 256)[FLOAT]], [bert.encoder.layer.4.attention.output.LayerNorm.bias -> (256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: bert.encoder.layer.4.attention.output.LayerNorm.bias for ONNX node: bert.encoder.layer.4.attention.output.LayerNorm.bias\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/output/LayerNorm/Add_1 for ONNX node: /bert/encoder/layer.4/attention/output/LayerNorm/Add_1\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/output/LayerNorm/Add_1_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/output/LayerNorm/Add_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/attention/output/LayerNorm/Add_1 [Add] outputs: [/bert/encoder/layer.4/attention/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.4/intermediate/dense/MatMul [MatMul]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/output/LayerNorm/Add_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: onnx::MatMul_856\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/intermediate/dense/MatMul [MatMul] inputs: [/bert/encoder/layer.4/attention/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], [onnx::MatMul_856 -> (256, 1024)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: onnx::MatMul_856 for ONNX node: onnx::MatMul_856\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.4/intermediate/dense/MatMul for ONNX node: /bert/encoder/layer.4/intermediate/dense/MatMul\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.4/intermediate/dense/MatMul_output_0 for ONNX tensor: /bert/encoder/layer.4/intermediate/dense/MatMul_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/intermediate/dense/MatMul [MatMul] outputs: [/bert/encoder/layer.4/intermediate/dense/MatMul_output_0 -> (-1, -1, 1024)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.4/intermediate/dense/Add [Add]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: bert.encoder.layer.4.intermediate.dense.bias\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.4/intermediate/dense/MatMul_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/intermediate/dense/Add [Add] inputs: [bert.encoder.layer.4.intermediate.dense.bias -> (1024)[FLOAT]], [/bert/encoder/layer.4/intermediate/dense/MatMul_output_0 -> (-1, -1, 1024)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: bert.encoder.layer.4.intermediate.dense.bias for ONNX node: bert.encoder.layer.4.intermediate.dense.bias\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.4/intermediate/dense/Add for ONNX node: /bert/encoder/layer.4/intermediate/dense/Add\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.4/intermediate/dense/Add_output_0 for ONNX tensor: /bert/encoder/layer.4/intermediate/dense/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/intermediate/dense/Add [Add] outputs: [/bert/encoder/layer.4/intermediate/dense/Add_output_0 -> (-1, -1, 1024)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.4/intermediate/intermediate_act_fn/Constant [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/intermediate/intermediate_act_fn/Constant [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/intermediate/intermediate_act_fn/Constant [Constant] outputs: [/bert/encoder/layer.4/intermediate/intermediate_act_fn/Constant_output_0 -> ()[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.4/intermediate/intermediate_act_fn/Div [Div]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.4/intermediate/dense/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.4/intermediate/intermediate_act_fn/Constant_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/intermediate/intermediate_act_fn/Div [Div] inputs: [/bert/encoder/layer.4/intermediate/dense/Add_output_0 -> (-1, -1, 1024)[FLOAT]], [/bert/encoder/layer.4/intermediate/intermediate_act_fn/Constant_output_0 -> ()[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.4/intermediate/intermediate_act_fn/Constant_output_0 for ONNX node: /bert/encoder/layer.4/intermediate/intermediate_act_fn/Constant_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.4/intermediate/intermediate_act_fn/Div for ONNX node: /bert/encoder/layer.4/intermediate/intermediate_act_fn/Div\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.4/intermediate/intermediate_act_fn/Div_output_0 for ONNX tensor: /bert/encoder/layer.4/intermediate/intermediate_act_fn/Div_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/intermediate/intermediate_act_fn/Div [Div] outputs: [/bert/encoder/layer.4/intermediate/intermediate_act_fn/Div_output_0 -> (-1, -1, 1024)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.4/intermediate/intermediate_act_fn/Erf [Erf]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.4/intermediate/intermediate_act_fn/Div_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/intermediate/intermediate_act_fn/Erf [Erf] inputs: [/bert/encoder/layer.4/intermediate/intermediate_act_fn/Div_output_0 -> (-1, -1, 1024)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.4/intermediate/intermediate_act_fn/Erf for ONNX node: /bert/encoder/layer.4/intermediate/intermediate_act_fn/Erf\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.4/intermediate/intermediate_act_fn/Erf_output_0 for ONNX tensor: /bert/encoder/layer.4/intermediate/intermediate_act_fn/Erf_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/intermediate/intermediate_act_fn/Erf [Erf] outputs: [/bert/encoder/layer.4/intermediate/intermediate_act_fn/Erf_output_0 -> (-1, -1, 1024)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.4/intermediate/intermediate_act_fn/Constant_1 [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/intermediate/intermediate_act_fn/Constant_1 [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/intermediate/intermediate_act_fn/Constant_1 [Constant] outputs: [/bert/encoder/layer.4/intermediate/intermediate_act_fn/Constant_1_output_0 -> ()[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.4/intermediate/intermediate_act_fn/Add [Add]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.4/intermediate/intermediate_act_fn/Erf_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.4/intermediate/intermediate_act_fn/Constant_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/intermediate/intermediate_act_fn/Add [Add] inputs: [/bert/encoder/layer.4/intermediate/intermediate_act_fn/Erf_output_0 -> (-1, -1, 1024)[FLOAT]], [/bert/encoder/layer.4/intermediate/intermediate_act_fn/Constant_1_output_0 -> ()[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.4/intermediate/intermediate_act_fn/Constant_1_output_0 for ONNX node: /bert/encoder/layer.4/intermediate/intermediate_act_fn/Constant_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.4/intermediate/intermediate_act_fn/Add for ONNX node: /bert/encoder/layer.4/intermediate/intermediate_act_fn/Add\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.4/intermediate/intermediate_act_fn/Add_output_0 for ONNX tensor: /bert/encoder/layer.4/intermediate/intermediate_act_fn/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/intermediate/intermediate_act_fn/Add [Add] outputs: [/bert/encoder/layer.4/intermediate/intermediate_act_fn/Add_output_0 -> (-1, -1, 1024)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.4/intermediate/intermediate_act_fn/Mul [Mul]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.4/intermediate/dense/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.4/intermediate/intermediate_act_fn/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/intermediate/intermediate_act_fn/Mul [Mul] inputs: [/bert/encoder/layer.4/intermediate/dense/Add_output_0 -> (-1, -1, 1024)[FLOAT]], [/bert/encoder/layer.4/intermediate/intermediate_act_fn/Add_output_0 -> (-1, -1, 1024)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.4/intermediate/intermediate_act_fn/Mul for ONNX node: /bert/encoder/layer.4/intermediate/intermediate_act_fn/Mul\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.4/intermediate/intermediate_act_fn/Mul_output_0 for ONNX tensor: /bert/encoder/layer.4/intermediate/intermediate_act_fn/Mul_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/intermediate/intermediate_act_fn/Mul [Mul] outputs: [/bert/encoder/layer.4/intermediate/intermediate_act_fn/Mul_output_0 -> (-1, -1, 1024)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.4/intermediate/intermediate_act_fn/Constant_2 [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/intermediate/intermediate_act_fn/Constant_2 [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/intermediate/intermediate_act_fn/Constant_2 [Constant] outputs: [/bert/encoder/layer.4/intermediate/intermediate_act_fn/Constant_2_output_0 -> ()[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.4/intermediate/intermediate_act_fn/Mul_1 [Mul]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.4/intermediate/intermediate_act_fn/Mul_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.4/intermediate/intermediate_act_fn/Constant_2_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/intermediate/intermediate_act_fn/Mul_1 [Mul] inputs: [/bert/encoder/layer.4/intermediate/intermediate_act_fn/Mul_output_0 -> (-1, -1, 1024)[FLOAT]], [/bert/encoder/layer.4/intermediate/intermediate_act_fn/Constant_2_output_0 -> ()[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.4/intermediate/intermediate_act_fn/Constant_2_output_0 for ONNX node: /bert/encoder/layer.4/intermediate/intermediate_act_fn/Constant_2_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.4/intermediate/intermediate_act_fn/Mul_1 for ONNX node: /bert/encoder/layer.4/intermediate/intermediate_act_fn/Mul_1\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.4/intermediate/intermediate_act_fn/Mul_1_output_0 for ONNX tensor: /bert/encoder/layer.4/intermediate/intermediate_act_fn/Mul_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/intermediate/intermediate_act_fn/Mul_1 [Mul] outputs: [/bert/encoder/layer.4/intermediate/intermediate_act_fn/Mul_1_output_0 -> (-1, -1, 1024)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.4/output/dense/MatMul [MatMul]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.4/intermediate/intermediate_act_fn/Mul_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: onnx::MatMul_857\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/output/dense/MatMul [MatMul] inputs: [/bert/encoder/layer.4/intermediate/intermediate_act_fn/Mul_1_output_0 -> (-1, -1, 1024)[FLOAT]], [onnx::MatMul_857 -> (1024, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: onnx::MatMul_857 for ONNX node: onnx::MatMul_857\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.4/output/dense/MatMul for ONNX node: /bert/encoder/layer.4/output/dense/MatMul\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.4/output/dense/MatMul_output_0 for ONNX tensor: /bert/encoder/layer.4/output/dense/MatMul_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/output/dense/MatMul [MatMul] outputs: [/bert/encoder/layer.4/output/dense/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.4/output/dense/Add [Add]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: bert.encoder.layer.4.output.dense.bias\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.4/output/dense/MatMul_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/output/dense/Add [Add] inputs: [bert.encoder.layer.4.output.dense.bias -> (256)[FLOAT]], [/bert/encoder/layer.4/output/dense/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: bert.encoder.layer.4.output.dense.bias for ONNX node: bert.encoder.layer.4.output.dense.bias\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.4/output/dense/Add for ONNX node: /bert/encoder/layer.4/output/dense/Add\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.4/output/dense/Add_output_0 for ONNX tensor: /bert/encoder/layer.4/output/dense/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/output/dense/Add [Add] outputs: [/bert/encoder/layer.4/output/dense/Add_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.4/output/Add [Add]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.4/output/dense/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/output/LayerNorm/Add_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/output/Add [Add] inputs: [/bert/encoder/layer.4/output/dense/Add_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.4/attention/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.4/output/Add for ONNX node: /bert/encoder/layer.4/output/Add\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.4/output/Add_output_0 for ONNX tensor: /bert/encoder/layer.4/output/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/output/Add [Add] outputs: [/bert/encoder/layer.4/output/Add_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.4/output/LayerNorm/ReduceMean [ReduceMean]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.4/output/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/output/LayerNorm/ReduceMean [ReduceMean] inputs: [/bert/encoder/layer.4/output/Add_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.4/output/LayerNorm/ReduceMean for ONNX node: /bert/encoder/layer.4/output/LayerNorm/ReduceMean\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.4/output/LayerNorm/ReduceMean_output_0 for ONNX tensor: /bert/encoder/layer.4/output/LayerNorm/ReduceMean_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/output/LayerNorm/ReduceMean [ReduceMean] outputs: [/bert/encoder/layer.4/output/LayerNorm/ReduceMean_output_0 -> (-1, -1, 1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.4/output/LayerNorm/Sub [Sub]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.4/output/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.4/output/LayerNorm/ReduceMean_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/output/LayerNorm/Sub [Sub] inputs: [/bert/encoder/layer.4/output/Add_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.4/output/LayerNorm/ReduceMean_output_0 -> (-1, -1, 1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.4/output/LayerNorm/Sub for ONNX node: /bert/encoder/layer.4/output/LayerNorm/Sub\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.4/output/LayerNorm/Sub_output_0 for ONNX tensor: /bert/encoder/layer.4/output/LayerNorm/Sub_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/output/LayerNorm/Sub [Sub] outputs: [/bert/encoder/layer.4/output/LayerNorm/Sub_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.4/output/LayerNorm/Constant [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/output/LayerNorm/Constant [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/output/LayerNorm/Constant [Constant] outputs: [/bert/encoder/layer.4/output/LayerNorm/Constant_output_0 -> ()[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.4/output/LayerNorm/Pow [Pow]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.4/output/LayerNorm/Sub_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.4/output/LayerNorm/Constant_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/output/LayerNorm/Pow [Pow] inputs: [/bert/encoder/layer.4/output/LayerNorm/Sub_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.4/output/LayerNorm/Constant_output_0 -> ()[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.4/output/LayerNorm/Constant_output_0 for ONNX node: /bert/encoder/layer.4/output/LayerNorm/Constant_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.4/output/LayerNorm/Pow for ONNX node: /bert/encoder/layer.4/output/LayerNorm/Pow\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.4/output/LayerNorm/Pow_output_0 for ONNX tensor: /bert/encoder/layer.4/output/LayerNorm/Pow_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/output/LayerNorm/Pow [Pow] outputs: [/bert/encoder/layer.4/output/LayerNorm/Pow_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.4/output/LayerNorm/ReduceMean_1 [ReduceMean]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.4/output/LayerNorm/Pow_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/output/LayerNorm/ReduceMean_1 [ReduceMean] inputs: [/bert/encoder/layer.4/output/LayerNorm/Pow_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.4/output/LayerNorm/ReduceMean_1 for ONNX node: /bert/encoder/layer.4/output/LayerNorm/ReduceMean_1\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.4/output/LayerNorm/ReduceMean_1_output_0 for ONNX tensor: /bert/encoder/layer.4/output/LayerNorm/ReduceMean_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/output/LayerNorm/ReduceMean_1 [ReduceMean] outputs: [/bert/encoder/layer.4/output/LayerNorm/ReduceMean_1_output_0 -> (-1, -1, 1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.4/output/LayerNorm/Constant_1 [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/output/LayerNorm/Constant_1 [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/output/LayerNorm/Constant_1 [Constant] outputs: [/bert/encoder/layer.4/output/LayerNorm/Constant_1_output_0 -> ()[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.4/output/LayerNorm/Add [Add]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.4/output/LayerNorm/ReduceMean_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.4/output/LayerNorm/Constant_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/output/LayerNorm/Add [Add] inputs: [/bert/encoder/layer.4/output/LayerNorm/ReduceMean_1_output_0 -> (-1, -1, 1)[FLOAT]], [/bert/encoder/layer.4/output/LayerNorm/Constant_1_output_0 -> ()[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.4/output/LayerNorm/Constant_1_output_0 for ONNX node: /bert/encoder/layer.4/output/LayerNorm/Constant_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.4/output/LayerNorm/Add for ONNX node: /bert/encoder/layer.4/output/LayerNorm/Add\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.4/output/LayerNorm/Add_output_0 for ONNX tensor: /bert/encoder/layer.4/output/LayerNorm/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/output/LayerNorm/Add [Add] outputs: [/bert/encoder/layer.4/output/LayerNorm/Add_output_0 -> (-1, -1, 1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.4/output/LayerNorm/Sqrt [Sqrt]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.4/output/LayerNorm/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/output/LayerNorm/Sqrt [Sqrt] inputs: [/bert/encoder/layer.4/output/LayerNorm/Add_output_0 -> (-1, -1, 1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.4/output/LayerNorm/Sqrt for ONNX node: /bert/encoder/layer.4/output/LayerNorm/Sqrt\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.4/output/LayerNorm/Sqrt_output_0 for ONNX tensor: /bert/encoder/layer.4/output/LayerNorm/Sqrt_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/output/LayerNorm/Sqrt [Sqrt] outputs: [/bert/encoder/layer.4/output/LayerNorm/Sqrt_output_0 -> (-1, -1, 1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.4/output/LayerNorm/Div [Div]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.4/output/LayerNorm/Sub_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.4/output/LayerNorm/Sqrt_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/output/LayerNorm/Div [Div] inputs: [/bert/encoder/layer.4/output/LayerNorm/Sub_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.4/output/LayerNorm/Sqrt_output_0 -> (-1, -1, 1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.4/output/LayerNorm/Div for ONNX node: /bert/encoder/layer.4/output/LayerNorm/Div\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.4/output/LayerNorm/Div_output_0 for ONNX tensor: /bert/encoder/layer.4/output/LayerNorm/Div_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/output/LayerNorm/Div [Div] outputs: [/bert/encoder/layer.4/output/LayerNorm/Div_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.4/output/LayerNorm/Mul [Mul]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.4/output/LayerNorm/Div_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: bert.encoder.layer.4.output.LayerNorm.weight\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/output/LayerNorm/Mul [Mul] inputs: [/bert/encoder/layer.4/output/LayerNorm/Div_output_0 -> (-1, -1, 256)[FLOAT]], [bert.encoder.layer.4.output.LayerNorm.weight -> (256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: bert.encoder.layer.4.output.LayerNorm.weight for ONNX node: bert.encoder.layer.4.output.LayerNorm.weight\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.4/output/LayerNorm/Mul for ONNX node: /bert/encoder/layer.4/output/LayerNorm/Mul\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.4/output/LayerNorm/Mul_output_0 for ONNX tensor: /bert/encoder/layer.4/output/LayerNorm/Mul_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/output/LayerNorm/Mul [Mul] outputs: [/bert/encoder/layer.4/output/LayerNorm/Mul_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.4/output/LayerNorm/Add_1 [Add]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.4/output/LayerNorm/Mul_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: bert.encoder.layer.4.output.LayerNorm.bias\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/output/LayerNorm/Add_1 [Add] inputs: [/bert/encoder/layer.4/output/LayerNorm/Mul_output_0 -> (-1, -1, 256)[FLOAT]], [bert.encoder.layer.4.output.LayerNorm.bias -> (256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: bert.encoder.layer.4.output.LayerNorm.bias for ONNX node: bert.encoder.layer.4.output.LayerNorm.bias\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.4/output/LayerNorm/Add_1 for ONNX node: /bert/encoder/layer.4/output/LayerNorm/Add_1\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.4/output/LayerNorm/Add_1_output_0 for ONNX tensor: /bert/encoder/layer.4/output/LayerNorm/Add_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.4/output/LayerNorm/Add_1 [Add] outputs: [/bert/encoder/layer.4/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/query/MatMul [MatMul]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.4/output/LayerNorm/Add_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: onnx::MatMul_858\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.5/attention/self/query/MatMul [MatMul] inputs: [/bert/encoder/layer.4/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], [onnx::MatMul_858 -> (256, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: onnx::MatMul_858 for ONNX node: onnx::MatMul_858\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/query/MatMul for ONNX node: /bert/encoder/layer.5/attention/self/query/MatMul\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/query/MatMul_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/query/MatMul_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.5/attention/self/query/MatMul [MatMul] outputs: [/bert/encoder/layer.5/attention/self/query/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/query/Add [Add]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: bert.encoder.layer.5.attention.self.query.bias\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/query/MatMul_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.5/attention/self/query/Add [Add] inputs: [bert.encoder.layer.5.attention.self.query.bias -> (256)[FLOAT]], [/bert/encoder/layer.5/attention/self/query/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: bert.encoder.layer.5.attention.self.query.bias for ONNX node: bert.encoder.layer.5.attention.self.query.bias\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/query/Add for ONNX node: /bert/encoder/layer.5/attention/self/query/Add\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/query/Add_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/query/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.5/attention/self/query/Add [Add] outputs: [/bert/encoder/layer.5/attention/self/query/Add_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/key/MatMul [MatMul]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.4/output/LayerNorm/Add_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: onnx::MatMul_859\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.5/attention/self/key/MatMul [MatMul] inputs: [/bert/encoder/layer.4/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], [onnx::MatMul_859 -> (256, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: onnx::MatMul_859 for ONNX node: onnx::MatMul_859\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/key/MatMul for ONNX node: /bert/encoder/layer.5/attention/self/key/MatMul\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/key/MatMul_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/key/MatMul_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.5/attention/self/key/MatMul [MatMul] outputs: [/bert/encoder/layer.5/attention/self/key/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/key/Add [Add]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: bert.encoder.layer.5.attention.self.key.bias\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/key/MatMul_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.5/attention/self/key/Add [Add] inputs: [bert.encoder.layer.5.attention.self.key.bias -> (256)[FLOAT]], [/bert/encoder/layer.5/attention/self/key/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: bert.encoder.layer.5.attention.self.key.bias for ONNX node: bert.encoder.layer.5.attention.self.key.bias\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/key/Add for ONNX node: /bert/encoder/layer.5/attention/self/key/Add\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/key/Add_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/key/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.5/attention/self/key/Add [Add] outputs: [/bert/encoder/layer.5/attention/self/key/Add_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Shape [Shape]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/key/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.5/attention/self/Shape [Shape] inputs: [/bert/encoder/layer.5/attention/self/key/Add_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Shape for ONNX node: /bert/encoder/layer.5/attention/self/Shape\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/Shape_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/Shape_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.5/attention/self/Shape [Shape] outputs: [/bert/encoder/layer.5/attention/self/Shape_output_0 -> (3)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Constant [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.5/attention/self/Constant [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.5/attention/self/Constant [Constant] outputs: [/bert/encoder/layer.5/attention/self/Constant_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Gather [Gather]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Shape_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Constant_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.5/attention/self/Gather [Gather] inputs: [/bert/encoder/layer.5/attention/self/Shape_output_0 -> (3)[INT32]], [/bert/encoder/layer.5/attention/self/Constant_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Constant_output_0 for ONNX node: /bert/encoder/layer.5/attention/self/Constant_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Using Gather axis: 0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Gather for ONNX node: /bert/encoder/layer.5/attention/self/Gather\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/Gather_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/Gather_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.5/attention/self/Gather [Gather] outputs: [/bert/encoder/layer.5/attention/self/Gather_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Shape_1 [Shape]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/key/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.5/attention/self/Shape_1 [Shape] inputs: [/bert/encoder/layer.5/attention/self/key/Add_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Shape_1 for ONNX node: /bert/encoder/layer.5/attention/self/Shape_1\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/Shape_1_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/Shape_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.5/attention/self/Shape_1 [Shape] outputs: [/bert/encoder/layer.5/attention/self/Shape_1_output_0 -> (3)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Constant_1 [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.5/attention/self/Constant_1 [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.5/attention/self/Constant_1 [Constant] outputs: [/bert/encoder/layer.5/attention/self/Constant_1_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Gather_1 [Gather]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Shape_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Constant_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.5/attention/self/Gather_1 [Gather] inputs: [/bert/encoder/layer.5/attention/self/Shape_1_output_0 -> (3)[INT32]], [/bert/encoder/layer.5/attention/self/Constant_1_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Constant_1_output_0 for ONNX node: /bert/encoder/layer.5/attention/self/Constant_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Using Gather axis: 0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Gather_1 for ONNX node: /bert/encoder/layer.5/attention/self/Gather_1\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/Gather_1_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/Gather_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.5/attention/self/Gather_1 [Gather] outputs: [/bert/encoder/layer.5/attention/self/Gather_1_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Unsqueeze [Unsqueeze]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Gather_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.5/attention/self/Unsqueeze [Unsqueeze] inputs: [/bert/encoder/layer.5/attention/self/Gather_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Original shape: (), unsqueezing to: (1,)\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Unsqueeze for ONNX node: /bert/encoder/layer.5/attention/self/Unsqueeze\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/Unsqueeze_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/Unsqueeze_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.5/attention/self/Unsqueeze [Unsqueeze] outputs: [/bert/encoder/layer.5/attention/self/Unsqueeze_output_0 -> (1)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Unsqueeze_1 [Unsqueeze]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Gather_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.5/attention/self/Unsqueeze_1 [Unsqueeze] inputs: [/bert/encoder/layer.5/attention/self/Gather_1_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Original shape: (), unsqueezing to: (1,)\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Unsqueeze_1 for ONNX node: /bert/encoder/layer.5/attention/self/Unsqueeze_1\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/Unsqueeze_1_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/Unsqueeze_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.5/attention/self/Unsqueeze_1 [Unsqueeze] outputs: [/bert/encoder/layer.5/attention/self/Unsqueeze_1_output_0 -> (1)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Constant_2 [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.5/attention/self/Constant_2 [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.5/attention/self/Constant_2 [Constant] outputs: [/bert/encoder/layer.5/attention/self/Constant_2_output_0 -> (1)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Constant_3 [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.5/attention/self/Constant_3 [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.5/attention/self/Constant_3 [Constant] outputs: [/bert/encoder/layer.5/attention/self/Constant_3_output_0 -> (1)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Concat [Concat]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Unsqueeze_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Unsqueeze_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Constant_2_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Constant_3_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.5/attention/self/Concat [Concat] inputs: [/bert/encoder/layer.5/attention/self/Unsqueeze_output_0 -> (1)[INT32]], [/bert/encoder/layer.5/attention/self/Unsqueeze_1_output_0 -> (1)[INT32]], [/bert/encoder/layer.5/attention/self/Constant_2_output_0 -> (1)[INT32]], [/bert/encoder/layer.5/attention/self/Constant_3_output_0 -> (1)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Constant_2_output_0 for ONNX node: /bert/encoder/layer.5/attention/self/Constant_2_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Constant_3_output_0 for ONNX node: /bert/encoder/layer.5/attention/self/Constant_3_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Concat for ONNX node: /bert/encoder/layer.5/attention/self/Concat\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/Concat_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/Concat_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.5/attention/self/Concat [Concat] outputs: [/bert/encoder/layer.5/attention/self/Concat_output_0 -> (4)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Reshape [Reshape]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/key/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Concat_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.5/attention/self/Reshape [Reshape] inputs: [/bert/encoder/layer.5/attention/self/key/Add_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.5/attention/self/Concat_output_0 -> (4)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Reshape for ONNX node: /bert/encoder/layer.5/attention/self/Reshape\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/Reshape_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/Reshape_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.5/attention/self/Reshape [Reshape] outputs: [/bert/encoder/layer.5/attention/self/Reshape_output_0 -> (-1, -1, 8, 32)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/value/MatMul [MatMul]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.4/output/LayerNorm/Add_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: onnx::MatMul_862\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.5/attention/self/value/MatMul [MatMul] inputs: [/bert/encoder/layer.4/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], [onnx::MatMul_862 -> (256, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: onnx::MatMul_862 for ONNX node: onnx::MatMul_862\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/value/MatMul for ONNX node: /bert/encoder/layer.5/attention/self/value/MatMul\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/value/MatMul_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/value/MatMul_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.5/attention/self/value/MatMul [MatMul] outputs: [/bert/encoder/layer.5/attention/self/value/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/value/Add [Add]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: bert.encoder.layer.5.attention.self.value.bias\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/value/MatMul_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.5/attention/self/value/Add [Add] inputs: [bert.encoder.layer.5.attention.self.value.bias -> (256)[FLOAT]], [/bert/encoder/layer.5/attention/self/value/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: bert.encoder.layer.5.attention.self.value.bias for ONNX node: bert.encoder.layer.5.attention.self.value.bias\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/value/Add for ONNX node: /bert/encoder/layer.5/attention/self/value/Add\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/value/Add_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/value/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.5/attention/self/value/Add [Add] outputs: [/bert/encoder/layer.5/attention/self/value/Add_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Shape_2 [Shape]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/value/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.5/attention/self/Shape_2 [Shape] inputs: [/bert/encoder/layer.5/attention/self/value/Add_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Shape_2 for ONNX node: /bert/encoder/layer.5/attention/self/Shape_2\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/Shape_2_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/Shape_2_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.5/attention/self/Shape_2 [Shape] outputs: [/bert/encoder/layer.5/attention/self/Shape_2_output_0 -> (3)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Constant_4 [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.5/attention/self/Constant_4 [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.5/attention/self/Constant_4 [Constant] outputs: [/bert/encoder/layer.5/attention/self/Constant_4_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Gather_2 [Gather]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Shape_2_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Constant_4_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.5/attention/self/Gather_2 [Gather] inputs: [/bert/encoder/layer.5/attention/self/Shape_2_output_0 -> (3)[INT32]], [/bert/encoder/layer.5/attention/self/Constant_4_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Constant_4_output_0 for ONNX node: /bert/encoder/layer.5/attention/self/Constant_4_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Using Gather axis: 0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Gather_2 for ONNX node: /bert/encoder/layer.5/attention/self/Gather_2\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/Gather_2_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/Gather_2_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.5/attention/self/Gather_2 [Gather] outputs: [/bert/encoder/layer.5/attention/self/Gather_2_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Shape_3 [Shape]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/value/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.5/attention/self/Shape_3 [Shape] inputs: [/bert/encoder/layer.5/attention/self/value/Add_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Shape_3 for ONNX node: /bert/encoder/layer.5/attention/self/Shape_3\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/Shape_3_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/Shape_3_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.5/attention/self/Shape_3 [Shape] outputs: [/bert/encoder/layer.5/attention/self/Shape_3_output_0 -> (3)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Constant_5 [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.5/attention/self/Constant_5 [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.5/attention/self/Constant_5 [Constant] outputs: [/bert/encoder/layer.5/attention/self/Constant_5_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Gather_3 [Gather]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Shape_3_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Constant_5_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.5/attention/self/Gather_3 [Gather] inputs: [/bert/encoder/layer.5/attention/self/Shape_3_output_0 -> (3)[INT32]], [/bert/encoder/layer.5/attention/self/Constant_5_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Constant_5_output_0 for ONNX node: /bert/encoder/layer.5/attention/self/Constant_5_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Using Gather axis: 0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Gather_3 for ONNX node: /bert/encoder/layer.5/attention/self/Gather_3\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/Gather_3_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/Gather_3_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.5/attention/self/Gather_3 [Gather] outputs: [/bert/encoder/layer.5/attention/self/Gather_3_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Unsqueeze_2 [Unsqueeze]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Gather_2_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.5/attention/self/Unsqueeze_2 [Unsqueeze] inputs: [/bert/encoder/layer.5/attention/self/Gather_2_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Original shape: (), unsqueezing to: (1,)\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Unsqueeze_2 for ONNX node: /bert/encoder/layer.5/attention/self/Unsqueeze_2\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/Unsqueeze_2_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/Unsqueeze_2_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.5/attention/self/Unsqueeze_2 [Unsqueeze] outputs: [/bert/encoder/layer.5/attention/self/Unsqueeze_2_output_0 -> (1)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Unsqueeze_3 [Unsqueeze]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Gather_3_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.5/attention/self/Unsqueeze_3 [Unsqueeze] inputs: [/bert/encoder/layer.5/attention/self/Gather_3_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Original shape: (), unsqueezing to: (1,)\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Unsqueeze_3 for ONNX node: /bert/encoder/layer.5/attention/self/Unsqueeze_3\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/Unsqueeze_3_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/Unsqueeze_3_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.5/attention/self/Unsqueeze_3 [Unsqueeze] outputs: [/bert/encoder/layer.5/attention/self/Unsqueeze_3_output_0 -> (1)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Constant_6 [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.5/attention/self/Constant_6 [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.5/attention/self/Constant_6 [Constant] outputs: [/bert/encoder/layer.5/attention/self/Constant_6_output_0 -> (1)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Constant_7 [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.5/attention/self/Constant_7 [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.5/attention/self/Constant_7 [Constant] outputs: [/bert/encoder/layer.5/attention/self/Constant_7_output_0 -> (1)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Concat_1 [Concat]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Unsqueeze_2_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Unsqueeze_3_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Constant_6_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Constant_7_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.5/attention/self/Concat_1 [Concat] inputs: [/bert/encoder/layer.5/attention/self/Unsqueeze_2_output_0 -> (1)[INT32]], [/bert/encoder/layer.5/attention/self/Unsqueeze_3_output_0 -> (1)[INT32]], [/bert/encoder/layer.5/attention/self/Constant_6_output_0 -> (1)[INT32]], [/bert/encoder/layer.5/attention/self/Constant_7_output_0 -> (1)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Constant_6_output_0 for ONNX node: /bert/encoder/layer.5/attention/self/Constant_6_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Constant_7_output_0 for ONNX node: /bert/encoder/layer.5/attention/self/Constant_7_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Concat_1 for ONNX node: /bert/encoder/layer.5/attention/self/Concat_1\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/Concat_1_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/Concat_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.5/attention/self/Concat_1 [Concat] outputs: [/bert/encoder/layer.5/attention/self/Concat_1_output_0 -> (4)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Reshape_1 [Reshape]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/value/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Concat_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.5/attention/self/Reshape_1 [Reshape] inputs: [/bert/encoder/layer.5/attention/self/value/Add_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.5/attention/self/Concat_1_output_0 -> (4)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Reshape_1 for ONNX node: /bert/encoder/layer.5/attention/self/Reshape_1\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/Reshape_1_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/Reshape_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.5/attention/self/Reshape_1 [Reshape] outputs: [/bert/encoder/layer.5/attention/self/Reshape_1_output_0 -> (-1, -1, 8, 32)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Transpose [Transpose]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Reshape_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.5/attention/self/Transpose [Transpose] inputs: [/bert/encoder/layer.5/attention/self/Reshape_1_output_0 -> (-1, -1, 8, 32)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Transpose for ONNX node: /bert/encoder/layer.5/attention/self/Transpose\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/Transpose_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/Transpose_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.5/attention/self/Transpose [Transpose] outputs: [/bert/encoder/layer.5/attention/self/Transpose_output_0 -> (-1, 8, -1, 32)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Shape_4 [Shape]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/query/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.5/attention/self/Shape_4 [Shape] inputs: [/bert/encoder/layer.5/attention/self/query/Add_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Shape_4 for ONNX node: /bert/encoder/layer.5/attention/self/Shape_4\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/Shape_4_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/Shape_4_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.5/attention/self/Shape_4 [Shape] outputs: [/bert/encoder/layer.5/attention/self/Shape_4_output_0 -> (3)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Constant_8 [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.5/attention/self/Constant_8 [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.5/attention/self/Constant_8 [Constant] outputs: [/bert/encoder/layer.5/attention/self/Constant_8_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Gather_4 [Gather]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Shape_4_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Constant_8_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.5/attention/self/Gather_4 [Gather] inputs: [/bert/encoder/layer.5/attention/self/Shape_4_output_0 -> (3)[INT32]], [/bert/encoder/layer.5/attention/self/Constant_8_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Constant_8_output_0 for ONNX node: /bert/encoder/layer.5/attention/self/Constant_8_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Using Gather axis: 0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Gather_4 for ONNX node: /bert/encoder/layer.5/attention/self/Gather_4\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/Gather_4_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/Gather_4_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.5/attention/self/Gather_4 [Gather] outputs: [/bert/encoder/layer.5/attention/self/Gather_4_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Shape_5 [Shape]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/query/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.5/attention/self/Shape_5 [Shape] inputs: [/bert/encoder/layer.5/attention/self/query/Add_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Shape_5 for ONNX node: /bert/encoder/layer.5/attention/self/Shape_5\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/Shape_5_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/Shape_5_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.5/attention/self/Shape_5 [Shape] outputs: [/bert/encoder/layer.5/attention/self/Shape_5_output_0 -> (3)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Constant_9 [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.5/attention/self/Constant_9 [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.5/attention/self/Constant_9 [Constant] outputs: [/bert/encoder/layer.5/attention/self/Constant_9_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Gather_5 [Gather]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Shape_5_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Constant_9_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.5/attention/self/Gather_5 [Gather] inputs: [/bert/encoder/layer.5/attention/self/Shape_5_output_0 -> (3)[INT32]], [/bert/encoder/layer.5/attention/self/Constant_9_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Constant_9_output_0 for ONNX node: /bert/encoder/layer.5/attention/self/Constant_9_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Using Gather axis: 0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Gather_5 for ONNX node: /bert/encoder/layer.5/attention/self/Gather_5\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/Gather_5_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/Gather_5_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.5/attention/self/Gather_5 [Gather] outputs: [/bert/encoder/layer.5/attention/self/Gather_5_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Unsqueeze_4 [Unsqueeze]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Gather_4_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.5/attention/self/Unsqueeze_4 [Unsqueeze] inputs: [/bert/encoder/layer.5/attention/self/Gather_4_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Original shape: (), unsqueezing to: (1,)\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Unsqueeze_4 for ONNX node: /bert/encoder/layer.5/attention/self/Unsqueeze_4\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/Unsqueeze_4_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/Unsqueeze_4_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.5/attention/self/Unsqueeze_4 [Unsqueeze] outputs: [/bert/encoder/layer.5/attention/self/Unsqueeze_4_output_0 -> (1)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Unsqueeze_5 [Unsqueeze]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Gather_5_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.5/attention/self/Unsqueeze_5 [Unsqueeze] inputs: [/bert/encoder/layer.5/attention/self/Gather_5_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Original shape: (), unsqueezing to: (1,)\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Unsqueeze_5 for ONNX node: /bert/encoder/layer.5/attention/self/Unsqueeze_5\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/Unsqueeze_5_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/Unsqueeze_5_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.5/attention/self/Unsqueeze_5 [Unsqueeze] outputs: [/bert/encoder/layer.5/attention/self/Unsqueeze_5_output_0 -> (1)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Constant_10 [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.5/attention/self/Constant_10 [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.5/attention/self/Constant_10 [Constant] outputs: [/bert/encoder/layer.5/attention/self/Constant_10_output_0 -> (1)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Constant_11 [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.5/attention/self/Constant_11 [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.5/attention/self/Constant_11 [Constant] outputs: [/bert/encoder/layer.5/attention/self/Constant_11_output_0 -> (1)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Concat_2 [Concat]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Unsqueeze_4_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Unsqueeze_5_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Constant_10_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Constant_11_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.5/attention/self/Concat_2 [Concat] inputs: [/bert/encoder/layer.5/attention/self/Unsqueeze_4_output_0 -> (1)[INT32]], [/bert/encoder/layer.5/attention/self/Unsqueeze_5_output_0 -> (1)[INT32]], [/bert/encoder/layer.5/attention/self/Constant_10_output_0 -> (1)[INT32]], [/bert/encoder/layer.5/attention/self/Constant_11_output_0 -> (1)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Constant_10_output_0 for ONNX node: /bert/encoder/layer.5/attention/self/Constant_10_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Constant_11_output_0 for ONNX node: /bert/encoder/layer.5/attention/self/Constant_11_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Concat_2 for ONNX node: /bert/encoder/layer.5/attention/self/Concat_2\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/Concat_2_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/Concat_2_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.5/attention/self/Concat_2 [Concat] outputs: [/bert/encoder/layer.5/attention/self/Concat_2_output_0 -> (4)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Reshape_2 [Reshape]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/query/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Concat_2_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.5/attention/self/Reshape_2 [Reshape] inputs: [/bert/encoder/layer.5/attention/self/query/Add_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.5/attention/self/Concat_2_output_0 -> (4)[INT32]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Reshape_2 for ONNX node: /bert/encoder/layer.5/attention/self/Reshape_2\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/Reshape_2_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/Reshape_2_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.5/attention/self/Reshape_2 [Reshape] outputs: [/bert/encoder/layer.5/attention/self/Reshape_2_output_0 -> (-1, -1, 8, 32)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Transpose_1 [Transpose]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Reshape_2_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.5/attention/self/Transpose_1 [Transpose] inputs: [/bert/encoder/layer.5/attention/self/Reshape_2_output_0 -> (-1, -1, 8, 32)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Transpose_1 for ONNX node: /bert/encoder/layer.5/attention/self/Transpose_1\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/Transpose_1_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/Transpose_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.5/attention/self/Transpose_1 [Transpose] outputs: [/bert/encoder/layer.5/attention/self/Transpose_1_output_0 -> (-1, 8, -1, 32)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Transpose_2 [Transpose]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Reshape_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.5/attention/self/Transpose_2 [Transpose] inputs: [/bert/encoder/layer.5/attention/self/Reshape_output_0 -> (-1, -1, 8, 32)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Transpose_2 for ONNX node: /bert/encoder/layer.5/attention/self/Transpose_2\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/Transpose_2_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/Transpose_2_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.5/attention/self/Transpose_2 [Transpose] outputs: [/bert/encoder/layer.5/attention/self/Transpose_2_output_0 -> (-1, 8, 32, -1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/MatMul [MatMul]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Transpose_1_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Transpose_2_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.5/attention/self/MatMul [MatMul] inputs: [/bert/encoder/layer.5/attention/self/Transpose_1_output_0 -> (-1, 8, -1, 32)[FLOAT]], [/bert/encoder/layer.5/attention/self/Transpose_2_output_0 -> (-1, 8, 32, -1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/MatMul for ONNX node: /bert/encoder/layer.5/attention/self/MatMul\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/MatMul_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/MatMul_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.5/attention/self/MatMul [MatMul] outputs: [/bert/encoder/layer.5/attention/self/MatMul_output_0 -> (-1, 8, -1, -1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Constant_12 [Constant]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.5/attention/self/Constant_12 [Constant] inputs: \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.5/attention/self/Constant_12 [Constant] outputs: [/bert/encoder/layer.5/attention/self/Constant_12_output_0 -> ()[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Div [Div]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/MatMul_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Constant_12_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.5/attention/self/Div [Div] inputs: [/bert/encoder/layer.5/attention/self/MatMul_output_0 -> (-1, 8, -1, -1)[FLOAT]], [/bert/encoder/layer.5/attention/self/Constant_12_output_0 -> ()[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Constant_12_output_0 for ONNX node: /bert/encoder/layer.5/attention/self/Constant_12_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Div for ONNX node: /bert/encoder/layer.5/attention/self/Div\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/Div_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/Div_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.5/attention/self/Div [Div] outputs: [/bert/encoder/layer.5/attention/self/Div_output_0 -> (-1, 8, -1, -1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Add [Add]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Div_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/Mul_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.5/attention/self/Add [Add] inputs: [/bert/encoder/layer.5/attention/self/Div_output_0 -> (-1, 8, -1, -1)[FLOAT]], [/bert/Mul_output_0 -> (-1, 1, 1, -1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Add for ONNX node: /bert/encoder/layer.5/attention/self/Add\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/Add_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.5/attention/self/Add [Add] outputs: [/bert/encoder/layer.5/attention/self/Add_output_0 -> (-1, 8, -1, -1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Softmax [Softmax]\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Add_output_0\r\n",
      "[02/02/2023-19:14:19] [V] [TRT] /bert/encoder/layer.5/attention/self/Softmax [Softmax] inputs: [/bert/encoder/layer.5/attention/self/Add_output_0 -> (-1, 8, -1, -1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Softmax for ONNX node: /bert/encoder/layer.5/attention/self/Softmax\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02/02/2023-19:14:20] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/Softmax_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/Softmax_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] /bert/encoder/layer.5/attention/self/Softmax [Softmax] outputs: [/bert/encoder/layer.5/attention/self/Softmax_output_0 -> (-1, 8, -1, -1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/MatMul_1 [MatMul]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Softmax_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Transpose_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] /bert/encoder/layer.5/attention/self/MatMul_1 [MatMul] inputs: [/bert/encoder/layer.5/attention/self/Softmax_output_0 -> (-1, 8, -1, -1)[FLOAT]], [/bert/encoder/layer.5/attention/self/Transpose_output_0 -> (-1, 8, -1, 32)[FLOAT]], \r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/MatMul_1 for ONNX node: /bert/encoder/layer.5/attention/self/MatMul_1\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/MatMul_1_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/MatMul_1_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] /bert/encoder/layer.5/attention/self/MatMul_1 [MatMul] outputs: [/bert/encoder/layer.5/attention/self/MatMul_1_output_0 -> (-1, 8, -1, 32)[FLOAT]], \r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Transpose_3 [Transpose]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/MatMul_1_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] /bert/encoder/layer.5/attention/self/Transpose_3 [Transpose] inputs: [/bert/encoder/layer.5/attention/self/MatMul_1_output_0 -> (-1, 8, -1, 32)[FLOAT]], \r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Transpose_3 for ONNX node: /bert/encoder/layer.5/attention/self/Transpose_3\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/Transpose_3_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/Transpose_3_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] /bert/encoder/layer.5/attention/self/Transpose_3 [Transpose] outputs: [/bert/encoder/layer.5/attention/self/Transpose_3_output_0 -> (-1, -1, 8, 32)[FLOAT]], \r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Shape_6 [Shape]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Transpose_3_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] /bert/encoder/layer.5/attention/self/Shape_6 [Shape] inputs: [/bert/encoder/layer.5/attention/self/Transpose_3_output_0 -> (-1, -1, 8, 32)[FLOAT]], \r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Shape_6 for ONNX node: /bert/encoder/layer.5/attention/self/Shape_6\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/Shape_6_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/Shape_6_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] /bert/encoder/layer.5/attention/self/Shape_6 [Shape] outputs: [/bert/encoder/layer.5/attention/self/Shape_6_output_0 -> (4)[INT32]], \r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Constant_13 [Constant]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] /bert/encoder/layer.5/attention/self/Constant_13 [Constant] inputs: \r\n",
      "[02/02/2023-19:14:20] [V] [TRT] /bert/encoder/layer.5/attention/self/Constant_13 [Constant] outputs: [/bert/encoder/layer.5/attention/self/Constant_13_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Gather_6 [Gather]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Shape_6_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Constant_13_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] /bert/encoder/layer.5/attention/self/Gather_6 [Gather] inputs: [/bert/encoder/layer.5/attention/self/Shape_6_output_0 -> (4)[INT32]], [/bert/encoder/layer.5/attention/self/Constant_13_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Constant_13_output_0 for ONNX node: /bert/encoder/layer.5/attention/self/Constant_13_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Using Gather axis: 0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Gather_6 for ONNX node: /bert/encoder/layer.5/attention/self/Gather_6\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/Gather_6_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/Gather_6_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] /bert/encoder/layer.5/attention/self/Gather_6 [Gather] outputs: [/bert/encoder/layer.5/attention/self/Gather_6_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Shape_7 [Shape]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Transpose_3_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] /bert/encoder/layer.5/attention/self/Shape_7 [Shape] inputs: [/bert/encoder/layer.5/attention/self/Transpose_3_output_0 -> (-1, -1, 8, 32)[FLOAT]], \r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Shape_7 for ONNX node: /bert/encoder/layer.5/attention/self/Shape_7\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/Shape_7_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/Shape_7_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] /bert/encoder/layer.5/attention/self/Shape_7 [Shape] outputs: [/bert/encoder/layer.5/attention/self/Shape_7_output_0 -> (4)[INT32]], \r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Constant_14 [Constant]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] /bert/encoder/layer.5/attention/self/Constant_14 [Constant] inputs: \r\n",
      "[02/02/2023-19:14:20] [V] [TRT] /bert/encoder/layer.5/attention/self/Constant_14 [Constant] outputs: [/bert/encoder/layer.5/attention/self/Constant_14_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Gather_7 [Gather]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Shape_7_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Constant_14_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] /bert/encoder/layer.5/attention/self/Gather_7 [Gather] inputs: [/bert/encoder/layer.5/attention/self/Shape_7_output_0 -> (4)[INT32]], [/bert/encoder/layer.5/attention/self/Constant_14_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Constant_14_output_0 for ONNX node: /bert/encoder/layer.5/attention/self/Constant_14_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Using Gather axis: 0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Gather_7 for ONNX node: /bert/encoder/layer.5/attention/self/Gather_7\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/Gather_7_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/Gather_7_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] /bert/encoder/layer.5/attention/self/Gather_7 [Gather] outputs: [/bert/encoder/layer.5/attention/self/Gather_7_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Unsqueeze_6 [Unsqueeze]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Gather_6_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] /bert/encoder/layer.5/attention/self/Unsqueeze_6 [Unsqueeze] inputs: [/bert/encoder/layer.5/attention/self/Gather_6_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Original shape: (), unsqueezing to: (1,)\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Unsqueeze_6 for ONNX node: /bert/encoder/layer.5/attention/self/Unsqueeze_6\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/Unsqueeze_6_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/Unsqueeze_6_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] /bert/encoder/layer.5/attention/self/Unsqueeze_6 [Unsqueeze] outputs: [/bert/encoder/layer.5/attention/self/Unsqueeze_6_output_0 -> (1)[INT32]], \r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Unsqueeze_7 [Unsqueeze]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Gather_7_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] /bert/encoder/layer.5/attention/self/Unsqueeze_7 [Unsqueeze] inputs: [/bert/encoder/layer.5/attention/self/Gather_7_output_0 -> ()[INT32]], \r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Original shape: (), unsqueezing to: (1,)\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Unsqueeze_7 for ONNX node: /bert/encoder/layer.5/attention/self/Unsqueeze_7\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/Unsqueeze_7_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/Unsqueeze_7_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] /bert/encoder/layer.5/attention/self/Unsqueeze_7 [Unsqueeze] outputs: [/bert/encoder/layer.5/attention/self/Unsqueeze_7_output_0 -> (1)[INT32]], \r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Constant_15 [Constant]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] /bert/encoder/layer.5/attention/self/Constant_15 [Constant] inputs: \r\n",
      "[02/02/2023-19:14:20] [V] [TRT] /bert/encoder/layer.5/attention/self/Constant_15 [Constant] outputs: [/bert/encoder/layer.5/attention/self/Constant_15_output_0 -> (1)[INT32]], \r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Concat_3 [Concat]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Unsqueeze_6_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Unsqueeze_7_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Constant_15_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] /bert/encoder/layer.5/attention/self/Concat_3 [Concat] inputs: [/bert/encoder/layer.5/attention/self/Unsqueeze_6_output_0 -> (1)[INT32]], [/bert/encoder/layer.5/attention/self/Unsqueeze_7_output_0 -> (1)[INT32]], [/bert/encoder/layer.5/attention/self/Constant_15_output_0 -> (1)[INT32]], \r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Constant_15_output_0 for ONNX node: /bert/encoder/layer.5/attention/self/Constant_15_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Concat_3 for ONNX node: /bert/encoder/layer.5/attention/self/Concat_3\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/Concat_3_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/Concat_3_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] /bert/encoder/layer.5/attention/self/Concat_3 [Concat] outputs: [/bert/encoder/layer.5/attention/self/Concat_3_output_0 -> (3)[INT32]], \r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Reshape_3 [Reshape]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Transpose_3_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Concat_3_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] /bert/encoder/layer.5/attention/self/Reshape_3 [Reshape] inputs: [/bert/encoder/layer.5/attention/self/Transpose_3_output_0 -> (-1, -1, 8, 32)[FLOAT]], [/bert/encoder/layer.5/attention/self/Concat_3_output_0 -> (3)[INT32]], \r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Reshape_3 for ONNX node: /bert/encoder/layer.5/attention/self/Reshape_3\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/Reshape_3_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/Reshape_3_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] /bert/encoder/layer.5/attention/self/Reshape_3 [Reshape] outputs: [/bert/encoder/layer.5/attention/self/Reshape_3_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/output/dense/MatMul [MatMul]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Reshape_3_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Searching for input: onnx::MatMul_868\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] /bert/encoder/layer.5/attention/output/dense/MatMul [MatMul] inputs: [/bert/encoder/layer.5/attention/self/Reshape_3_output_0 -> (-1, -1, 256)[FLOAT]], [onnx::MatMul_868 -> (256, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Registering layer: onnx::MatMul_868 for ONNX node: onnx::MatMul_868\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/output/dense/MatMul for ONNX node: /bert/encoder/layer.5/attention/output/dense/MatMul\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/output/dense/MatMul_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/output/dense/MatMul_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] /bert/encoder/layer.5/attention/output/dense/MatMul [MatMul] outputs: [/bert/encoder/layer.5/attention/output/dense/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/output/dense/Add [Add]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Searching for input: bert.encoder.layer.5.attention.output.dense.bias\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/output/dense/MatMul_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] /bert/encoder/layer.5/attention/output/dense/Add [Add] inputs: [bert.encoder.layer.5.attention.output.dense.bias -> (256)[FLOAT]], [/bert/encoder/layer.5/attention/output/dense/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Registering layer: bert.encoder.layer.5.attention.output.dense.bias for ONNX node: bert.encoder.layer.5.attention.output.dense.bias\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/output/dense/Add for ONNX node: /bert/encoder/layer.5/attention/output/dense/Add\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/output/dense/Add_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/output/dense/Add_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] /bert/encoder/layer.5/attention/output/dense/Add [Add] outputs: [/bert/encoder/layer.5/attention/output/dense/Add_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/output/Add [Add]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/output/dense/Add_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Searching for input: /bert/encoder/layer.4/output/LayerNorm/Add_1_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] /bert/encoder/layer.5/attention/output/Add [Add] inputs: [/bert/encoder/layer.5/attention/output/dense/Add_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.4/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/output/Add for ONNX node: /bert/encoder/layer.5/attention/output/Add\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/output/Add_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/output/Add_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] /bert/encoder/layer.5/attention/output/Add [Add] outputs: [/bert/encoder/layer.5/attention/output/Add_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/output/LayerNorm/ReduceMean [ReduceMean]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/output/Add_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] /bert/encoder/layer.5/attention/output/LayerNorm/ReduceMean [ReduceMean] inputs: [/bert/encoder/layer.5/attention/output/Add_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/output/LayerNorm/ReduceMean for ONNX node: /bert/encoder/layer.5/attention/output/LayerNorm/ReduceMean\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/output/LayerNorm/ReduceMean_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/output/LayerNorm/ReduceMean_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] /bert/encoder/layer.5/attention/output/LayerNorm/ReduceMean [ReduceMean] outputs: [/bert/encoder/layer.5/attention/output/LayerNorm/ReduceMean_output_0 -> (-1, -1, 1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/output/LayerNorm/Sub [Sub]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/output/Add_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/output/LayerNorm/ReduceMean_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] /bert/encoder/layer.5/attention/output/LayerNorm/Sub [Sub] inputs: [/bert/encoder/layer.5/attention/output/Add_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.5/attention/output/LayerNorm/ReduceMean_output_0 -> (-1, -1, 1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/output/LayerNorm/Sub for ONNX node: /bert/encoder/layer.5/attention/output/LayerNorm/Sub\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/output/LayerNorm/Sub_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/output/LayerNorm/Sub_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] /bert/encoder/layer.5/attention/output/LayerNorm/Sub [Sub] outputs: [/bert/encoder/layer.5/attention/output/LayerNorm/Sub_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/output/LayerNorm/Constant [Constant]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] /bert/encoder/layer.5/attention/output/LayerNorm/Constant [Constant] inputs: \r\n",
      "[02/02/2023-19:14:20] [V] [TRT] /bert/encoder/layer.5/attention/output/LayerNorm/Constant [Constant] outputs: [/bert/encoder/layer.5/attention/output/LayerNorm/Constant_output_0 -> ()[FLOAT]], \r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/output/LayerNorm/Pow [Pow]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/output/LayerNorm/Sub_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/output/LayerNorm/Constant_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] /bert/encoder/layer.5/attention/output/LayerNorm/Pow [Pow] inputs: [/bert/encoder/layer.5/attention/output/LayerNorm/Sub_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.5/attention/output/LayerNorm/Constant_output_0 -> ()[FLOAT]], \r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/output/LayerNorm/Constant_output_0 for ONNX node: /bert/encoder/layer.5/attention/output/LayerNorm/Constant_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/output/LayerNorm/Pow for ONNX node: /bert/encoder/layer.5/attention/output/LayerNorm/Pow\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/output/LayerNorm/Pow_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/output/LayerNorm/Pow_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] /bert/encoder/layer.5/attention/output/LayerNorm/Pow [Pow] outputs: [/bert/encoder/layer.5/attention/output/LayerNorm/Pow_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/output/LayerNorm/ReduceMean_1 [ReduceMean]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/output/LayerNorm/Pow_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] /bert/encoder/layer.5/attention/output/LayerNorm/ReduceMean_1 [ReduceMean] inputs: [/bert/encoder/layer.5/attention/output/LayerNorm/Pow_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/output/LayerNorm/ReduceMean_1 for ONNX node: /bert/encoder/layer.5/attention/output/LayerNorm/ReduceMean_1\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/output/LayerNorm/ReduceMean_1_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/output/LayerNorm/ReduceMean_1_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] /bert/encoder/layer.5/attention/output/LayerNorm/ReduceMean_1 [ReduceMean] outputs: [/bert/encoder/layer.5/attention/output/LayerNorm/ReduceMean_1_output_0 -> (-1, -1, 1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/output/LayerNorm/Constant_1 [Constant]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] /bert/encoder/layer.5/attention/output/LayerNorm/Constant_1 [Constant] inputs: \r\n",
      "[02/02/2023-19:14:20] [V] [TRT] /bert/encoder/layer.5/attention/output/LayerNorm/Constant_1 [Constant] outputs: [/bert/encoder/layer.5/attention/output/LayerNorm/Constant_1_output_0 -> ()[FLOAT]], \r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/output/LayerNorm/Add [Add]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/output/LayerNorm/ReduceMean_1_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/output/LayerNorm/Constant_1_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] /bert/encoder/layer.5/attention/output/LayerNorm/Add [Add] inputs: [/bert/encoder/layer.5/attention/output/LayerNorm/ReduceMean_1_output_0 -> (-1, -1, 1)[FLOAT]], [/bert/encoder/layer.5/attention/output/LayerNorm/Constant_1_output_0 -> ()[FLOAT]], \r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/output/LayerNorm/Constant_1_output_0 for ONNX node: /bert/encoder/layer.5/attention/output/LayerNorm/Constant_1_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/output/LayerNorm/Add for ONNX node: /bert/encoder/layer.5/attention/output/LayerNorm/Add\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/output/LayerNorm/Add_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/output/LayerNorm/Add_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] /bert/encoder/layer.5/attention/output/LayerNorm/Add [Add] outputs: [/bert/encoder/layer.5/attention/output/LayerNorm/Add_output_0 -> (-1, -1, 1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/output/LayerNorm/Sqrt [Sqrt]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/output/LayerNorm/Add_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] /bert/encoder/layer.5/attention/output/LayerNorm/Sqrt [Sqrt] inputs: [/bert/encoder/layer.5/attention/output/LayerNorm/Add_output_0 -> (-1, -1, 1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/output/LayerNorm/Sqrt for ONNX node: /bert/encoder/layer.5/attention/output/LayerNorm/Sqrt\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/output/LayerNorm/Sqrt_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/output/LayerNorm/Sqrt_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] /bert/encoder/layer.5/attention/output/LayerNorm/Sqrt [Sqrt] outputs: [/bert/encoder/layer.5/attention/output/LayerNorm/Sqrt_output_0 -> (-1, -1, 1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/output/LayerNorm/Div [Div]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/output/LayerNorm/Sub_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/output/LayerNorm/Sqrt_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] /bert/encoder/layer.5/attention/output/LayerNorm/Div [Div] inputs: [/bert/encoder/layer.5/attention/output/LayerNorm/Sub_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.5/attention/output/LayerNorm/Sqrt_output_0 -> (-1, -1, 1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/output/LayerNorm/Div for ONNX node: /bert/encoder/layer.5/attention/output/LayerNorm/Div\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/output/LayerNorm/Div_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/output/LayerNorm/Div_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] /bert/encoder/layer.5/attention/output/LayerNorm/Div [Div] outputs: [/bert/encoder/layer.5/attention/output/LayerNorm/Div_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/output/LayerNorm/Mul [Mul]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/output/LayerNorm/Div_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Searching for input: bert.encoder.layer.5.attention.output.LayerNorm.weight\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] /bert/encoder/layer.5/attention/output/LayerNorm/Mul [Mul] inputs: [/bert/encoder/layer.5/attention/output/LayerNorm/Div_output_0 -> (-1, -1, 256)[FLOAT]], [bert.encoder.layer.5.attention.output.LayerNorm.weight -> (256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Registering layer: bert.encoder.layer.5.attention.output.LayerNorm.weight for ONNX node: bert.encoder.layer.5.attention.output.LayerNorm.weight\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/output/LayerNorm/Mul for ONNX node: /bert/encoder/layer.5/attention/output/LayerNorm/Mul\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/output/LayerNorm/Mul_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/output/LayerNorm/Mul_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] /bert/encoder/layer.5/attention/output/LayerNorm/Mul [Mul] outputs: [/bert/encoder/layer.5/attention/output/LayerNorm/Mul_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/output/LayerNorm/Add_1 [Add]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/output/LayerNorm/Mul_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Searching for input: bert.encoder.layer.5.attention.output.LayerNorm.bias\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] /bert/encoder/layer.5/attention/output/LayerNorm/Add_1 [Add] inputs: [/bert/encoder/layer.5/attention/output/LayerNorm/Mul_output_0 -> (-1, -1, 256)[FLOAT]], [bert.encoder.layer.5.attention.output.LayerNorm.bias -> (256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Registering layer: bert.encoder.layer.5.attention.output.LayerNorm.bias for ONNX node: bert.encoder.layer.5.attention.output.LayerNorm.bias\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02/02/2023-19:14:20] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/output/LayerNorm/Add_1 for ONNX node: /bert/encoder/layer.5/attention/output/LayerNorm/Add_1\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/output/LayerNorm/Add_1_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/output/LayerNorm/Add_1_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] /bert/encoder/layer.5/attention/output/LayerNorm/Add_1 [Add] outputs: [/bert/encoder/layer.5/attention/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Parsing node: /bert/encoder/layer.5/intermediate/dense/MatMul [MatMul]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/output/LayerNorm/Add_1_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Searching for input: onnx::MatMul_869\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] /bert/encoder/layer.5/intermediate/dense/MatMul [MatMul] inputs: [/bert/encoder/layer.5/attention/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], [onnx::MatMul_869 -> (256, 1024)[FLOAT]], \r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Registering layer: onnx::MatMul_869 for ONNX node: onnx::MatMul_869\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Registering layer: /bert/encoder/layer.5/intermediate/dense/MatMul for ONNX node: /bert/encoder/layer.5/intermediate/dense/MatMul\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Registering tensor: /bert/encoder/layer.5/intermediate/dense/MatMul_output_0 for ONNX tensor: /bert/encoder/layer.5/intermediate/dense/MatMul_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] /bert/encoder/layer.5/intermediate/dense/MatMul [MatMul] outputs: [/bert/encoder/layer.5/intermediate/dense/MatMul_output_0 -> (-1, -1, 1024)[FLOAT]], \r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Parsing node: /bert/encoder/layer.5/intermediate/dense/Add [Add]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Searching for input: bert.encoder.layer.5.intermediate.dense.bias\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Searching for input: /bert/encoder/layer.5/intermediate/dense/MatMul_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] /bert/encoder/layer.5/intermediate/dense/Add [Add] inputs: [bert.encoder.layer.5.intermediate.dense.bias -> (1024)[FLOAT]], [/bert/encoder/layer.5/intermediate/dense/MatMul_output_0 -> (-1, -1, 1024)[FLOAT]], \r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Registering layer: bert.encoder.layer.5.intermediate.dense.bias for ONNX node: bert.encoder.layer.5.intermediate.dense.bias\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Registering layer: /bert/encoder/layer.5/intermediate/dense/Add for ONNX node: /bert/encoder/layer.5/intermediate/dense/Add\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Registering tensor: /bert/encoder/layer.5/intermediate/dense/Add_output_0 for ONNX tensor: /bert/encoder/layer.5/intermediate/dense/Add_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] /bert/encoder/layer.5/intermediate/dense/Add [Add] outputs: [/bert/encoder/layer.5/intermediate/dense/Add_output_0 -> (-1, -1, 1024)[FLOAT]], \r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Parsing node: /bert/encoder/layer.5/intermediate/intermediate_act_fn/Constant [Constant]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] /bert/encoder/layer.5/intermediate/intermediate_act_fn/Constant [Constant] inputs: \r\n",
      "[02/02/2023-19:14:20] [V] [TRT] /bert/encoder/layer.5/intermediate/intermediate_act_fn/Constant [Constant] outputs: [/bert/encoder/layer.5/intermediate/intermediate_act_fn/Constant_output_0 -> ()[FLOAT]], \r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Parsing node: /bert/encoder/layer.5/intermediate/intermediate_act_fn/Div [Div]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Searching for input: /bert/encoder/layer.5/intermediate/dense/Add_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Searching for input: /bert/encoder/layer.5/intermediate/intermediate_act_fn/Constant_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] /bert/encoder/layer.5/intermediate/intermediate_act_fn/Div [Div] inputs: [/bert/encoder/layer.5/intermediate/dense/Add_output_0 -> (-1, -1, 1024)[FLOAT]], [/bert/encoder/layer.5/intermediate/intermediate_act_fn/Constant_output_0 -> ()[FLOAT]], \r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Registering layer: /bert/encoder/layer.5/intermediate/intermediate_act_fn/Constant_output_0 for ONNX node: /bert/encoder/layer.5/intermediate/intermediate_act_fn/Constant_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Registering layer: /bert/encoder/layer.5/intermediate/intermediate_act_fn/Div for ONNX node: /bert/encoder/layer.5/intermediate/intermediate_act_fn/Div\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Registering tensor: /bert/encoder/layer.5/intermediate/intermediate_act_fn/Div_output_0 for ONNX tensor: /bert/encoder/layer.5/intermediate/intermediate_act_fn/Div_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] /bert/encoder/layer.5/intermediate/intermediate_act_fn/Div [Div] outputs: [/bert/encoder/layer.5/intermediate/intermediate_act_fn/Div_output_0 -> (-1, -1, 1024)[FLOAT]], \r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Parsing node: /bert/encoder/layer.5/intermediate/intermediate_act_fn/Erf [Erf]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Searching for input: /bert/encoder/layer.5/intermediate/intermediate_act_fn/Div_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] /bert/encoder/layer.5/intermediate/intermediate_act_fn/Erf [Erf] inputs: [/bert/encoder/layer.5/intermediate/intermediate_act_fn/Div_output_0 -> (-1, -1, 1024)[FLOAT]], \r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Registering layer: /bert/encoder/layer.5/intermediate/intermediate_act_fn/Erf for ONNX node: /bert/encoder/layer.5/intermediate/intermediate_act_fn/Erf\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Registering tensor: /bert/encoder/layer.5/intermediate/intermediate_act_fn/Erf_output_0 for ONNX tensor: /bert/encoder/layer.5/intermediate/intermediate_act_fn/Erf_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] /bert/encoder/layer.5/intermediate/intermediate_act_fn/Erf [Erf] outputs: [/bert/encoder/layer.5/intermediate/intermediate_act_fn/Erf_output_0 -> (-1, -1, 1024)[FLOAT]], \r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Parsing node: /bert/encoder/layer.5/intermediate/intermediate_act_fn/Constant_1 [Constant]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] /bert/encoder/layer.5/intermediate/intermediate_act_fn/Constant_1 [Constant] inputs: \r\n",
      "[02/02/2023-19:14:20] [V] [TRT] /bert/encoder/layer.5/intermediate/intermediate_act_fn/Constant_1 [Constant] outputs: [/bert/encoder/layer.5/intermediate/intermediate_act_fn/Constant_1_output_0 -> ()[FLOAT]], \r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Parsing node: /bert/encoder/layer.5/intermediate/intermediate_act_fn/Add [Add]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Searching for input: /bert/encoder/layer.5/intermediate/intermediate_act_fn/Erf_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Searching for input: /bert/encoder/layer.5/intermediate/intermediate_act_fn/Constant_1_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] /bert/encoder/layer.5/intermediate/intermediate_act_fn/Add [Add] inputs: [/bert/encoder/layer.5/intermediate/intermediate_act_fn/Erf_output_0 -> (-1, -1, 1024)[FLOAT]], [/bert/encoder/layer.5/intermediate/intermediate_act_fn/Constant_1_output_0 -> ()[FLOAT]], \r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Registering layer: /bert/encoder/layer.5/intermediate/intermediate_act_fn/Constant_1_output_0 for ONNX node: /bert/encoder/layer.5/intermediate/intermediate_act_fn/Constant_1_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Registering layer: /bert/encoder/layer.5/intermediate/intermediate_act_fn/Add for ONNX node: /bert/encoder/layer.5/intermediate/intermediate_act_fn/Add\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Registering tensor: /bert/encoder/layer.5/intermediate/intermediate_act_fn/Add_output_0 for ONNX tensor: /bert/encoder/layer.5/intermediate/intermediate_act_fn/Add_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] /bert/encoder/layer.5/intermediate/intermediate_act_fn/Add [Add] outputs: [/bert/encoder/layer.5/intermediate/intermediate_act_fn/Add_output_0 -> (-1, -1, 1024)[FLOAT]], \r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Parsing node: /bert/encoder/layer.5/intermediate/intermediate_act_fn/Mul [Mul]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Searching for input: /bert/encoder/layer.5/intermediate/dense/Add_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Searching for input: /bert/encoder/layer.5/intermediate/intermediate_act_fn/Add_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] /bert/encoder/layer.5/intermediate/intermediate_act_fn/Mul [Mul] inputs: [/bert/encoder/layer.5/intermediate/dense/Add_output_0 -> (-1, -1, 1024)[FLOAT]], [/bert/encoder/layer.5/intermediate/intermediate_act_fn/Add_output_0 -> (-1, -1, 1024)[FLOAT]], \r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Registering layer: /bert/encoder/layer.5/intermediate/intermediate_act_fn/Mul for ONNX node: /bert/encoder/layer.5/intermediate/intermediate_act_fn/Mul\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Registering tensor: /bert/encoder/layer.5/intermediate/intermediate_act_fn/Mul_output_0 for ONNX tensor: /bert/encoder/layer.5/intermediate/intermediate_act_fn/Mul_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] /bert/encoder/layer.5/intermediate/intermediate_act_fn/Mul [Mul] outputs: [/bert/encoder/layer.5/intermediate/intermediate_act_fn/Mul_output_0 -> (-1, -1, 1024)[FLOAT]], \r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Parsing node: /bert/encoder/layer.5/intermediate/intermediate_act_fn/Constant_2 [Constant]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] /bert/encoder/layer.5/intermediate/intermediate_act_fn/Constant_2 [Constant] inputs: \r\n",
      "[02/02/2023-19:14:20] [V] [TRT] /bert/encoder/layer.5/intermediate/intermediate_act_fn/Constant_2 [Constant] outputs: [/bert/encoder/layer.5/intermediate/intermediate_act_fn/Constant_2_output_0 -> ()[FLOAT]], \r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Parsing node: /bert/encoder/layer.5/intermediate/intermediate_act_fn/Mul_1 [Mul]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Searching for input: /bert/encoder/layer.5/intermediate/intermediate_act_fn/Mul_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Searching for input: /bert/encoder/layer.5/intermediate/intermediate_act_fn/Constant_2_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] /bert/encoder/layer.5/intermediate/intermediate_act_fn/Mul_1 [Mul] inputs: [/bert/encoder/layer.5/intermediate/intermediate_act_fn/Mul_output_0 -> (-1, -1, 1024)[FLOAT]], [/bert/encoder/layer.5/intermediate/intermediate_act_fn/Constant_2_output_0 -> ()[FLOAT]], \r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Registering layer: /bert/encoder/layer.5/intermediate/intermediate_act_fn/Constant_2_output_0 for ONNX node: /bert/encoder/layer.5/intermediate/intermediate_act_fn/Constant_2_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Registering layer: /bert/encoder/layer.5/intermediate/intermediate_act_fn/Mul_1 for ONNX node: /bert/encoder/layer.5/intermediate/intermediate_act_fn/Mul_1\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Registering tensor: /bert/encoder/layer.5/intermediate/intermediate_act_fn/Mul_1_output_0 for ONNX tensor: /bert/encoder/layer.5/intermediate/intermediate_act_fn/Mul_1_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] /bert/encoder/layer.5/intermediate/intermediate_act_fn/Mul_1 [Mul] outputs: [/bert/encoder/layer.5/intermediate/intermediate_act_fn/Mul_1_output_0 -> (-1, -1, 1024)[FLOAT]], \r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Parsing node: /bert/encoder/layer.5/output/dense/MatMul [MatMul]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Searching for input: /bert/encoder/layer.5/intermediate/intermediate_act_fn/Mul_1_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Searching for input: onnx::MatMul_870\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] /bert/encoder/layer.5/output/dense/MatMul [MatMul] inputs: [/bert/encoder/layer.5/intermediate/intermediate_act_fn/Mul_1_output_0 -> (-1, -1, 1024)[FLOAT]], [onnx::MatMul_870 -> (1024, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Registering layer: onnx::MatMul_870 for ONNX node: onnx::MatMul_870\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Registering layer: /bert/encoder/layer.5/output/dense/MatMul for ONNX node: /bert/encoder/layer.5/output/dense/MatMul\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Registering tensor: /bert/encoder/layer.5/output/dense/MatMul_output_0 for ONNX tensor: /bert/encoder/layer.5/output/dense/MatMul_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] /bert/encoder/layer.5/output/dense/MatMul [MatMul] outputs: [/bert/encoder/layer.5/output/dense/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Parsing node: /bert/encoder/layer.5/output/dense/Add [Add]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Searching for input: bert.encoder.layer.5.output.dense.bias\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Searching for input: /bert/encoder/layer.5/output/dense/MatMul_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] /bert/encoder/layer.5/output/dense/Add [Add] inputs: [bert.encoder.layer.5.output.dense.bias -> (256)[FLOAT]], [/bert/encoder/layer.5/output/dense/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Registering layer: bert.encoder.layer.5.output.dense.bias for ONNX node: bert.encoder.layer.5.output.dense.bias\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Registering layer: /bert/encoder/layer.5/output/dense/Add for ONNX node: /bert/encoder/layer.5/output/dense/Add\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Registering tensor: /bert/encoder/layer.5/output/dense/Add_output_0 for ONNX tensor: /bert/encoder/layer.5/output/dense/Add_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] /bert/encoder/layer.5/output/dense/Add [Add] outputs: [/bert/encoder/layer.5/output/dense/Add_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Parsing node: /bert/encoder/layer.5/output/Add [Add]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Searching for input: /bert/encoder/layer.5/output/dense/Add_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/output/LayerNorm/Add_1_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] /bert/encoder/layer.5/output/Add [Add] inputs: [/bert/encoder/layer.5/output/dense/Add_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.5/attention/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Registering layer: /bert/encoder/layer.5/output/Add for ONNX node: /bert/encoder/layer.5/output/Add\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Registering tensor: /bert/encoder/layer.5/output/Add_output_0 for ONNX tensor: /bert/encoder/layer.5/output/Add_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] /bert/encoder/layer.5/output/Add [Add] outputs: [/bert/encoder/layer.5/output/Add_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Parsing node: /bert/encoder/layer.5/output/LayerNorm/ReduceMean [ReduceMean]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Searching for input: /bert/encoder/layer.5/output/Add_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] /bert/encoder/layer.5/output/LayerNorm/ReduceMean [ReduceMean] inputs: [/bert/encoder/layer.5/output/Add_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Registering layer: /bert/encoder/layer.5/output/LayerNorm/ReduceMean for ONNX node: /bert/encoder/layer.5/output/LayerNorm/ReduceMean\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Registering tensor: /bert/encoder/layer.5/output/LayerNorm/ReduceMean_output_0 for ONNX tensor: /bert/encoder/layer.5/output/LayerNorm/ReduceMean_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] /bert/encoder/layer.5/output/LayerNorm/ReduceMean [ReduceMean] outputs: [/bert/encoder/layer.5/output/LayerNorm/ReduceMean_output_0 -> (-1, -1, 1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Parsing node: /bert/encoder/layer.5/output/LayerNorm/Sub [Sub]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Searching for input: /bert/encoder/layer.5/output/Add_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Searching for input: /bert/encoder/layer.5/output/LayerNorm/ReduceMean_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] /bert/encoder/layer.5/output/LayerNorm/Sub [Sub] inputs: [/bert/encoder/layer.5/output/Add_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.5/output/LayerNorm/ReduceMean_output_0 -> (-1, -1, 1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Registering layer: /bert/encoder/layer.5/output/LayerNorm/Sub for ONNX node: /bert/encoder/layer.5/output/LayerNorm/Sub\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Registering tensor: /bert/encoder/layer.5/output/LayerNorm/Sub_output_0 for ONNX tensor: /bert/encoder/layer.5/output/LayerNorm/Sub_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] /bert/encoder/layer.5/output/LayerNorm/Sub [Sub] outputs: [/bert/encoder/layer.5/output/LayerNorm/Sub_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Parsing node: /bert/encoder/layer.5/output/LayerNorm/Constant [Constant]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] /bert/encoder/layer.5/output/LayerNorm/Constant [Constant] inputs: \r\n",
      "[02/02/2023-19:14:20] [V] [TRT] /bert/encoder/layer.5/output/LayerNorm/Constant [Constant] outputs: [/bert/encoder/layer.5/output/LayerNorm/Constant_output_0 -> ()[FLOAT]], \r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Parsing node: /bert/encoder/layer.5/output/LayerNorm/Pow [Pow]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Searching for input: /bert/encoder/layer.5/output/LayerNorm/Sub_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Searching for input: /bert/encoder/layer.5/output/LayerNorm/Constant_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] /bert/encoder/layer.5/output/LayerNorm/Pow [Pow] inputs: [/bert/encoder/layer.5/output/LayerNorm/Sub_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.5/output/LayerNorm/Constant_output_0 -> ()[FLOAT]], \r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Registering layer: /bert/encoder/layer.5/output/LayerNorm/Constant_output_0 for ONNX node: /bert/encoder/layer.5/output/LayerNorm/Constant_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Registering layer: /bert/encoder/layer.5/output/LayerNorm/Pow for ONNX node: /bert/encoder/layer.5/output/LayerNorm/Pow\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Registering tensor: /bert/encoder/layer.5/output/LayerNorm/Pow_output_0 for ONNX tensor: /bert/encoder/layer.5/output/LayerNorm/Pow_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] /bert/encoder/layer.5/output/LayerNorm/Pow [Pow] outputs: [/bert/encoder/layer.5/output/LayerNorm/Pow_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Parsing node: /bert/encoder/layer.5/output/LayerNorm/ReduceMean_1 [ReduceMean]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Searching for input: /bert/encoder/layer.5/output/LayerNorm/Pow_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] /bert/encoder/layer.5/output/LayerNorm/ReduceMean_1 [ReduceMean] inputs: [/bert/encoder/layer.5/output/LayerNorm/Pow_output_0 -> (-1, -1, 256)[FLOAT]], \r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Registering layer: /bert/encoder/layer.5/output/LayerNorm/ReduceMean_1 for ONNX node: /bert/encoder/layer.5/output/LayerNorm/ReduceMean_1\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Registering tensor: /bert/encoder/layer.5/output/LayerNorm/ReduceMean_1_output_0 for ONNX tensor: /bert/encoder/layer.5/output/LayerNorm/ReduceMean_1_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] /bert/encoder/layer.5/output/LayerNorm/ReduceMean_1 [ReduceMean] outputs: [/bert/encoder/layer.5/output/LayerNorm/ReduceMean_1_output_0 -> (-1, -1, 1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Parsing node: /bert/encoder/layer.5/output/LayerNorm/Constant_1 [Constant]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] /bert/encoder/layer.5/output/LayerNorm/Constant_1 [Constant] inputs: \r\n",
      "[02/02/2023-19:14:20] [V] [TRT] /bert/encoder/layer.5/output/LayerNorm/Constant_1 [Constant] outputs: [/bert/encoder/layer.5/output/LayerNorm/Constant_1_output_0 -> ()[FLOAT]], \r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Parsing node: /bert/encoder/layer.5/output/LayerNorm/Add [Add]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Searching for input: /bert/encoder/layer.5/output/LayerNorm/ReduceMean_1_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Searching for input: /bert/encoder/layer.5/output/LayerNorm/Constant_1_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] /bert/encoder/layer.5/output/LayerNorm/Add [Add] inputs: [/bert/encoder/layer.5/output/LayerNorm/ReduceMean_1_output_0 -> (-1, -1, 1)[FLOAT]], [/bert/encoder/layer.5/output/LayerNorm/Constant_1_output_0 -> ()[FLOAT]], \r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Registering layer: /bert/encoder/layer.5/output/LayerNorm/Constant_1_output_0 for ONNX node: /bert/encoder/layer.5/output/LayerNorm/Constant_1_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Registering layer: /bert/encoder/layer.5/output/LayerNorm/Add for ONNX node: /bert/encoder/layer.5/output/LayerNorm/Add\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Registering tensor: /bert/encoder/layer.5/output/LayerNorm/Add_output_0 for ONNX tensor: /bert/encoder/layer.5/output/LayerNorm/Add_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] /bert/encoder/layer.5/output/LayerNorm/Add [Add] outputs: [/bert/encoder/layer.5/output/LayerNorm/Add_output_0 -> (-1, -1, 1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Parsing node: /bert/encoder/layer.5/output/LayerNorm/Sqrt [Sqrt]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Searching for input: /bert/encoder/layer.5/output/LayerNorm/Add_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] /bert/encoder/layer.5/output/LayerNorm/Sqrt [Sqrt] inputs: [/bert/encoder/layer.5/output/LayerNorm/Add_output_0 -> (-1, -1, 1)[FLOAT]], \r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Registering layer: /bert/encoder/layer.5/output/LayerNorm/Sqrt for ONNX node: /bert/encoder/layer.5/output/LayerNorm/Sqrt\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02/02/2023-19:14:20] [V] [TRT] Registering tensor: /bert/encoder/layer.5/output/LayerNorm/Sqrt_output_0 for ONNX tensor: /bert/encoder/layer.5/output/LayerNorm/Sqrt_output_0\n",
      "[02/02/2023-19:14:20] [V] [TRT] /bert/encoder/layer.5/output/LayerNorm/Sqrt [Sqrt] outputs: [/bert/encoder/layer.5/output/LayerNorm/Sqrt_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[02/02/2023-19:14:20] [V] [TRT] Parsing node: /bert/encoder/layer.5/output/LayerNorm/Div [Div]\n",
      "[02/02/2023-19:14:20] [V] [TRT] Searching for input: /bert/encoder/layer.5/output/LayerNorm/Sub_output_0\n",
      "[02/02/2023-19:14:20] [V] [TRT] Searching for input: /bert/encoder/layer.5/output/LayerNorm/Sqrt_output_0\n",
      "[02/02/2023-19:14:20] [V] [TRT] /bert/encoder/layer.5/output/LayerNorm/Div [Div] inputs: [/bert/encoder/layer.5/output/LayerNorm/Sub_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.5/output/LayerNorm/Sqrt_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[02/02/2023-19:14:20] [V] [TRT] Registering layer: /bert/encoder/layer.5/output/LayerNorm/Div for ONNX node: /bert/encoder/layer.5/output/LayerNorm/Div\n",
      "[02/02/2023-19:14:20] [V] [TRT] Registering tensor: /bert/encoder/layer.5/output/LayerNorm/Div_output_0 for ONNX tensor: /bert/encoder/layer.5/output/LayerNorm/Div_output_0\n",
      "[02/02/2023-19:14:20] [V] [TRT] /bert/encoder/layer.5/output/LayerNorm/Div [Div] outputs: [/bert/encoder/layer.5/output/LayerNorm/Div_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[02/02/2023-19:14:20] [V] [TRT] Parsing node: /bert/encoder/layer.5/output/LayerNorm/Mul [Mul]\n",
      "[02/02/2023-19:14:20] [V] [TRT] Searching for input: /bert/encoder/layer.5/output/LayerNorm/Div_output_0\n",
      "[02/02/2023-19:14:20] [V] [TRT] Searching for input: bert.encoder.layer.5.output.LayerNorm.weight\n",
      "[02/02/2023-19:14:20] [V] [TRT] /bert/encoder/layer.5/output/LayerNorm/Mul [Mul] inputs: [/bert/encoder/layer.5/output/LayerNorm/Div_output_0 -> (-1, -1, 256)[FLOAT]], [bert.encoder.layer.5.output.LayerNorm.weight -> (256)[FLOAT]], \n",
      "[02/02/2023-19:14:20] [V] [TRT] Registering layer: bert.encoder.layer.5.output.LayerNorm.weight for ONNX node: bert.encoder.layer.5.output.LayerNorm.weight\n",
      "[02/02/2023-19:14:20] [V] [TRT] Registering layer: /bert/encoder/layer.5/output/LayerNorm/Mul for ONNX node: /bert/encoder/layer.5/output/LayerNorm/Mul\n",
      "[02/02/2023-19:14:20] [V] [TRT] Registering tensor: /bert/encoder/layer.5/output/LayerNorm/Mul_output_0 for ONNX tensor: /bert/encoder/layer.5/output/LayerNorm/Mul_output_0\n",
      "[02/02/2023-19:14:20] [V] [TRT] /bert/encoder/layer.5/output/LayerNorm/Mul [Mul] outputs: [/bert/encoder/layer.5/output/LayerNorm/Mul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[02/02/2023-19:14:20] [V] [TRT] Parsing node: /bert/encoder/layer.5/output/LayerNorm/Add_1 [Add]\n",
      "[02/02/2023-19:14:20] [V] [TRT] Searching for input: /bert/encoder/layer.5/output/LayerNorm/Mul_output_0\n",
      "[02/02/2023-19:14:20] [V] [TRT] Searching for input: bert.encoder.layer.5.output.LayerNorm.bias\n",
      "[02/02/2023-19:14:20] [V] [TRT] /bert/encoder/layer.5/output/LayerNorm/Add_1 [Add] inputs: [/bert/encoder/layer.5/output/LayerNorm/Mul_output_0 -> (-1, -1, 256)[FLOAT]], [bert.encoder.layer.5.output.LayerNorm.bias -> (256)[FLOAT]], \n",
      "[02/02/2023-19:14:20] [V] [TRT] Registering layer: bert.encoder.layer.5.output.LayerNorm.bias for ONNX node: bert.encoder.layer.5.output.LayerNorm.bias\n",
      "[02/02/2023-19:14:20] [V] [TRT] Registering layer: /bert/encoder/layer.5/output/LayerNorm/Add_1 for ONNX node: /bert/encoder/layer.5/output/LayerNorm/Add_1\n",
      "[02/02/2023-19:14:20] [V] [TRT] Registering tensor: /bert/encoder/layer.5/output/LayerNorm/Add_1_output_0 for ONNX tensor: /bert/encoder/layer.5/output/LayerNorm/Add_1_output_0\n",
      "[02/02/2023-19:14:20] [V] [TRT] /bert/encoder/layer.5/output/LayerNorm/Add_1 [Add] outputs: [/bert/encoder/layer.5/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[02/02/2023-19:14:20] [V] [TRT] Parsing node: /bert/pooler/Gather [Gather]\n",
      "[02/02/2023-19:14:20] [V] [TRT] Searching for input: /bert/encoder/layer.5/output/LayerNorm/Add_1_output_0\n",
      "[02/02/2023-19:14:20] [V] [TRT] Searching for input: /bert/Constant_output_0\n",
      "[02/02/2023-19:14:20] [V] [TRT] /bert/pooler/Gather [Gather] inputs: [/bert/encoder/layer.5/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/Constant_output_0 -> ()[INT32]], \n",
      "[02/02/2023-19:14:20] [V] [TRT] Registering layer: /bert/Constant_output_0 for ONNX node: /bert/Constant_output_0\n",
      "[02/02/2023-19:14:20] [V] [TRT] Using Gather axis: 1\n",
      "[02/02/2023-19:14:20] [V] [TRT] Registering layer: /bert/pooler/Gather for ONNX node: /bert/pooler/Gather\n",
      "[02/02/2023-19:14:20] [V] [TRT] Registering tensor: /bert/pooler/Gather_output_0 for ONNX tensor: /bert/pooler/Gather_output_0\n",
      "[02/02/2023-19:14:20] [V] [TRT] /bert/pooler/Gather [Gather] outputs: [/bert/pooler/Gather_output_0 -> (-1, 256)[FLOAT]], \n",
      "[02/02/2023-19:14:20] [V] [TRT] Parsing node: /bert/pooler/dense/Gemm [Gemm]\n",
      "[02/02/2023-19:14:20] [V] [TRT] Searching for input: /bert/pooler/Gather_output_0\n",
      "[02/02/2023-19:14:20] [V] [TRT] Searching for input: bert.pooler.dense.weight\n",
      "[02/02/2023-19:14:20] [V] [TRT] Searching for input: bert.pooler.dense.bias\n",
      "[02/02/2023-19:14:20] [V] [TRT] /bert/pooler/dense/Gemm [Gemm] inputs: [/bert/pooler/Gather_output_0 -> (-1, 256)[FLOAT]], [bert.pooler.dense.weight -> (256, 256)[FLOAT]], [bert.pooler.dense.bias -> (256)[FLOAT]], \n",
      "[02/02/2023-19:14:20] [V] [TRT] Registering layer: bert.pooler.dense.weight for ONNX node: bert.pooler.dense.weight\n",
      "[02/02/2023-19:14:20] [V] [TRT] Using opA: 0 opB: 1\n",
      "[02/02/2023-19:14:20] [V] [TRT] Registering layer: /bert/pooler/dense/Gemm for ONNX node: /bert/pooler/dense/Gemm\n",
      "[02/02/2023-19:14:20] [V] [TRT] Registering layer: bert.pooler.dense.bias for ONNX node: bert.pooler.dense.bias\n",
      "[02/02/2023-19:14:20] [V] [TRT] Registering tensor: /bert/pooler/dense/Gemm_output_0 for ONNX tensor: /bert/pooler/dense/Gemm_output_0\n",
      "[02/02/2023-19:14:20] [V] [TRT] /bert/pooler/dense/Gemm [Gemm] outputs: [/bert/pooler/dense/Gemm_output_0 -> (-1, 256)[FLOAT]], \n",
      "[02/02/2023-19:14:20] [V] [TRT] Parsing node: /bert/pooler/activation/Tanh [Tanh]\n",
      "[02/02/2023-19:14:20] [V] [TRT] Searching for input: /bert/pooler/dense/Gemm_output_0\n",
      "[02/02/2023-19:14:20] [V] [TRT] /bert/pooler/activation/Tanh [Tanh] inputs: [/bert/pooler/dense/Gemm_output_0 -> (-1, 256)[FLOAT]], \n",
      "[02/02/2023-19:14:20] [V] [TRT] Registering layer: /bert/pooler/activation/Tanh for ONNX node: /bert/pooler/activation/Tanh\n",
      "[02/02/2023-19:14:20] [V] [TRT] Registering tensor: /bert/pooler/activation/Tanh_output_0 for ONNX tensor: /bert/pooler/activation/Tanh_output_0\n",
      "[02/02/2023-19:14:20] [V] [TRT] /bert/pooler/activation/Tanh [Tanh] outputs: [/bert/pooler/activation/Tanh_output_0 -> (-1, 256)[FLOAT]], \n",
      "[02/02/2023-19:14:20] [V] [TRT] Parsing node: /classifier/Gemm [Gemm]\n",
      "[02/02/2023-19:14:20] [V] [TRT] Searching for input: /bert/pooler/activation/Tanh_output_0\n",
      "[02/02/2023-19:14:20] [V] [TRT] Searching for input: classifier.weight\n",
      "[02/02/2023-19:14:20] [V] [TRT] Searching for input: classifier.bias\n",
      "[02/02/2023-19:14:20] [V] [TRT] /classifier/Gemm [Gemm] inputs: [/bert/pooler/activation/Tanh_output_0 -> (-1, 256)[FLOAT]], [classifier.weight -> (6, 256)[FLOAT]], [classifier.bias -> (6)[FLOAT]], \n",
      "[02/02/2023-19:14:20] [V] [TRT] Registering layer: classifier.weight for ONNX node: classifier.weight\n",
      "[02/02/2023-19:14:20] [V] [TRT] Using opA: 0 opB: 1\n",
      "[02/02/2023-19:14:20] [V] [TRT] Registering layer: /classifier/Gemm for ONNX node: /classifier/Gemm\n",
      "[02/02/2023-19:14:20] [V] [TRT] Registering layer: classifier.bias for ONNX node: classifier.bias\n",
      "[02/02/2023-19:14:20] [V] [TRT] Registering tensor: logits_129 for ONNX tensor: logits\n",
      "[02/02/2023-19:14:20] [V] [TRT] /classifier/Gemm [Gemm] outputs: [logits -> (-1, 6)[FLOAT]], \n",
      "[02/02/2023-19:14:20] [V] [TRT] Marking logits_129 as output: logits\n",
      "[02/02/2023-19:14:20] [I] Finish parsing network model\n",
      "[02/02/2023-19:14:20] [V] [TRT] Original: 649 layers\n",
      "[02/02/2023-19:14:20] [V] [TRT] After dead-layer removal: 649 layers\n",
      "[02/02/2023-19:14:20] [V] [TRT] Applying generic optimizations to the graph for inference.\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on /bert/Constant_1_output_0\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing /bert/Constant_1_output_0 with (Unnamed Layer* 14) [Shuffle]\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on /bert/Constant_2_output_0\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing /bert/Constant_2_output_0 with (Unnamed Layer* 17) [Shuffle]\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on /bert/embeddings/LayerNorm/Constant_output_0\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing /bert/embeddings/LayerNorm/Constant_output_0 with (Unnamed Layer* 51) [Shuffle]\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on /bert/embeddings/LayerNorm/Constant_1_output_0\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing /bert/embeddings/LayerNorm/Constant_1_output_0 with (Unnamed Layer* 55) [Shuffle]\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on bert.embeddings.LayerNorm.weight\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing bert.embeddings.LayerNorm.weight with (Unnamed Layer* 60) [Shuffle]\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on bert.embeddings.LayerNorm.bias\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing bert.embeddings.LayerNorm.bias with (Unnamed Layer* 63) [Shuffle]\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on onnx::MatMul_793\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing onnx::MatMul_793 with (Unnamed Layer* 66) [Shuffle]\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.0.attention.self.query.bias\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.0.attention.self.query.bias with (Unnamed Layer* 69) [Shuffle]\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on onnx::MatMul_794\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing onnx::MatMul_794 with (Unnamed Layer* 72) [Shuffle]\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.0.attention.self.key.bias\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.0.attention.self.key.bias with (Unnamed Layer* 75) [Shuffle]\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on onnx::MatMul_797\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing onnx::MatMul_797 with (Unnamed Layer* 90) [Shuffle]\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.0.attention.self.value.bias\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.0.attention.self.value.bias with (Unnamed Layer* 93) [Shuffle]\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.0/attention/self/Constant_12_output_0\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.0/attention/self/Constant_12_output_0 with (Unnamed Layer* 124) [Shuffle]\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on onnx::MatMul_803\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing onnx::MatMul_803 with (Unnamed Layer* 156) [Shuffle]\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.0.attention.output.dense.bias\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.0.attention.output.dense.bias with (Unnamed Layer* 159) [Shuffle]\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.0/attention/output/LayerNorm/Constant_output_0\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.0/attention/output/LayerNorm/Constant_output_0 with (Unnamed Layer* 165) [Shuffle]\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.0/attention/output/LayerNorm/Constant_1_output_0\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.0/attention/output/LayerNorm/Constant_1_output_0 with (Unnamed Layer* 169) [Shuffle]\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.0.attention.output.LayerNorm.weight\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.0.attention.output.LayerNorm.weight with (Unnamed Layer* 174) [Shuffle]\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.0.attention.output.LayerNorm.bias\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.0.attention.output.LayerNorm.bias with (Unnamed Layer* 177) [Shuffle]\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on onnx::MatMul_804\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing onnx::MatMul_804 with (Unnamed Layer* 180) [Shuffle]\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.0.intermediate.dense.bias\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.0.intermediate.dense.bias with (Unnamed Layer* 183) [Shuffle]\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.0/intermediate/intermediate_act_fn/Constant_output_0\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.0/intermediate/intermediate_act_fn/Constant_output_0 with (Unnamed Layer* 186) [Shuffle]\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.0/intermediate/intermediate_act_fn/Constant_1_output_0\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.0/intermediate/intermediate_act_fn/Constant_1_output_0 with (Unnamed Layer* 190) [Shuffle]\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.0/intermediate/intermediate_act_fn/Constant_2_output_0\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.0/intermediate/intermediate_act_fn/Constant_2_output_0 with (Unnamed Layer* 194) [Shuffle]\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on onnx::MatMul_805\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing onnx::MatMul_805 with (Unnamed Layer* 197) [Shuffle]\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.0.output.dense.bias\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.0.output.dense.bias with (Unnamed Layer* 200) [Shuffle]\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.0/output/LayerNorm/Constant_output_0\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.0/output/LayerNorm/Constant_output_0 with (Unnamed Layer* 206) [Shuffle]\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.0/output/LayerNorm/Constant_1_output_0\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.0/output/LayerNorm/Constant_1_output_0 with (Unnamed Layer* 210) [Shuffle]\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.0.output.LayerNorm.weight\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.0.output.LayerNorm.weight with (Unnamed Layer* 215) [Shuffle]\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.0.output.LayerNorm.bias\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.0.output.LayerNorm.bias with (Unnamed Layer* 218) [Shuffle]\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on onnx::MatMul_806\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing onnx::MatMul_806 with (Unnamed Layer* 221) [Shuffle]\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.1.attention.self.query.bias\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.1.attention.self.query.bias with (Unnamed Layer* 224) [Shuffle]\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on onnx::MatMul_807\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing onnx::MatMul_807 with (Unnamed Layer* 227) [Shuffle]\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.1.attention.self.key.bias\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.1.attention.self.key.bias with (Unnamed Layer* 230) [Shuffle]\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on onnx::MatMul_810\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing onnx::MatMul_810 with (Unnamed Layer* 245) [Shuffle]\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.1.attention.self.value.bias\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.1.attention.self.value.bias with (Unnamed Layer* 248) [Shuffle]\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.1/attention/self/Constant_12_output_0\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.1/attention/self/Constant_12_output_0 with (Unnamed Layer* 279) [Shuffle]\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on onnx::MatMul_816\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing onnx::MatMul_816 with (Unnamed Layer* 311) [Shuffle]\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.1.attention.output.dense.bias\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.1.attention.output.dense.bias with (Unnamed Layer* 314) [Shuffle]\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.1/attention/output/LayerNorm/Constant_output_0\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.1/attention/output/LayerNorm/Constant_output_0 with (Unnamed Layer* 320) [Shuffle]\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.1/attention/output/LayerNorm/Constant_1_output_0\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.1/attention/output/LayerNorm/Constant_1_output_0 with (Unnamed Layer* 324) [Shuffle]\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.1.attention.output.LayerNorm.weight\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.1.attention.output.LayerNorm.weight with (Unnamed Layer* 329) [Shuffle]\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.1.attention.output.LayerNorm.bias\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.1.attention.output.LayerNorm.bias with (Unnamed Layer* 332) [Shuffle]\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on onnx::MatMul_817\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing onnx::MatMul_817 with (Unnamed Layer* 335) [Shuffle]\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.1.intermediate.dense.bias\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.1.intermediate.dense.bias with (Unnamed Layer* 338) [Shuffle]\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.1/intermediate/intermediate_act_fn/Constant_output_0\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.1/intermediate/intermediate_act_fn/Constant_output_0 with (Unnamed Layer* 341) [Shuffle]\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.1/intermediate/intermediate_act_fn/Constant_1_output_0\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.1/intermediate/intermediate_act_fn/Constant_1_output_0 with (Unnamed Layer* 345) [Shuffle]\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.1/intermediate/intermediate_act_fn/Constant_2_output_0\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.1/intermediate/intermediate_act_fn/Constant_2_output_0 with (Unnamed Layer* 349) [Shuffle]\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on onnx::MatMul_818\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing onnx::MatMul_818 with (Unnamed Layer* 352) [Shuffle]\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.1.output.dense.bias\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.1.output.dense.bias with (Unnamed Layer* 355) [Shuffle]\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.1/output/LayerNorm/Constant_output_0\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.1/output/LayerNorm/Constant_output_0 with (Unnamed Layer* 361) [Shuffle]\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.1/output/LayerNorm/Constant_1_output_0\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.1/output/LayerNorm/Constant_1_output_0 with (Unnamed Layer* 365) [Shuffle]\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.1.output.LayerNorm.weight\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.1.output.LayerNorm.weight with (Unnamed Layer* 370) [Shuffle]\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.1.output.LayerNorm.bias\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.1.output.LayerNorm.bias with (Unnamed Layer* 373) [Shuffle]\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on onnx::MatMul_819\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing onnx::MatMul_819 with (Unnamed Layer* 376) [Shuffle]\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.2.attention.self.query.bias\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.2.attention.self.query.bias with (Unnamed Layer* 379) [Shuffle]\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on onnx::MatMul_820\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing onnx::MatMul_820 with (Unnamed Layer* 382) [Shuffle]\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.2.attention.self.key.bias\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.2.attention.self.key.bias with (Unnamed Layer* 385) [Shuffle]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on onnx::MatMul_823\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing onnx::MatMul_823 with (Unnamed Layer* 400) [Shuffle]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.2.attention.self.value.bias\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.2.attention.self.value.bias with (Unnamed Layer* 403) [Shuffle]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.2/attention/self/Constant_12_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.2/attention/self/Constant_12_output_0 with (Unnamed Layer* 434) [Shuffle]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on onnx::MatMul_829\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing onnx::MatMul_829 with (Unnamed Layer* 466) [Shuffle]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.2.attention.output.dense.bias\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.2.attention.output.dense.bias with (Unnamed Layer* 469) [Shuffle]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.2/attention/output/LayerNorm/Constant_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.2/attention/output/LayerNorm/Constant_output_0 with (Unnamed Layer* 475) [Shuffle]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.2/attention/output/LayerNorm/Constant_1_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.2/attention/output/LayerNorm/Constant_1_output_0 with (Unnamed Layer* 479) [Shuffle]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.2.attention.output.LayerNorm.weight\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.2.attention.output.LayerNorm.weight with (Unnamed Layer* 484) [Shuffle]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.2.attention.output.LayerNorm.bias\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.2.attention.output.LayerNorm.bias with (Unnamed Layer* 487) [Shuffle]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on onnx::MatMul_830\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing onnx::MatMul_830 with (Unnamed Layer* 490) [Shuffle]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.2.intermediate.dense.bias\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.2.intermediate.dense.bias with (Unnamed Layer* 493) [Shuffle]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.2/intermediate/intermediate_act_fn/Constant_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.2/intermediate/intermediate_act_fn/Constant_output_0 with (Unnamed Layer* 496) [Shuffle]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.2/intermediate/intermediate_act_fn/Constant_1_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.2/intermediate/intermediate_act_fn/Constant_1_output_0 with (Unnamed Layer* 500) [Shuffle]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.2/intermediate/intermediate_act_fn/Constant_2_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.2/intermediate/intermediate_act_fn/Constant_2_output_0 with (Unnamed Layer* 504) [Shuffle]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on onnx::MatMul_831\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing onnx::MatMul_831 with (Unnamed Layer* 507) [Shuffle]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.2.output.dense.bias\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.2.output.dense.bias with (Unnamed Layer* 510) [Shuffle]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.2/output/LayerNorm/Constant_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.2/output/LayerNorm/Constant_output_0 with (Unnamed Layer* 516) [Shuffle]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.2/output/LayerNorm/Constant_1_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.2/output/LayerNorm/Constant_1_output_0 with (Unnamed Layer* 520) [Shuffle]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.2.output.LayerNorm.weight\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.2.output.LayerNorm.weight with (Unnamed Layer* 525) [Shuffle]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.2.output.LayerNorm.bias\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.2.output.LayerNorm.bias with (Unnamed Layer* 528) [Shuffle]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on onnx::MatMul_832\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing onnx::MatMul_832 with (Unnamed Layer* 531) [Shuffle]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.3.attention.self.query.bias\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.3.attention.self.query.bias with (Unnamed Layer* 534) [Shuffle]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on onnx::MatMul_833\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing onnx::MatMul_833 with (Unnamed Layer* 537) [Shuffle]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.3.attention.self.key.bias\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.3.attention.self.key.bias with (Unnamed Layer* 540) [Shuffle]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on onnx::MatMul_836\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing onnx::MatMul_836 with (Unnamed Layer* 555) [Shuffle]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.3.attention.self.value.bias\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.3.attention.self.value.bias with (Unnamed Layer* 558) [Shuffle]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.3/attention/self/Constant_12_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.3/attention/self/Constant_12_output_0 with (Unnamed Layer* 589) [Shuffle]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on onnx::MatMul_842\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing onnx::MatMul_842 with (Unnamed Layer* 621) [Shuffle]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.3.attention.output.dense.bias\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.3.attention.output.dense.bias with (Unnamed Layer* 624) [Shuffle]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.3/attention/output/LayerNorm/Constant_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.3/attention/output/LayerNorm/Constant_output_0 with (Unnamed Layer* 630) [Shuffle]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.3/attention/output/LayerNorm/Constant_1_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.3/attention/output/LayerNorm/Constant_1_output_0 with (Unnamed Layer* 634) [Shuffle]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.3.attention.output.LayerNorm.weight\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.3.attention.output.LayerNorm.weight with (Unnamed Layer* 639) [Shuffle]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.3.attention.output.LayerNorm.bias\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.3.attention.output.LayerNorm.bias with (Unnamed Layer* 642) [Shuffle]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on onnx::MatMul_843\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing onnx::MatMul_843 with (Unnamed Layer* 645) [Shuffle]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.3.intermediate.dense.bias\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.3.intermediate.dense.bias with (Unnamed Layer* 648) [Shuffle]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.3/intermediate/intermediate_act_fn/Constant_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.3/intermediate/intermediate_act_fn/Constant_output_0 with (Unnamed Layer* 651) [Shuffle]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.3/intermediate/intermediate_act_fn/Constant_1_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.3/intermediate/intermediate_act_fn/Constant_1_output_0 with (Unnamed Layer* 655) [Shuffle]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.3/intermediate/intermediate_act_fn/Constant_2_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.3/intermediate/intermediate_act_fn/Constant_2_output_0 with (Unnamed Layer* 659) [Shuffle]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on onnx::MatMul_844\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing onnx::MatMul_844 with (Unnamed Layer* 662) [Shuffle]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.3.output.dense.bias\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.3.output.dense.bias with (Unnamed Layer* 665) [Shuffle]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.3/output/LayerNorm/Constant_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.3/output/LayerNorm/Constant_output_0 with (Unnamed Layer* 671) [Shuffle]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.3/output/LayerNorm/Constant_1_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.3/output/LayerNorm/Constant_1_output_0 with (Unnamed Layer* 675) [Shuffle]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.3.output.LayerNorm.weight\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.3.output.LayerNorm.weight with (Unnamed Layer* 680) [Shuffle]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.3.output.LayerNorm.bias\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.3.output.LayerNorm.bias with (Unnamed Layer* 683) [Shuffle]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on onnx::MatMul_845\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing onnx::MatMul_845 with (Unnamed Layer* 686) [Shuffle]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.4.attention.self.query.bias\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.4.attention.self.query.bias with (Unnamed Layer* 689) [Shuffle]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on onnx::MatMul_846\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing onnx::MatMul_846 with (Unnamed Layer* 692) [Shuffle]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.4.attention.self.key.bias\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.4.attention.self.key.bias with (Unnamed Layer* 695) [Shuffle]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on onnx::MatMul_849\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing onnx::MatMul_849 with (Unnamed Layer* 710) [Shuffle]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.4.attention.self.value.bias\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.4.attention.self.value.bias with (Unnamed Layer* 713) [Shuffle]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.4/attention/self/Constant_12_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.4/attention/self/Constant_12_output_0 with (Unnamed Layer* 744) [Shuffle]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on onnx::MatMul_855\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing onnx::MatMul_855 with (Unnamed Layer* 776) [Shuffle]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.4.attention.output.dense.bias\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.4.attention.output.dense.bias with (Unnamed Layer* 779) [Shuffle]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.4/attention/output/LayerNorm/Constant_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.4/attention/output/LayerNorm/Constant_output_0 with (Unnamed Layer* 785) [Shuffle]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.4/attention/output/LayerNorm/Constant_1_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.4/attention/output/LayerNorm/Constant_1_output_0 with (Unnamed Layer* 789) [Shuffle]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.4.attention.output.LayerNorm.weight\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.4.attention.output.LayerNorm.weight with (Unnamed Layer* 794) [Shuffle]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.4.attention.output.LayerNorm.bias\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.4.attention.output.LayerNorm.bias with (Unnamed Layer* 797) [Shuffle]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on onnx::MatMul_856\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing onnx::MatMul_856 with (Unnamed Layer* 800) [Shuffle]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.4.intermediate.dense.bias\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.4.intermediate.dense.bias with (Unnamed Layer* 803) [Shuffle]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.4/intermediate/intermediate_act_fn/Constant_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.4/intermediate/intermediate_act_fn/Constant_output_0 with (Unnamed Layer* 806) [Shuffle]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.4/intermediate/intermediate_act_fn/Constant_1_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.4/intermediate/intermediate_act_fn/Constant_1_output_0 with (Unnamed Layer* 810) [Shuffle]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.4/intermediate/intermediate_act_fn/Constant_2_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.4/intermediate/intermediate_act_fn/Constant_2_output_0 with (Unnamed Layer* 814) [Shuffle]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on onnx::MatMul_857\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing onnx::MatMul_857 with (Unnamed Layer* 817) [Shuffle]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.4.output.dense.bias\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.4.output.dense.bias with (Unnamed Layer* 820) [Shuffle]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.4/output/LayerNorm/Constant_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.4/output/LayerNorm/Constant_output_0 with (Unnamed Layer* 826) [Shuffle]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.4/output/LayerNorm/Constant_1_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.4/output/LayerNorm/Constant_1_output_0 with (Unnamed Layer* 830) [Shuffle]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.4.output.LayerNorm.weight\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.4.output.LayerNorm.weight with (Unnamed Layer* 835) [Shuffle]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.4.output.LayerNorm.bias\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.4.output.LayerNorm.bias with (Unnamed Layer* 838) [Shuffle]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on onnx::MatMul_858\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing onnx::MatMul_858 with (Unnamed Layer* 841) [Shuffle]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.5.attention.self.query.bias\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.5.attention.self.query.bias with (Unnamed Layer* 844) [Shuffle]\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on onnx::MatMul_859\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing onnx::MatMul_859 with (Unnamed Layer* 847) [Shuffle]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.5.attention.self.key.bias\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.5.attention.self.key.bias with (Unnamed Layer* 850) [Shuffle]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on onnx::MatMul_862\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing onnx::MatMul_862 with (Unnamed Layer* 865) [Shuffle]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.5.attention.self.value.bias\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.5.attention.self.value.bias with (Unnamed Layer* 868) [Shuffle]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.5/attention/self/Constant_12_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.5/attention/self/Constant_12_output_0 with (Unnamed Layer* 899) [Shuffle]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ShuffleShuffleFusion on /bert/Unsqueeze\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] ShuffleShuffleFusion: Fusing /bert/Unsqueeze with /bert/Unsqueeze_1\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ShuffleShuffleFusion on /bert/encoder/layer.0/attention/self/Reshape_2\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] ShuffleShuffleFusion: Fusing /bert/encoder/layer.0/attention/self/Reshape_2 with /bert/encoder/layer.0/attention/self/Transpose_1\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ShuffleShuffleFusion on /bert/encoder/layer.0/attention/self/Reshape\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] ShuffleShuffleFusion: Fusing /bert/encoder/layer.0/attention/self/Reshape with /bert/encoder/layer.0/attention/self/Transpose_2\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ShuffleShuffleFusion on /bert/encoder/layer.0/attention/self/Reshape_1\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] ShuffleShuffleFusion: Fusing /bert/encoder/layer.0/attention/self/Reshape_1 with /bert/encoder/layer.0/attention/self/Transpose\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ShuffleShuffleFusion on /bert/encoder/layer.0/attention/self/Transpose_3\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] ShuffleShuffleFusion: Fusing /bert/encoder/layer.0/attention/self/Transpose_3 with /bert/encoder/layer.0/attention/self/Reshape_3\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ShuffleShuffleFusion on /bert/encoder/layer.1/attention/self/Reshape_2\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] ShuffleShuffleFusion: Fusing /bert/encoder/layer.1/attention/self/Reshape_2 with /bert/encoder/layer.1/attention/self/Transpose_1\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ShuffleShuffleFusion on /bert/encoder/layer.1/attention/self/Reshape\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] ShuffleShuffleFusion: Fusing /bert/encoder/layer.1/attention/self/Reshape with /bert/encoder/layer.1/attention/self/Transpose_2\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ShuffleShuffleFusion on /bert/encoder/layer.1/attention/self/Reshape_1\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] ShuffleShuffleFusion: Fusing /bert/encoder/layer.1/attention/self/Reshape_1 with /bert/encoder/layer.1/attention/self/Transpose\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ShuffleShuffleFusion on /bert/encoder/layer.1/attention/self/Transpose_3\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] ShuffleShuffleFusion: Fusing /bert/encoder/layer.1/attention/self/Transpose_3 with /bert/encoder/layer.1/attention/self/Reshape_3\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ShuffleShuffleFusion on /bert/encoder/layer.2/attention/self/Reshape_2\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] ShuffleShuffleFusion: Fusing /bert/encoder/layer.2/attention/self/Reshape_2 with /bert/encoder/layer.2/attention/self/Transpose_1\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ShuffleShuffleFusion on /bert/encoder/layer.2/attention/self/Reshape\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] ShuffleShuffleFusion: Fusing /bert/encoder/layer.2/attention/self/Reshape with /bert/encoder/layer.2/attention/self/Transpose_2\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ShuffleShuffleFusion on /bert/encoder/layer.2/attention/self/Reshape_1\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] ShuffleShuffleFusion: Fusing /bert/encoder/layer.2/attention/self/Reshape_1 with /bert/encoder/layer.2/attention/self/Transpose\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ShuffleShuffleFusion on /bert/encoder/layer.2/attention/self/Transpose_3\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] ShuffleShuffleFusion: Fusing /bert/encoder/layer.2/attention/self/Transpose_3 with /bert/encoder/layer.2/attention/self/Reshape_3\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ShuffleShuffleFusion on /bert/encoder/layer.3/attention/self/Reshape_2\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] ShuffleShuffleFusion: Fusing /bert/encoder/layer.3/attention/self/Reshape_2 with /bert/encoder/layer.3/attention/self/Transpose_1\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ShuffleShuffleFusion on /bert/encoder/layer.3/attention/self/Reshape\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] ShuffleShuffleFusion: Fusing /bert/encoder/layer.3/attention/self/Reshape with /bert/encoder/layer.3/attention/self/Transpose_2\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ShuffleShuffleFusion on /bert/encoder/layer.3/attention/self/Reshape_1\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] ShuffleShuffleFusion: Fusing /bert/encoder/layer.3/attention/self/Reshape_1 with /bert/encoder/layer.3/attention/self/Transpose\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ShuffleShuffleFusion on /bert/encoder/layer.3/attention/self/Transpose_3\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] ShuffleShuffleFusion: Fusing /bert/encoder/layer.3/attention/self/Transpose_3 with /bert/encoder/layer.3/attention/self/Reshape_3\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ShuffleShuffleFusion on /bert/encoder/layer.4/attention/self/Reshape_2\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] ShuffleShuffleFusion: Fusing /bert/encoder/layer.4/attention/self/Reshape_2 with /bert/encoder/layer.4/attention/self/Transpose_1\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ShuffleShuffleFusion on /bert/encoder/layer.4/attention/self/Reshape\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] ShuffleShuffleFusion: Fusing /bert/encoder/layer.4/attention/self/Reshape with /bert/encoder/layer.4/attention/self/Transpose_2\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ShuffleShuffleFusion on /bert/encoder/layer.4/attention/self/Reshape_1\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] ShuffleShuffleFusion: Fusing /bert/encoder/layer.4/attention/self/Reshape_1 with /bert/encoder/layer.4/attention/self/Transpose\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ShuffleShuffleFusion on /bert/encoder/layer.4/attention/self/Transpose_3\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] ShuffleShuffleFusion: Fusing /bert/encoder/layer.4/attention/self/Transpose_3 with /bert/encoder/layer.4/attention/self/Reshape_3\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ShuffleShuffleFusion on /bert/encoder/layer.5/attention/self/Reshape_2\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] ShuffleShuffleFusion: Fusing /bert/encoder/layer.5/attention/self/Reshape_2 with /bert/encoder/layer.5/attention/self/Transpose_1\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ShuffleShuffleFusion on /bert/encoder/layer.5/attention/self/Reshape\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] ShuffleShuffleFusion: Fusing /bert/encoder/layer.5/attention/self/Reshape with /bert/encoder/layer.5/attention/self/Transpose_2\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ShuffleShuffleFusion on /bert/encoder/layer.5/attention/self/Reshape_1\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] ShuffleShuffleFusion: Fusing /bert/encoder/layer.5/attention/self/Reshape_1 with /bert/encoder/layer.5/attention/self/Transpose\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ShuffleShuffleFusion on /bert/encoder/layer.5/attention/self/Transpose_3\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] ShuffleShuffleFusion: Fusing /bert/encoder/layer.5/attention/self/Transpose_3 with /bert/encoder/layer.5/attention/self/Reshape_3\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on onnx::MatMul_868\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing onnx::MatMul_868 with (Unnamed Layer* 931) [Shuffle]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.5.attention.output.dense.bias\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.5.attention.output.dense.bias with (Unnamed Layer* 934) [Shuffle]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.5/attention/output/LayerNorm/Constant_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.5/attention/output/LayerNorm/Constant_output_0 with (Unnamed Layer* 940) [Shuffle]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.5/attention/output/LayerNorm/Constant_1_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.5/attention/output/LayerNorm/Constant_1_output_0 with (Unnamed Layer* 944) [Shuffle]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.5.attention.output.LayerNorm.weight\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.5.attention.output.LayerNorm.weight with (Unnamed Layer* 949) [Shuffle]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.5.attention.output.LayerNorm.bias\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.5.attention.output.LayerNorm.bias with (Unnamed Layer* 952) [Shuffle]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on onnx::MatMul_869\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing onnx::MatMul_869 with (Unnamed Layer* 955) [Shuffle]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.5.intermediate.dense.bias\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.5.intermediate.dense.bias with (Unnamed Layer* 958) [Shuffle]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.5/intermediate/intermediate_act_fn/Constant_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.5/intermediate/intermediate_act_fn/Constant_output_0 with (Unnamed Layer* 961) [Shuffle]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.5/intermediate/intermediate_act_fn/Constant_1_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.5/intermediate/intermediate_act_fn/Constant_1_output_0 with (Unnamed Layer* 965) [Shuffle]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.5/intermediate/intermediate_act_fn/Constant_2_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.5/intermediate/intermediate_act_fn/Constant_2_output_0 with (Unnamed Layer* 969) [Shuffle]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on onnx::MatMul_870\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing onnx::MatMul_870 with (Unnamed Layer* 972) [Shuffle]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.5.output.dense.bias\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.5.output.dense.bias with (Unnamed Layer* 975) [Shuffle]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.5/output/LayerNorm/Constant_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.5/output/LayerNorm/Constant_output_0 with (Unnamed Layer* 981) [Shuffle]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.5/output/LayerNorm/Constant_1_output_0\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.5/output/LayerNorm/Constant_1_output_0 with (Unnamed Layer* 985) [Shuffle]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.5.output.LayerNorm.weight\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.5.output.LayerNorm.weight with (Unnamed Layer* 990) [Shuffle]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.5.output.LayerNorm.bias\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.5.output.LayerNorm.bias with (Unnamed Layer* 993) [Shuffle]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on bert.pooler.dense.bias\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing bert.pooler.dense.bias with (Unnamed Layer* 1000) [Shuffle]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Running: ConstShuffleFusion on classifier.bias\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] ConstShuffleFusion: Fusing classifier.bias with (Unnamed Layer* 1006) [Shuffle]\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Found /bert/encoder/layer.0/attention/self/query/MatMul to be part of self-attention pattern.\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Found /bert/encoder/layer.0/attention/self/key/MatMul to be part of self-attention pattern.\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Found /bert/encoder/layer.0/attention/self/value/MatMul to be part of self-attention pattern.\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Found /bert/encoder/layer.0/attention/self/MatMul to be part of self-attention pattern.\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Found /bert/encoder/layer.0/attention/self/Softmax to be part of self-attention pattern.\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Found /bert/encoder/layer.0/attention/self/MatMul_1 to be part of self-attention pattern.\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Found /bert/encoder/layer.1/attention/self/query/MatMul to be part of self-attention pattern.\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Found /bert/encoder/layer.1/attention/self/key/MatMul to be part of self-attention pattern.\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Found /bert/encoder/layer.1/attention/self/value/MatMul to be part of self-attention pattern.\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Found /bert/encoder/layer.1/attention/self/MatMul to be part of self-attention pattern.\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Found /bert/encoder/layer.1/attention/self/Softmax to be part of self-attention pattern.\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Found /bert/encoder/layer.1/attention/self/MatMul_1 to be part of self-attention pattern.\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Found /bert/encoder/layer.2/attention/self/query/MatMul to be part of self-attention pattern.\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Found /bert/encoder/layer.2/attention/self/key/MatMul to be part of self-attention pattern.\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Found /bert/encoder/layer.2/attention/self/value/MatMul to be part of self-attention pattern.\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Found /bert/encoder/layer.2/attention/self/MatMul to be part of self-attention pattern.\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Found /bert/encoder/layer.2/attention/self/Softmax to be part of self-attention pattern.\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Found /bert/encoder/layer.2/attention/self/MatMul_1 to be part of self-attention pattern.\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Found /bert/encoder/layer.3/attention/self/query/MatMul to be part of self-attention pattern.\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Found /bert/encoder/layer.3/attention/self/key/MatMul to be part of self-attention pattern.\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Found /bert/encoder/layer.3/attention/self/value/MatMul to be part of self-attention pattern.\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Found /bert/encoder/layer.3/attention/self/MatMul to be part of self-attention pattern.\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Found /bert/encoder/layer.3/attention/self/Softmax to be part of self-attention pattern.\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Found /bert/encoder/layer.3/attention/self/MatMul_1 to be part of self-attention pattern.\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Found /bert/encoder/layer.4/attention/self/query/MatMul to be part of self-attention pattern.\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Found /bert/encoder/layer.4/attention/self/key/MatMul to be part of self-attention pattern.\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Found /bert/encoder/layer.4/attention/self/value/MatMul to be part of self-attention pattern.\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Found /bert/encoder/layer.4/attention/self/MatMul to be part of self-attention pattern.\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Found /bert/encoder/layer.4/attention/self/Softmax to be part of self-attention pattern.\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Found /bert/encoder/layer.4/attention/self/MatMul_1 to be part of self-attention pattern.\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Found /bert/encoder/layer.5/attention/self/query/MatMul to be part of self-attention pattern.\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Found /bert/encoder/layer.5/attention/self/key/MatMul to be part of self-attention pattern.\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Found /bert/encoder/layer.5/attention/self/value/MatMul to be part of self-attention pattern.\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Found /bert/encoder/layer.5/attention/self/MatMul to be part of self-attention pattern.\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Found /bert/encoder/layer.5/attention/self/Softmax to be part of self-attention pattern.\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Found /bert/encoder/layer.5/attention/self/MatMul_1 to be part of self-attention pattern.\r\n",
      "[02/02/2023-19:14:20] [V] [TRT] Found and reassigned Myelin backends for Self-Attention nodes\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02/02/2023-19:14:20] [V] [TRT] After Myelin optimization: 1 layers\n",
      "[02/02/2023-19:14:20] [V] [TRT] Applying ScaleNodes fusions.\n",
      "[02/02/2023-19:14:20] [V] [TRT] After scale fusion: 1 layers\n",
      "[02/02/2023-19:14:20] [V] [TRT] After dupe layer removal: 1 layers\n",
      "[02/02/2023-19:14:20] [V] [TRT] After final dead-layer removal: 1 layers\n",
      "[02/02/2023-19:14:20] [V] [TRT] After tensor merging: 1 layers\n",
      "[02/02/2023-19:14:20] [V] [TRT] After vertical fusions: 1 layers\n",
      "[02/02/2023-19:14:20] [V] [TRT] After dupe layer removal: 1 layers\n",
      "[02/02/2023-19:14:20] [V] [TRT] After final dead-layer removal: 1 layers\n",
      "[02/02/2023-19:14:20] [V] [TRT] After tensor merging: 1 layers\n",
      "[02/02/2023-19:14:20] [V] [TRT] After slice removal: 1 layers\n",
      "[02/02/2023-19:14:20] [V] [TRT] After concat removal: 1 layers\n",
      "[02/02/2023-19:14:20] [V] [TRT] Trying to split Reshape and strided tensor\n",
      "[02/02/2023-19:14:20] [V] [TRT] Graph construction and optimization completed in 0.200018 seconds.\n",
      "[02/02/2023-19:14:20] [V] [TRT] Trying to load shared library libcublas.so.11\n",
      "[02/02/2023-19:14:20] [V] [TRT] Loaded shared library libcublas.so.11\n",
      "[02/02/2023-19:14:20] [V] [TRT] Using cublas as plugin tactic source\n",
      "[02/02/2023-19:14:20] [V] [TRT] Trying to load shared library libcublasLt.so.11\n",
      "[02/02/2023-19:14:20] [V] [TRT] Loaded shared library libcublasLt.so.11\n",
      "[02/02/2023-19:14:20] [V] [TRT] Using cublasLt as core library tactic source\n",
      "[02/02/2023-19:14:20] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +6, GPU +10, now: CPU 580, GPU 378 (MiB)\n",
      "[02/02/2023-19:14:20] [V] [TRT] Trying to load shared library libcudnn.so.8\n",
      "[02/02/2023-19:14:20] [V] [TRT] Loaded shared library libcudnn.so.8\n",
      "[02/02/2023-19:14:20] [V] [TRT] Using cuDNN as plugin tactic source\n",
      "[02/02/2023-19:14:20] [V] [TRT] Using cuDNN as core library tactic source\n",
      "[02/02/2023-19:14:20] [I] [TRT] [MemUsageChange] Init cuDNN: CPU +2, GPU +10, now: CPU 582, GPU 388 (MiB)\n",
      "[02/02/2023-19:14:20] [I] [TRT] Local timing cache in use. Profiling results in this builder pass will not be stored.\n",
      "[02/02/2023-19:14:20] [V] [TRT] Constructing optimization profile number 0 [1/1].\n",
      "[02/02/2023-19:14:20] [V] [TRT] Reserving memory for host IO tensors. Host: 0 bytes\n",
      "[02/02/2023-19:14:20] [V] [TRT] =============== Computing reformatting costs: \n",
      "[02/02/2023-19:14:20] [V] [TRT] *************** Autotuning Reformat: Half(6,1) -> Float(6,1) ***************\n",
      "[02/02/2023-19:14:20] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> logits) (Reformat)\n",
      "[02/02/2023-19:14:20] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00658327\n",
      "[02/02/2023-19:14:20] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0148631\n",
      "[02/02/2023-19:14:20] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0119341\n",
      "[02/02/2023-19:14:20] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00658327\n",
      "[02/02/2023-19:14:20] [V] [TRT] =============== Computing costs for \n",
      "[02/02/2023-19:14:20] [V] [TRT] *************** Autotuning format combination:  -> Int32() ***************\n",
      "[02/02/2023-19:14:20] [V] [TRT] --------------- Timing Runner: [HostToDeviceCopy 0] (ShapeHostToDevice)\n",
      "[02/02/2023-19:14:20] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00977219\n",
      "[02/02/2023-19:14:20] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00977219\n",
      "[02/02/2023-19:14:20] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: ShapeHostToDevice Tactic: 0x0000000000000000\n",
      "[02/02/2023-19:14:20] [V] [TRT] =============== Computing costs for \n",
      "[02/02/2023-19:14:20] [V] [TRT] *************** Autotuning format combination: Int32(128,1), Int32(128,1), Int32(128,1), Int32() -> Float(6,1) ***************\n",
      "[02/02/2023-19:14:20] [V] [TRT] --------------- Timing Runner: {ForeignNode[bert.embeddings.position_embeddings.weight...(Unnamed Layer* 1007) [ElementWise]]} (Myelin)\n",
      "[02/02/2023-19:14:24] [V] [TRT]  (foreignNode) Set user's cuda kernel library\n",
      "[02/02/2023-19:14:24] [V] [TRT]  (foreignNode) Pass fuse_conv_padding is currently skipped for dynamic shapes\n",
      "[02/02/2023-19:14:24] [V] [TRT]  (foreignNode) Pass pad_conv_channel is currently skipped for dynamic shapes\n",
      "[02/02/2023-19:14:24] [V] [TRT]  (foreignNode) Pass fuse_conv_padding is currently skipped for dynamic shapes\n",
      "[02/02/2023-19:14:24] [V] [TRT]  (foreignNode) Pass pad_conv_channel is currently skipped for dynamic shapes\n",
      "[02/02/2023-19:14:27] [V] [TRT]  (foreignNode) Set user's cuda kernel library\n",
      "[02/02/2023-19:14:27] [V] [TRT]  (foreignNode) Pass fuse_conv_padding is currently skipped for dynamic shapes\n",
      "[02/02/2023-19:14:27] [V] [TRT]  (foreignNode) Pass pad_conv_channel is currently skipped for dynamic shapes\n",
      "[02/02/2023-19:14:27] [V] [TRT]  (foreignNode) Pass fuse_conv_padding is currently skipped for dynamic shapes\n",
      "[02/02/2023-19:14:27] [V] [TRT]  (foreignNode) Pass pad_conv_channel is currently skipped for dynamic shapes\n",
      "[02/02/2023-19:14:30] [V] [TRT]  (foreignNode) Set user's cuda kernel library\n",
      "[02/02/2023-19:14:30] [V] [TRT]  (foreignNode) Pass fuse_conv_padding is currently skipped for dynamic shapes\n",
      "[02/02/2023-19:14:30] [V] [TRT]  (foreignNode) Pass pad_conv_channel is currently skipped for dynamic shapes\n",
      "[02/02/2023-19:14:30] [V] [TRT]  (foreignNode) Pass fuse_conv_padding is currently skipped for dynamic shapes\n",
      "[02/02/2023-19:14:30] [V] [TRT]  (foreignNode) Pass pad_conv_channel is currently skipped for dynamic shapes\n",
      "[02/02/2023-19:14:33] [V] [TRT]  (foreignNode) Set user's cuda kernel library\n",
      "[02/02/2023-19:14:33] [V] [TRT]  (foreignNode) Pass fuse_conv_padding is currently skipped for dynamic shapes\n",
      "[02/02/2023-19:14:33] [V] [TRT]  (foreignNode) Pass pad_conv_channel is currently skipped for dynamic shapes\n",
      "[02/02/2023-19:14:33] [V] [TRT]  (foreignNode) Pass fuse_conv_padding is currently skipped for dynamic shapes\n",
      "[02/02/2023-19:14:33] [V] [TRT]  (foreignNode) Pass pad_conv_channel is currently skipped for dynamic shapes\n",
      "[02/02/2023-19:14:36] [V] [TRT]  (foreignNode) Set user's cuda kernel library\n",
      "[02/02/2023-19:14:36] [V] [TRT]  (foreignNode) Pass fuse_conv_padding is currently skipped for dynamic shapes\n",
      "[02/02/2023-19:14:36] [V] [TRT]  (foreignNode) Pass pad_conv_channel is currently skipped for dynamic shapes\n",
      "[02/02/2023-19:14:36] [V] [TRT]  (foreignNode) Pass fuse_conv_padding is currently skipped for dynamic shapes\n",
      "[02/02/2023-19:14:36] [V] [TRT]  (foreignNode) Pass pad_conv_channel is currently skipped for dynamic shapes\n",
      "[02/02/2023-19:14:39] [V] [TRT]  (foreignNode) Set user's cuda kernel library\n",
      "[02/02/2023-19:14:39] [V] [TRT]  (foreignNode) Pass fuse_conv_padding is currently skipped for dynamic shapes\n",
      "[02/02/2023-19:14:39] [V] [TRT]  (foreignNode) Pass pad_conv_channel is currently skipped for dynamic shapes\n",
      "[02/02/2023-19:14:39] [V] [TRT]  (foreignNode) Pass fuse_conv_padding is currently skipped for dynamic shapes\n",
      "[02/02/2023-19:14:39] [V] [TRT]  (foreignNode) Pass pad_conv_channel is currently skipped for dynamic shapes\n",
      "[02/02/2023-19:14:42] [V] [TRT]  (foreignNode) Set user's cuda kernel library\n",
      "[02/02/2023-19:14:42] [V] [TRT]  (foreignNode) Pass fuse_conv_padding is currently skipped for dynamic shapes\n",
      "[02/02/2023-19:14:42] [V] [TRT]  (foreignNode) Pass pad_conv_channel is currently skipped for dynamic shapes\n",
      "[02/02/2023-19:14:42] [V] [TRT]  (foreignNode) Pass fuse_conv_padding is currently skipped for dynamic shapes\n",
      "[02/02/2023-19:14:42] [V] [TRT]  (foreignNode) Pass pad_conv_channel is currently skipped for dynamic shapes\n",
      "[02/02/2023-19:14:45] [V] [TRT]  (foreignNode) Set user's cuda kernel library\n",
      "[02/02/2023-19:14:45] [V] [TRT]  (foreignNode) Pass fuse_conv_padding is currently skipped for dynamic shapes\n",
      "[02/02/2023-19:14:45] [V] [TRT]  (foreignNode) Pass pad_conv_channel is currently skipped for dynamic shapes\n",
      "[02/02/2023-19:14:45] [V] [TRT]  (foreignNode) Pass fuse_conv_padding is currently skipped for dynamic shapes\n",
      "[02/02/2023-19:14:45] [V] [TRT]  (foreignNode) Pass pad_conv_channel is currently skipped for dynamic shapes\n",
      "[02/02/2023-19:14:47] [V] [TRT]  (foreignNode) Set user's cuda kernel library\n",
      "[02/02/2023-19:14:47] [V] [TRT]  (foreignNode) Pass fuse_conv_padding is currently skipped for dynamic shapes\n",
      "[02/02/2023-19:14:47] [V] [TRT]  (foreignNode) Pass pad_conv_channel is currently skipped for dynamic shapes\n",
      "[02/02/2023-19:14:47] [V] [TRT]  (foreignNode) Pass fuse_conv_padding is currently skipped for dynamic shapes\n",
      "[02/02/2023-19:14:47] [V] [TRT]  (foreignNode) Pass pad_conv_channel is currently skipped for dynamic shapes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02/02/2023-19:14:49] [V] [TRT]  (foreignNode) Set user's cuda kernel library\n",
      "[02/02/2023-19:14:49] [V] [TRT]  (foreignNode) Pass fuse_conv_padding is currently skipped for dynamic shapes\n",
      "[02/02/2023-19:14:49] [V] [TRT]  (foreignNode) Pass pad_conv_channel is currently skipped for dynamic shapes\n",
      "[02/02/2023-19:14:49] [V] [TRT]  (foreignNode) Pass fuse_conv_padding is currently skipped for dynamic shapes\n",
      "[02/02/2023-19:14:49] [V] [TRT]  (foreignNode) Pass pad_conv_channel is currently skipped for dynamic shapes\n",
      "[02/02/2023-19:14:50] [V] [TRT] Tactic: 0x0000000000000000 Time: 1.92907\n",
      "[02/02/2023-19:14:50] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 1.92907\n",
      "[02/02/2023-19:14:50] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Myelin Tactic: 0x0000000000000000\n",
      "[02/02/2023-19:14:50] [V] [TRT] *************** Autotuning format combination: Int32(128,1), Int32(128,1), Int32(128,1), Int32() -> Half(6,1) ***************\n",
      "[02/02/2023-19:14:50] [V] [TRT] --------------- Timing Runner: {ForeignNode[bert.embeddings.position_embeddings.weight...(Unnamed Layer* 1007) [ElementWise]]} (Myelin)\n",
      "[02/02/2023-19:16:05] [V] [TRT]  (foreignNode) Set user's cuda kernel library\n",
      "[02/02/2023-19:16:05] [V] [TRT]  (foreignNode) Pass fuse_conv_padding is currently skipped for dynamic shapes\n",
      "[02/02/2023-19:16:05] [V] [TRT]  (foreignNode) Pass pad_conv_channel is currently skipped for dynamic shapes\n",
      "[02/02/2023-19:16:05] [V] [TRT]  (foreignNode) Pass fuse_conv_padding is currently skipped for dynamic shapes\n",
      "[02/02/2023-19:16:05] [V] [TRT]  (foreignNode) Pass pad_conv_channel is currently skipped for dynamic shapes\n",
      "[02/02/2023-19:17:07] [V] [TRT]  (foreignNode) Set user's cuda kernel library\n",
      "[02/02/2023-19:17:07] [V] [TRT]  (foreignNode) Pass fuse_conv_padding is currently skipped for dynamic shapes\n",
      "[02/02/2023-19:17:07] [V] [TRT]  (foreignNode) Pass pad_conv_channel is currently skipped for dynamic shapes\n",
      "[02/02/2023-19:17:07] [V] [TRT]  (foreignNode) Pass fuse_conv_padding is currently skipped for dynamic shapes\n",
      "[02/02/2023-19:17:07] [V] [TRT]  (foreignNode) Pass pad_conv_channel is currently skipped for dynamic shapes\n",
      "[02/02/2023-19:18:16] [V] [TRT]  (foreignNode) Set user's cuda kernel library\n",
      "[02/02/2023-19:18:16] [V] [TRT]  (foreignNode) Pass fuse_conv_padding is currently skipped for dynamic shapes\n",
      "[02/02/2023-19:18:16] [V] [TRT]  (foreignNode) Pass pad_conv_channel is currently skipped for dynamic shapes\n",
      "[02/02/2023-19:18:16] [V] [TRT]  (foreignNode) Pass fuse_conv_padding is currently skipped for dynamic shapes\n",
      "[02/02/2023-19:18:16] [V] [TRT]  (foreignNode) Pass pad_conv_channel is currently skipped for dynamic shapes\n",
      "[02/02/2023-19:19:15] [V] [TRT]  (foreignNode) Set user's cuda kernel library\n",
      "[02/02/2023-19:19:15] [V] [TRT]  (foreignNode) Pass fuse_conv_padding is currently skipped for dynamic shapes\n",
      "[02/02/2023-19:19:15] [V] [TRT]  (foreignNode) Pass pad_conv_channel is currently skipped for dynamic shapes\n",
      "[02/02/2023-19:19:15] [V] [TRT]  (foreignNode) Pass fuse_conv_padding is currently skipped for dynamic shapes\n",
      "[02/02/2023-19:19:15] [V] [TRT]  (foreignNode) Pass pad_conv_channel is currently skipped for dynamic shapes\n",
      "[02/02/2023-19:20:16] [V] [TRT]  (foreignNode) Set user's cuda kernel library\n",
      "[02/02/2023-19:20:16] [V] [TRT]  (foreignNode) Pass fuse_conv_padding is currently skipped for dynamic shapes\n",
      "[02/02/2023-19:20:16] [V] [TRT]  (foreignNode) Pass pad_conv_channel is currently skipped for dynamic shapes\n",
      "[02/02/2023-19:20:16] [V] [TRT]  (foreignNode) Pass fuse_conv_padding is currently skipped for dynamic shapes\n",
      "[02/02/2023-19:20:16] [V] [TRT]  (foreignNode) Pass pad_conv_channel is currently skipped for dynamic shapes\n",
      "[02/02/2023-19:21:18] [V] [TRT]  (foreignNode) Set user's cuda kernel library\n",
      "[02/02/2023-19:21:18] [V] [TRT]  (foreignNode) Pass fuse_conv_padding is currently skipped for dynamic shapes\n",
      "[02/02/2023-19:21:18] [V] [TRT]  (foreignNode) Pass pad_conv_channel is currently skipped for dynamic shapes\n",
      "[02/02/2023-19:21:18] [V] [TRT]  (foreignNode) Pass fuse_conv_padding is currently skipped for dynamic shapes\n",
      "[02/02/2023-19:21:18] [V] [TRT]  (foreignNode) Pass pad_conv_channel is currently skipped for dynamic shapes\n",
      "[02/02/2023-19:22:15] [V] [TRT]  (foreignNode) Set user's cuda kernel library\n",
      "[02/02/2023-19:22:15] [V] [TRT]  (foreignNode) Pass fuse_conv_padding is currently skipped for dynamic shapes\n",
      "[02/02/2023-19:22:15] [V] [TRT]  (foreignNode) Pass pad_conv_channel is currently skipped for dynamic shapes\n",
      "[02/02/2023-19:22:15] [V] [TRT]  (foreignNode) Pass fuse_conv_padding is currently skipped for dynamic shapes\n",
      "[02/02/2023-19:22:15] [V] [TRT]  (foreignNode) Pass pad_conv_channel is currently skipped for dynamic shapes\n",
      "[02/02/2023-19:23:12] [V] [TRT]  (foreignNode) Set user's cuda kernel library\n",
      "[02/02/2023-19:23:12] [V] [TRT]  (foreignNode) Pass fuse_conv_padding is currently skipped for dynamic shapes\n",
      "[02/02/2023-19:23:12] [V] [TRT]  (foreignNode) Pass pad_conv_channel is currently skipped for dynamic shapes\n",
      "[02/02/2023-19:23:12] [V] [TRT]  (foreignNode) Pass fuse_conv_padding is currently skipped for dynamic shapes\n",
      "[02/02/2023-19:23:12] [V] [TRT]  (foreignNode) Pass pad_conv_channel is currently skipped for dynamic shapes\n",
      "[02/02/2023-19:24:07] [V] [TRT]  (foreignNode) Set user's cuda kernel library\n",
      "[02/02/2023-19:24:07] [V] [TRT]  (foreignNode) Pass fuse_conv_padding is currently skipped for dynamic shapes\n",
      "[02/02/2023-19:24:07] [V] [TRT]  (foreignNode) Pass pad_conv_channel is currently skipped for dynamic shapes\n",
      "[02/02/2023-19:24:07] [V] [TRT]  (foreignNode) Pass fuse_conv_padding is currently skipped for dynamic shapes\n",
      "[02/02/2023-19:24:07] [V] [TRT]  (foreignNode) Pass pad_conv_channel is currently skipped for dynamic shapes\n",
      "[02/02/2023-19:24:22] [V] [TRT]  (foreignNode) Set user's cuda kernel library\n",
      "[02/02/2023-19:24:22] [V] [TRT]  (foreignNode) Pass fuse_conv_padding is currently skipped for dynamic shapes\n",
      "[02/02/2023-19:24:22] [V] [TRT]  (foreignNode) Pass pad_conv_channel is currently skipped for dynamic shapes\n",
      "[02/02/2023-19:24:22] [V] [TRT]  (foreignNode) Pass fuse_conv_padding is currently skipped for dynamic shapes\n",
      "[02/02/2023-19:24:22] [V] [TRT]  (foreignNode) Pass pad_conv_channel is currently skipped for dynamic shapes\n",
      "[02/02/2023-19:24:24] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.861335\n",
      "[02/02/2023-19:24:24] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.861335\n",
      "[02/02/2023-19:24:24] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Myelin Tactic: 0x0000000000000000\n",
      "[02/02/2023-19:24:24] [V] [TRT] Adding reformat layer: Reformatted Output Tensor 0 to {ForeignNode[bert.embeddings.position_embeddings.weight...(Unnamed Layer* 1007) [ElementWise]]} (logits) from Half(6,1) to Float(6,1)\n",
      "[02/02/2023-19:24:24] [V] [TRT] Formats and tactics selection completed in 603.925 seconds.\n",
      "[02/02/2023-19:24:24] [V] [TRT] After reformat layers: 3 layers\n",
      "[02/02/2023-19:24:24] [V] [TRT] Total number of blocks in pre-optimized block assignment: 3\n",
      "[02/02/2023-19:24:24] [I] [TRT] Total Activation Memory: 14680067584\n",
      "[02/02/2023-19:24:24] [I] [TRT] Detected 3 inputs and 1 output network tensors.\n",
      "[02/02/2023-19:24:25] [V] [TRT] Layer: [HostToDeviceCopy 0] Host Persistent: 4 Device Persistent: 0 Scratch Memory: 0\n",
      "[02/02/2023-19:24:25] [V] [TRT] Layer: {ForeignNode[bert.embeddings.position_embeddings.weight...(Unnamed Layer* 1007) [ElementWise]]} Host Persistent: 240 Device Persistent: 0 Scratch Memory: 191242240\n",
      "[02/02/2023-19:24:25] [V] [TRT] Skipped printing memory information for 1 layers with 0 memory size i.e. Host Persistent + Device Persistent + Scratch Memory == 0.\n",
      "[02/02/2023-19:24:25] [I] [TRT] Total Host Persistent Memory: 256\n",
      "[02/02/2023-19:24:25] [I] [TRT] Total Device Persistent Memory: 0\n",
      "[02/02/2023-19:24:25] [I] [TRT] Total Scratch Memory: 191242240\n",
      "[02/02/2023-19:24:25] [I] [TRT] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 24 MiB, GPU 526 MiB\n",
      "[02/02/2023-19:24:25] [I] [TRT] [BlockAssignment] Started assigning block shifts. This will take 3 steps to complete.\n",
      "[02/02/2023-19:24:25] [I] [TRT] [BlockAssignment] Algorithm ShiftNTopDown took 0.048061ms to assign 3 blocks to 3 nodes requiring 191245824 bytes.\n",
      "[02/02/2023-19:24:25] [V] [TRT] Total number of blocks in optimized block assignment: 3\n",
      "[02/02/2023-19:24:25] [I] [TRT] Total Activation Memory: 191245824\n",
      "[02/02/2023-19:24:25] [V] [TRT] Total number of generated kernels selected for the engine: 0\n",
      "[02/02/2023-19:24:25] [V] [TRT] Disabling unused tactic source: CUDNN\n",
      "[02/02/2023-19:24:25] [V] [TRT] Disabling unused tactic source: CUBLAS, CUBLAS_LT\n",
      "[02/02/2023-19:24:25] [V] [TRT] Disabling unused tactic source: EDGE_MASK_CONVOLUTIONS\n",
      "[02/02/2023-19:24:25] [V] [TRT] Disabling unused tactic source: JIT_CONVOLUTIONS\n",
      "[[02/02/2023-19:24:25] [V] [TRT] Engine generation completed in 605.485 seconds.\n",
      "02/02/2023-19:24:25] [W] [TRT] TensorRT encountered issues when converting weights between types and that could affect accuracy.\n",
      "[02/02/2023-19:24:25] [W] [TRT] If this is not the desired behavior, please modify the weights or retrain with regularization to adjust the magnitude of the weights.\n",
      "[02/02/2023-19:24:25] [W] [TRT] Check verbose logs for the list of affected weights.\n",
      "[02/02/2023-19:24:25] [W] [TRT] - 59 weights are affected by this issue: Detected subnormal FP16 values.\n",
      "[02/02/2023-19:24:25] [V] [TRT]   List of affected weights: bert_embeddings_position_embeddings_weight_constant, bert_embeddings_token_type_embeddings_weight_constant, bert_embeddings_word_embeddings_weight_constant, bert_encoder_layer_0_attention_self_key_bias _ (Unnamed Layer_ 75) [Shuffle]_constant, bert_encoder_layer_1_attention_self_value_bias _ (Unnamed Layer_ 248) [Shuffle]_constant, bert_encoder_layer_1_intermediate_dense_bias _ (Unnamed Layer_ 338) [Shuffle]_constant, bert_encoder_layer_1_output_dense_bias _ (Unnamed Layer_ 355) [Shuffle]_constant, bert_encoder_layer_2_attention_self_key_bias _ (Unnamed Layer_ 385) [Shuffle]_constant, bert_encoder_layer_2_attention_self_value_bias _ (Unnamed Layer_ 403) [Shuffle]_constant, bert_encoder_layer_2_intermediate_dense_bias _ (Unnamed Layer_ 493) [Shuffle]_constant, bert_encoder_layer_3_attention_self_key_bias _ (Unnamed Layer_ 540) [Shuffle]_constant, bert_encoder_layer_4_attention_self_value_bias _ (Unnamed Layer_ 713) [Shuffle]_constant, bert_encoder_layer_4_intermediate_dense_bias _ (Unnamed Layer_ 803) [Shuffle]_constant, bert_encoder_layer_5_attention_output_LayerNorm_bias _ (Unnamed Layer_ 952) [Shuffle]_constant, bert_encoder_layer_5_attention_output_dense_bias _ (Unnamed Layer_ 934) [Shuffle]_constant, bert_encoder_layer_5_attention_self_key_bias _ (Unnamed Layer_ 850) [Shuffle]_constant, bert_encoder_layer_5_intermediate_dense_bias _ (Unnamed Layer_ 958) [Shuffle]_constant, bert_encoder_layer_5_output_LayerNorm_bias _ (Unnamed Layer_ 993) [Shuffle]_constant, bert_encoder_layer_5_output_dense_bias _ (Unnamed Layer_ 975) [Shuffle]_constant, bert_pooler_dense_bias _ (Unnamed Layer_ 1000) [Shuffle]_constant, bert_pooler_dense_weight_constant, classifier_bias _ (Unnamed Layer_ 1006) [Shuffle]_constant, classifier_weight_constant, onnx__MatMul_793 _ (Unnamed Layer_ 66) [Shuffle]_constant, onnx__MatMul_794 _ (Unnamed Layer_ 72) [Shuffle]_constant, onnx__MatMul_797 _ (Unnamed Layer_ 90) [Shuffle]_constant, onnx__MatMul_803 _ (Unnamed Layer_ 156) [Shuffle]_constant, onnx__MatMul_804 _ (Unnamed Layer_ 180) [Shuffle]_constant, onnx__MatMul_805 _ (Unnamed Layer_ 197) [Shuffle]_constant, onnx__MatMul_806 _ (Unnamed Layer_ 221) [Shuffle]_constant, onnx__MatMul_807 _ (Unnamed Layer_ 227) [Shuffle]_constant, onnx__MatMul_810 _ (Unnamed Layer_ 245) [Shuffle]_constant, onnx__MatMul_816 _ (Unnamed Layer_ 311) [Shuffle]_constant, onnx__MatMul_817 _ (Unnamed Layer_ 335) [Shuffle]_constant, onnx__MatMul_818 _ (Unnamed Layer_ 352) [Shuffle]_constant, onnx__MatMul_819 _ (Unnamed Layer_ 376) [Shuffle]_constant, onnx__MatMul_820 _ (Unnamed Layer_ 382) [Shuffle]_constant, onnx__MatMul_823 _ (Unnamed Layer_ 400) [Shuffle]_constant, onnx__MatMul_829 _ (Unnamed Layer_ 466) [Shuffle]_constant, onnx__MatMul_830 _ (Unnamed Layer_ 490) [Shuffle]_constant, onnx__MatMul_831 _ (Unnamed Layer_ 507) [Shuffle]_constant, onnx__MatMul_832 _ (Unnamed Layer_ 531) [Shuffle]_constant, onnx__MatMul_833 _ (Unnamed Layer_ 537) [Shuffle]_constant, onnx__MatMul_836 _ (Unnamed Layer_ 555) [Shuffle]_constant, onnx__MatMul_842 _ (Unnamed Layer_ 621) [Shuffle]_constant, onnx__MatMul_843 _ (Unnamed Layer_ 645) [Shuffle]_constant, onnx__MatMul_844 _ (Unnamed Layer_ 662) [Shuffle]_constant, onnx__MatMul_845 _ (Unnamed Layer_ 686) [Shuffle]_constant, onnx__MatMul_846 _ (Unnamed Layer_ 692) [Shuffle]_constant, onnx__MatMul_849 _ (Unnamed Layer_ 710) [Shuffle]_constant, onnx__MatMul_855 _ (Unnamed Layer_ 776) [Shuffle]_constant, onnx__MatMul_856 _ (Unnamed Layer_ 800) [Shuffle]_constant, onnx__MatMul_857 _ (Unnamed Layer_ 817) [Shuffle]_constant, onnx__MatMul_858 _ (Unnamed Layer_ 841) [Shuffle]_constant, onnx__MatMul_859 _ (Unnamed Layer_ 847) [Shuffle]_constant, onnx__MatMul_862 _ (Unnamed Layer_ 865) [Shuffle]_constant, onnx__MatMul_868 _ (Unnamed Layer_ 931) [Shuffle]_constant, onnx__MatMul_869 _ (Unnamed Layer_ 955) [Shuffle]_constant, onnx__MatMul_870 _ (Unnamed Layer_ 972) [Shuffle]_constant\n",
      "[02/02/2023-19:24:25] [W] [TRT] - 18 weights are affected by this issue: Detected values less than smallest positive FP16 subnormal value and converted them to the FP16 minimum subnormalized value.\n",
      "[02/02/2023-19:24:25] [V] [TRT]   List of affected weights: /bert/embeddings/LayerNorm/Constant_1_output_0 + (Unnamed Layer* 55) [Shuffle], /bert/encoder/layer.0/attention/output/LayerNorm/Constant_1_output_0 + (Unnamed Layer* 169) [Shuffle], /bert/encoder/layer.0/output/LayerNorm/Constant_1_output_0 + (Unnamed Layer* 210) [Shuffle], /bert/encoder/layer.1/attention/output/LayerNorm/Constant_1_output_0 + (Unnamed Layer* 324) [Shuffle], /bert/encoder/layer.1/output/LayerNorm/Constant_1_output_0 + (Unnamed Layer* 365) [Shuffle], /bert/encoder/layer.2/attention/output/LayerNorm/Constant_1_output_0 + (Unnamed Layer* 479) [Shuffle], /bert/encoder/layer.2/output/LayerNorm/Constant_1_output_0 + (Unnamed Layer* 520) [Shuffle], /bert/encoder/layer.3/attention/output/LayerNorm/Constant_1_output_0 + (Unnamed Layer* 634) [Shuffle], /bert/encoder/layer.3/output/LayerNorm/Constant_1_output_0 + (Unnamed Layer* 675) [Shuffle], /bert/encoder/layer.4/attention/output/LayerNorm/Constant_1_output_0 + (Unnamed Layer* 789) [Shuffle], /bert/encoder/layer.4/output/LayerNorm/Constant_1_output_0 + (Unnamed Layer* 830) [Shuffle], /bert/encoder/layer.5/attention/output/LayerNorm/Constant_1_output_0 + (Unnamed Layer* 944) [Shuffle], /bert/encoder/layer.5/output/LayerNorm/Constant_1_output_0 + (Unnamed Layer* 985) [Shuffle], bert_embeddings_word_embeddings_weight_constant, onnx__MatMul_830 _ (Unnamed Layer_ 490) [Shuffle]_constant, onnx__MatMul_845 _ (Unnamed Layer_ 686) [Shuffle]_constant, onnx__MatMul_869 _ (Unnamed Layer_ 955) [Shuffle]_constant, onnx__MatMul_870 _ (Unnamed Layer_ 972) [Shuffle]_constant\n",
      "[02/02/2023-19:24:25] [W] [TRT] - 1 weights are affected by this issue: Detected finite FP32 values which would overflow in FP16 and converted them to the closest finite FP16 value.\n",
      "[02/02/2023-19:24:25] [V] [TRT]   List of affected weights: /bert/Constant_2_output_0 + (Unnamed Layer* 17) [Shuffle]\n",
      "[02/02/2023-19:24:25] [V] [TRT] Deleting timing cache: 1 entries, served 0 hits since creation.\n",
      "[02/02/2023-19:24:25] [V] [TRT] Engine Layer Information:\n",
      "Layer(ShapeHostToDevice): [HostToDeviceCopy 0], Tactic: 0x0000000000000000,  -> token_type_ids[implicit padding mask tensor 0] (Int32[])\n",
      "Layer(Myelin): {ForeignNode[bert.embeddings.position_embeddings.weight...(Unnamed Layer* 1007) [ElementWise]]}, Tactic: 0x0000000000000000, token_type_ids (Int32[-1,128]), input_ids (Int32[-1,128]), attention_mask (Int32[-1,128]), token_type_ids[implicit padding mask tensor 0] (Int32[]) -> Reformatted Output Tensor 0 to {ForeignNode[bert.embeddings.position_embeddings.weight...(Unnamed Layer* 1007) [ElementWise]]} (Half[-1,6])\n",
      "Layer(Reformat): Reformatting CopyNode for Output Tensor 0 to {ForeignNode[bert.embeddings.position_embeddings.weight...(Unnamed Layer* 1007) [ElementWise]]}, Tactic: 0x00000000000003e8, Reformatted Output Tensor 0 to {ForeignNode[bert.embeddings.position_embeddings.weight...(Unnamed Layer* 1007) [ElementWise]]} (Half[-1,6]) -> logits (Float[-1,6])\n",
      "[02/02/2023-19:24:25] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in building engine: CPU +24, GPU +32, now: CPU 24, GPU 32 (MiB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02/02/2023-19:24:25] [I] Engine built in 609.625 sec.\n",
      "[02/02/2023-19:24:26] [I] [TRT] Loaded engine size: 37 MiB\n",
      "[02/02/2023-19:24:26] [V] [TRT] Deserialization required 12208 microseconds.\n",
      "[02/02/2023-19:24:26] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in engine deserialization: CPU +0, GPU +28, now: CPU 0, GPU 28 (MiB)\n",
      "[02/02/2023-19:24:26] [I] Engine deserialized in 0.0125832 sec.\n",
      "[02/02/2023-19:24:26] [V] [TRT] Total per-runner device persistent memory is 0\n",
      "[02/02/2023-19:24:26] [V] [TRT] Total per-runner host persistent memory is 256\n",
      "[02/02/2023-19:24:26] [V] [TRT] Allocated activation device memory of size 191245824\n",
      "[02/02/2023-19:24:26] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +182, now: CPU 0, GPU 210 (MiB)\n",
      "[02/02/2023-19:24:26] [V] [TRT] CUDA lazy loading is enabled.\n",
      "[02/02/2023-19:24:26] [I] Setting persistentCacheLimit to 0 bytes.\n",
      "[02/02/2023-19:24:26] [V] Using enqueueV3.\n",
      "[02/02/2023-19:24:26] [I] Using random values for input input_ids\n",
      "[02/02/2023-19:24:26] [I] Created input binding for input_ids with dimensions 16x128\n",
      "[02/02/2023-19:24:26] [I] Using random values for input attention_mask\n",
      "[02/02/2023-19:24:26] [I] Created input binding for attention_mask with dimensions 16x128\n",
      "[02/02/2023-19:24:26] [I] Using random values for input token_type_ids\n",
      "[02/02/2023-19:24:26] [I] Created input binding for token_type_ids with dimensions 16x128\n",
      "[02/02/2023-19:24:26] [I] Using random values for output logits\n",
      "[02/02/2023-19:24:26] [I] Created output binding for logits with dimensions 16x6\n",
      "[02/02/2023-19:24:26] [I] Starting inference\n",
      "[02/02/2023-19:24:29] [I] Warmup completed 221 queries over 200 ms\n",
      "[02/02/2023-19:24:29] [I] Timing trace has 3325 queries over 3.00223 s\n",
      "[02/02/2023-19:24:29] [I] \n",
      "[02/02/2023-19:24:29] [I] === Trace details ===\n",
      "[02/02/2023-19:24:29] [I] Trace averages of 10 runs:\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.856989 ms - Host latency: 0.871431 ms (enqueue 0.85986 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.855656 ms - Host latency: 0.870395 ms (enqueue 0.859499 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.856567 ms - Host latency: 0.870807 ms (enqueue 0.860416 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.854942 ms - Host latency: 0.869141 ms (enqueue 0.8586 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.857886 ms - Host latency: 0.872307 ms (enqueue 0.861707 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.85555 ms - Host latency: 0.870912 ms (enqueue 0.860251 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.854637 ms - Host latency: 0.8687 ms (enqueue 0.858516 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.854819 ms - Host latency: 0.868939 ms (enqueue 0.858441 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.855975 ms - Host latency: 0.870166 ms (enqueue 0.85834 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.856982 ms - Host latency: 0.871289 ms (enqueue 0.860272 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.855966 ms - Host latency: 0.870364 ms (enqueue 0.86004 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.856076 ms - Host latency: 0.870496 ms (enqueue 0.860025 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.856363 ms - Host latency: 0.870938 ms (enqueue 0.860349 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.856677 ms - Host latency: 0.872202 ms (enqueue 0.859442 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.855661 ms - Host latency: 0.869714 ms (enqueue 0.859573 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.85672 ms - Host latency: 0.871841 ms (enqueue 0.860794 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.855133 ms - Host latency: 0.869205 ms (enqueue 0.85889 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.855539 ms - Host latency: 0.869583 ms (enqueue 0.859564 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.856937 ms - Host latency: 0.871036 ms (enqueue 0.860999 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.855255 ms - Host latency: 0.869366 ms (enqueue 0.859372 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.857364 ms - Host latency: 0.871668 ms (enqueue 0.861652 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.85921 ms - Host latency: 0.873868 ms (enqueue 0.862549 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.856372 ms - Host latency: 0.870523 ms (enqueue 0.860193 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.856982 ms - Host latency: 0.871188 ms (enqueue 0.861124 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.855753 ms - Host latency: 0.870007 ms (enqueue 0.859921 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.855438 ms - Host latency: 0.869556 ms (enqueue 0.859164 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.857391 ms - Host latency: 0.871823 ms (enqueue 0.861523 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.856567 ms - Host latency: 0.871005 ms (enqueue 0.860568 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.856256 ms - Host latency: 0.870605 ms (enqueue 0.860254 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.857086 ms - Host latency: 0.871207 ms (enqueue 0.860895 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.854703 ms - Host latency: 0.86987 ms (enqueue 0.859344 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.856174 ms - Host latency: 0.870248 ms (enqueue 0.860239 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.857974 ms - Host latency: 0.872302 ms (enqueue 0.86167 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.854938 ms - Host latency: 0.869138 ms (enqueue 0.859033 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.856284 ms - Host latency: 0.87066 ms (enqueue 0.860416 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.856262 ms - Host latency: 0.870496 ms (enqueue 0.859955 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.854944 ms - Host latency: 0.869098 ms (enqueue 0.85885 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.856165 ms - Host latency: 0.870599 ms (enqueue 0.859973 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.858325 ms - Host latency: 0.872736 ms (enqueue 0.862164 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.862244 ms - Host latency: 0.877209 ms (enqueue 0.865576 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.859729 ms - Host latency: 0.874573 ms (enqueue 0.862164 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.861957 ms - Host latency: 0.876855 ms (enqueue 0.865924 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.859021 ms - Host latency: 0.873749 ms (enqueue 0.863318 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.862903 ms - Host latency: 0.877509 ms (enqueue 0.865997 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.85708 ms - Host latency: 0.871167 ms (enqueue 0.860992 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.858185 ms - Host latency: 0.874091 ms (enqueue 0.861768 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.85946 ms - Host latency: 0.873523 ms (enqueue 0.863104 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.857477 ms - Host latency: 0.871405 ms (enqueue 0.860468 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.855719 ms - Host latency: 0.869934 ms (enqueue 0.859467 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.8573 ms - Host latency: 0.871411 ms (enqueue 0.86142 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.856268 ms - Host latency: 0.870551 ms (enqueue 0.860229 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.85462 ms - Host latency: 0.868555 ms (enqueue 0.85849 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.854962 ms - Host latency: 0.86972 ms (enqueue 0.858948 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.856281 ms - Host latency: 0.871472 ms (enqueue 0.859241 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.856982 ms - Host latency: 0.87121 ms (enqueue 0.860669 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.855615 ms - Host latency: 0.870032 ms (enqueue 0.859454 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.857629 ms - Host latency: 0.871698 ms (enqueue 0.861761 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.856879 ms - Host latency: 0.87102 ms (enqueue 0.860638 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.855334 ms - Host latency: 0.869482 ms (enqueue 0.859125 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.855768 ms - Host latency: 0.869965 ms (enqueue 0.859607 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.857666 ms - Host latency: 0.872235 ms (enqueue 0.861493 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.85545 ms - Host latency: 0.870917 ms (enqueue 0.859949 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.856165 ms - Host latency: 0.870331 ms (enqueue 0.860132 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.856592 ms - Host latency: 0.870941 ms (enqueue 0.859631 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.857953 ms - Host latency: 0.87204 ms (enqueue 0.862048 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.855316 ms - Host latency: 0.869391 ms (enqueue 0.859497 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.857611 ms - Host latency: 0.871887 ms (enqueue 0.861768 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.858649 ms - Host latency: 0.875073 ms (enqueue 0.861572 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.856488 ms - Host latency: 0.870825 ms (enqueue 0.860535 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.855121 ms - Host latency: 0.869312 ms (enqueue 0.858649 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.85556 ms - Host latency: 0.869745 ms (enqueue 0.859692 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.860986 ms - Host latency: 0.875903 ms (enqueue 0.864282 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.858417 ms - Host latency: 0.873187 ms (enqueue 0.861188 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.857458 ms - Host latency: 0.871857 ms (enqueue 0.861639 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.855048 ms - Host latency: 0.869244 ms (enqueue 0.858942 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.857825 ms - Host latency: 0.872357 ms (enqueue 0.861981 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.856586 ms - Host latency: 0.870544 ms (enqueue 0.860657 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.86167 ms - Host latency: 0.876514 ms (enqueue 0.865283 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.859528 ms - Host latency: 0.873914 ms (enqueue 0.862872 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.857495 ms - Host latency: 0.872064 ms (enqueue 0.86131 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.856165 ms - Host latency: 0.870831 ms (enqueue 0.859375 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.857562 ms - Host latency: 0.871478 ms (enqueue 0.861468 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.856171 ms - Host latency: 0.870154 ms (enqueue 0.859631 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.86012 ms - Host latency: 0.874548 ms (enqueue 0.864685 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.863104 ms - Host latency: 0.880096 ms (enqueue 0.865576 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.858813 ms - Host latency: 0.873096 ms (enqueue 0.863202 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.858502 ms - Host latency: 0.872681 ms (enqueue 0.863049 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.86236 ms - Host latency: 0.87688 ms (enqueue 0.866803 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.857898 ms - Host latency: 0.872235 ms (enqueue 0.862299 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.860718 ms - Host latency: 0.875159 ms (enqueue 0.865027 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.862567 ms - Host latency: 0.877283 ms (enqueue 0.867023 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.860748 ms - Host latency: 0.875067 ms (enqueue 0.864117 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.858496 ms - Host latency: 0.872986 ms (enqueue 0.863196 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.859802 ms - Host latency: 0.874133 ms (enqueue 0.864111 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.85791 ms - Host latency: 0.872583 ms (enqueue 0.862122 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.855579 ms - Host latency: 0.870032 ms (enqueue 0.859338 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.856458 ms - Host latency: 0.870654 ms (enqueue 0.860266 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.854529 ms - Host latency: 0.868689 ms (enqueue 0.858667 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.856482 ms - Host latency: 0.870801 ms (enqueue 0.860571 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.859668 ms - Host latency: 0.874487 ms (enqueue 0.863525 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.860657 ms - Host latency: 0.875134 ms (enqueue 0.864038 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.862866 ms - Host latency: 0.877881 ms (enqueue 0.866284 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.859448 ms - Host latency: 0.87417 ms (enqueue 0.863843 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.861877 ms - Host latency: 0.876294 ms (enqueue 0.866284 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.86167 ms - Host latency: 0.87655 ms (enqueue 0.865723 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.86665 ms - Host latency: 0.882288 ms (enqueue 0.869275 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.860266 ms - Host latency: 0.874768 ms (enqueue 0.864697 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.85918 ms - Host latency: 0.873682 ms (enqueue 0.863623 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.859045 ms - Host latency: 0.873523 ms (enqueue 0.863672 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.859314 ms - Host latency: 0.874084 ms (enqueue 0.863794 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.863672 ms - Host latency: 0.87832 ms (enqueue 0.867908 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.862122 ms - Host latency: 0.876746 ms (enqueue 0.865869 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.865771 ms - Host latency: 0.881055 ms (enqueue 0.869873 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.861682 ms - Host latency: 0.876343 ms (enqueue 0.865234 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.85929 ms - Host latency: 0.873523 ms (enqueue 0.863391 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.859985 ms - Host latency: 0.874072 ms (enqueue 0.864197 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.858337 ms - Host latency: 0.872449 ms (enqueue 0.862732 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.859436 ms - Host latency: 0.873511 ms (enqueue 0.863928 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.860095 ms - Host latency: 0.874853 ms (enqueue 0.864441 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.861536 ms - Host latency: 0.876648 ms (enqueue 0.86521 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.859937 ms - Host latency: 0.87428 ms (enqueue 0.863757 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.860474 ms - Host latency: 0.875024 ms (enqueue 0.864587 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.861963 ms - Host latency: 0.87655 ms (enqueue 0.865283 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.862903 ms - Host latency: 0.878308 ms (enqueue 0.866663 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.858325 ms - Host latency: 0.872668 ms (enqueue 0.862634 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.861401 ms - Host latency: 0.875806 ms (enqueue 0.865149 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.859839 ms - Host latency: 0.874231 ms (enqueue 0.864038 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.858203 ms - Host latency: 0.872656 ms (enqueue 0.862537 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.858118 ms - Host latency: 0.872729 ms (enqueue 0.862793 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.862207 ms - Host latency: 0.876807 ms (enqueue 0.866699 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.861243 ms - Host latency: 0.875928 ms (enqueue 0.865552 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.858813 ms - Host latency: 0.873206 ms (enqueue 0.863391 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.863074 ms - Host latency: 0.877661 ms (enqueue 0.867297 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.863098 ms - Host latency: 0.877917 ms (enqueue 0.866968 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.866248 ms - Host latency: 0.881006 ms (enqueue 0.869861 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.858826 ms - Host latency: 0.873291 ms (enqueue 0.863062 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.860522 ms - Host latency: 0.875012 ms (enqueue 0.864941 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.859619 ms - Host latency: 0.874048 ms (enqueue 0.86405 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.862707 ms - Host latency: 0.877356 ms (enqueue 0.865759 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.855029 ms - Host latency: 0.869275 ms (enqueue 0.859033 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.8578 ms - Host latency: 0.872278 ms (enqueue 0.860144 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.855566 ms - Host latency: 0.869702 ms (enqueue 0.859399 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.855969 ms - Host latency: 0.870813 ms (enqueue 0.860425 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.854626 ms - Host latency: 0.86936 ms (enqueue 0.858618 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.860303 ms - Host latency: 0.874719 ms (enqueue 0.864392 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.861523 ms - Host latency: 0.876221 ms (enqueue 0.865833 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.860852 ms - Host latency: 0.876587 ms (enqueue 0.864392 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.859058 ms - Host latency: 0.873657 ms (enqueue 0.86322 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.85769 ms - Host latency: 0.87179 ms (enqueue 0.861841 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.862488 ms - Host latency: 0.877161 ms (enqueue 0.86615 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.862354 ms - Host latency: 0.877051 ms (enqueue 0.865076 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.855676 ms - Host latency: 0.869556 ms (enqueue 0.859656 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.857397 ms - Host latency: 0.871973 ms (enqueue 0.861719 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.855151 ms - Host latency: 0.869202 ms (enqueue 0.859326 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.855615 ms - Host latency: 0.869812 ms (enqueue 0.85957 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.859338 ms - Host latency: 0.873767 ms (enqueue 0.862463 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.85896 ms - Host latency: 0.87323 ms (enqueue 0.862292 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.856799 ms - Host latency: 0.871143 ms (enqueue 0.860901 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.85813 ms - Host latency: 0.872498 ms (enqueue 0.862183 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.854858 ms - Host latency: 0.868909 ms (enqueue 0.858972 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.858301 ms - Host latency: 0.872852 ms (enqueue 0.862256 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.862793 ms - Host latency: 0.877551 ms (enqueue 0.866284 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.860828 ms - Host latency: 0.875574 ms (enqueue 0.865222 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.860779 ms - Host latency: 0.875537 ms (enqueue 0.864453 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.859021 ms - Host latency: 0.873462 ms (enqueue 0.86322 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.860046 ms - Host latency: 0.874487 ms (enqueue 0.864026 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.862622 ms - Host latency: 0.878833 ms (enqueue 0.866846 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.862683 ms - Host latency: 0.877527 ms (enqueue 0.866907 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.860754 ms - Host latency: 0.875049 ms (enqueue 0.864978 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.859668 ms - Host latency: 0.873975 ms (enqueue 0.864221 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.860547 ms - Host latency: 0.875513 ms (enqueue 0.864404 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.861169 ms - Host latency: 0.875732 ms (enqueue 0.865771 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.862988 ms - Host latency: 0.877881 ms (enqueue 0.867383 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.86189 ms - Host latency: 0.876965 ms (enqueue 0.865881 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.858728 ms - Host latency: 0.873352 ms (enqueue 0.862878 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.860376 ms - Host latency: 0.876196 ms (enqueue 0.86405 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.859924 ms - Host latency: 0.874316 ms (enqueue 0.864453 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.860022 ms - Host latency: 0.875269 ms (enqueue 0.864307 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.861377 ms - Host latency: 0.876147 ms (enqueue 0.864917 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.855408 ms - Host latency: 0.870007 ms (enqueue 0.859619 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.856396 ms - Host latency: 0.870691 ms (enqueue 0.8599 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.854968 ms - Host latency: 0.871777 ms (enqueue 0.85885 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.856238 ms - Host latency: 0.870837 ms (enqueue 0.860303 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.857971 ms - Host latency: 0.872937 ms (enqueue 0.861121 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.855103 ms - Host latency: 0.869226 ms (enqueue 0.859277 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.858044 ms - Host latency: 0.87207 ms (enqueue 0.862268 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.855859 ms - Host latency: 0.869849 ms (enqueue 0.859839 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.855774 ms - Host latency: 0.87063 ms (enqueue 0.859546 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.85553 ms - Host latency: 0.869592 ms (enqueue 0.859607 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.858826 ms - Host latency: 0.87561 ms (enqueue 0.862561 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.855591 ms - Host latency: 0.869702 ms (enqueue 0.859656 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.856177 ms - Host latency: 0.870496 ms (enqueue 0.859863 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.854541 ms - Host latency: 0.868713 ms (enqueue 0.858545 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.858813 ms - Host latency: 0.872937 ms (enqueue 0.86261 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.857983 ms - Host latency: 0.872498 ms (enqueue 0.862048 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.855359 ms - Host latency: 0.86958 ms (enqueue 0.859363 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.856677 ms - Host latency: 0.87085 ms (enqueue 0.860645 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.854724 ms - Host latency: 0.868958 ms (enqueue 0.85835 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.855847 ms - Host latency: 0.870215 ms (enqueue 0.859692 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.855432 ms - Host latency: 0.86958 ms (enqueue 0.859546 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.861658 ms - Host latency: 0.876208 ms (enqueue 0.865662 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.85647 ms - Host latency: 0.87052 ms (enqueue 0.860071 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.856177 ms - Host latency: 0.870374 ms (enqueue 0.859228 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.856384 ms - Host latency: 0.872034 ms (enqueue 0.859717 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.855151 ms - Host latency: 0.869739 ms (enqueue 0.85929 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.858008 ms - Host latency: 0.872778 ms (enqueue 0.861133 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.857178 ms - Host latency: 0.871826 ms (enqueue 0.86123 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.855786 ms - Host latency: 0.870068 ms (enqueue 0.859424 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.854565 ms - Host latency: 0.868774 ms (enqueue 0.858521 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.855176 ms - Host latency: 0.869507 ms (enqueue 0.858936 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.856055 ms - Host latency: 0.870313 ms (enqueue 0.860181 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.856982 ms - Host latency: 0.871411 ms (enqueue 0.861206 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.857104 ms - Host latency: 0.871362 ms (enqueue 0.860791 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.856738 ms - Host latency: 0.870728 ms (enqueue 0.860693 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.855786 ms - Host latency: 0.869897 ms (enqueue 0.859619 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.858105 ms - Host latency: 0.872559 ms (enqueue 0.861304 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.857275 ms - Host latency: 0.871509 ms (enqueue 0.861548 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.864648 ms - Host latency: 0.878882 ms (enqueue 0.867236 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.855762 ms - Host latency: 0.869849 ms (enqueue 0.859814 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.857007 ms - Host latency: 0.87085 ms (enqueue 0.860205 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.856812 ms - Host latency: 0.870923 ms (enqueue 0.861035 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.856714 ms - Host latency: 0.870801 ms (enqueue 0.860815 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.860522 ms - Host latency: 0.874927 ms (enqueue 0.864453 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.859082 ms - Host latency: 0.873291 ms (enqueue 0.863135 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.855884 ms - Host latency: 0.870337 ms (enqueue 0.859595 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.855273 ms - Host latency: 0.869751 ms (enqueue 0.859326 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.854419 ms - Host latency: 0.868481 ms (enqueue 0.858423 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.855298 ms - Host latency: 0.869604 ms (enqueue 0.858911 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.859228 ms - Host latency: 0.873364 ms (enqueue 0.86377 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.854614 ms - Host latency: 0.868677 ms (enqueue 0.858691 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.855395 ms - Host latency: 0.869678 ms (enqueue 0.859326 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.859326 ms - Host latency: 0.874097 ms (enqueue 0.862183 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.857349 ms - Host latency: 0.871826 ms (enqueue 0.861401 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.856934 ms - Host latency: 0.871484 ms (enqueue 0.860889 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.857007 ms - Host latency: 0.871289 ms (enqueue 0.861182 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.857007 ms - Host latency: 0.871191 ms (enqueue 0.860791 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.85625 ms - Host latency: 0.870532 ms (enqueue 0.860278 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.855957 ms - Host latency: 0.870239 ms (enqueue 0.859717 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.85542 ms - Host latency: 0.8698 ms (enqueue 0.859351 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.858813 ms - Host latency: 0.873145 ms (enqueue 0.862793 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.855762 ms - Host latency: 0.870044 ms (enqueue 0.86001 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.856689 ms - Host latency: 0.870947 ms (enqueue 0.860547 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.856177 ms - Host latency: 0.87041 ms (enqueue 0.859985 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.857593 ms - Host latency: 0.871997 ms (enqueue 0.860889 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.855884 ms - Host latency: 0.870215 ms (enqueue 0.859863 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.860498 ms - Host latency: 0.875464 ms (enqueue 0.863696 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.855664 ms - Host latency: 0.869922 ms (enqueue 0.85957 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.85542 ms - Host latency: 0.869678 ms (enqueue 0.859424 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.855078 ms - Host latency: 0.869043 ms (enqueue 0.858862 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.856177 ms - Host latency: 0.870776 ms (enqueue 0.860303 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.860278 ms - Host latency: 0.874756 ms (enqueue 0.863355 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.855713 ms - Host latency: 0.869775 ms (enqueue 0.859522 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.856836 ms - Host latency: 0.870923 ms (enqueue 0.860596 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.857617 ms - Host latency: 0.871558 ms (enqueue 0.861572 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.856055 ms - Host latency: 0.870068 ms (enqueue 0.859937 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.856982 ms - Host latency: 0.871191 ms (enqueue 0.861353 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.860645 ms - Host latency: 0.875171 ms (enqueue 0.86394 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.856201 ms - Host latency: 0.870264 ms (enqueue 0.860156 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.856909 ms - Host latency: 0.871338 ms (enqueue 0.860498 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.856006 ms - Host latency: 0.870923 ms (enqueue 0.859033 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.854541 ms - Host latency: 0.86875 ms (enqueue 0.858496 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.862402 ms - Host latency: 0.877075 ms (enqueue 0.866431 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.867969 ms - Host latency: 0.883228 ms (enqueue 0.869922 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.863062 ms - Host latency: 0.87771 ms (enqueue 0.866211 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.855688 ms - Host latency: 0.870117 ms (enqueue 0.859888 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.857202 ms - Host latency: 0.871631 ms (enqueue 0.860107 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.85686 ms - Host latency: 0.871191 ms (enqueue 0.860962 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.856348 ms - Host latency: 0.872144 ms (enqueue 0.860254 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.8573 ms - Host latency: 0.871558 ms (enqueue 0.860742 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.856689 ms - Host latency: 0.871069 ms (enqueue 0.860596 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.855225 ms - Host latency: 0.869604 ms (enqueue 0.859277 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.854736 ms - Host latency: 0.86897 ms (enqueue 0.85896 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.857495 ms - Host latency: 0.871875 ms (enqueue 0.861646 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.860669 ms - Host latency: 0.875098 ms (enqueue 0.8646 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.860376 ms - Host latency: 0.875 ms (enqueue 0.862939 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.853662 ms - Host latency: 0.86792 ms (enqueue 0.857764 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.853687 ms - Host latency: 0.868091 ms (enqueue 0.857788 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.856372 ms - Host latency: 0.870679 ms (enqueue 0.859888 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.858765 ms - Host latency: 0.873315 ms (enqueue 0.862451 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.858569 ms - Host latency: 0.872827 ms (enqueue 0.862769 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.858105 ms - Host latency: 0.872656 ms (enqueue 0.862427 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.858838 ms - Host latency: 0.87312 ms (enqueue 0.863355 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.860059 ms - Host latency: 0.874414 ms (enqueue 0.863477 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.859326 ms - Host latency: 0.874609 ms (enqueue 0.864404 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.863525 ms - Host latency: 0.878149 ms (enqueue 0.867749 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.859522 ms - Host latency: 0.873755 ms (enqueue 0.863916 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.857422 ms - Host latency: 0.872559 ms (enqueue 0.861572 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.858691 ms - Host latency: 0.872803 ms (enqueue 0.863208 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.863184 ms - Host latency: 0.877686 ms (enqueue 0.867603 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.861499 ms - Host latency: 0.876123 ms (enqueue 0.865747 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.858569 ms - Host latency: 0.872681 ms (enqueue 0.861548 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.856689 ms - Host latency: 0.870825 ms (enqueue 0.86062 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.856592 ms - Host latency: 0.870581 ms (enqueue 0.859863 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.857495 ms - Host latency: 0.871558 ms (enqueue 0.861401 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.857007 ms - Host latency: 0.871362 ms (enqueue 0.8604 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.860498 ms - Host latency: 0.875147 ms (enqueue 0.864502 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.858179 ms - Host latency: 0.872314 ms (enqueue 0.861743 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.857935 ms - Host latency: 0.872168 ms (enqueue 0.861499 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.858496 ms - Host latency: 0.872925 ms (enqueue 0.862402 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.858423 ms - Host latency: 0.872852 ms (enqueue 0.8625 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.859912 ms - Host latency: 0.874268 ms (enqueue 0.863721 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.857886 ms - Host latency: 0.872144 ms (enqueue 0.86145 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.855884 ms - Host latency: 0.870142 ms (enqueue 0.859839 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.860742 ms - Host latency: 0.874927 ms (enqueue 0.86416 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.855176 ms - Host latency: 0.869336 ms (enqueue 0.858838 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.859424 ms - Host latency: 0.87417 ms (enqueue 0.862622 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.858838 ms - Host latency: 0.876001 ms (enqueue 0.861426 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.855347 ms - Host latency: 0.869482 ms (enqueue 0.859155 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.856226 ms - Host latency: 0.870459 ms (enqueue 0.85979 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.855493 ms - Host latency: 0.870142 ms (enqueue 0.859326 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.85481 ms - Host latency: 0.869141 ms (enqueue 0.858618 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.85625 ms - Host latency: 0.870654 ms (enqueue 0.86001 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.859985 ms - Host latency: 0.874634 ms (enqueue 0.863208 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.855273 ms - Host latency: 0.869531 ms (enqueue 0.85896 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.857007 ms - Host latency: 0.871338 ms (enqueue 0.860645 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.856714 ms - Host latency: 0.870703 ms (enqueue 0.860522 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.856714 ms - Host latency: 0.870947 ms (enqueue 0.8604 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.855933 ms - Host latency: 0.870215 ms (enqueue 0.859692 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.858008 ms - Host latency: 0.872314 ms (enqueue 0.861768 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.855957 ms - Host latency: 0.87002 ms (enqueue 0.859619 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.855762 ms - Host latency: 0.869922 ms (enqueue 0.859302 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.85564 ms - Host latency: 0.869604 ms (enqueue 0.859399 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.856421 ms - Host latency: 0.870605 ms (enqueue 0.860034 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.858081 ms - Host latency: 0.872168 ms (enqueue 0.861621 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.855811 ms - Host latency: 0.870044 ms (enqueue 0.859228 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.855493 ms - Host latency: 0.869653 ms (enqueue 0.858545 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.855469 ms - Host latency: 0.869727 ms (enqueue 0.859644 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.856396 ms - Host latency: 0.870703 ms (enqueue 0.859814 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.855029 ms - Host latency: 0.869238 ms (enqueue 0.858667 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.859692 ms - Host latency: 0.874194 ms (enqueue 0.862622 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.855469 ms - Host latency: 0.869556 ms (enqueue 0.859351 ms)\n",
      "[02/02/2023-19:24:29] [I] Average on 10 runs - GPU latency: 0.855029 ms - Host latency: 0.869116 ms (enqueue 0.858716 ms)\n",
      "[02/02/2023-19:24:29] [I] \n",
      "[02/02/2023-19:24:29] [I] === Performance summary ===\n",
      "[02/02/2023-19:24:29] [I] Throughput: 1107.51 qps\n",
      "[02/02/2023-19:24:29] [I] Latency: min = 0.862305 ms, max = 0.925537 ms, mean = 0.872383 ms, median = 0.871307 ms, percentile(90%) = 0.877686 ms, percentile(95%) = 0.882751 ms, percentile(99%) = 0.894928 ms\n",
      "[02/02/2023-19:24:29] [W] * Throughput may be bound by Enqueue Time rather than GPU Compute and the GPU may be under-utilized.\n",
      "[02/02/2023-19:24:29] [W]   If not already in use, --useCudaGraph (utilize CUDA graphs where possible) may increase the throughput.\n",
      "[02/02/2023-19:24:29] [I] Enqueue Time: min = 0.85257 ms, max = 0.908447 ms, mean = 0.861765 ms, median = 0.860962 ms, percentile(90%) = 0.866699 ms, percentile(95%) = 0.869629 ms, percentile(99%) = 0.876221 ms\n",
      "[02/02/2023-19:24:29] [I] H2D Latency: min = 0.00939941 ms, max = 0.0349731 ms, mean = 0.0103461 ms, median = 0.0102539 ms, percentile(90%) = 0.010498 ms, percentile(95%) = 0.0106201 ms, percentile(99%) = 0.0128174 ms\n",
      "[02/02/2023-19:24:29] [I] GPU Compute Time: min = 0.8479 ms, max = 0.911377 ms, mean = 0.857922 ms, median = 0.857056 ms, percentile(90%) = 0.863037 ms, percentile(95%) = 0.86731 ms, percentile(99%) = 0.876587 ms\n",
      "[02/02/2023-19:24:29] [I] D2H Latency: min = 0.00341797 ms, max = 0.0299072 ms, mean = 0.0041219 ms, median = 0.00396729 ms, percentile(90%) = 0.00463867 ms, percentile(95%) = 0.00488281 ms, percentile(99%) = 0.00622559 ms\n",
      "[02/02/2023-19:24:29] [I] Total Host Walltime: 3.00223 s\n",
      "[02/02/2023-19:24:29] [I] Total GPU Compute Time: 2.85259 s\n",
      "[02/02/2023-19:24:29] [I] Explanations of the performance metrics are printed in the verbose logs.\n",
      "[02/02/2023-19:24:29] [V] \n",
      "[02/02/2023-19:24:29] [V] === Explanations of the performance metrics ===\n",
      "[02/02/2023-19:24:29] [V] Total Host Walltime: the host walltime from when the first query (after warmups) is enqueued to when the last query is completed.\n",
      "[02/02/2023-19:24:29] [V] GPU Compute Time: the GPU latency to execute the kernels for a query.\n",
      "[02/02/2023-19:24:29] [V] Total GPU Compute Time: the summation of the GPU Compute Time of all the queries. If this is significantly shorter than Total Host Walltime, the GPU may be under-utilized because of host-side overheads or data transfers.\n",
      "[02/02/2023-19:24:29] [V] Throughput: the observed throughput computed by dividing the number of queries by the Total Host Walltime. If this is significantly lower than the reciprocal of GPU Compute Time, the GPU may be under-utilized because of host-side overheads or data transfers.\n",
      "[02/02/2023-19:24:29] [V] Enqueue Time: the host latency to enqueue a query. If this is longer than GPU Compute Time, the GPU may be under-utilized.\n",
      "[02/02/2023-19:24:29] [V] H2D Latency: the latency for host-to-device data transfers for input tensors of a single query.\n",
      "[02/02/2023-19:24:29] [V] D2H Latency: the latency for device-to-host data transfers for output tensors of a single query.\n",
      "[02/02/2023-19:24:29] [V] Latency: the summation of H2D Latency, GPU Compute Time, and D2H Latency. This is the latency to infer a single query.\n",
      "[02/02/2023-19:24:29] [I] \n",
      "&&&& PASSED TensorRT.trtexec [TensorRT v8501] # trtexec --onnx=/workspace/onnx/model.onnx --saveEngine=/workspace/model.plan --minShapes=input_ids:1x128,attention_mask:1x128,token_type_ids:1x128 --optShapes=input_ids:16x128,attention_mask:16x128,token_type_ids:16x128 --maxShapes=input_ids:224x128,attention_mask:224x128,token_type_ids:224x128 --fp16 --verbose --memPoolSize=workspace:14000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished exporting all models...\r\n"
     ]
    }
   ],
   "source": [
    "!docker run --gpus=all --rm -it --ipc=host --ulimit memlock=-1 --ulimit stack=67108864 \\\n",
    "            -v `pwd`/workspace:/workspace -w /workspace nvcr.io/nvidia/pytorch:22.12-py3 \\\n",
    "            /bin/bash generate_model_trt.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a293bd",
   "metadata": {},
   "source": [
    "#### Setup TensorRT Model Repository\n",
    "\n",
    "Similar to PyTorch model, this is the expected structure of the TensorRT model repository:\n",
    "```\n",
    "xdistilbert_trt\n",
    "â”œâ”€â”€ 1\n",
    "â”‚   â””â”€â”€ model.plan\n",
    "â””â”€â”€ config.pbtxt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092dec73",
   "metadata": {},
   "source": [
    "#### TensorRT Model configuration <a class=\"anchor\" id=\"create-pytorch-model-config\"></a>\n",
    "\n",
    "Model configuration file `config.pbtxt` contains the following  \n",
    "- `name`: xdistilbert_trt\n",
    "- `backend`: tensorrt\n",
    "- `max_batch_size`: maximum batch size 224 that the model supports\n",
    "- `input` and `output` tensor shapes with the `data_types`\n",
    "\n",
    "Additionally, you can specify [instance_group](https://github.com/triton-inference-server/server/blob/main/docs/user_guide/model_configuration.md#instance-groups) and [dynamic_batching](https://github.com/triton-inference-server/server/blob/main/docs/user_guide/model_configuration.md#dynamic-batcher) properties to achieve high performance inference. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3610b257-20d2-4f16-8f05-e482d42608a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p model_repository/xdistilbert_trt/1/\n",
    "!cp workspace/model.plan model_repository/xdistilbert_trt/1/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "440d9fdb-b6d0-40fd-bd29-96a53a6a1971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting model_repository/xdistilbert_trt/config.pbtxt\n"
     ]
    }
   ],
   "source": [
    "%%writefile model_repository/xdistilbert_trt/config.pbtxt\n",
    "name: \"xdistilbert_trt\"\n",
    "backend: \"tensorrt\"\n",
    "max_batch_size: 224\n",
    "input [\n",
    "  {\n",
    "    name: \"input_ids\"\n",
    "    data_type: TYPE_INT32\n",
    "    dims: [128]\n",
    "  },\n",
    "  {\n",
    "    name: \"attention_mask\"\n",
    "    data_type: TYPE_INT32\n",
    "    dims: [128]\n",
    "  },\n",
    "  {\n",
    "    name: \"token_type_ids\"\n",
    "    data_type: TYPE_INT32\n",
    "    dims: [128]\n",
    "  }\n",
    "]\n",
    "output [\n",
    "  {\n",
    "    name: \"logits\"\n",
    "    data_type: TYPE_FP32\n",
    "    dims: [6]\n",
    "  }\n",
    "]\n",
    "instance_group {\n",
    "  count: 1\n",
    "  kind: KIND_GPU\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d67ee3-e301-4edb-a6d4-d0b1f35ad2b3",
   "metadata": {},
   "source": [
    "## Export model artifacts to S3 <a class=\"anchor\" id=\"export-to-s3\"></a>\n",
    "\n",
    "Next, we will package our models as `*.tar.gz` files for uploading to S3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5022a48f-5d52-4697-8b12-f00fc297f420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Model S3 location: s3://sagemaker-us-west-2-############/nlp-mme-gpu/xdistilbert_pt.tar.gz\n"
     ]
    }
   ],
   "source": [
    "pytorch_model_file_name = \"xdistilbert_pt.tar.gz\"\n",
    "!tar -C model_repository -czf $pytorch_model_file_name xdistilbert_pt\n",
    "model_uri_pt = sagemaker_session.upload_data(path=pytorch_model_file_name, key_prefix=prefix)\n",
    "print_safe(f\"PyTorch Model S3 location: {model_uri_pt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "296c069a-2fad-4e22-891a-cf0a05920327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorRT Model S3 location: s3://sagemaker-us-west-2-############/nlp-mme-gpu/xdistilbert_trt.tar.gz\n"
     ]
    }
   ],
   "source": [
    "tensorrt_model_file_name = \"xdistilbert_trt.tar.gz\"\n",
    "!tar -C model_repository -czf $tensorrt_model_file_name xdistilbert_trt\n",
    "model_uri_trt = sagemaker_session.upload_data(path=tensorrt_model_file_name, key_prefix=prefix)\n",
    "print_safe(f\"TensorRT Model S3 location: {model_uri_trt}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cab8f41-08e5-4999-98e7-92ee2852940d",
   "metadata": {},
   "source": [
    "## Setup GPU Multi-Model Endpoint <a class=\"anchor\" id=\"deploy-models-with-mme\"></a>\n",
    "\n",
    "We will now setup Multi-Model Endpoint on GPU where we can deploy our DistilBERT PyTorch and TensorRT models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6379000a-3116-4ed4-851b-a041e4cfb3bf",
   "metadata": {},
   "source": [
    "### SageMaker Triton Container Image\n",
    "\n",
    "First we define the SageMaker Triton container image we will be using that supports deploying multi-model endpoints with GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25758107-1d7a-4085-8a6a-908844f03ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# account mapping for SageMaker MME Triton Image\n",
    "account_id_map = {\n",
    "    \"us-east-1\": \"785573368785\",\n",
    "    \"us-east-2\": \"007439368137\",\n",
    "    \"us-west-1\": \"710691900526\",\n",
    "    \"us-west-2\": \"301217895009\",\n",
    "    \"eu-west-1\": \"802834080501\",\n",
    "    \"eu-west-2\": \"205493899709\",\n",
    "    \"eu-west-3\": \"254080097072\",\n",
    "    \"eu-north-1\": \"601324751636\",\n",
    "    \"eu-south-1\": \"966458181534\",\n",
    "    \"eu-central-1\": \"746233611703\",\n",
    "    \"ap-east-1\": \"110948597952\",\n",
    "    \"ap-south-1\": \"763008648453\",\n",
    "    \"ap-northeast-1\": \"941853720454\",\n",
    "    \"ap-northeast-2\": \"151534178276\",\n",
    "    \"ap-southeast-1\": \"324986816169\",\n",
    "    \"ap-southeast-2\": \"355873309152\",\n",
    "    \"cn-northwest-1\": \"474822919863\",\n",
    "    \"cn-north-1\": \"472730292857\",\n",
    "    \"sa-east-1\": \"756306329178\",\n",
    "    \"ca-central-1\": \"464438896020\",\n",
    "    \"me-south-1\": \"836785723513\",\n",
    "    \"af-south-1\": \"774647643957\",\n",
    "}\n",
    "\n",
    "region = boto3.Session().region_name\n",
    "if region not in account_id_map.keys():\n",
    "    raise (\"UNSUPPORTED REGION\")\n",
    "\n",
    "base = \"amazonaws.com.cn\" if region.startswith(\"cn-\") else \"amazonaws.com\"\n",
    "mme_triton_image_uri = (\n",
    "    \"{account_id}.dkr.ecr.{region}.{base}/sagemaker-tritonserver:22.12-py3\".format(\n",
    "        account_id=account_id_map[region], region=region, base=base\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc897e94",
   "metadata": {},
   "source": [
    "### Define the serving container  <a class=\"anchor\" id=\"define-container-def\"></a>\n",
    "\n",
    "Next, we define the serving container based on the Triton SageMaker image\n",
    "* In the container definition, define the `ModelDataUrl` to specify the S3 directory that contains all the models that SageMaker multi-model endpoint will use to load  and serve predictions. \n",
    "* Set `Mode` to `MultiModel` to indicate SageMaker should create the endpoint with MME specifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b00914-a237-4455-a08c-d79b3715cac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data_url = f\"s3://{bucket}/{prefix}/\"\n",
    "\n",
    "container = {\"Image\": mme_triton_image_uri, \"ModelDataUrl\": model_data_url, \"Mode\": \"MultiModel\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e28483-e6cf-4769-b6f3-4ccaa61471ec",
   "metadata": {},
   "source": [
    "### Create SageMaker model <a class=\"anchor\" id=\"create-mme-model-obj\"></a>\n",
    "\n",
    "We then create a sagemaker model from the model files we uploaded to s3 in the previous steps. We do this using the SageMaker boto3 client and [create_model](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/sagemaker.html#SageMaker.Client.create_model) API. We will pass the container definition to the `create model` API along with ModelName and ExecutionRoleArn.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2077c860-1ef6-42f6-b10b-c77e075d2be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.gmtime())\n",
    "\n",
    "sm_model_name = f\"{prefix}-model-{ts}\"\n",
    "create_model_response = sm_client.create_model(\n",
    "    ModelName=sm_model_name, ExecutionRoleArn=role, PrimaryContainer=container\n",
    ")\n",
    "\n",
    "print_safe(\"Model Arn: \" + create_model_response[\"ModelArn\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a8e07e-1410-471e-9c2c-10e0c23db00f",
   "metadata": {},
   "source": [
    "### Define configuration for the Multi-Model <Endpoint class=\"anchor\" id=\"config-mme\"></a>\n",
    "\n",
    "Next, we create a multi-model endpoint configuration using [create_endpoint_config](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/sagemaker.html#SageMaker.Client.create_endpoint_config) boto3 API. Specify an accelerated GPU computing instance in InstanceType **(we will use the same instance type that we are using to host our SageMaker Notebook)**. We recommend configuring your endpoints with at least two instances with real-life use-cases. This allows SageMaker to provide a highly available set of predictions across multiple Availability Zones for the models.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b55e160-8aa0-4ef7-84f5-cb975df99f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_config_name = f\"{prefix}-epc-{ts}\"\n",
    "create_endpoint_config_response = sm_client.create_endpoint_config(\n",
    "    EndpointConfigName=endpoint_config_name,\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            \"InstanceType\": ml.g5.xlarge,\n",
    "            \"InitialVariantWeight\": 1,\n",
    "            \"InitialInstanceCount\": 1,\n",
    "            \"ModelName\": sm_model_name,\n",
    "            \"VariantName\": \"AllTraffic\",\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "\n",
    "print_safe(\"Endpoint Config Arn: \" + create_endpoint_config_response[\"EndpointConfigArn\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21943aee-7692-4048-9a47-256d8e21c112",
   "metadata": {},
   "source": [
    "### Create Multi-Model Endpoint  <a class=\"anchor\" id=\"create-mme\"></a>\n",
    "\n",
    "Using the above endpoint configuration we create a new sagemaker endpoint and wait for the deployment to finish. The status will change to **InService** once the deployment is successful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc49275-e1c2-46c3-a8be-9e193c271262",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_name = f\"{prefix}-ep-{ts}\"\n",
    "create_endpoint_response = sm_client.create_endpoint(\n",
    "    EndpointName=endpoint_name, EndpointConfigName=endpoint_config_name\n",
    ")\n",
    "\n",
    "print_safe(\"Endpoint Arn: \" + create_endpoint_response[\"EndpointArn\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7ac9f8-8ba9-4f37-a2cb-7dc6d428885d",
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "status = resp[\"EndpointStatus\"]\n",
    "print(\"Status: \" + status)\n",
    "\n",
    "while status == \"Creating\":\n",
    "    time.sleep(60)\n",
    "    resp = sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "    status = resp[\"EndpointStatus\"]\n",
    "    print(\"Status: \" + status)\n",
    "\n",
    "print_safe(\"\\nArn: \" + resp[\"EndpointArn\"])\n",
    "print(\"Status: \" + status)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0afddbf7",
   "metadata": {},
   "source": [
    "## Helper functions to prepare Inference Payload\n",
    "\n",
    "The following helper functions help us transform sample texts into inference payload that can be sent to Triton server on MME which is what is really serving our PyTorch and TensorRT DistilBERT NLP models.\n",
    "\n",
    "The `tritonclient` package provides utility methods to generate the payload without having to know the details of the specification. We'll use the following methods to convert our inference request into a binary format which provides lower latencies for inference.\n",
    "\n",
    "**Note:** With the `binary+json` format, we have to specify the length of the request metadata in the header to allow Triton to correctly parse the binary payload. This is done using a custom Content-Type header `application/vnd.sagemaker-triton.binary+json;json-header-size={}`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daae74d9-1058-4686-9f36-e297277d26e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import tokenize_text, logits2prediction, get_random_text\n",
    "import tritonclient.http as httpclient\n",
    "import numpy as np\n",
    "\n",
    "def _get_tokenized_text_binary(text, input_names, output_names):\n",
    "    inputs = []\n",
    "    outputs = []\n",
    "    input_ids, attention_mask, token_type_ids = tokenize_text(tokenizer, text)\n",
    "    inputs.append(httpclient.InferInput(input_names[0], input_ids.shape, \"INT32\"))\n",
    "    inputs.append(httpclient.InferInput(input_names[1], attention_mask.shape, \"INT32\"))\n",
    "    inputs.append(httpclient.InferInput(input_names[2], token_type_ids.shape, \"INT32\"))\n",
    "\n",
    "    inputs[0].set_data_from_numpy(input_ids.astype(np.int32), binary_data=True)\n",
    "    inputs[1].set_data_from_numpy(attention_mask.astype(np.int32), binary_data=True)\n",
    "    inputs[2].set_data_from_numpy(token_type_ids.astype(np.int32), binary_data=True)\n",
    "    \n",
    "    outputs.append(httpclient.InferRequestedOutput(output_names[0], binary_data=True))\n",
    "    request_body, header_length = httpclient.InferenceServerClient.generate_request_body(\n",
    "        inputs, outputs=outputs\n",
    "    )\n",
    "    return request_body, header_length\n",
    "\n",
    "def get_tokenized_text_binary_pt(text):\n",
    "    return _get_tokenized_text_binary(text, [\"INPUT__0\", \"INPUT__1\", \"INPUT__2\"], [\"OUTPUT__0\"])\n",
    "\n",
    "def get_tokenized_text_binary_trt(text):\n",
    "    return _get_tokenized_text_binary(text, [\"input_ids\", \"attention_mask\", \"token_type_ids\"], [\"logits\"])\n",
    "\n",
    "def read_response(response, output_name):\n",
    "    # Parse json header size length from the response\n",
    "    header_length_prefix = \"application/vnd.sagemaker-triton.binary+json;json-header-size=\"\n",
    "    header_length_str = response['ContentType'][len(header_length_prefix):]\n",
    "    # Read response body\n",
    "    result = httpclient.InferenceServerClient.parse_response_body(response['Body'].read(), header_length=int(header_length_str))\n",
    "    logits = result.as_numpy(output_name)\n",
    "    prediction = logits2prediction(logits)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8887d53d-d9b4-41bf-ab74-07a86cecd04c",
   "metadata": {},
   "source": [
    "## Invoking Models on Multi-Model Endpoint\n",
    "\n",
    "Once the endpoint is successfully created, we can send inference request to multi-model endpoint using `invoke_enpoint` API. We specify the TargetModel in the invocation call and pass in the payload for each model type. Sample invocation for PyTorch model and TensorRT model is shown below\n",
    "\n",
    "### Invoke TensorRT Model <a class=\"anchor\" id=\"invoke-tensorrt-model\"></a>\n",
    "\n",
    "Let's invoke the same model twice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a84bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = get_random_text()\n",
    "request_body, header_length = get_tokenized_text_binary_trt(sample_text)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "response = runtime_sm_client.invoke_endpoint(EndpointName=endpoint_name,\n",
    "                                  ContentType=f\"application/vnd.sagemaker-triton.binary+json;json-header-size={header_length}\",\n",
    "                                  Body=request_body,\n",
    "                                  TargetModel='xdistilbert_trt.tar.gz')\n",
    "duration = time.time() - start_time\n",
    "\n",
    "output_name = 'logits'\n",
    "prediction = read_response(response, output_name)\n",
    "print(f\"text: {sample_text}\\n\")\n",
    "print(f\"prediction: {prediction}, took {int(duration * 1000)} ms\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386a5b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = get_random_text()\n",
    "request_body, header_length = get_tokenized_text_binary_trt(sample_text)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "response = runtime_sm_client.invoke_endpoint(EndpointName=endpoint_name,\n",
    "                                  ContentType=f\"application/vnd.sagemaker-triton.binary+json;json-header-size={header_length}\",\n",
    "                                  Body=request_body,\n",
    "                                  TargetModel='xdistilbert_trt.tar.gz')\n",
    "duration = time.time() - start_time\n",
    "\n",
    "output_name = 'logits'\n",
    "prediction = read_response(response, output_name)\n",
    "print(f\"text: {sample_text}\\n\")\n",
    "print(f\"prediction: {prediction}, took {int(duration * 1000)} ms\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce77ad2",
   "metadata": {},
   "source": [
    "Notice the higher latencies on the first invocation of any given model. This is due to the time it takes SageMaker to download the model to the Endpoint instance and then load the model into the inference container. Subsequent invocations of the same model take advantage of the model already being loaded into the inference container and so are fast."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef06a05c-ae58-484c-9fed-4c9584795c7f",
   "metadata": {},
   "source": [
    "### Invoke PyTorch Model <a class=\"anchor\" id=\"invoke-pytorch-model\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ab429b-5b9c-4edd-9ff7-5f974dd35924",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = get_random_text()\n",
    "request_body, header_length = get_tokenized_text_binary_pt(sample_text)\n",
    "\n",
    "response = runtime_sm_client.invoke_endpoint(EndpointName=endpoint_name,\n",
    "                                  ContentType=f\"application/vnd.sagemaker-triton.binary+json;json-header-size={header_length}\",\n",
    "                                  Body=request_body,\n",
    "                                  TargetModel='xdistilbert_pt.tar.gz')\n",
    "\n",
    "output_name = 'OUTPUT__0'\n",
    "prediction = read_response(response, output_name)\n",
    "print(f\"text: {sample_text}\\n\")\n",
    "print(f\"prediction: {prediction}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05aa3d1a-c0f2-4809-a7e2-71056556c864",
   "metadata": {},
   "source": [
    "# Deploying Hundreds of Models to GPUs using Multi-Model Endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132f67b3-0eb6-4ead-8851-c89b2628cb1c",
   "metadata": {},
   "source": [
    "Let's say you are trying to deploy 300 customer-specific distilBERT models which are a mixture of frequently and infrequently accessed models which need GPU acceleration for good inference performance. These models might even be coming from different frameworks like PyTorch, TensorFlow, ONNX, TensorRT.\n",
    "\n",
    "Deploying these 300 models on GPU instances like `g5.xlarge` using dedicated Single-Model Endpoints would take ~300 instances.\n",
    "\n",
    "By deploying these models behind a Multi-Model endpoint on GPUs you can end up using ~100x less instances. Thus reducing costs by **100x**. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccedb827-b9e7-4b54-98f4-f3effa813bc5",
   "metadata": {},
   "source": [
    "## Dynamically adding models to an existing Multi-Model Endpoint\n",
    "\n",
    "Itâ€™s easy to deploy a new model to an existing multi-model endpoint. With the endpoint already running, copy a new set of model artifacts to the same S3 location you set up earlier. Client applications are then free to request predictions from that target model, and Amazon SageMaker handles the rest. \n",
    "\n",
    "This step below will take around few minutes to complete as we are copying 300 files to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd99243-9f2e-4954-8ec8-d9b9c8301ddb",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "num_models = 300\n",
    "for i in range(num_models):\n",
    "    customer_model_name = f\"xdistilbert_customer{i}.tar.gz\"\n",
    "    model_copy = f\"{model_data_url}{customer_model_name}\"\n",
    "    !aws s3 cp $model_data_url$pytorch_model_file_name $model_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ccbc78",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!aws s3 ls $model_data_url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3724cccf",
   "metadata": {},
   "source": [
    "### Helper function to invoke models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adca7b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_model(text, model_name, show_latency=False):\n",
    "    print(f\"Using model {model_name} to predict\")\n",
    "    \n",
    "    request_body, header_length = get_tokenized_text_binary_pt(text)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    response = runtime_sm_client.invoke_endpoint(EndpointName=endpoint_name,\n",
    "                                  ContentType='application/vnd.sagemaker-triton.binary+json;json-header-size={}'.format(header_length),\n",
    "                                  Body=request_body,\n",
    "                                  TargetModel=model_name)\n",
    "    \n",
    "    duration = time.time() - start_time\n",
    "    \n",
    "    prediction = read_response(response, output_name=\"OUTPUT__0\")\n",
    "    \n",
    "    if show_latency:\n",
    "        print(f\"prediction: {prediction}, took {int(duration * 1000)} ms\\n\")\n",
    "    else:\n",
    "        print(f\"prediction: {prediction}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cef1a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_model(text=get_random_text(), model_name=\"xdistilbert_customer1.tar.gz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065544db",
   "metadata": {},
   "source": [
    "## Monitoring GPU MME using Amazon CloudWatch metrics\n",
    "To make price and performance tradeoffs, you will want to test multi-model endpoints with models and representative traffic from your own application. Amazon SageMaker provides metrics in CloudWatch for multi-model endpoints so you can determine the endpoint usage and the cache hit rate and optimize your endpoint.\n",
    "\n",
    "* **LoadedModelCount**: The number of models loaded in the containers of the multi-model endpoint\n",
    "* **GPUUtilization**: Precentage of GPU units that are used by the containers on an instance \n",
    "* **GPUMemoryUtilization**: Precentage of GPU memory used by the containers on an instance \n",
    "* **DiskUtilization**: Precentage of disk space used by the containers on an instance \n",
    "and others\n",
    "\n",
    "SageMaker MME also provides Model loading metrics such as:\n",
    "\n",
    "* **ModelLoadingWaitTime**: Time interval for model to be downloaded or loaded\n",
    "* **ModelUnloadingTime**: Time interval to unload model from container\n",
    "* **ModelDownloadingTime** Time to download the model from S3\n",
    "* **ModelCacheHit**: Number of invocations to model that are already loaded onto the container\n",
    "\n",
    "For more details refer [Monitor Amazon SageMaker with Amazon CloudWatch](https://docs.aws.amazon.com/sagemaker/latest/dg/monitoring-cloudwatch.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bef26cf-3ca9-4702-88eb-963e794b69f4",
   "metadata": {},
   "source": [
    "# Dynamic Model Unloading in Multi-Model Endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e089cd1f",
   "metadata": {},
   "source": [
    "In this section, we show dynamic loading and unloading of models based on the resource utilization on the GPU based compute instance. When the `GPUMemoryUtilization` is at the maximum and SageMaker cannot load more models to serve the requests, SageMaker unloads previously loaded models to free up GPU memory. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be87edd6",
   "metadata": {},
   "source": [
    "In this case, 1 `g5.xlarge` instance's NVIDIA A10G GPU (24GB memory) can handle 270 models in memory and beyond that if requests for newer models are made MME starts unloading LRU models to make room for newer models which can be seen in the CloudWatch logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35875ae-e2b5-4626-a88e-6b77dc6c6f94",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(300):\n",
    "    customer_model_name = f\"xdistilbert_customer{i}.tar.gz\"\n",
    "    predict_model(text=get_random_text(), model_name=customer_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b006088-db0a-45e4-96a7-37e901d17e75",
   "metadata": {},
   "source": [
    "# Autoscaling in Multi-Model Endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197e4f89",
   "metadata": {},
   "source": [
    "Amazon SageMaker multi-model endpoints on GPU fully support automatic scaling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f091ec-f438-41c0-b00a-71f50111b546",
   "metadata": {},
   "source": [
    "## Set up AutoScaling Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2eb482-42ee-43f0-a7d9-2bb7328a5dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_scaling_client = boto3.client('application-autoscaling')\n",
    "\n",
    "resource_id='endpoint/' + endpoint_name + '/variant/' + 'AllTraffic' \n",
    "response = auto_scaling_client.register_scalable_target(\n",
    "    ServiceNamespace='sagemaker',\n",
    "    ResourceId=resource_id,\n",
    "    ScalableDimension='sagemaker:variant:DesiredInstanceCount',\n",
    "    MinCapacity = 1,\n",
    "    MaxCapacity = 2\n",
    ")\n",
    "\n",
    "response = auto_scaling_client.put_scaling_policy(\n",
    "    PolicyName='GPUMemUtil-ScalingPolicy',\n",
    "    ServiceNamespace='sagemaker',\n",
    "    ResourceId=resource_id,\n",
    "    ScalableDimension='sagemaker:variant:DesiredInstanceCount', \n",
    "    PolicyType='TargetTrackingScaling',\n",
    "    TargetTrackingScalingPolicyConfiguration={\n",
    "        'TargetValue': 75, \n",
    "        'CustomizedMetricSpecification':\n",
    "        {\n",
    "            'MetricName': 'GPUMemoryUtilization',\n",
    "            'Namespace': '/aws/sagemaker/Endpoints',\n",
    "            'Dimensions': [\n",
    "                {'Name': 'EndpointName', 'Value': endpoint_name},\n",
    "                {'Name': 'VariantName','Value': 'AllTraffic'}\n",
    "            ],\n",
    "            'Statistic': 'Average',\n",
    "            'Unit': 'Percent'\n",
    "        },\n",
    "        'ScaleInCooldown': 600,\n",
    "        'ScaleOutCooldown': 100\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"Autoscaling policy for GPU MME endpoint has been set up\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599dca6a-93cd-4045-aaa2-857e22a81311",
   "metadata": {},
   "source": [
    "### During Autoscaling the endpoint is still active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef815d0-fc2f-4b0a-80ef-d9d925e78a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_model(text=get_random_text(), model_name=\"xdistilbert_customer200.tar.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc675900",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0612c721",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012f0417",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3a33b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b62ac8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7e5599ff-15b5-4bb3-9b7d-d22a87aab8f9",
   "metadata": {},
   "source": [
    "## Invoke All Models Again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f33883",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(1, 300):\n",
    "    customer_model_name = f\"xdistilbert_customer{i}.tar.gz\"\n",
    "    predict_model(sample_text, customer_model_name, show_latency=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb41f68a",
   "metadata": {},
   "source": [
    "## Matching your endpoint configuration to your use case"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858829eb",
   "metadata": {},
   "source": [
    "In some cases, you may opt to reduce costs by choosing an instance type that cannot hold all the targeted models in memory at the same time. Amazon SageMaker unloads models dynamically when it runs out of memory to make room for a newly-targeted model. For infrequently requested models, the dynamic load latency may still be acceptable given the resulting lower costs. In cases with more stringent latency needs, you may opt for larger instance types or more instances. Investing time up front to do use-case specific testing and analysis with your multi-model endpoint will help to best optimize cost while meeting the performance needs of your application."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbec88f-cbdb-4567-9048-50c0d9746fae",
   "metadata": {},
   "source": [
    "# Clean Up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e0f756-6a47-4a8a-970a-32493ddb27f2",
   "metadata": {},
   "source": [
    "### Terminate endpoint and clean up artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1081fd3f-48c1-4de1-bbfc-4368ae8e8742",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_client.delete_endpoint(EndpointName=endpoint_name)\n",
    "sm_client.delete_endpoint_config(EndpointConfigName=endpoint_config_name)\n",
    "sm_client.delete_model(ModelName=sm_model_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
