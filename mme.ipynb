{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7210102-aba1-42f4-a5f7-90bac19ac6b3",
   "metadata": {},
   "source": [
    "## Deploying Multiple Frameworks Models on GPU "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66483eb5-f1ee-43ac-8f8b-3bc2a02a1fc3",
   "metadata": {},
   "source": [
    "## Installs <a class=\"anchor\" id=\"installs-and-set-up\"></a>\n",
    "\n",
    "Install required packages using pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e2956ae-e471-401e-9eb7-87a69df9c4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qU pip boto3 sagemaker awscli tritonclient[http] transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b537a3-72b8-40d9-aed4-415efd008d09",
   "metadata": {},
   "source": [
    "#### Imports and variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92279c0c-cd98-4928-8425-3530697fb9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "import time\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "#variables\n",
    "prefix = \"mme-gpu\"\n",
    "model_name = \"xdistilbert\"\n",
    "pytorch_model_file_name = f\"{model_name}_pt.tar.gz\"\n",
    "tensorrt_model_file_name = f\"{model_name}_trt.tar.gz\"\n",
    "s3_client = boto3.client(\"s3\")\n",
    "ts = time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.gmtime())\n",
    "\n",
    "# sagemaker variables\n",
    "role = get_execution_role()\n",
    "sm_client = boto3.client(service_name=\"sagemaker\")\n",
    "runtime_sm_client = boto3.client(\"sagemaker-runtime\")\n",
    "sagemaker_session = sagemaker.Session(boto_session=boto3.Session())\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "\n",
    "# endpoint variables\n",
    "sm_model_name = f\"{prefix}-mdl-{ts}\"\n",
    "endpoint_config_name = f\"{prefix}-epc-{ts}\"\n",
    "endpoint_name = f\"{prefix}-ep-{ts}\"\n",
    "model_data_url = f\"s3://{bucket}/{prefix}/\"\n",
    "instance_type = \"ml.g5.xlarge\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308dede4-e603-4e48-adb8-2d5a55b8f0d0",
   "metadata": {},
   "source": [
    "## Creating Model Artifacts <a class=\"anchor\" id=\"pytorch-efficientnet-model\"></a>\n",
    "\n",
    "\n",
    "\n",
    "<div class=\"alert alert-info\"><strong> Note </strong>\n",
    "We are demonstrating deployment with\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eeb7345-7bee-4ade-9213-1bd7082ca900",
   "metadata": {},
   "source": [
    "### Prepare PyTorch Model  <a class=\"anchor\" id=\"create-pytorch-model\"></a>\n",
    "\n",
    "Run the cell below and check out the [pt_exporter.py](./workspace/pt_exporter.py) file for more details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0dae16a-1bde-422b-9635-5b6e005e59c2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=============\n",
      "== PyTorch ==\n",
      "=============\n",
      "\n",
      "NVIDIA Release 22.12 (build 49968248)\n",
      "PyTorch Version 1.14.0a0+410ce96\n",
      "\n",
      "Container image Copyright (c) 2022, NVIDIA CORPORATION & AFFILIATES. All rights reserved.\n",
      "\n",
      "Copyright (c) 2014-2022 Facebook Inc.\n",
      "Copyright (c) 2011-2014 Idiap Research Institute (Ronan Collobert)\n",
      "Copyright (c) 2012-2014 Deepmind Technologies    (Koray Kavukcuoglu)\n",
      "Copyright (c) 2011-2012 NEC Laboratories America (Koray Kavukcuoglu)\n",
      "Copyright (c) 2011-2013 NYU                      (Clement Farabet)\n",
      "Copyright (c) 2006-2010 NEC Laboratories America (Ronan Collobert, Leon Bottou, Iain Melvin, Jason Weston)\n",
      "Copyright (c) 2006      Idiap Research Institute (Samy Bengio)\n",
      "Copyright (c) 2001-2004 Idiap Research Institute (Ronan Collobert, Samy Bengio, Johnny Mariethoz)\n",
      "Copyright (c) 2015      Google Inc.\n",
      "Copyright (c) 2015      Yangqing Jia\n",
      "Copyright (c) 2013-2016 The Caffe contributors\n",
      "All rights reserved.\n",
      "\n",
      "Various files include modifications (c) NVIDIA CORPORATION & AFFILIATES.  All rights reserved.\n",
      "\n",
      "This container image and its contents are governed by the NVIDIA Deep Learning Container License.\n",
      "By pulling and using the container, you accept the terms and conditions of this license:\n",
      "https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license\n",
      "\n",
      "NOTE: CUDA Forward Compatibility mode ENABLED.\n",
      "  Using CUDA 11.8 driver version 520.61.05 with kernel driver version 510.47.03.\n",
      "  See https://docs.nvidia.com/deploy/cuda-compatibility/ for details.\n",
      "\n",
      "Installing Transformers...\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Downloading xdistillbert model from HuggingFace...\n",
      "Exporting model to Torchscript...\n",
      "Downloading: 100%|█████████████████████████████| 991/991 [00:00<00:00, 1.39MB/s]\n",
      "Downloading: 100%|█████████████████████████| 51.1M/51.1M [00:02<00:00, 17.4MB/s]\n"
     ]
    }
   ],
   "source": [
    "!docker run --gpus=all --rm -it --ipc=host --ulimit memlock=-1 --ulimit stack=67108864 \\\n",
    "            -v `pwd`/workspace:/workspace -w /workspace nvcr.io/nvidia/pytorch:22.12-py3 \\\n",
    "            /bin/bash generate_model_pytorch.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9a21ac8-012c-4e6c-8d17-27838295f507",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p model_repository/xdistilbert_pt/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b45c395e-c52a-4a28-a18b-7baa746fc1b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting model_repository/xdistilbert_pt/config.pbtxt\n"
     ]
    }
   ],
   "source": [
    "%%writefile model_repository/xdistilbert_pt/config.pbtxt\n",
    "backend: \"pytorch\"\n",
    "max_batch_size: 224\n",
    "input [\n",
    "  {\n",
    "    name: \"INPUT__0\"\n",
    "    data_type: TYPE_INT32\n",
    "    dims: [128]\n",
    "  },\n",
    "  {\n",
    "    name: \"INPUT__1\"\n",
    "    data_type: TYPE_INT32\n",
    "    dims: [128]\n",
    "  },\n",
    "    {\n",
    "    name: \"INPUT__2\"\n",
    "    data_type: TYPE_INT32\n",
    "    dims: [128]\n",
    "  }\n",
    "]\n",
    "output [\n",
    "  {\n",
    "    name: \"OUTPUT__0\"\n",
    "    data_type: TYPE_FP32\n",
    "    dims: [6]\n",
    "  }\n",
    "]\n",
    "instance_group {\n",
    "  count: 1\n",
    "  kind: KIND_GPU\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87036cb6-f830-495a-b2cc-9651ec93fe06",
   "metadata": {},
   "source": [
    "### Prepare TensorRT Model <a class=\"anchor\" id=\"create-tensorrt-model\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca98ddb-d90b-4095-b310-825d09774954",
   "metadata": {},
   "source": [
    "- We load pre-trained xdistilbert from torch\n",
    "- Convert to onnx representation using torch onnx exporter.\n",
    "- Use TensorRT trtexec command to create the model plan to be hosted with Triton. \n",
    "- The script for exporting this model can be found [here](./workspace/generate_model_trt.sh). \n",
    "\n",
    "Execute the below cell and check out the file for more details\n",
    "\n",
    "<div class=\"alert alert-info\"><strong> Note </strong>\n",
    "This step takes around 10 minutes to complete. While the step is running, please take a look at the logs in the below cell to understand TensorRT optimizations\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "daefd65d-f654-44b6-9569-0a1d5597a7f2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=============\n",
      "== PyTorch ==\n",
      "=============\n",
      "\n",
      "NVIDIA Release 22.12 (build 49968248)\n",
      "PyTorch Version 1.14.0a0+410ce96\n",
      "\n",
      "Container image Copyright (c) 2022, NVIDIA CORPORATION & AFFILIATES. All rights reserved.\n",
      "\n",
      "Copyright (c) 2014-2022 Facebook Inc.\n",
      "Copyright (c) 2011-2014 Idiap Research Institute (Ronan Collobert)\n",
      "Copyright (c) 2012-2014 Deepmind Technologies    (Koray Kavukcuoglu)\n",
      "Copyright (c) 2011-2012 NEC Laboratories America (Koray Kavukcuoglu)\n",
      "Copyright (c) 2011-2013 NYU                      (Clement Farabet)\n",
      "Copyright (c) 2006-2010 NEC Laboratories America (Ronan Collobert, Leon Bottou, Iain Melvin, Jason Weston)\n",
      "Copyright (c) 2006      Idiap Research Institute (Samy Bengio)\n",
      "Copyright (c) 2001-2004 Idiap Research Institute (Ronan Collobert, Samy Bengio, Johnny Mariethoz)\n",
      "Copyright (c) 2015      Google Inc.\n",
      "Copyright (c) 2015      Yangqing Jia\n",
      "Copyright (c) 2013-2016 The Caffe contributors\n",
      "All rights reserved.\n",
      "\n",
      "Various files include modifications (c) NVIDIA CORPORATION & AFFILIATES.  All rights reserved.\n",
      "\n",
      "This container image and its contents are governed by the NVIDIA Deep Learning Container License.\n",
      "By pulling and using the container, you accept the terms and conditions of this license:\n",
      "https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license\n",
      "\n",
      "NOTE: CUDA Forward Compatibility mode ENABLED.\n",
      "  Using CUDA 11.8 driver version 520.61.05 with kernel driver version 510.47.03.\n",
      "  See https://docs.nvidia.com/deploy/cuda-compatibility/ for details.\n",
      "\n",
      "Installing Transformers...\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Exporting model to ONNX...\n",
      "Framework not requested. Using torch to export to ONNX.\n",
      "Downloading: 100%|█████████████████████████████| 991/991 [00:00<00:00, 1.29MB/s]\n",
      "Downloading: 100%|█████████████████████████| 51.1M/51.1M [00:00<00:00, 86.2MB/s]\n",
      "Downloading: 100%|██████████████████████████████| 365/365 [00:00<00:00, 464kB/s]\n",
      "Downloading: 100%|████████████████████████████| 232k/232k [00:00<00:00, 951kB/s]\n",
      "Downloading: 100%|███████████████████████████| 466k/466k [00:00<00:00, 1.84MB/s]\n",
      "Downloading: 100%|██████████████████████████████| 112/112 [00:00<00:00, 140kB/s]\n",
      "Using framework PyTorch: 1.14.0a0+410ce96\n",
      "Overriding 1 configuration item(s)\n",
      "\t- use_cache -> False\n",
      "Validating ONNX model...\n",
      "\t-[✓] ONNX model output names match reference model ({'logits'})\n",
      "\t- Validating ONNX Model output \"logits\":\n",
      "\t\t-[✓] (3, 6) matches (3, 6)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "All good, model saved at: /workspace/onnx/model.onnx\n",
      "Converting ONNX Model to TensorRT FP16 Plan...\n",
      "&&&& RUNNING TensorRT.trtexec [TensorRT v8501] # trtexec --onnx=/workspace/onnx/model.onnx --saveEngine=/workspace/model.plan --minShapes=input_ids:1x128,attention_mask:1x128,token_type_ids:1x128 --optShapes=input_ids:16x128,attention_mask:16x128,token_type_ids:16x128 --maxShapes=input_ids:224x128,attention_mask:224x128,token_type_ids:224x128 --fp16 --verbose --memPoolSize=workspace:14000\n",
      "[01/20/2023-00:15:56] [I] === Model Options ===\n",
      "[01/20/2023-00:15:56] [I] Format: ONNX\n",
      "[01/20/2023-00:15:56] [I] Model: /workspace/onnx/model.onnx\n",
      "[01/20/2023-00:15:56] [I] Output:\n",
      "[01/20/2023-00:15:56] [I] === Build Options ===\n",
      "[01/20/2023-00:15:56] [I] Max batch: explicit batch\n",
      "[01/20/2023-00:15:56] [I] Memory Pools: workspace: 14000 MiB, dlaSRAM: default, dlaLocalDRAM: default, dlaGlobalDRAM: default\n",
      "[01/20/2023-00:15:56] [I] minTiming: 1\n",
      "[01/20/2023-00:15:56] [I] avgTiming: 8\n",
      "[01/20/2023-00:15:56] [I] Precision: FP32+FP16\n",
      "[01/20/2023-00:15:56] [I] LayerPrecisions: \n",
      "[01/20/2023-00:15:56] [I] Calibration: \n",
      "[01/20/2023-00:15:56] [I] Refit: Disabled\n",
      "[01/20/2023-00:15:56] [I] Sparsity: Disabled\n",
      "[01/20/2023-00:15:56] [I] Safe mode: Disabled\n",
      "[01/20/2023-00:15:56] [I] DirectIO mode: Disabled\n",
      "[01/20/2023-00:15:56] [I] Restricted mode: Disabled\n",
      "[01/20/2023-00:15:56] [I] Build only: Disabled\n",
      "[01/20/2023-00:15:56] [I] Save engine: /workspace/model.plan\n",
      "[01/20/2023-00:15:56] [I] Load engine: \n",
      "[01/20/2023-00:15:56] [I] Profiling verbosity: 0\n",
      "[01/20/2023-00:15:56] [I] Tactic sources: Using default tactic sources\n",
      "[01/20/2023-00:15:56] [I] timingCacheMode: local\n",
      "[01/20/2023-00:15:56] [I] timingCacheFile: \n",
      "[01/20/2023-00:15:56] [I] Heuristic: Disabled\n",
      "[01/20/2023-00:15:56] [I] Preview Features: Use default preview flags.\n",
      "[01/20/2023-00:15:56] [I] Input(s)s format: fp32:CHW\n",
      "[01/20/2023-00:15:56] [I] Output(s)s format: fp32:CHW\n",
      "[01/20/2023-00:15:56] [I] Input build shape: input_ids=1x128+16x128+224x128\n",
      "[01/20/2023-00:15:56] [I] Input build shape: attention_mask=1x128+16x128+224x128\n",
      "[01/20/2023-00:15:56] [I] Input build shape: token_type_ids=1x128+16x128+224x128\n",
      "[01/20/2023-00:15:56] [I] Input calibration shapes: model\n",
      "[01/20/2023-00:15:56] [I] === System Options ===\n",
      "[01/20/2023-00:15:56] [I] Device: 0\n",
      "[01/20/2023-00:15:56] [I] DLACore: \n",
      "[01/20/2023-00:15:56] [I] Plugins:\n",
      "[01/20/2023-00:15:56] [I] === Inference Options ===\n",
      "[01/20/2023-00:15:56] [I] Batch: Explicit\n",
      "[01/20/2023-00:15:56] [I] Input inference shape: token_type_ids=16x128\n",
      "[01/20/2023-00:15:56] [I] Input inference shape: attention_mask=16x128\n",
      "[01/20/2023-00:15:56] [I] Input inference shape: input_ids=16x128\n",
      "[01/20/2023-00:15:56] [I] Iterations: 10\n",
      "[01/20/2023-00:15:56] [I] Duration: 3s (+ 200ms warm up)\n",
      "[01/20/2023-00:15:56] [I] Sleep time: 0ms\n",
      "[01/20/2023-00:15:56] [I] Idle time: 0ms\n",
      "[01/20/2023-00:15:56] [I] Streams: 1\n",
      "[01/20/2023-00:15:56] [I] ExposeDMA: Disabled\n",
      "[01/20/2023-00:15:56] [I] Data transfers: Enabled\n",
      "[01/20/2023-00:15:56] [I] Spin-wait: Disabled\n",
      "[01/20/2023-00:15:56] [I] Multithreading: Disabled\n",
      "[01/20/2023-00:15:56] [I] CUDA Graph: Disabled\n",
      "[01/20/2023-00:15:56] [I] Separate profiling: Disabled\n",
      "[01/20/2023-00:15:56] [I] Time Deserialize: Disabled\n",
      "[01/20/2023-00:15:56] [I] Time Refit: Disabled\n",
      "[01/20/2023-00:15:56] [I] NVTX verbosity: 0\n",
      "[01/20/2023-00:15:56] [I] Persistent Cache Ratio: 0\n",
      "[01/20/2023-00:15:56] [I] Inputs:\n",
      "[01/20/2023-00:15:56] [I] === Reporting Options ===\n",
      "[01/20/2023-00:15:56] [I] Verbose: Enabled\n",
      "[01/20/2023-00:15:56] [I] Averages: 10 inferences\n",
      "[01/20/2023-00:15:56] [I] Percentiles: 90,95,99\n",
      "[01/20/2023-00:15:56] [I] Dump refittable layers:Disabled\n",
      "[01/20/2023-00:15:56] [I] Dump output: Disabled\n",
      "[01/20/2023-00:15:56] [I] Profile: Disabled\n",
      "[01/20/2023-00:15:56] [I] Export timing to JSON file: \n",
      "[01/20/2023-00:15:56] [I] Export output to JSON file: \n",
      "[01/20/2023-00:15:56] [I] Export profile to JSON file: \n",
      "[01/20/2023-00:15:56] [I] \n",
      "[01/20/2023-00:15:56] [I] === Device Information ===\n",
      "[01/20/2023-00:15:56] [I] Selected Device: NVIDIA A10G\n",
      "[01/20/2023-00:15:56] [I] Compute Capability: 8.6\n",
      "[01/20/2023-00:15:56] [I] SMs: 80\n",
      "[01/20/2023-00:15:56] [I] Compute Clock Rate: 1.71 GHz\n",
      "[01/20/2023-00:15:56] [I] Device Global Memory: 22731 MiB\n",
      "[01/20/2023-00:15:56] [I] Shared Memory per SM: 100 KiB\n",
      "[01/20/2023-00:15:56] [I] Memory Bus Width: 384 bits (ECC enabled)\n",
      "[01/20/2023-00:15:56] [I] Memory Clock Rate: 6.251 GHz\n",
      "[01/20/2023-00:15:56] [I] \n",
      "[01/20/2023-00:15:56] [I] TensorRT version: 8.5.1\n",
      "[01/20/2023-00:15:56] [V] [TRT] Registered plugin creator - ::BatchTilePlugin_TRT version 1\n",
      "[01/20/2023-00:15:56] [V] [TRT] Registered plugin creator - ::BatchedNMS_TRT version 1\n",
      "[01/20/2023-00:15:56] [V] [TRT] Registered plugin creator - ::BatchedNMSDynamic_TRT version 1\n",
      "[01/20/2023-00:15:56] [V] [TRT] Registered plugin creator - ::Clip_TRT version 1\n",
      "[01/20/2023-00:15:56] [V] [TRT] Registered plugin creator - ::CoordConvAC version 1\n",
      "[01/20/2023-00:15:56] [V] [TRT] Registered plugin creator - ::CropAndResize version 1\n",
      "[01/20/2023-00:15:56] [V] [TRT] Registered plugin creator - ::CropAndResizeDynamic version 1\n",
      "[01/20/2023-00:15:56] [V] [TRT] Registered plugin creator - ::DecodeBbox3DPlugin version 1\n",
      "[01/20/2023-00:15:56] [V] [TRT] Registered plugin creator - ::DetectionLayer_TRT version 1\n",
      "[01/20/2023-00:15:56] [V] [TRT] Registered plugin creator - ::EfficientNMS_TRT version 1\n",
      "[01/20/2023-00:15:56] [V] [TRT] Registered plugin creator - ::EfficientNMS_ONNX_TRT version 1\n",
      "[01/20/2023-00:15:56] [V] [TRT] Registered plugin creator - ::EfficientNMS_Explicit_TF_TRT version 1\n",
      "[01/20/2023-00:15:56] [V] [TRT] Registered plugin creator - ::EfficientNMS_Implicit_TF_TRT version 1\n",
      "[01/20/2023-00:15:56] [V] [TRT] Registered plugin creator - ::FlattenConcat_TRT version 1\n",
      "[01/20/2023-00:15:56] [V] [TRT] Registered plugin creator - ::GenerateDetection_TRT version 1\n",
      "[01/20/2023-00:15:56] [V] [TRT] Registered plugin creator - ::GridAnchor_TRT version 1\n",
      "[01/20/2023-00:15:56] [V] [TRT] Registered plugin creator - ::GridAnchorRect_TRT version 1\n",
      "[01/20/2023-00:15:56] [V] [TRT] Registered plugin creator - ::GroupNorm version 1\n",
      "[01/20/2023-00:15:56] [V] [TRT] Registered plugin creator - ::InstanceNormalization_TRT version 1\n",
      "[01/20/2023-00:15:56] [V] [TRT] Registered plugin creator - ::LayerNorm version 1\n",
      "[01/20/2023-00:15:56] [V] [TRT] Registered plugin creator - ::LReLU_TRT version 1\n",
      "[01/20/2023-00:15:56] [V] [TRT] Registered plugin creator - ::MultilevelCropAndResize_TRT version 1\n",
      "[01/20/2023-00:15:56] [V] [TRT] Registered plugin creator - ::MultilevelProposeROI_TRT version 1\n",
      "[01/20/2023-00:15:56] [V] [TRT] Registered plugin creator - ::MultiscaleDeformableAttnPlugin_TRT version 1\n",
      "[01/20/2023-00:15:56] [V] [TRT] Registered plugin creator - ::NMS_TRT version 1\n",
      "[01/20/2023-00:15:56] [V] [TRT] Registered plugin creator - ::NMSDynamic_TRT version 1\n",
      "[01/20/2023-00:15:56] [V] [TRT] Registered plugin creator - ::Normalize_TRT version 1\n",
      "[01/20/2023-00:15:56] [V] [TRT] Registered plugin creator - ::PillarScatterPlugin version 1\n",
      "[01/20/2023-00:15:56] [V] [TRT] Registered plugin creator - ::PriorBox_TRT version 1\n",
      "[01/20/2023-00:15:56] [V] [TRT] Registered plugin creator - ::ProposalLayer_TRT version 1\n",
      "[01/20/2023-00:15:56] [V] [TRT] Registered plugin creator - ::Proposal version 1\n",
      "[01/20/2023-00:15:56] [V] [TRT] Registered plugin creator - ::ProposalDynamic version 1\n",
      "[01/20/2023-00:15:56] [V] [TRT] Registered plugin creator - ::PyramidROIAlign_TRT version 1\n",
      "[01/20/2023-00:15:56] [V] [TRT] Registered plugin creator - ::Region_TRT version 1\n",
      "[01/20/2023-00:15:56] [V] [TRT] Registered plugin creator - ::Reorg_TRT version 1\n",
      "[01/20/2023-00:15:56] [V] [TRT] Registered plugin creator - ::ResizeNearest_TRT version 1\n",
      "[01/20/2023-00:15:56] [V] [TRT] Registered plugin creator - ::RPROI_TRT version 1\n",
      "[01/20/2023-00:15:56] [V] [TRT] Registered plugin creator - ::ROIAlign_TRT version 1\n",
      "[01/20/2023-00:15:56] [V] [TRT] Registered plugin creator - ::ScatterND version 1\n",
      "[01/20/2023-00:15:56] [V] [TRT] Registered plugin creator - ::SeqLen2Spatial version 1\n",
      "[01/20/2023-00:15:56] [V] [TRT] Registered plugin creator - ::SpecialSlice_TRT version 1\n",
      "[01/20/2023-00:15:56] [V] [TRT] Registered plugin creator - ::SplitGeLU version 1\n",
      "[01/20/2023-00:15:56] [V] [TRT] Registered plugin creator - ::Split version 1\n",
      "[01/20/2023-00:15:56] [V] [TRT] Registered plugin creator - ::VoxelGeneratorPlugin version 1\n",
      "[01/20/2023-00:15:56] [I] [TRT] [MemUsageChange] Init CUDA: CPU +10, GPU +0, now: CPU 23, GPU 248 (MiB)\n",
      "[01/20/2023-00:15:57] [V] [TRT] Trying to load shared library libnvinfer_builder_resource.so.8.5.1\n",
      "[01/20/2023-00:15:57] [V] [TRT] Loaded shared library libnvinfer_builder_resource.so.8.5.1\n",
      "[01/20/2023-00:15:59] [I] [TRT] [MemUsageChange] Init builder kernel library: CPU +444, GPU +120, now: CPU 522, GPU 368 (MiB)\n",
      "[01/20/2023-00:15:59] [V] [TRT] CUDA lazy loading is enabled.\n",
      "[01/20/2023-00:15:59] [I] Start parsing network model\n",
      "[01/20/2023-00:15:59] [I] [TRT] ----------------------------------------------------------------\n",
      "[01/20/2023-00:15:59] [I] [TRT] Input filename:   /workspace/onnx/model.onnx\n",
      "[01/20/2023-00:15:59] [I] [TRT] ONNX IR version:  0.0.6\n",
      "[01/20/2023-00:15:59] [I] [TRT] Opset version:    11\n",
      "[01/20/2023-00:15:59] [I] [TRT] Producer name:    pytorch\n",
      "[01/20/2023-00:15:59] [I] [TRT] Producer version: 1.14.0\n",
      "[01/20/2023-00:15:59] [I] [TRT] Domain:           \n",
      "[01/20/2023-00:15:59] [I] [TRT] Model version:    0\n",
      "[01/20/2023-00:15:59] [I] [TRT] Doc string:       \n",
      "[01/20/2023-00:15:59] [I] [TRT] ----------------------------------------------------------------\n",
      "[01/20/2023-00:15:59] [V] [TRT] Plugin creator already registered - ::BatchTilePlugin_TRT version 1\n",
      "[01/20/2023-00:15:59] [V] [TRT] Plugin creator already registered - ::BatchedNMS_TRT version 1\n",
      "[01/20/2023-00:15:59] [V] [TRT] Plugin creator already registered - ::BatchedNMSDynamic_TRT version 1\n",
      "[01/20/2023-00:15:59] [V] [TRT] Plugin creator already registered - ::Clip_TRT version 1\n",
      "[01/20/2023-00:15:59] [V] [TRT] Plugin creator already registered - ::CoordConvAC version 1\n",
      "[01/20/2023-00:15:59] [V] [TRT] Plugin creator already registered - ::CropAndResize version 1\n",
      "[01/20/2023-00:15:59] [V] [TRT] Plugin creator already registered - ::CropAndResizeDynamic version 1\n",
      "[01/20/2023-00:15:59] [V] [TRT] Plugin creator already registered - ::DecodeBbox3DPlugin version 1\n",
      "[01/20/2023-00:15:59] [V] [TRT] Plugin creator already registered - ::DetectionLayer_TRT version 1\n",
      "[01/20/2023-00:15:59] [V] [TRT] Plugin creator already registered - ::EfficientNMS_TRT version 1\n",
      "[01/20/2023-00:15:59] [V] [TRT] Plugin creator already registered - ::EfficientNMS_ONNX_TRT version 1\n",
      "[01/20/2023-00:15:59] [V] [TRT] Plugin creator already registered - ::EfficientNMS_Explicit_TF_TRT version 1\n",
      "[01/20/2023-00:15:59] [V] [TRT] Plugin creator already registered - ::EfficientNMS_Implicit_TF_TRT version 1\n",
      "[01/20/2023-00:15:59] [V] [TRT] Plugin creator already registered - ::FlattenConcat_TRT version 1\n",
      "[01/20/2023-00:15:59] [V] [TRT] Plugin creator already registered - ::GenerateDetection_TRT version 1\n",
      "[01/20/2023-00:15:59] [V] [TRT] Plugin creator already registered - ::GridAnchor_TRT version 1\n",
      "[01/20/2023-00:15:59] [V] [TRT] Plugin creator already registered - ::GridAnchorRect_TRT version 1\n",
      "[01/20/2023-00:15:59] [V] [TRT] Plugin creator already registered - ::GroupNorm version 1\n",
      "[01/20/2023-00:15:59] [V] [TRT] Plugin creator already registered - ::InstanceNormalization_TRT version 1\n",
      "[01/20/2023-00:15:59] [V] [TRT] Plugin creator already registered - ::LayerNorm version 1\n",
      "[01/20/2023-00:15:59] [V] [TRT] Plugin creator already registered - ::LReLU_TRT version 1\n",
      "[01/20/2023-00:15:59] [V] [TRT] Plugin creator already registered - ::MultilevelCropAndResize_TRT version 1\n",
      "[01/20/2023-00:15:59] [V] [TRT] Plugin creator already registered - ::MultilevelProposeROI_TRT version 1\n",
      "[01/20/2023-00:15:59] [V] [TRT] Plugin creator already registered - ::MultiscaleDeformableAttnPlugin_TRT version 1\n",
      "[01/20/2023-00:15:59] [V] [TRT] Plugin creator already registered - ::NMS_TRT version 1\n",
      "[01/20/2023-00:15:59] [V] [TRT] Plugin creator already registered - ::NMSDynamic_TRT version 1\n",
      "[01/20/2023-00:15:59] [V] [TRT] Plugin creator already registered - ::Normalize_TRT version 1\n",
      "[01/20/2023-00:15:59] [V] [TRT] Plugin creator already registered - ::PillarScatterPlugin version 1\n",
      "[01/20/2023-00:15:59] [V] [TRT] Plugin creator already registered - ::PriorBox_TRT version 1\n",
      "[01/20/2023-00:15:59] [V] [TRT] Plugin creator already registered - ::ProposalLayer_TRT version 1\n",
      "[01/20/2023-00:15:59] [V] [TRT] Plugin creator already registered - ::Proposal version 1\n",
      "[01/20/2023-00:15:59] [V] [TRT] Plugin creator already registered - ::ProposalDynamic version 1\n",
      "[01/20/2023-00:15:59] [V] [TRT] Plugin creator already registered - ::PyramidROIAlign_TRT version 1\n",
      "[01/20/2023-00:15:59] [V] [TRT] Plugin creator already registered - ::Region_TRT version 1\n",
      "[01/20/2023-00:15:59] [V] [TRT] Plugin creator already registered - ::Reorg_TRT version 1\n",
      "[01/20/2023-00:15:59] [V] [TRT] Plugin creator already registered - ::ResizeNearest_TRT version 1\n",
      "[01/20/2023-00:15:59] [V] [TRT] Plugin creator already registered - ::RPROI_TRT version 1\n",
      "[01/20/2023-00:15:59] [V] [TRT] Plugin creator already registered - ::ROIAlign_TRT version 1\n",
      "[01/20/2023-00:15:59] [V] [TRT] Plugin creator already registered - ::ScatterND version 1\n",
      "[01/20/2023-00:15:59] [V] [TRT] Plugin creator already registered - ::SeqLen2Spatial version 1\n",
      "[01/20/2023-00:15:59] [V] [TRT] Plugin creator already registered - ::SpecialSlice_TRT version 1\n",
      "[01/20/2023-00:15:59] [V] [TRT] Plugin creator already registered - ::SplitGeLU version 1\n",
      "[01/20/2023-00:15:59] [V] [TRT] Plugin creator already registered - ::Split version 1\n",
      "[01/20/2023-00:15:59] [V] [TRT] Plugin creator already registered - ::VoxelGeneratorPlugin version 1\n",
      "[01/20/2023-00:15:59] [V] [TRT] Adding network input: input_ids with dtype: int32, dimensions: (-1, -1)\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: input_ids for ONNX tensor: input_ids\n",
      "[01/20/2023-00:15:59] [V] [TRT] Adding network input: attention_mask with dtype: int32, dimensions: (-1, -1)\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: attention_mask for ONNX tensor: attention_mask\n",
      "[01/20/2023-00:15:59] [V] [TRT] Adding network input: token_type_ids with dtype: int32, dimensions: (-1, -1)\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: token_type_ids for ONNX tensor: token_type_ids\n",
      "[01/20/2023-00:15:59] [V] [TRT] Importing initializer: bert.embeddings.position_ids\n",
      "[01/20/2023-00:15:59] [W] [TRT] parsers/onnx/onnx2trt_utils.cpp:375: Your ONNX model has been generated with INT64 weights, while TensorRT does not natively support INT64. Attempting to cast down to INT32.\n",
      "[01/20/2023-00:15:59] [V] [TRT] Importing initializer: bert.embeddings.word_embeddings.weight\n",
      "[01/20/2023-00:15:59] [V] [TRT] Importing initializer: bert.embeddings.position_embeddings.weight\n",
      "[01/20/2023-00:15:59] [V] [TRT] Importing initializer: bert.embeddings.token_type_embeddings.weight\n",
      "[01/20/2023-00:15:59] [V] [TRT] Importing initializer: bert.embeddings.LayerNorm.weight\n",
      "[01/20/2023-00:15:59] [V] [TRT] Importing initializer: bert.embeddings.LayerNorm.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Importing initializer: bert.encoder.layer.0.attention.self.query.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Importing initializer: bert.encoder.layer.0.attention.self.key.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Importing initializer: bert.encoder.layer.0.attention.self.value.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Importing initializer: bert.encoder.layer.0.attention.output.dense.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Importing initializer: bert.encoder.layer.0.attention.output.LayerNorm.weight\n",
      "[01/20/2023-00:15:59] [V] [TRT] Importing initializer: bert.encoder.layer.0.attention.output.LayerNorm.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Importing initializer: bert.encoder.layer.0.intermediate.dense.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Importing initializer: bert.encoder.layer.0.output.dense.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Importing initializer: bert.encoder.layer.0.output.LayerNorm.weight\n",
      "[01/20/2023-00:15:59] [V] [TRT] Importing initializer: bert.encoder.layer.0.output.LayerNorm.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Importing initializer: bert.encoder.layer.1.attention.self.query.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Importing initializer: bert.encoder.layer.1.attention.self.key.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Importing initializer: bert.encoder.layer.1.attention.self.value.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Importing initializer: bert.encoder.layer.1.attention.output.dense.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Importing initializer: bert.encoder.layer.1.attention.output.LayerNorm.weight\n",
      "[01/20/2023-00:15:59] [V] [TRT] Importing initializer: bert.encoder.layer.1.attention.output.LayerNorm.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Importing initializer: bert.encoder.layer.1.intermediate.dense.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Importing initializer: bert.encoder.layer.1.output.dense.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Importing initializer: bert.encoder.layer.1.output.LayerNorm.weight\n",
      "[01/20/2023-00:15:59] [V] [TRT] Importing initializer: bert.encoder.layer.1.output.LayerNorm.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Importing initializer: bert.encoder.layer.2.attention.self.query.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Importing initializer: bert.encoder.layer.2.attention.self.key.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Importing initializer: bert.encoder.layer.2.attention.self.value.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Importing initializer: bert.encoder.layer.2.attention.output.dense.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Importing initializer: bert.encoder.layer.2.attention.output.LayerNorm.weight\n",
      "[01/20/2023-00:15:59] [V] [TRT] Importing initializer: bert.encoder.layer.2.attention.output.LayerNorm.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Importing initializer: bert.encoder.layer.2.intermediate.dense.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Importing initializer: bert.encoder.layer.2.output.dense.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Importing initializer: bert.encoder.layer.2.output.LayerNorm.weight\n",
      "[01/20/2023-00:15:59] [V] [TRT] Importing initializer: bert.encoder.layer.2.output.LayerNorm.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Importing initializer: bert.encoder.layer.3.attention.self.query.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Importing initializer: bert.encoder.layer.3.attention.self.key.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Importing initializer: bert.encoder.layer.3.attention.self.value.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Importing initializer: bert.encoder.layer.3.attention.output.dense.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Importing initializer: bert.encoder.layer.3.attention.output.LayerNorm.weight\n",
      "[01/20/2023-00:15:59] [V] [TRT] Importing initializer: bert.encoder.layer.3.attention.output.LayerNorm.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Importing initializer: bert.encoder.layer.3.intermediate.dense.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Importing initializer: bert.encoder.layer.3.output.dense.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Importing initializer: bert.encoder.layer.3.output.LayerNorm.weight\n",
      "[01/20/2023-00:15:59] [V] [TRT] Importing initializer: bert.encoder.layer.3.output.LayerNorm.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Importing initializer: bert.encoder.layer.4.attention.self.query.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Importing initializer: bert.encoder.layer.4.attention.self.key.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Importing initializer: bert.encoder.layer.4.attention.self.value.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Importing initializer: bert.encoder.layer.4.attention.output.dense.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Importing initializer: bert.encoder.layer.4.attention.output.LayerNorm.weight\n",
      "[01/20/2023-00:15:59] [V] [TRT] Importing initializer: bert.encoder.layer.4.attention.output.LayerNorm.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Importing initializer: bert.encoder.layer.4.intermediate.dense.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Importing initializer: bert.encoder.layer.4.output.dense.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Importing initializer: bert.encoder.layer.4.output.LayerNorm.weight\n",
      "[01/20/2023-00:15:59] [V] [TRT] Importing initializer: bert.encoder.layer.4.output.LayerNorm.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Importing initializer: bert.encoder.layer.5.attention.self.query.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Importing initializer: bert.encoder.layer.5.attention.self.key.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Importing initializer: bert.encoder.layer.5.attention.self.value.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Importing initializer: bert.encoder.layer.5.attention.output.dense.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Importing initializer: bert.encoder.layer.5.attention.output.LayerNorm.weight\n",
      "[01/20/2023-00:15:59] [V] [TRT] Importing initializer: bert.encoder.layer.5.attention.output.LayerNorm.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Importing initializer: bert.encoder.layer.5.intermediate.dense.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Importing initializer: bert.encoder.layer.5.output.dense.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Importing initializer: bert.encoder.layer.5.output.LayerNorm.weight\n",
      "[01/20/2023-00:15:59] [V] [TRT] Importing initializer: bert.encoder.layer.5.output.LayerNorm.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Importing initializer: bert.pooler.dense.weight\n",
      "[01/20/2023-00:15:59] [V] [TRT] Importing initializer: bert.pooler.dense.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Importing initializer: classifier.weight\n",
      "[01/20/2023-00:15:59] [V] [TRT] Importing initializer: classifier.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Importing initializer: onnx::MatMul_793\n",
      "[01/20/2023-00:15:59] [V] [TRT] Importing initializer: onnx::MatMul_794\n",
      "[01/20/2023-00:15:59] [V] [TRT] Importing initializer: onnx::MatMul_797\n",
      "[01/20/2023-00:15:59] [V] [TRT] Importing initializer: onnx::MatMul_803\n",
      "[01/20/2023-00:15:59] [V] [TRT] Importing initializer: onnx::MatMul_804\n",
      "[01/20/2023-00:15:59] [V] [TRT] Importing initializer: onnx::MatMul_805\n",
      "[01/20/2023-00:15:59] [V] [TRT] Importing initializer: onnx::MatMul_806\n",
      "[01/20/2023-00:15:59] [V] [TRT] Importing initializer: onnx::MatMul_807\n",
      "[01/20/2023-00:15:59] [V] [TRT] Importing initializer: onnx::MatMul_810\n",
      "[01/20/2023-00:15:59] [V] [TRT] Importing initializer: onnx::MatMul_816\n",
      "[01/20/2023-00:15:59] [V] [TRT] Importing initializer: onnx::MatMul_817\n",
      "[01/20/2023-00:15:59] [V] [TRT] Importing initializer: onnx::MatMul_818\n",
      "[01/20/2023-00:15:59] [V] [TRT] Importing initializer: onnx::MatMul_819\n",
      "[01/20/2023-00:15:59] [V] [TRT] Importing initializer: onnx::MatMul_820\n",
      "[01/20/2023-00:15:59] [V] [TRT] Importing initializer: onnx::MatMul_823\n",
      "[01/20/2023-00:15:59] [V] [TRT] Importing initializer: onnx::MatMul_829\n",
      "[01/20/2023-00:15:59] [V] [TRT] Importing initializer: onnx::MatMul_830\n",
      "[01/20/2023-00:15:59] [V] [TRT] Importing initializer: onnx::MatMul_831\n",
      "[01/20/2023-00:15:59] [V] [TRT] Importing initializer: onnx::MatMul_832\n",
      "[01/20/2023-00:15:59] [V] [TRT] Importing initializer: onnx::MatMul_833\n",
      "[01/20/2023-00:15:59] [V] [TRT] Importing initializer: onnx::MatMul_836\n",
      "[01/20/2023-00:15:59] [V] [TRT] Importing initializer: onnx::MatMul_842\n",
      "[01/20/2023-00:15:59] [V] [TRT] Importing initializer: onnx::MatMul_843\n",
      "[01/20/2023-00:15:59] [V] [TRT] Importing initializer: onnx::MatMul_844\n",
      "[01/20/2023-00:15:59] [V] [TRT] Importing initializer: onnx::MatMul_845\n",
      "[01/20/2023-00:15:59] [V] [TRT] Importing initializer: onnx::MatMul_846\n",
      "[01/20/2023-00:15:59] [V] [TRT] Importing initializer: onnx::MatMul_849\n",
      "[01/20/2023-00:15:59] [V] [TRT] Importing initializer: onnx::MatMul_855\n",
      "[01/20/2023-00:15:59] [V] [TRT] Importing initializer: onnx::MatMul_856\n",
      "[01/20/2023-00:15:59] [V] [TRT] Importing initializer: onnx::MatMul_857\n",
      "[01/20/2023-00:15:59] [V] [TRT] Importing initializer: onnx::MatMul_858\n",
      "[01/20/2023-00:15:59] [V] [TRT] Importing initializer: onnx::MatMul_859\n",
      "[01/20/2023-00:15:59] [V] [TRT] Importing initializer: onnx::MatMul_862\n",
      "[01/20/2023-00:15:59] [V] [TRT] Importing initializer: onnx::MatMul_868\n",
      "[01/20/2023-00:15:59] [V] [TRT] Importing initializer: onnx::MatMul_869\n",
      "[01/20/2023-00:15:59] [V] [TRT] Importing initializer: onnx::MatMul_870\n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/Constant [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/Constant [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/Constant [Constant] outputs: [/bert/Constant_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/Unsqueeze [Unsqueeze]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: attention_mask\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/Unsqueeze [Unsqueeze] inputs: [attention_mask -> (-1, -1)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Original shape: (_, _), unsqueezing to: (_, _, _)\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/Unsqueeze for ONNX node: /bert/Unsqueeze\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/Unsqueeze_output_0 for ONNX tensor: /bert/Unsqueeze_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/Unsqueeze [Unsqueeze] outputs: [/bert/Unsqueeze_output_0 -> (-1, 1, -1)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/Unsqueeze_1 [Unsqueeze]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/Unsqueeze_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/Unsqueeze_1 [Unsqueeze] inputs: [/bert/Unsqueeze_output_0 -> (-1, 1, -1)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Original shape: (_, 1, _), unsqueezing to: (_, _, _, _)\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/Unsqueeze_1 for ONNX node: /bert/Unsqueeze_1\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/Unsqueeze_1_output_0 for ONNX tensor: /bert/Unsqueeze_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/Unsqueeze_1 [Unsqueeze] outputs: [/bert/Unsqueeze_1_output_0 -> (-1, 1, 1, -1)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/Cast [Cast]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/Unsqueeze_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/Cast [Cast] inputs: [/bert/Unsqueeze_1_output_0 -> (-1, 1, 1, -1)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Casting to type: float32\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/Cast for ONNX node: /bert/Cast\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/Cast_output_0 for ONNX tensor: /bert/Cast_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/Cast [Cast] outputs: [/bert/Cast_output_0 -> (-1, 1, 1, -1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/Constant_1 [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/Constant_1 [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/Constant_1 [Constant] outputs: [/bert/Constant_1_output_0 -> ()[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/Sub [Sub]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/Constant_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/Cast_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/Sub [Sub] inputs: [/bert/Constant_1_output_0 -> ()[FLOAT]], [/bert/Cast_output_0 -> (-1, 1, 1, -1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/Constant_1_output_0 for ONNX node: /bert/Constant_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/Sub for ONNX node: /bert/Sub\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/Sub_output_0 for ONNX tensor: /bert/Sub_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/Sub [Sub] outputs: [/bert/Sub_output_0 -> (-1, 1, 1, -1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/Constant_2 [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/Constant_2 [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/Constant_2 [Constant] outputs: [/bert/Constant_2_output_0 -> ()[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/Mul [Mul]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/Sub_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/Constant_2_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/Mul [Mul] inputs: [/bert/Sub_output_0 -> (-1, 1, 1, -1)[FLOAT]], [/bert/Constant_2_output_0 -> ()[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/Constant_2_output_0 for ONNX node: /bert/Constant_2_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/Mul for ONNX node: /bert/Mul\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/Mul_output_0 for ONNX tensor: /bert/Mul_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/Mul [Mul] outputs: [/bert/Mul_output_0 -> (-1, 1, 1, -1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/embeddings/Shape [Shape]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: input_ids\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/embeddings/Shape [Shape] inputs: [input_ids -> (-1, -1)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/embeddings/Shape for ONNX node: /bert/embeddings/Shape\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/embeddings/Shape_output_0 for ONNX tensor: /bert/embeddings/Shape_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/embeddings/Shape [Shape] outputs: [/bert/embeddings/Shape_output_0 -> (2)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/embeddings/Constant [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/embeddings/Constant [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/embeddings/Constant [Constant] outputs: [/bert/embeddings/Constant_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/embeddings/Gather [Gather]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/embeddings/Shape_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/embeddings/Constant_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/embeddings/Gather [Gather] inputs: [/bert/embeddings/Shape_output_0 -> (2)[INT32]], [/bert/embeddings/Constant_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/embeddings/Constant_output_0 for ONNX node: /bert/embeddings/Constant_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Using Gather axis: 0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/embeddings/Gather for ONNX node: /bert/embeddings/Gather\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/embeddings/Gather_output_0 for ONNX tensor: /bert/embeddings/Gather_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/embeddings/Gather [Gather] outputs: [/bert/embeddings/Gather_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/embeddings/Constant_1 [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/embeddings/Constant_1 [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/embeddings/Constant_1 [Constant] outputs: [/bert/embeddings/Constant_1_output_0 -> (1)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/embeddings/Unsqueeze [Unsqueeze]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/embeddings/Gather_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/embeddings/Unsqueeze [Unsqueeze] inputs: [/bert/embeddings/Gather_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/embeddings/Unsqueeze for ONNX node: /bert/embeddings/Unsqueeze\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/embeddings/Unsqueeze_output_0 for ONNX tensor: /bert/embeddings/Unsqueeze_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/embeddings/Unsqueeze [Unsqueeze] outputs: [/bert/embeddings/Unsqueeze_output_0 -> (1)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/embeddings/Constant_2 [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/embeddings/Constant_2 [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/embeddings/Constant_2 [Constant] outputs: [/bert/embeddings/Constant_2_output_0 -> (1)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/embeddings/Constant_3 [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/embeddings/Constant_3 [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/embeddings/Constant_3 [Constant] outputs: [/bert/embeddings/Constant_3_output_0 -> (1)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/embeddings/Slice [Slice]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: bert.embeddings.position_ids\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/embeddings/Constant_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/embeddings/Unsqueeze_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/embeddings/Constant_2_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/embeddings/Constant_3_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/embeddings/Slice [Slice] inputs: [bert.embeddings.position_ids -> (1, 512)[INT32]], [/bert/embeddings/Constant_1_output_0 -> (1)[INT32]], [/bert/embeddings/Unsqueeze_output_0 -> (1)[INT32]], [/bert/embeddings/Constant_2_output_0 -> (1)[INT32]], [/bert/embeddings/Constant_3_output_0 -> (1)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: bert.embeddings.position_ids for ONNX node: bert.embeddings.position_ids\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/embeddings/Slice for ONNX node: /bert/embeddings/Slice\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/embeddings/Slice_output_0 for ONNX tensor: /bert/embeddings/Slice_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/embeddings/Slice [Slice] outputs: [/bert/embeddings/Slice_output_0 -> (1, -1)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/embeddings/word_embeddings/Gather [Gather]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: bert.embeddings.word_embeddings.weight\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: input_ids\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/embeddings/word_embeddings/Gather [Gather] inputs: [bert.embeddings.word_embeddings.weight -> (30522, 256)[FLOAT]], [input_ids -> (-1, -1)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: bert.embeddings.word_embeddings.weight for ONNX node: bert.embeddings.word_embeddings.weight\n",
      "[01/20/2023-00:15:59] [V] [TRT] Using Gather axis: 0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/embeddings/word_embeddings/Gather for ONNX node: /bert/embeddings/word_embeddings/Gather\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/embeddings/word_embeddings/Gather_output_0 for ONNX tensor: /bert/embeddings/word_embeddings/Gather_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/embeddings/word_embeddings/Gather [Gather] outputs: [/bert/embeddings/word_embeddings/Gather_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/embeddings/token_type_embeddings/Gather [Gather]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: bert.embeddings.token_type_embeddings.weight\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: token_type_ids\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/embeddings/token_type_embeddings/Gather [Gather] inputs: [bert.embeddings.token_type_embeddings.weight -> (2, 256)[FLOAT]], [token_type_ids -> (-1, -1)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: bert.embeddings.token_type_embeddings.weight for ONNX node: bert.embeddings.token_type_embeddings.weight\n",
      "[01/20/2023-00:15:59] [V] [TRT] Using Gather axis: 0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/embeddings/token_type_embeddings/Gather for ONNX node: /bert/embeddings/token_type_embeddings/Gather\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/embeddings/token_type_embeddings/Gather_output_0 for ONNX tensor: /bert/embeddings/token_type_embeddings/Gather_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/embeddings/token_type_embeddings/Gather [Gather] outputs: [/bert/embeddings/token_type_embeddings/Gather_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/embeddings/Add [Add]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/embeddings/word_embeddings/Gather_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/embeddings/token_type_embeddings/Gather_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/embeddings/Add [Add] inputs: [/bert/embeddings/word_embeddings/Gather_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/embeddings/token_type_embeddings/Gather_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/embeddings/Add for ONNX node: /bert/embeddings/Add\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/embeddings/Add_output_0 for ONNX tensor: /bert/embeddings/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/embeddings/Add [Add] outputs: [/bert/embeddings/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/embeddings/position_embeddings/Gather [Gather]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: bert.embeddings.position_embeddings.weight\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/embeddings/Slice_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/embeddings/position_embeddings/Gather [Gather] inputs: [bert.embeddings.position_embeddings.weight -> (512, 256)[FLOAT]], [/bert/embeddings/Slice_output_0 -> (1, -1)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: bert.embeddings.position_embeddings.weight for ONNX node: bert.embeddings.position_embeddings.weight\n",
      "[01/20/2023-00:15:59] [V] [TRT] Using Gather axis: 0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/embeddings/position_embeddings/Gather for ONNX node: /bert/embeddings/position_embeddings/Gather\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/embeddings/position_embeddings/Gather_output_0 for ONNX tensor: /bert/embeddings/position_embeddings/Gather_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/embeddings/position_embeddings/Gather [Gather] outputs: [/bert/embeddings/position_embeddings/Gather_output_0 -> (1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/embeddings/Add_1 [Add]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/embeddings/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/embeddings/position_embeddings/Gather_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/embeddings/Add_1 [Add] inputs: [/bert/embeddings/Add_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/embeddings/position_embeddings/Gather_output_0 -> (1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/embeddings/Add_1 for ONNX node: /bert/embeddings/Add_1\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/embeddings/Add_1_output_0 for ONNX tensor: /bert/embeddings/Add_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/embeddings/Add_1 [Add] outputs: [/bert/embeddings/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/embeddings/LayerNorm/ReduceMean [ReduceMean]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/embeddings/Add_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/embeddings/LayerNorm/ReduceMean [ReduceMean] inputs: [/bert/embeddings/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/embeddings/LayerNorm/ReduceMean for ONNX node: /bert/embeddings/LayerNorm/ReduceMean\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/embeddings/LayerNorm/ReduceMean_output_0 for ONNX tensor: /bert/embeddings/LayerNorm/ReduceMean_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/embeddings/LayerNorm/ReduceMean [ReduceMean] outputs: [/bert/embeddings/LayerNorm/ReduceMean_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/embeddings/LayerNorm/Sub [Sub]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/embeddings/Add_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/embeddings/LayerNorm/ReduceMean_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/embeddings/LayerNorm/Sub [Sub] inputs: [/bert/embeddings/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/embeddings/LayerNorm/ReduceMean_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/embeddings/LayerNorm/Sub for ONNX node: /bert/embeddings/LayerNorm/Sub\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/embeddings/LayerNorm/Sub_output_0 for ONNX tensor: /bert/embeddings/LayerNorm/Sub_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/embeddings/LayerNorm/Sub [Sub] outputs: [/bert/embeddings/LayerNorm/Sub_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/embeddings/LayerNorm/Constant [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/embeddings/LayerNorm/Constant [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/embeddings/LayerNorm/Constant [Constant] outputs: [/bert/embeddings/LayerNorm/Constant_output_0 -> ()[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/embeddings/LayerNorm/Pow [Pow]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/embeddings/LayerNorm/Sub_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/embeddings/LayerNorm/Constant_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/embeddings/LayerNorm/Pow [Pow] inputs: [/bert/embeddings/LayerNorm/Sub_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/embeddings/LayerNorm/Constant_output_0 -> ()[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/embeddings/LayerNorm/Constant_output_0 for ONNX node: /bert/embeddings/LayerNorm/Constant_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/embeddings/LayerNorm/Pow for ONNX node: /bert/embeddings/LayerNorm/Pow\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/embeddings/LayerNorm/Pow_output_0 for ONNX tensor: /bert/embeddings/LayerNorm/Pow_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/embeddings/LayerNorm/Pow [Pow] outputs: [/bert/embeddings/LayerNorm/Pow_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/embeddings/LayerNorm/ReduceMean_1 [ReduceMean]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/embeddings/LayerNorm/Pow_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/embeddings/LayerNorm/ReduceMean_1 [ReduceMean] inputs: [/bert/embeddings/LayerNorm/Pow_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/embeddings/LayerNorm/ReduceMean_1 for ONNX node: /bert/embeddings/LayerNorm/ReduceMean_1\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/embeddings/LayerNorm/ReduceMean_1_output_0 for ONNX tensor: /bert/embeddings/LayerNorm/ReduceMean_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/embeddings/LayerNorm/ReduceMean_1 [ReduceMean] outputs: [/bert/embeddings/LayerNorm/ReduceMean_1_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/embeddings/LayerNorm/Constant_1 [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/embeddings/LayerNorm/Constant_1 [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/embeddings/LayerNorm/Constant_1 [Constant] outputs: [/bert/embeddings/LayerNorm/Constant_1_output_0 -> ()[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/embeddings/LayerNorm/Add [Add]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/embeddings/LayerNorm/ReduceMean_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/embeddings/LayerNorm/Constant_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/embeddings/LayerNorm/Add [Add] inputs: [/bert/embeddings/LayerNorm/ReduceMean_1_output_0 -> (-1, -1, 1)[FLOAT]], [/bert/embeddings/LayerNorm/Constant_1_output_0 -> ()[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/embeddings/LayerNorm/Constant_1_output_0 for ONNX node: /bert/embeddings/LayerNorm/Constant_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/embeddings/LayerNorm/Add for ONNX node: /bert/embeddings/LayerNorm/Add\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/embeddings/LayerNorm/Add_output_0 for ONNX tensor: /bert/embeddings/LayerNorm/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/embeddings/LayerNorm/Add [Add] outputs: [/bert/embeddings/LayerNorm/Add_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/embeddings/LayerNorm/Sqrt [Sqrt]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/embeddings/LayerNorm/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/embeddings/LayerNorm/Sqrt [Sqrt] inputs: [/bert/embeddings/LayerNorm/Add_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/embeddings/LayerNorm/Sqrt for ONNX node: /bert/embeddings/LayerNorm/Sqrt\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/embeddings/LayerNorm/Sqrt_output_0 for ONNX tensor: /bert/embeddings/LayerNorm/Sqrt_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/embeddings/LayerNorm/Sqrt [Sqrt] outputs: [/bert/embeddings/LayerNorm/Sqrt_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/embeddings/LayerNorm/Div [Div]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/embeddings/LayerNorm/Sub_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/embeddings/LayerNorm/Sqrt_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/embeddings/LayerNorm/Div [Div] inputs: [/bert/embeddings/LayerNorm/Sub_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/embeddings/LayerNorm/Sqrt_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/embeddings/LayerNorm/Div for ONNX node: /bert/embeddings/LayerNorm/Div\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/embeddings/LayerNorm/Div_output_0 for ONNX tensor: /bert/embeddings/LayerNorm/Div_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/embeddings/LayerNorm/Div [Div] outputs: [/bert/embeddings/LayerNorm/Div_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/embeddings/LayerNorm/Mul [Mul]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/embeddings/LayerNorm/Div_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: bert.embeddings.LayerNorm.weight\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/embeddings/LayerNorm/Mul [Mul] inputs: [/bert/embeddings/LayerNorm/Div_output_0 -> (-1, -1, 256)[FLOAT]], [bert.embeddings.LayerNorm.weight -> (256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: bert.embeddings.LayerNorm.weight for ONNX node: bert.embeddings.LayerNorm.weight\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/embeddings/LayerNorm/Mul for ONNX node: /bert/embeddings/LayerNorm/Mul\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/embeddings/LayerNorm/Mul_output_0 for ONNX tensor: /bert/embeddings/LayerNorm/Mul_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/embeddings/LayerNorm/Mul [Mul] outputs: [/bert/embeddings/LayerNorm/Mul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/embeddings/LayerNorm/Add_1 [Add]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/embeddings/LayerNorm/Mul_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: bert.embeddings.LayerNorm.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/embeddings/LayerNorm/Add_1 [Add] inputs: [/bert/embeddings/LayerNorm/Mul_output_0 -> (-1, -1, 256)[FLOAT]], [bert.embeddings.LayerNorm.bias -> (256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: bert.embeddings.LayerNorm.bias for ONNX node: bert.embeddings.LayerNorm.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/embeddings/LayerNorm/Add_1 for ONNX node: /bert/embeddings/LayerNorm/Add_1\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/embeddings/LayerNorm/Add_1_output_0 for ONNX tensor: /bert/embeddings/LayerNorm/Add_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/embeddings/LayerNorm/Add_1 [Add] outputs: [/bert/embeddings/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/query/MatMul [MatMul]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/embeddings/LayerNorm/Add_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: onnx::MatMul_793\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/self/query/MatMul [MatMul] inputs: [/bert/embeddings/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], [onnx::MatMul_793 -> (256, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: onnx::MatMul_793 for ONNX node: onnx::MatMul_793\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/query/MatMul for ONNX node: /bert/encoder/layer.0/attention/self/query/MatMul\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/query/MatMul_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/query/MatMul_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/self/query/MatMul [MatMul] outputs: [/bert/encoder/layer.0/attention/self/query/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/query/Add [Add]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: bert.encoder.layer.0.attention.self.query.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/query/MatMul_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/self/query/Add [Add] inputs: [bert.encoder.layer.0.attention.self.query.bias -> (256)[FLOAT]], [/bert/encoder/layer.0/attention/self/query/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: bert.encoder.layer.0.attention.self.query.bias for ONNX node: bert.encoder.layer.0.attention.self.query.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/query/Add for ONNX node: /bert/encoder/layer.0/attention/self/query/Add\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/query/Add_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/query/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/self/query/Add [Add] outputs: [/bert/encoder/layer.0/attention/self/query/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/key/MatMul [MatMul]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/embeddings/LayerNorm/Add_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: onnx::MatMul_794\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/self/key/MatMul [MatMul] inputs: [/bert/embeddings/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], [onnx::MatMul_794 -> (256, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: onnx::MatMul_794 for ONNX node: onnx::MatMul_794\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/key/MatMul for ONNX node: /bert/encoder/layer.0/attention/self/key/MatMul\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/key/MatMul_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/key/MatMul_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/self/key/MatMul [MatMul] outputs: [/bert/encoder/layer.0/attention/self/key/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/key/Add [Add]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: bert.encoder.layer.0.attention.self.key.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/key/MatMul_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/self/key/Add [Add] inputs: [bert.encoder.layer.0.attention.self.key.bias -> (256)[FLOAT]], [/bert/encoder/layer.0/attention/self/key/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: bert.encoder.layer.0.attention.self.key.bias for ONNX node: bert.encoder.layer.0.attention.self.key.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/key/Add for ONNX node: /bert/encoder/layer.0/attention/self/key/Add\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/key/Add_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/key/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/self/key/Add [Add] outputs: [/bert/encoder/layer.0/attention/self/key/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Shape [Shape]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/key/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/self/Shape [Shape] inputs: [/bert/encoder/layer.0/attention/self/key/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Shape for ONNX node: /bert/encoder/layer.0/attention/self/Shape\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/Shape_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/Shape_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/self/Shape [Shape] outputs: [/bert/encoder/layer.0/attention/self/Shape_output_0 -> (3)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Constant [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/self/Constant [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/self/Constant [Constant] outputs: [/bert/encoder/layer.0/attention/self/Constant_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Gather [Gather]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Shape_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Constant_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/self/Gather [Gather] inputs: [/bert/encoder/layer.0/attention/self/Shape_output_0 -> (3)[INT32]], [/bert/encoder/layer.0/attention/self/Constant_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Constant_output_0 for ONNX node: /bert/encoder/layer.0/attention/self/Constant_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Using Gather axis: 0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Gather for ONNX node: /bert/encoder/layer.0/attention/self/Gather\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/Gather_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/Gather_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/self/Gather [Gather] outputs: [/bert/encoder/layer.0/attention/self/Gather_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Shape_1 [Shape]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/key/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/self/Shape_1 [Shape] inputs: [/bert/encoder/layer.0/attention/self/key/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Shape_1 for ONNX node: /bert/encoder/layer.0/attention/self/Shape_1\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/Shape_1_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/Shape_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/self/Shape_1 [Shape] outputs: [/bert/encoder/layer.0/attention/self/Shape_1_output_0 -> (3)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Constant_1 [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/self/Constant_1 [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/self/Constant_1 [Constant] outputs: [/bert/encoder/layer.0/attention/self/Constant_1_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Gather_1 [Gather]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Shape_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Constant_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/self/Gather_1 [Gather] inputs: [/bert/encoder/layer.0/attention/self/Shape_1_output_0 -> (3)[INT32]], [/bert/encoder/layer.0/attention/self/Constant_1_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Constant_1_output_0 for ONNX node: /bert/encoder/layer.0/attention/self/Constant_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Using Gather axis: 0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Gather_1 for ONNX node: /bert/encoder/layer.0/attention/self/Gather_1\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/Gather_1_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/Gather_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/self/Gather_1 [Gather] outputs: [/bert/encoder/layer.0/attention/self/Gather_1_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Unsqueeze [Unsqueeze]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Gather_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/self/Unsqueeze [Unsqueeze] inputs: [/bert/encoder/layer.0/attention/self/Gather_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Unsqueeze for ONNX node: /bert/encoder/layer.0/attention/self/Unsqueeze\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/Unsqueeze_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/Unsqueeze_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/self/Unsqueeze [Unsqueeze] outputs: [/bert/encoder/layer.0/attention/self/Unsqueeze_output_0 -> (1)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Unsqueeze_1 [Unsqueeze]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Gather_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/self/Unsqueeze_1 [Unsqueeze] inputs: [/bert/encoder/layer.0/attention/self/Gather_1_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Unsqueeze_1 for ONNX node: /bert/encoder/layer.0/attention/self/Unsqueeze_1\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/Unsqueeze_1_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/Unsqueeze_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/self/Unsqueeze_1 [Unsqueeze] outputs: [/bert/encoder/layer.0/attention/self/Unsqueeze_1_output_0 -> (1)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Constant_2 [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/self/Constant_2 [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/self/Constant_2 [Constant] outputs: [/bert/encoder/layer.0/attention/self/Constant_2_output_0 -> (1)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Constant_3 [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/self/Constant_3 [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/self/Constant_3 [Constant] outputs: [/bert/encoder/layer.0/attention/self/Constant_3_output_0 -> (1)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Concat [Concat]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Unsqueeze_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Unsqueeze_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Constant_2_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Constant_3_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/self/Concat [Concat] inputs: [/bert/encoder/layer.0/attention/self/Unsqueeze_output_0 -> (1)[INT32]], [/bert/encoder/layer.0/attention/self/Unsqueeze_1_output_0 -> (1)[INT32]], [/bert/encoder/layer.0/attention/self/Constant_2_output_0 -> (1)[INT32]], [/bert/encoder/layer.0/attention/self/Constant_3_output_0 -> (1)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Constant_2_output_0 for ONNX node: /bert/encoder/layer.0/attention/self/Constant_2_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Constant_3_output_0 for ONNX node: /bert/encoder/layer.0/attention/self/Constant_3_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Concat for ONNX node: /bert/encoder/layer.0/attention/self/Concat\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/Concat_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/Concat_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/self/Concat [Concat] outputs: [/bert/encoder/layer.0/attention/self/Concat_output_0 -> (4)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Reshape [Reshape]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/key/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Concat_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/self/Reshape [Reshape] inputs: [/bert/encoder/layer.0/attention/self/key/Add_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.0/attention/self/Concat_output_0 -> (4)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Reshape for ONNX node: /bert/encoder/layer.0/attention/self/Reshape\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/Reshape_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/Reshape_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/self/Reshape [Reshape] outputs: [/bert/encoder/layer.0/attention/self/Reshape_output_0 -> (-1, -1, 8, 32)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/value/MatMul [MatMul]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/embeddings/LayerNorm/Add_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: onnx::MatMul_797\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/self/value/MatMul [MatMul] inputs: [/bert/embeddings/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], [onnx::MatMul_797 -> (256, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: onnx::MatMul_797 for ONNX node: onnx::MatMul_797\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/value/MatMul for ONNX node: /bert/encoder/layer.0/attention/self/value/MatMul\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/value/MatMul_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/value/MatMul_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/self/value/MatMul [MatMul] outputs: [/bert/encoder/layer.0/attention/self/value/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/value/Add [Add]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: bert.encoder.layer.0.attention.self.value.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/value/MatMul_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/self/value/Add [Add] inputs: [bert.encoder.layer.0.attention.self.value.bias -> (256)[FLOAT]], [/bert/encoder/layer.0/attention/self/value/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: bert.encoder.layer.0.attention.self.value.bias for ONNX node: bert.encoder.layer.0.attention.self.value.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/value/Add for ONNX node: /bert/encoder/layer.0/attention/self/value/Add\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/value/Add_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/value/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/self/value/Add [Add] outputs: [/bert/encoder/layer.0/attention/self/value/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Shape_2 [Shape]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/value/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/self/Shape_2 [Shape] inputs: [/bert/encoder/layer.0/attention/self/value/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Shape_2 for ONNX node: /bert/encoder/layer.0/attention/self/Shape_2\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/Shape_2_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/Shape_2_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/self/Shape_2 [Shape] outputs: [/bert/encoder/layer.0/attention/self/Shape_2_output_0 -> (3)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Constant_4 [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/self/Constant_4 [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/self/Constant_4 [Constant] outputs: [/bert/encoder/layer.0/attention/self/Constant_4_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Gather_2 [Gather]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Shape_2_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Constant_4_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/self/Gather_2 [Gather] inputs: [/bert/encoder/layer.0/attention/self/Shape_2_output_0 -> (3)[INT32]], [/bert/encoder/layer.0/attention/self/Constant_4_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Constant_4_output_0 for ONNX node: /bert/encoder/layer.0/attention/self/Constant_4_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Using Gather axis: 0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Gather_2 for ONNX node: /bert/encoder/layer.0/attention/self/Gather_2\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/Gather_2_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/Gather_2_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/self/Gather_2 [Gather] outputs: [/bert/encoder/layer.0/attention/self/Gather_2_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Shape_3 [Shape]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/value/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/self/Shape_3 [Shape] inputs: [/bert/encoder/layer.0/attention/self/value/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Shape_3 for ONNX node: /bert/encoder/layer.0/attention/self/Shape_3\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/Shape_3_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/Shape_3_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/self/Shape_3 [Shape] outputs: [/bert/encoder/layer.0/attention/self/Shape_3_output_0 -> (3)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Constant_5 [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/self/Constant_5 [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/self/Constant_5 [Constant] outputs: [/bert/encoder/layer.0/attention/self/Constant_5_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Gather_3 [Gather]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Shape_3_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Constant_5_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/self/Gather_3 [Gather] inputs: [/bert/encoder/layer.0/attention/self/Shape_3_output_0 -> (3)[INT32]], [/bert/encoder/layer.0/attention/self/Constant_5_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Constant_5_output_0 for ONNX node: /bert/encoder/layer.0/attention/self/Constant_5_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Using Gather axis: 0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Gather_3 for ONNX node: /bert/encoder/layer.0/attention/self/Gather_3\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/Gather_3_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/Gather_3_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/self/Gather_3 [Gather] outputs: [/bert/encoder/layer.0/attention/self/Gather_3_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Unsqueeze_2 [Unsqueeze]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Gather_2_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/self/Unsqueeze_2 [Unsqueeze] inputs: [/bert/encoder/layer.0/attention/self/Gather_2_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Unsqueeze_2 for ONNX node: /bert/encoder/layer.0/attention/self/Unsqueeze_2\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/Unsqueeze_2_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/Unsqueeze_2_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/self/Unsqueeze_2 [Unsqueeze] outputs: [/bert/encoder/layer.0/attention/self/Unsqueeze_2_output_0 -> (1)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Unsqueeze_3 [Unsqueeze]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Gather_3_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/self/Unsqueeze_3 [Unsqueeze] inputs: [/bert/encoder/layer.0/attention/self/Gather_3_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Unsqueeze_3 for ONNX node: /bert/encoder/layer.0/attention/self/Unsqueeze_3\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/Unsqueeze_3_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/Unsqueeze_3_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/self/Unsqueeze_3 [Unsqueeze] outputs: [/bert/encoder/layer.0/attention/self/Unsqueeze_3_output_0 -> (1)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Constant_6 [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/self/Constant_6 [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/self/Constant_6 [Constant] outputs: [/bert/encoder/layer.0/attention/self/Constant_6_output_0 -> (1)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Constant_7 [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/self/Constant_7 [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/self/Constant_7 [Constant] outputs: [/bert/encoder/layer.0/attention/self/Constant_7_output_0 -> (1)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Concat_1 [Concat]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Unsqueeze_2_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Unsqueeze_3_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Constant_6_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Constant_7_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/self/Concat_1 [Concat] inputs: [/bert/encoder/layer.0/attention/self/Unsqueeze_2_output_0 -> (1)[INT32]], [/bert/encoder/layer.0/attention/self/Unsqueeze_3_output_0 -> (1)[INT32]], [/bert/encoder/layer.0/attention/self/Constant_6_output_0 -> (1)[INT32]], [/bert/encoder/layer.0/attention/self/Constant_7_output_0 -> (1)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Constant_6_output_0 for ONNX node: /bert/encoder/layer.0/attention/self/Constant_6_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Constant_7_output_0 for ONNX node: /bert/encoder/layer.0/attention/self/Constant_7_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Concat_1 for ONNX node: /bert/encoder/layer.0/attention/self/Concat_1\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/Concat_1_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/Concat_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/self/Concat_1 [Concat] outputs: [/bert/encoder/layer.0/attention/self/Concat_1_output_0 -> (4)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Reshape_1 [Reshape]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/value/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Concat_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/self/Reshape_1 [Reshape] inputs: [/bert/encoder/layer.0/attention/self/value/Add_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.0/attention/self/Concat_1_output_0 -> (4)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Reshape_1 for ONNX node: /bert/encoder/layer.0/attention/self/Reshape_1\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/Reshape_1_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/Reshape_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/self/Reshape_1 [Reshape] outputs: [/bert/encoder/layer.0/attention/self/Reshape_1_output_0 -> (-1, -1, 8, 32)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Transpose [Transpose]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Reshape_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/self/Transpose [Transpose] inputs: [/bert/encoder/layer.0/attention/self/Reshape_1_output_0 -> (-1, -1, 8, 32)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Transpose for ONNX node: /bert/encoder/layer.0/attention/self/Transpose\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/Transpose_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/Transpose_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/self/Transpose [Transpose] outputs: [/bert/encoder/layer.0/attention/self/Transpose_output_0 -> (-1, 8, -1, 32)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Shape_4 [Shape]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/query/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/self/Shape_4 [Shape] inputs: [/bert/encoder/layer.0/attention/self/query/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Shape_4 for ONNX node: /bert/encoder/layer.0/attention/self/Shape_4\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/Shape_4_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/Shape_4_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/self/Shape_4 [Shape] outputs: [/bert/encoder/layer.0/attention/self/Shape_4_output_0 -> (3)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Constant_8 [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/self/Constant_8 [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/self/Constant_8 [Constant] outputs: [/bert/encoder/layer.0/attention/self/Constant_8_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Gather_4 [Gather]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Shape_4_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Constant_8_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/self/Gather_4 [Gather] inputs: [/bert/encoder/layer.0/attention/self/Shape_4_output_0 -> (3)[INT32]], [/bert/encoder/layer.0/attention/self/Constant_8_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Constant_8_output_0 for ONNX node: /bert/encoder/layer.0/attention/self/Constant_8_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Using Gather axis: 0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Gather_4 for ONNX node: /bert/encoder/layer.0/attention/self/Gather_4\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/Gather_4_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/Gather_4_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/self/Gather_4 [Gather] outputs: [/bert/encoder/layer.0/attention/self/Gather_4_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Shape_5 [Shape]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/query/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/self/Shape_5 [Shape] inputs: [/bert/encoder/layer.0/attention/self/query/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Shape_5 for ONNX node: /bert/encoder/layer.0/attention/self/Shape_5\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/Shape_5_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/Shape_5_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/self/Shape_5 [Shape] outputs: [/bert/encoder/layer.0/attention/self/Shape_5_output_0 -> (3)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Constant_9 [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/self/Constant_9 [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/self/Constant_9 [Constant] outputs: [/bert/encoder/layer.0/attention/self/Constant_9_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Gather_5 [Gather]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Shape_5_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Constant_9_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/self/Gather_5 [Gather] inputs: [/bert/encoder/layer.0/attention/self/Shape_5_output_0 -> (3)[INT32]], [/bert/encoder/layer.0/attention/self/Constant_9_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Constant_9_output_0 for ONNX node: /bert/encoder/layer.0/attention/self/Constant_9_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Using Gather axis: 0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Gather_5 for ONNX node: /bert/encoder/layer.0/attention/self/Gather_5\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/Gather_5_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/Gather_5_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/self/Gather_5 [Gather] outputs: [/bert/encoder/layer.0/attention/self/Gather_5_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Unsqueeze_4 [Unsqueeze]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Gather_4_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/self/Unsqueeze_4 [Unsqueeze] inputs: [/bert/encoder/layer.0/attention/self/Gather_4_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Unsqueeze_4 for ONNX node: /bert/encoder/layer.0/attention/self/Unsqueeze_4\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/Unsqueeze_4_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/Unsqueeze_4_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/self/Unsqueeze_4 [Unsqueeze] outputs: [/bert/encoder/layer.0/attention/self/Unsqueeze_4_output_0 -> (1)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Unsqueeze_5 [Unsqueeze]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Gather_5_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/self/Unsqueeze_5 [Unsqueeze] inputs: [/bert/encoder/layer.0/attention/self/Gather_5_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Unsqueeze_5 for ONNX node: /bert/encoder/layer.0/attention/self/Unsqueeze_5\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/Unsqueeze_5_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/Unsqueeze_5_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/self/Unsqueeze_5 [Unsqueeze] outputs: [/bert/encoder/layer.0/attention/self/Unsqueeze_5_output_0 -> (1)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Constant_10 [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/self/Constant_10 [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/self/Constant_10 [Constant] outputs: [/bert/encoder/layer.0/attention/self/Constant_10_output_0 -> (1)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Constant_11 [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/self/Constant_11 [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/self/Constant_11 [Constant] outputs: [/bert/encoder/layer.0/attention/self/Constant_11_output_0 -> (1)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Concat_2 [Concat]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Unsqueeze_4_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Unsqueeze_5_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Constant_10_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Constant_11_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/self/Concat_2 [Concat] inputs: [/bert/encoder/layer.0/attention/self/Unsqueeze_4_output_0 -> (1)[INT32]], [/bert/encoder/layer.0/attention/self/Unsqueeze_5_output_0 -> (1)[INT32]], [/bert/encoder/layer.0/attention/self/Constant_10_output_0 -> (1)[INT32]], [/bert/encoder/layer.0/attention/self/Constant_11_output_0 -> (1)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Constant_10_output_0 for ONNX node: /bert/encoder/layer.0/attention/self/Constant_10_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Constant_11_output_0 for ONNX node: /bert/encoder/layer.0/attention/self/Constant_11_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Concat_2 for ONNX node: /bert/encoder/layer.0/attention/self/Concat_2\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/Concat_2_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/Concat_2_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/self/Concat_2 [Concat] outputs: [/bert/encoder/layer.0/attention/self/Concat_2_output_0 -> (4)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Reshape_2 [Reshape]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/query/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Concat_2_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/self/Reshape_2 [Reshape] inputs: [/bert/encoder/layer.0/attention/self/query/Add_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.0/attention/self/Concat_2_output_0 -> (4)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Reshape_2 for ONNX node: /bert/encoder/layer.0/attention/self/Reshape_2\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/Reshape_2_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/Reshape_2_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/self/Reshape_2 [Reshape] outputs: [/bert/encoder/layer.0/attention/self/Reshape_2_output_0 -> (-1, -1, 8, 32)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Transpose_1 [Transpose]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Reshape_2_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/self/Transpose_1 [Transpose] inputs: [/bert/encoder/layer.0/attention/self/Reshape_2_output_0 -> (-1, -1, 8, 32)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Transpose_1 for ONNX node: /bert/encoder/layer.0/attention/self/Transpose_1\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/Transpose_1_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/Transpose_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/self/Transpose_1 [Transpose] outputs: [/bert/encoder/layer.0/attention/self/Transpose_1_output_0 -> (-1, 8, -1, 32)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Transpose_2 [Transpose]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Reshape_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/self/Transpose_2 [Transpose] inputs: [/bert/encoder/layer.0/attention/self/Reshape_output_0 -> (-1, -1, 8, 32)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Transpose_2 for ONNX node: /bert/encoder/layer.0/attention/self/Transpose_2\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/Transpose_2_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/Transpose_2_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/self/Transpose_2 [Transpose] outputs: [/bert/encoder/layer.0/attention/self/Transpose_2_output_0 -> (-1, 8, 32, -1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/MatMul [MatMul]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Transpose_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Transpose_2_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/self/MatMul [MatMul] inputs: [/bert/encoder/layer.0/attention/self/Transpose_1_output_0 -> (-1, 8, -1, 32)[FLOAT]], [/bert/encoder/layer.0/attention/self/Transpose_2_output_0 -> (-1, 8, 32, -1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/MatMul for ONNX node: /bert/encoder/layer.0/attention/self/MatMul\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/MatMul_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/MatMul_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/self/MatMul [MatMul] outputs: [/bert/encoder/layer.0/attention/self/MatMul_output_0 -> (-1, 8, -1, -1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Constant_12 [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/self/Constant_12 [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/self/Constant_12 [Constant] outputs: [/bert/encoder/layer.0/attention/self/Constant_12_output_0 -> ()[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Div [Div]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/MatMul_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Constant_12_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/self/Div [Div] inputs: [/bert/encoder/layer.0/attention/self/MatMul_output_0 -> (-1, 8, -1, -1)[FLOAT]], [/bert/encoder/layer.0/attention/self/Constant_12_output_0 -> ()[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Constant_12_output_0 for ONNX node: /bert/encoder/layer.0/attention/self/Constant_12_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Div for ONNX node: /bert/encoder/layer.0/attention/self/Div\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/Div_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/Div_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/self/Div [Div] outputs: [/bert/encoder/layer.0/attention/self/Div_output_0 -> (-1, 8, -1, -1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Add [Add]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Div_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/Mul_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/self/Add [Add] inputs: [/bert/encoder/layer.0/attention/self/Div_output_0 -> (-1, 8, -1, -1)[FLOAT]], [/bert/Mul_output_0 -> (-1, 1, 1, -1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Add for ONNX node: /bert/encoder/layer.0/attention/self/Add\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/Add_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/self/Add [Add] outputs: [/bert/encoder/layer.0/attention/self/Add_output_0 -> (-1, 8, -1, -1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Softmax [Softmax]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/self/Softmax [Softmax] inputs: [/bert/encoder/layer.0/attention/self/Add_output_0 -> (-1, 8, -1, -1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Softmax for ONNX node: /bert/encoder/layer.0/attention/self/Softmax\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/Softmax_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/Softmax_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/self/Softmax [Softmax] outputs: [/bert/encoder/layer.0/attention/self/Softmax_output_0 -> (-1, 8, -1, -1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/MatMul_1 [MatMul]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Softmax_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Transpose_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/self/MatMul_1 [MatMul] inputs: [/bert/encoder/layer.0/attention/self/Softmax_output_0 -> (-1, 8, -1, -1)[FLOAT]], [/bert/encoder/layer.0/attention/self/Transpose_output_0 -> (-1, 8, -1, 32)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/MatMul_1 for ONNX node: /bert/encoder/layer.0/attention/self/MatMul_1\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/MatMul_1_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/MatMul_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/self/MatMul_1 [MatMul] outputs: [/bert/encoder/layer.0/attention/self/MatMul_1_output_0 -> (-1, 8, -1, 32)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Transpose_3 [Transpose]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/MatMul_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/self/Transpose_3 [Transpose] inputs: [/bert/encoder/layer.0/attention/self/MatMul_1_output_0 -> (-1, 8, -1, 32)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Transpose_3 for ONNX node: /bert/encoder/layer.0/attention/self/Transpose_3\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/Transpose_3_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/Transpose_3_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/self/Transpose_3 [Transpose] outputs: [/bert/encoder/layer.0/attention/self/Transpose_3_output_0 -> (-1, -1, 8, 32)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Shape_6 [Shape]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Transpose_3_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/self/Shape_6 [Shape] inputs: [/bert/encoder/layer.0/attention/self/Transpose_3_output_0 -> (-1, -1, 8, 32)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Shape_6 for ONNX node: /bert/encoder/layer.0/attention/self/Shape_6\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/Shape_6_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/Shape_6_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/self/Shape_6 [Shape] outputs: [/bert/encoder/layer.0/attention/self/Shape_6_output_0 -> (4)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Constant_13 [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/self/Constant_13 [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/self/Constant_13 [Constant] outputs: [/bert/encoder/layer.0/attention/self/Constant_13_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Gather_6 [Gather]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Shape_6_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Constant_13_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/self/Gather_6 [Gather] inputs: [/bert/encoder/layer.0/attention/self/Shape_6_output_0 -> (4)[INT32]], [/bert/encoder/layer.0/attention/self/Constant_13_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Constant_13_output_0 for ONNX node: /bert/encoder/layer.0/attention/self/Constant_13_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Using Gather axis: 0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Gather_6 for ONNX node: /bert/encoder/layer.0/attention/self/Gather_6\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/Gather_6_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/Gather_6_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/self/Gather_6 [Gather] outputs: [/bert/encoder/layer.0/attention/self/Gather_6_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Shape_7 [Shape]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Transpose_3_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/self/Shape_7 [Shape] inputs: [/bert/encoder/layer.0/attention/self/Transpose_3_output_0 -> (-1, -1, 8, 32)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Shape_7 for ONNX node: /bert/encoder/layer.0/attention/self/Shape_7\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/Shape_7_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/Shape_7_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/self/Shape_7 [Shape] outputs: [/bert/encoder/layer.0/attention/self/Shape_7_output_0 -> (4)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Constant_14 [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/self/Constant_14 [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/self/Constant_14 [Constant] outputs: [/bert/encoder/layer.0/attention/self/Constant_14_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Gather_7 [Gather]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Shape_7_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Constant_14_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/self/Gather_7 [Gather] inputs: [/bert/encoder/layer.0/attention/self/Shape_7_output_0 -> (4)[INT32]], [/bert/encoder/layer.0/attention/self/Constant_14_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Constant_14_output_0 for ONNX node: /bert/encoder/layer.0/attention/self/Constant_14_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Using Gather axis: 0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Gather_7 for ONNX node: /bert/encoder/layer.0/attention/self/Gather_7\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/Gather_7_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/Gather_7_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/self/Gather_7 [Gather] outputs: [/bert/encoder/layer.0/attention/self/Gather_7_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Unsqueeze_6 [Unsqueeze]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Gather_6_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/self/Unsqueeze_6 [Unsqueeze] inputs: [/bert/encoder/layer.0/attention/self/Gather_6_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Unsqueeze_6 for ONNX node: /bert/encoder/layer.0/attention/self/Unsqueeze_6\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/Unsqueeze_6_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/Unsqueeze_6_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/self/Unsqueeze_6 [Unsqueeze] outputs: [/bert/encoder/layer.0/attention/self/Unsqueeze_6_output_0 -> (1)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Unsqueeze_7 [Unsqueeze]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Gather_7_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/self/Unsqueeze_7 [Unsqueeze] inputs: [/bert/encoder/layer.0/attention/self/Gather_7_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Unsqueeze_7 for ONNX node: /bert/encoder/layer.0/attention/self/Unsqueeze_7\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/Unsqueeze_7_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/Unsqueeze_7_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/self/Unsqueeze_7 [Unsqueeze] outputs: [/bert/encoder/layer.0/attention/self/Unsqueeze_7_output_0 -> (1)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Constant_15 [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/self/Constant_15 [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/self/Constant_15 [Constant] outputs: [/bert/encoder/layer.0/attention/self/Constant_15_output_0 -> (1)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Concat_3 [Concat]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Unsqueeze_6_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Unsqueeze_7_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Constant_15_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/self/Concat_3 [Concat] inputs: [/bert/encoder/layer.0/attention/self/Unsqueeze_6_output_0 -> (1)[INT32]], [/bert/encoder/layer.0/attention/self/Unsqueeze_7_output_0 -> (1)[INT32]], [/bert/encoder/layer.0/attention/self/Constant_15_output_0 -> (1)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Constant_15_output_0 for ONNX node: /bert/encoder/layer.0/attention/self/Constant_15_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Concat_3 for ONNX node: /bert/encoder/layer.0/attention/self/Concat_3\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/Concat_3_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/Concat_3_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/self/Concat_3 [Concat] outputs: [/bert/encoder/layer.0/attention/self/Concat_3_output_0 -> (3)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Reshape_3 [Reshape]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Transpose_3_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Concat_3_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/self/Reshape_3 [Reshape] inputs: [/bert/encoder/layer.0/attention/self/Transpose_3_output_0 -> (-1, -1, 8, 32)[FLOAT]], [/bert/encoder/layer.0/attention/self/Concat_3_output_0 -> (3)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Reshape_3 for ONNX node: /bert/encoder/layer.0/attention/self/Reshape_3\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/Reshape_3_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/Reshape_3_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/self/Reshape_3 [Reshape] outputs: [/bert/encoder/layer.0/attention/self/Reshape_3_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/output/dense/MatMul [MatMul]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Reshape_3_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: onnx::MatMul_803\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/output/dense/MatMul [MatMul] inputs: [/bert/encoder/layer.0/attention/self/Reshape_3_output_0 -> (-1, -1, 256)[FLOAT]], [onnx::MatMul_803 -> (256, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: onnx::MatMul_803 for ONNX node: onnx::MatMul_803\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/output/dense/MatMul for ONNX node: /bert/encoder/layer.0/attention/output/dense/MatMul\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/output/dense/MatMul_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/output/dense/MatMul_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/output/dense/MatMul [MatMul] outputs: [/bert/encoder/layer.0/attention/output/dense/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/output/dense/Add [Add]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: bert.encoder.layer.0.attention.output.dense.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/output/dense/MatMul_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/output/dense/Add [Add] inputs: [bert.encoder.layer.0.attention.output.dense.bias -> (256)[FLOAT]], [/bert/encoder/layer.0/attention/output/dense/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: bert.encoder.layer.0.attention.output.dense.bias for ONNX node: bert.encoder.layer.0.attention.output.dense.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/output/dense/Add for ONNX node: /bert/encoder/layer.0/attention/output/dense/Add\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/output/dense/Add_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/output/dense/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/output/dense/Add [Add] outputs: [/bert/encoder/layer.0/attention/output/dense/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/output/Add [Add]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/output/dense/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/embeddings/LayerNorm/Add_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/output/Add [Add] inputs: [/bert/encoder/layer.0/attention/output/dense/Add_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/embeddings/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/output/Add for ONNX node: /bert/encoder/layer.0/attention/output/Add\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/output/Add_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/output/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/output/Add [Add] outputs: [/bert/encoder/layer.0/attention/output/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/output/LayerNorm/ReduceMean [ReduceMean]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/output/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/output/LayerNorm/ReduceMean [ReduceMean] inputs: [/bert/encoder/layer.0/attention/output/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/output/LayerNorm/ReduceMean for ONNX node: /bert/encoder/layer.0/attention/output/LayerNorm/ReduceMean\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/output/LayerNorm/ReduceMean_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/output/LayerNorm/ReduceMean_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/output/LayerNorm/ReduceMean [ReduceMean] outputs: [/bert/encoder/layer.0/attention/output/LayerNorm/ReduceMean_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/output/LayerNorm/Sub [Sub]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/output/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/output/LayerNorm/ReduceMean_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/output/LayerNorm/Sub [Sub] inputs: [/bert/encoder/layer.0/attention/output/Add_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.0/attention/output/LayerNorm/ReduceMean_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/output/LayerNorm/Sub for ONNX node: /bert/encoder/layer.0/attention/output/LayerNorm/Sub\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/output/LayerNorm/Sub_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/output/LayerNorm/Sub_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/output/LayerNorm/Sub [Sub] outputs: [/bert/encoder/layer.0/attention/output/LayerNorm/Sub_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/output/LayerNorm/Constant [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/output/LayerNorm/Constant [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/output/LayerNorm/Constant [Constant] outputs: [/bert/encoder/layer.0/attention/output/LayerNorm/Constant_output_0 -> ()[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/output/LayerNorm/Pow [Pow]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/output/LayerNorm/Sub_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/output/LayerNorm/Constant_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/output/LayerNorm/Pow [Pow] inputs: [/bert/encoder/layer.0/attention/output/LayerNorm/Sub_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.0/attention/output/LayerNorm/Constant_output_0 -> ()[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/output/LayerNorm/Constant_output_0 for ONNX node: /bert/encoder/layer.0/attention/output/LayerNorm/Constant_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/output/LayerNorm/Pow for ONNX node: /bert/encoder/layer.0/attention/output/LayerNorm/Pow\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/output/LayerNorm/Pow_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/output/LayerNorm/Pow_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/output/LayerNorm/Pow [Pow] outputs: [/bert/encoder/layer.0/attention/output/LayerNorm/Pow_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/output/LayerNorm/ReduceMean_1 [ReduceMean]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/output/LayerNorm/Pow_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/output/LayerNorm/ReduceMean_1 [ReduceMean] inputs: [/bert/encoder/layer.0/attention/output/LayerNorm/Pow_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/output/LayerNorm/ReduceMean_1 for ONNX node: /bert/encoder/layer.0/attention/output/LayerNorm/ReduceMean_1\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/output/LayerNorm/ReduceMean_1_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/output/LayerNorm/ReduceMean_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/output/LayerNorm/ReduceMean_1 [ReduceMean] outputs: [/bert/encoder/layer.0/attention/output/LayerNorm/ReduceMean_1_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/output/LayerNorm/Constant_1 [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/output/LayerNorm/Constant_1 [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/output/LayerNorm/Constant_1 [Constant] outputs: [/bert/encoder/layer.0/attention/output/LayerNorm/Constant_1_output_0 -> ()[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/output/LayerNorm/Add [Add]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/output/LayerNorm/ReduceMean_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/output/LayerNorm/Constant_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/output/LayerNorm/Add [Add] inputs: [/bert/encoder/layer.0/attention/output/LayerNorm/ReduceMean_1_output_0 -> (-1, -1, 1)[FLOAT]], [/bert/encoder/layer.0/attention/output/LayerNorm/Constant_1_output_0 -> ()[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/output/LayerNorm/Constant_1_output_0 for ONNX node: /bert/encoder/layer.0/attention/output/LayerNorm/Constant_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/output/LayerNorm/Add for ONNX node: /bert/encoder/layer.0/attention/output/LayerNorm/Add\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/output/LayerNorm/Add_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/output/LayerNorm/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/output/LayerNorm/Add [Add] outputs: [/bert/encoder/layer.0/attention/output/LayerNorm/Add_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/output/LayerNorm/Sqrt [Sqrt]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/output/LayerNorm/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/output/LayerNorm/Sqrt [Sqrt] inputs: [/bert/encoder/layer.0/attention/output/LayerNorm/Add_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/output/LayerNorm/Sqrt for ONNX node: /bert/encoder/layer.0/attention/output/LayerNorm/Sqrt\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/output/LayerNorm/Sqrt_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/output/LayerNorm/Sqrt_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/output/LayerNorm/Sqrt [Sqrt] outputs: [/bert/encoder/layer.0/attention/output/LayerNorm/Sqrt_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/output/LayerNorm/Div [Div]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/output/LayerNorm/Sub_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/output/LayerNorm/Sqrt_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/output/LayerNorm/Div [Div] inputs: [/bert/encoder/layer.0/attention/output/LayerNorm/Sub_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.0/attention/output/LayerNorm/Sqrt_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/output/LayerNorm/Div for ONNX node: /bert/encoder/layer.0/attention/output/LayerNorm/Div\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/output/LayerNorm/Div_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/output/LayerNorm/Div_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/output/LayerNorm/Div [Div] outputs: [/bert/encoder/layer.0/attention/output/LayerNorm/Div_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/output/LayerNorm/Mul [Mul]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/output/LayerNorm/Div_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: bert.encoder.layer.0.attention.output.LayerNorm.weight\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/output/LayerNorm/Mul [Mul] inputs: [/bert/encoder/layer.0/attention/output/LayerNorm/Div_output_0 -> (-1, -1, 256)[FLOAT]], [bert.encoder.layer.0.attention.output.LayerNorm.weight -> (256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: bert.encoder.layer.0.attention.output.LayerNorm.weight for ONNX node: bert.encoder.layer.0.attention.output.LayerNorm.weight\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/output/LayerNorm/Mul for ONNX node: /bert/encoder/layer.0/attention/output/LayerNorm/Mul\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/output/LayerNorm/Mul_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/output/LayerNorm/Mul_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/output/LayerNorm/Mul [Mul] outputs: [/bert/encoder/layer.0/attention/output/LayerNorm/Mul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/output/LayerNorm/Add_1 [Add]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/output/LayerNorm/Mul_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: bert.encoder.layer.0.attention.output.LayerNorm.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/output/LayerNorm/Add_1 [Add] inputs: [/bert/encoder/layer.0/attention/output/LayerNorm/Mul_output_0 -> (-1, -1, 256)[FLOAT]], [bert.encoder.layer.0.attention.output.LayerNorm.bias -> (256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: bert.encoder.layer.0.attention.output.LayerNorm.bias for ONNX node: bert.encoder.layer.0.attention.output.LayerNorm.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/output/LayerNorm/Add_1 for ONNX node: /bert/encoder/layer.0/attention/output/LayerNorm/Add_1\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/output/LayerNorm/Add_1_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/output/LayerNorm/Add_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/attention/output/LayerNorm/Add_1 [Add] outputs: [/bert/encoder/layer.0/attention/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.0/intermediate/dense/MatMul [MatMul]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/output/LayerNorm/Add_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: onnx::MatMul_804\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/intermediate/dense/MatMul [MatMul] inputs: [/bert/encoder/layer.0/attention/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], [onnx::MatMul_804 -> (256, 1024)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: onnx::MatMul_804 for ONNX node: onnx::MatMul_804\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.0/intermediate/dense/MatMul for ONNX node: /bert/encoder/layer.0/intermediate/dense/MatMul\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.0/intermediate/dense/MatMul_output_0 for ONNX tensor: /bert/encoder/layer.0/intermediate/dense/MatMul_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/intermediate/dense/MatMul [MatMul] outputs: [/bert/encoder/layer.0/intermediate/dense/MatMul_output_0 -> (-1, -1, 1024)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.0/intermediate/dense/Add [Add]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: bert.encoder.layer.0.intermediate.dense.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.0/intermediate/dense/MatMul_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/intermediate/dense/Add [Add] inputs: [bert.encoder.layer.0.intermediate.dense.bias -> (1024)[FLOAT]], [/bert/encoder/layer.0/intermediate/dense/MatMul_output_0 -> (-1, -1, 1024)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: bert.encoder.layer.0.intermediate.dense.bias for ONNX node: bert.encoder.layer.0.intermediate.dense.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.0/intermediate/dense/Add for ONNX node: /bert/encoder/layer.0/intermediate/dense/Add\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.0/intermediate/dense/Add_output_0 for ONNX tensor: /bert/encoder/layer.0/intermediate/dense/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/intermediate/dense/Add [Add] outputs: [/bert/encoder/layer.0/intermediate/dense/Add_output_0 -> (-1, -1, 1024)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.0/intermediate/intermediate_act_fn/Constant [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/intermediate/intermediate_act_fn/Constant [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/intermediate/intermediate_act_fn/Constant [Constant] outputs: [/bert/encoder/layer.0/intermediate/intermediate_act_fn/Constant_output_0 -> ()[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.0/intermediate/intermediate_act_fn/Div [Div]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.0/intermediate/dense/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.0/intermediate/intermediate_act_fn/Constant_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/intermediate/intermediate_act_fn/Div [Div] inputs: [/bert/encoder/layer.0/intermediate/dense/Add_output_0 -> (-1, -1, 1024)[FLOAT]], [/bert/encoder/layer.0/intermediate/intermediate_act_fn/Constant_output_0 -> ()[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.0/intermediate/intermediate_act_fn/Constant_output_0 for ONNX node: /bert/encoder/layer.0/intermediate/intermediate_act_fn/Constant_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.0/intermediate/intermediate_act_fn/Div for ONNX node: /bert/encoder/layer.0/intermediate/intermediate_act_fn/Div\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.0/intermediate/intermediate_act_fn/Div_output_0 for ONNX tensor: /bert/encoder/layer.0/intermediate/intermediate_act_fn/Div_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/intermediate/intermediate_act_fn/Div [Div] outputs: [/bert/encoder/layer.0/intermediate/intermediate_act_fn/Div_output_0 -> (-1, -1, 1024)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.0/intermediate/intermediate_act_fn/Erf [Erf]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.0/intermediate/intermediate_act_fn/Div_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/intermediate/intermediate_act_fn/Erf [Erf] inputs: [/bert/encoder/layer.0/intermediate/intermediate_act_fn/Div_output_0 -> (-1, -1, 1024)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.0/intermediate/intermediate_act_fn/Erf for ONNX node: /bert/encoder/layer.0/intermediate/intermediate_act_fn/Erf\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.0/intermediate/intermediate_act_fn/Erf_output_0 for ONNX tensor: /bert/encoder/layer.0/intermediate/intermediate_act_fn/Erf_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/intermediate/intermediate_act_fn/Erf [Erf] outputs: [/bert/encoder/layer.0/intermediate/intermediate_act_fn/Erf_output_0 -> (-1, -1, 1024)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.0/intermediate/intermediate_act_fn/Constant_1 [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/intermediate/intermediate_act_fn/Constant_1 [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/intermediate/intermediate_act_fn/Constant_1 [Constant] outputs: [/bert/encoder/layer.0/intermediate/intermediate_act_fn/Constant_1_output_0 -> ()[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.0/intermediate/intermediate_act_fn/Add [Add]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.0/intermediate/intermediate_act_fn/Erf_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.0/intermediate/intermediate_act_fn/Constant_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/intermediate/intermediate_act_fn/Add [Add] inputs: [/bert/encoder/layer.0/intermediate/intermediate_act_fn/Erf_output_0 -> (-1, -1, 1024)[FLOAT]], [/bert/encoder/layer.0/intermediate/intermediate_act_fn/Constant_1_output_0 -> ()[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.0/intermediate/intermediate_act_fn/Constant_1_output_0 for ONNX node: /bert/encoder/layer.0/intermediate/intermediate_act_fn/Constant_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.0/intermediate/intermediate_act_fn/Add for ONNX node: /bert/encoder/layer.0/intermediate/intermediate_act_fn/Add\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.0/intermediate/intermediate_act_fn/Add_output_0 for ONNX tensor: /bert/encoder/layer.0/intermediate/intermediate_act_fn/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/intermediate/intermediate_act_fn/Add [Add] outputs: [/bert/encoder/layer.0/intermediate/intermediate_act_fn/Add_output_0 -> (-1, -1, 1024)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.0/intermediate/intermediate_act_fn/Mul [Mul]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.0/intermediate/dense/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.0/intermediate/intermediate_act_fn/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/intermediate/intermediate_act_fn/Mul [Mul] inputs: [/bert/encoder/layer.0/intermediate/dense/Add_output_0 -> (-1, -1, 1024)[FLOAT]], [/bert/encoder/layer.0/intermediate/intermediate_act_fn/Add_output_0 -> (-1, -1, 1024)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.0/intermediate/intermediate_act_fn/Mul for ONNX node: /bert/encoder/layer.0/intermediate/intermediate_act_fn/Mul\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.0/intermediate/intermediate_act_fn/Mul_output_0 for ONNX tensor: /bert/encoder/layer.0/intermediate/intermediate_act_fn/Mul_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/intermediate/intermediate_act_fn/Mul [Mul] outputs: [/bert/encoder/layer.0/intermediate/intermediate_act_fn/Mul_output_0 -> (-1, -1, 1024)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.0/intermediate/intermediate_act_fn/Constant_2 [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/intermediate/intermediate_act_fn/Constant_2 [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/intermediate/intermediate_act_fn/Constant_2 [Constant] outputs: [/bert/encoder/layer.0/intermediate/intermediate_act_fn/Constant_2_output_0 -> ()[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.0/intermediate/intermediate_act_fn/Mul_1 [Mul]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.0/intermediate/intermediate_act_fn/Mul_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.0/intermediate/intermediate_act_fn/Constant_2_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/intermediate/intermediate_act_fn/Mul_1 [Mul] inputs: [/bert/encoder/layer.0/intermediate/intermediate_act_fn/Mul_output_0 -> (-1, -1, 1024)[FLOAT]], [/bert/encoder/layer.0/intermediate/intermediate_act_fn/Constant_2_output_0 -> ()[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.0/intermediate/intermediate_act_fn/Constant_2_output_0 for ONNX node: /bert/encoder/layer.0/intermediate/intermediate_act_fn/Constant_2_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.0/intermediate/intermediate_act_fn/Mul_1 for ONNX node: /bert/encoder/layer.0/intermediate/intermediate_act_fn/Mul_1\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.0/intermediate/intermediate_act_fn/Mul_1_output_0 for ONNX tensor: /bert/encoder/layer.0/intermediate/intermediate_act_fn/Mul_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/intermediate/intermediate_act_fn/Mul_1 [Mul] outputs: [/bert/encoder/layer.0/intermediate/intermediate_act_fn/Mul_1_output_0 -> (-1, -1, 1024)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.0/output/dense/MatMul [MatMul]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.0/intermediate/intermediate_act_fn/Mul_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: onnx::MatMul_805\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/output/dense/MatMul [MatMul] inputs: [/bert/encoder/layer.0/intermediate/intermediate_act_fn/Mul_1_output_0 -> (-1, -1, 1024)[FLOAT]], [onnx::MatMul_805 -> (1024, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: onnx::MatMul_805 for ONNX node: onnx::MatMul_805\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.0/output/dense/MatMul for ONNX node: /bert/encoder/layer.0/output/dense/MatMul\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.0/output/dense/MatMul_output_0 for ONNX tensor: /bert/encoder/layer.0/output/dense/MatMul_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/output/dense/MatMul [MatMul] outputs: [/bert/encoder/layer.0/output/dense/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.0/output/dense/Add [Add]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: bert.encoder.layer.0.output.dense.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.0/output/dense/MatMul_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/output/dense/Add [Add] inputs: [bert.encoder.layer.0.output.dense.bias -> (256)[FLOAT]], [/bert/encoder/layer.0/output/dense/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: bert.encoder.layer.0.output.dense.bias for ONNX node: bert.encoder.layer.0.output.dense.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.0/output/dense/Add for ONNX node: /bert/encoder/layer.0/output/dense/Add\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.0/output/dense/Add_output_0 for ONNX tensor: /bert/encoder/layer.0/output/dense/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/output/dense/Add [Add] outputs: [/bert/encoder/layer.0/output/dense/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.0/output/Add [Add]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.0/output/dense/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/output/LayerNorm/Add_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/output/Add [Add] inputs: [/bert/encoder/layer.0/output/dense/Add_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.0/attention/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.0/output/Add for ONNX node: /bert/encoder/layer.0/output/Add\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.0/output/Add_output_0 for ONNX tensor: /bert/encoder/layer.0/output/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/output/Add [Add] outputs: [/bert/encoder/layer.0/output/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.0/output/LayerNorm/ReduceMean [ReduceMean]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.0/output/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/output/LayerNorm/ReduceMean [ReduceMean] inputs: [/bert/encoder/layer.0/output/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.0/output/LayerNorm/ReduceMean for ONNX node: /bert/encoder/layer.0/output/LayerNorm/ReduceMean\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.0/output/LayerNorm/ReduceMean_output_0 for ONNX tensor: /bert/encoder/layer.0/output/LayerNorm/ReduceMean_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/output/LayerNorm/ReduceMean [ReduceMean] outputs: [/bert/encoder/layer.0/output/LayerNorm/ReduceMean_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.0/output/LayerNorm/Sub [Sub]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.0/output/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.0/output/LayerNorm/ReduceMean_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/output/LayerNorm/Sub [Sub] inputs: [/bert/encoder/layer.0/output/Add_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.0/output/LayerNorm/ReduceMean_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.0/output/LayerNorm/Sub for ONNX node: /bert/encoder/layer.0/output/LayerNorm/Sub\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.0/output/LayerNorm/Sub_output_0 for ONNX tensor: /bert/encoder/layer.0/output/LayerNorm/Sub_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/output/LayerNorm/Sub [Sub] outputs: [/bert/encoder/layer.0/output/LayerNorm/Sub_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.0/output/LayerNorm/Constant [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/output/LayerNorm/Constant [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/output/LayerNorm/Constant [Constant] outputs: [/bert/encoder/layer.0/output/LayerNorm/Constant_output_0 -> ()[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.0/output/LayerNorm/Pow [Pow]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.0/output/LayerNorm/Sub_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.0/output/LayerNorm/Constant_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/output/LayerNorm/Pow [Pow] inputs: [/bert/encoder/layer.0/output/LayerNorm/Sub_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.0/output/LayerNorm/Constant_output_0 -> ()[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.0/output/LayerNorm/Constant_output_0 for ONNX node: /bert/encoder/layer.0/output/LayerNorm/Constant_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.0/output/LayerNorm/Pow for ONNX node: /bert/encoder/layer.0/output/LayerNorm/Pow\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.0/output/LayerNorm/Pow_output_0 for ONNX tensor: /bert/encoder/layer.0/output/LayerNorm/Pow_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/output/LayerNorm/Pow [Pow] outputs: [/bert/encoder/layer.0/output/LayerNorm/Pow_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.0/output/LayerNorm/ReduceMean_1 [ReduceMean]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.0/output/LayerNorm/Pow_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/output/LayerNorm/ReduceMean_1 [ReduceMean] inputs: [/bert/encoder/layer.0/output/LayerNorm/Pow_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.0/output/LayerNorm/ReduceMean_1 for ONNX node: /bert/encoder/layer.0/output/LayerNorm/ReduceMean_1\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.0/output/LayerNorm/ReduceMean_1_output_0 for ONNX tensor: /bert/encoder/layer.0/output/LayerNorm/ReduceMean_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/output/LayerNorm/ReduceMean_1 [ReduceMean] outputs: [/bert/encoder/layer.0/output/LayerNorm/ReduceMean_1_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.0/output/LayerNorm/Constant_1 [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/output/LayerNorm/Constant_1 [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/output/LayerNorm/Constant_1 [Constant] outputs: [/bert/encoder/layer.0/output/LayerNorm/Constant_1_output_0 -> ()[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.0/output/LayerNorm/Add [Add]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.0/output/LayerNorm/ReduceMean_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.0/output/LayerNorm/Constant_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/output/LayerNorm/Add [Add] inputs: [/bert/encoder/layer.0/output/LayerNorm/ReduceMean_1_output_0 -> (-1, -1, 1)[FLOAT]], [/bert/encoder/layer.0/output/LayerNorm/Constant_1_output_0 -> ()[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.0/output/LayerNorm/Constant_1_output_0 for ONNX node: /bert/encoder/layer.0/output/LayerNorm/Constant_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.0/output/LayerNorm/Add for ONNX node: /bert/encoder/layer.0/output/LayerNorm/Add\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.0/output/LayerNorm/Add_output_0 for ONNX tensor: /bert/encoder/layer.0/output/LayerNorm/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/output/LayerNorm/Add [Add] outputs: [/bert/encoder/layer.0/output/LayerNorm/Add_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.0/output/LayerNorm/Sqrt [Sqrt]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.0/output/LayerNorm/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/output/LayerNorm/Sqrt [Sqrt] inputs: [/bert/encoder/layer.0/output/LayerNorm/Add_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.0/output/LayerNorm/Sqrt for ONNX node: /bert/encoder/layer.0/output/LayerNorm/Sqrt\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.0/output/LayerNorm/Sqrt_output_0 for ONNX tensor: /bert/encoder/layer.0/output/LayerNorm/Sqrt_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/output/LayerNorm/Sqrt [Sqrt] outputs: [/bert/encoder/layer.0/output/LayerNorm/Sqrt_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.0/output/LayerNorm/Div [Div]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.0/output/LayerNorm/Sub_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.0/output/LayerNorm/Sqrt_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/output/LayerNorm/Div [Div] inputs: [/bert/encoder/layer.0/output/LayerNorm/Sub_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.0/output/LayerNorm/Sqrt_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.0/output/LayerNorm/Div for ONNX node: /bert/encoder/layer.0/output/LayerNorm/Div\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.0/output/LayerNorm/Div_output_0 for ONNX tensor: /bert/encoder/layer.0/output/LayerNorm/Div_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/output/LayerNorm/Div [Div] outputs: [/bert/encoder/layer.0/output/LayerNorm/Div_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.0/output/LayerNorm/Mul [Mul]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.0/output/LayerNorm/Div_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: bert.encoder.layer.0.output.LayerNorm.weight\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/output/LayerNorm/Mul [Mul] inputs: [/bert/encoder/layer.0/output/LayerNorm/Div_output_0 -> (-1, -1, 256)[FLOAT]], [bert.encoder.layer.0.output.LayerNorm.weight -> (256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: bert.encoder.layer.0.output.LayerNorm.weight for ONNX node: bert.encoder.layer.0.output.LayerNorm.weight\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.0/output/LayerNorm/Mul for ONNX node: /bert/encoder/layer.0/output/LayerNorm/Mul\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.0/output/LayerNorm/Mul_output_0 for ONNX tensor: /bert/encoder/layer.0/output/LayerNorm/Mul_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/output/LayerNorm/Mul [Mul] outputs: [/bert/encoder/layer.0/output/LayerNorm/Mul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.0/output/LayerNorm/Add_1 [Add]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.0/output/LayerNorm/Mul_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: bert.encoder.layer.0.output.LayerNorm.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/output/LayerNorm/Add_1 [Add] inputs: [/bert/encoder/layer.0/output/LayerNorm/Mul_output_0 -> (-1, -1, 256)[FLOAT]], [bert.encoder.layer.0.output.LayerNorm.bias -> (256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: bert.encoder.layer.0.output.LayerNorm.bias for ONNX node: bert.encoder.layer.0.output.LayerNorm.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.0/output/LayerNorm/Add_1 for ONNX node: /bert/encoder/layer.0/output/LayerNorm/Add_1\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.0/output/LayerNorm/Add_1_output_0 for ONNX tensor: /bert/encoder/layer.0/output/LayerNorm/Add_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.0/output/LayerNorm/Add_1 [Add] outputs: [/bert/encoder/layer.0/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/query/MatMul [MatMul]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.0/output/LayerNorm/Add_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: onnx::MatMul_806\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/self/query/MatMul [MatMul] inputs: [/bert/encoder/layer.0/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], [onnx::MatMul_806 -> (256, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: onnx::MatMul_806 for ONNX node: onnx::MatMul_806\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/query/MatMul for ONNX node: /bert/encoder/layer.1/attention/self/query/MatMul\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/query/MatMul_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/query/MatMul_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/self/query/MatMul [MatMul] outputs: [/bert/encoder/layer.1/attention/self/query/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/query/Add [Add]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: bert.encoder.layer.1.attention.self.query.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/query/MatMul_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/self/query/Add [Add] inputs: [bert.encoder.layer.1.attention.self.query.bias -> (256)[FLOAT]], [/bert/encoder/layer.1/attention/self/query/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: bert.encoder.layer.1.attention.self.query.bias for ONNX node: bert.encoder.layer.1.attention.self.query.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/query/Add for ONNX node: /bert/encoder/layer.1/attention/self/query/Add\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/query/Add_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/query/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/self/query/Add [Add] outputs: [/bert/encoder/layer.1/attention/self/query/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/key/MatMul [MatMul]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.0/output/LayerNorm/Add_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: onnx::MatMul_807\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/self/key/MatMul [MatMul] inputs: [/bert/encoder/layer.0/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], [onnx::MatMul_807 -> (256, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: onnx::MatMul_807 for ONNX node: onnx::MatMul_807\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/key/MatMul for ONNX node: /bert/encoder/layer.1/attention/self/key/MatMul\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/key/MatMul_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/key/MatMul_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/self/key/MatMul [MatMul] outputs: [/bert/encoder/layer.1/attention/self/key/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/key/Add [Add]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: bert.encoder.layer.1.attention.self.key.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/key/MatMul_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/self/key/Add [Add] inputs: [bert.encoder.layer.1.attention.self.key.bias -> (256)[FLOAT]], [/bert/encoder/layer.1/attention/self/key/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: bert.encoder.layer.1.attention.self.key.bias for ONNX node: bert.encoder.layer.1.attention.self.key.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/key/Add for ONNX node: /bert/encoder/layer.1/attention/self/key/Add\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/key/Add_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/key/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/self/key/Add [Add] outputs: [/bert/encoder/layer.1/attention/self/key/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Shape [Shape]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/key/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/self/Shape [Shape] inputs: [/bert/encoder/layer.1/attention/self/key/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Shape for ONNX node: /bert/encoder/layer.1/attention/self/Shape\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/Shape_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/Shape_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/self/Shape [Shape] outputs: [/bert/encoder/layer.1/attention/self/Shape_output_0 -> (3)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Constant [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/self/Constant [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/self/Constant [Constant] outputs: [/bert/encoder/layer.1/attention/self/Constant_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Gather [Gather]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Shape_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Constant_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/self/Gather [Gather] inputs: [/bert/encoder/layer.1/attention/self/Shape_output_0 -> (3)[INT32]], [/bert/encoder/layer.1/attention/self/Constant_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Constant_output_0 for ONNX node: /bert/encoder/layer.1/attention/self/Constant_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Using Gather axis: 0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Gather for ONNX node: /bert/encoder/layer.1/attention/self/Gather\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/Gather_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/Gather_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/self/Gather [Gather] outputs: [/bert/encoder/layer.1/attention/self/Gather_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Shape_1 [Shape]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/key/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/self/Shape_1 [Shape] inputs: [/bert/encoder/layer.1/attention/self/key/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Shape_1 for ONNX node: /bert/encoder/layer.1/attention/self/Shape_1\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/Shape_1_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/Shape_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/self/Shape_1 [Shape] outputs: [/bert/encoder/layer.1/attention/self/Shape_1_output_0 -> (3)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Constant_1 [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/self/Constant_1 [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/self/Constant_1 [Constant] outputs: [/bert/encoder/layer.1/attention/self/Constant_1_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Gather_1 [Gather]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Shape_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Constant_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/self/Gather_1 [Gather] inputs: [/bert/encoder/layer.1/attention/self/Shape_1_output_0 -> (3)[INT32]], [/bert/encoder/layer.1/attention/self/Constant_1_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Constant_1_output_0 for ONNX node: /bert/encoder/layer.1/attention/self/Constant_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Using Gather axis: 0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Gather_1 for ONNX node: /bert/encoder/layer.1/attention/self/Gather_1\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/Gather_1_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/Gather_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/self/Gather_1 [Gather] outputs: [/bert/encoder/layer.1/attention/self/Gather_1_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Unsqueeze [Unsqueeze]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Gather_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/self/Unsqueeze [Unsqueeze] inputs: [/bert/encoder/layer.1/attention/self/Gather_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Unsqueeze for ONNX node: /bert/encoder/layer.1/attention/self/Unsqueeze\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/Unsqueeze_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/Unsqueeze_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/self/Unsqueeze [Unsqueeze] outputs: [/bert/encoder/layer.1/attention/self/Unsqueeze_output_0 -> (1)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Unsqueeze_1 [Unsqueeze]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Gather_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/self/Unsqueeze_1 [Unsqueeze] inputs: [/bert/encoder/layer.1/attention/self/Gather_1_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Unsqueeze_1 for ONNX node: /bert/encoder/layer.1/attention/self/Unsqueeze_1\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/Unsqueeze_1_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/Unsqueeze_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/self/Unsqueeze_1 [Unsqueeze] outputs: [/bert/encoder/layer.1/attention/self/Unsqueeze_1_output_0 -> (1)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Constant_2 [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/self/Constant_2 [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/self/Constant_2 [Constant] outputs: [/bert/encoder/layer.1/attention/self/Constant_2_output_0 -> (1)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Constant_3 [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/self/Constant_3 [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/self/Constant_3 [Constant] outputs: [/bert/encoder/layer.1/attention/self/Constant_3_output_0 -> (1)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Concat [Concat]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Unsqueeze_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Unsqueeze_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Constant_2_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Constant_3_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/self/Concat [Concat] inputs: [/bert/encoder/layer.1/attention/self/Unsqueeze_output_0 -> (1)[INT32]], [/bert/encoder/layer.1/attention/self/Unsqueeze_1_output_0 -> (1)[INT32]], [/bert/encoder/layer.1/attention/self/Constant_2_output_0 -> (1)[INT32]], [/bert/encoder/layer.1/attention/self/Constant_3_output_0 -> (1)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Constant_2_output_0 for ONNX node: /bert/encoder/layer.1/attention/self/Constant_2_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Constant_3_output_0 for ONNX node: /bert/encoder/layer.1/attention/self/Constant_3_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Concat for ONNX node: /bert/encoder/layer.1/attention/self/Concat\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/Concat_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/Concat_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/self/Concat [Concat] outputs: [/bert/encoder/layer.1/attention/self/Concat_output_0 -> (4)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Reshape [Reshape]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/key/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Concat_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/self/Reshape [Reshape] inputs: [/bert/encoder/layer.1/attention/self/key/Add_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.1/attention/self/Concat_output_0 -> (4)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Reshape for ONNX node: /bert/encoder/layer.1/attention/self/Reshape\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/Reshape_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/Reshape_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/self/Reshape [Reshape] outputs: [/bert/encoder/layer.1/attention/self/Reshape_output_0 -> (-1, -1, 8, 32)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/value/MatMul [MatMul]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.0/output/LayerNorm/Add_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: onnx::MatMul_810\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/self/value/MatMul [MatMul] inputs: [/bert/encoder/layer.0/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], [onnx::MatMul_810 -> (256, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: onnx::MatMul_810 for ONNX node: onnx::MatMul_810\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/value/MatMul for ONNX node: /bert/encoder/layer.1/attention/self/value/MatMul\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/value/MatMul_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/value/MatMul_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/self/value/MatMul [MatMul] outputs: [/bert/encoder/layer.1/attention/self/value/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/value/Add [Add]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: bert.encoder.layer.1.attention.self.value.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/value/MatMul_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/self/value/Add [Add] inputs: [bert.encoder.layer.1.attention.self.value.bias -> (256)[FLOAT]], [/bert/encoder/layer.1/attention/self/value/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: bert.encoder.layer.1.attention.self.value.bias for ONNX node: bert.encoder.layer.1.attention.self.value.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/value/Add for ONNX node: /bert/encoder/layer.1/attention/self/value/Add\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/value/Add_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/value/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/self/value/Add [Add] outputs: [/bert/encoder/layer.1/attention/self/value/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Shape_2 [Shape]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/value/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/self/Shape_2 [Shape] inputs: [/bert/encoder/layer.1/attention/self/value/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Shape_2 for ONNX node: /bert/encoder/layer.1/attention/self/Shape_2\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/Shape_2_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/Shape_2_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/self/Shape_2 [Shape] outputs: [/bert/encoder/layer.1/attention/self/Shape_2_output_0 -> (3)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Constant_4 [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/self/Constant_4 [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/self/Constant_4 [Constant] outputs: [/bert/encoder/layer.1/attention/self/Constant_4_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Gather_2 [Gather]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Shape_2_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Constant_4_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/self/Gather_2 [Gather] inputs: [/bert/encoder/layer.1/attention/self/Shape_2_output_0 -> (3)[INT32]], [/bert/encoder/layer.1/attention/self/Constant_4_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Constant_4_output_0 for ONNX node: /bert/encoder/layer.1/attention/self/Constant_4_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Using Gather axis: 0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Gather_2 for ONNX node: /bert/encoder/layer.1/attention/self/Gather_2\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/Gather_2_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/Gather_2_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/self/Gather_2 [Gather] outputs: [/bert/encoder/layer.1/attention/self/Gather_2_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Shape_3 [Shape]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/value/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/self/Shape_3 [Shape] inputs: [/bert/encoder/layer.1/attention/self/value/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Shape_3 for ONNX node: /bert/encoder/layer.1/attention/self/Shape_3\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/Shape_3_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/Shape_3_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/self/Shape_3 [Shape] outputs: [/bert/encoder/layer.1/attention/self/Shape_3_output_0 -> (3)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Constant_5 [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/self/Constant_5 [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/self/Constant_5 [Constant] outputs: [/bert/encoder/layer.1/attention/self/Constant_5_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Gather_3 [Gather]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Shape_3_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Constant_5_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/self/Gather_3 [Gather] inputs: [/bert/encoder/layer.1/attention/self/Shape_3_output_0 -> (3)[INT32]], [/bert/encoder/layer.1/attention/self/Constant_5_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Constant_5_output_0 for ONNX node: /bert/encoder/layer.1/attention/self/Constant_5_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Using Gather axis: 0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Gather_3 for ONNX node: /bert/encoder/layer.1/attention/self/Gather_3\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/Gather_3_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/Gather_3_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/self/Gather_3 [Gather] outputs: [/bert/encoder/layer.1/attention/self/Gather_3_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Unsqueeze_2 [Unsqueeze]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Gather_2_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/self/Unsqueeze_2 [Unsqueeze] inputs: [/bert/encoder/layer.1/attention/self/Gather_2_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Unsqueeze_2 for ONNX node: /bert/encoder/layer.1/attention/self/Unsqueeze_2\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/Unsqueeze_2_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/Unsqueeze_2_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/self/Unsqueeze_2 [Unsqueeze] outputs: [/bert/encoder/layer.1/attention/self/Unsqueeze_2_output_0 -> (1)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Unsqueeze_3 [Unsqueeze]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Gather_3_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/self/Unsqueeze_3 [Unsqueeze] inputs: [/bert/encoder/layer.1/attention/self/Gather_3_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Unsqueeze_3 for ONNX node: /bert/encoder/layer.1/attention/self/Unsqueeze_3\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/Unsqueeze_3_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/Unsqueeze_3_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/self/Unsqueeze_3 [Unsqueeze] outputs: [/bert/encoder/layer.1/attention/self/Unsqueeze_3_output_0 -> (1)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Constant_6 [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/self/Constant_6 [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/self/Constant_6 [Constant] outputs: [/bert/encoder/layer.1/attention/self/Constant_6_output_0 -> (1)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Constant_7 [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/self/Constant_7 [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/self/Constant_7 [Constant] outputs: [/bert/encoder/layer.1/attention/self/Constant_7_output_0 -> (1)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Concat_1 [Concat]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Unsqueeze_2_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Unsqueeze_3_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Constant_6_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Constant_7_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/self/Concat_1 [Concat] inputs: [/bert/encoder/layer.1/attention/self/Unsqueeze_2_output_0 -> (1)[INT32]], [/bert/encoder/layer.1/attention/self/Unsqueeze_3_output_0 -> (1)[INT32]], [/bert/encoder/layer.1/attention/self/Constant_6_output_0 -> (1)[INT32]], [/bert/encoder/layer.1/attention/self/Constant_7_output_0 -> (1)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Constant_6_output_0 for ONNX node: /bert/encoder/layer.1/attention/self/Constant_6_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Constant_7_output_0 for ONNX node: /bert/encoder/layer.1/attention/self/Constant_7_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Concat_1 for ONNX node: /bert/encoder/layer.1/attention/self/Concat_1\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/Concat_1_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/Concat_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/self/Concat_1 [Concat] outputs: [/bert/encoder/layer.1/attention/self/Concat_1_output_0 -> (4)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Reshape_1 [Reshape]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/value/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Concat_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/self/Reshape_1 [Reshape] inputs: [/bert/encoder/layer.1/attention/self/value/Add_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.1/attention/self/Concat_1_output_0 -> (4)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Reshape_1 for ONNX node: /bert/encoder/layer.1/attention/self/Reshape_1\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/Reshape_1_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/Reshape_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/self/Reshape_1 [Reshape] outputs: [/bert/encoder/layer.1/attention/self/Reshape_1_output_0 -> (-1, -1, 8, 32)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Transpose [Transpose]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Reshape_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/self/Transpose [Transpose] inputs: [/bert/encoder/layer.1/attention/self/Reshape_1_output_0 -> (-1, -1, 8, 32)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Transpose for ONNX node: /bert/encoder/layer.1/attention/self/Transpose\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/Transpose_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/Transpose_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/self/Transpose [Transpose] outputs: [/bert/encoder/layer.1/attention/self/Transpose_output_0 -> (-1, 8, -1, 32)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Shape_4 [Shape]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/query/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/self/Shape_4 [Shape] inputs: [/bert/encoder/layer.1/attention/self/query/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Shape_4 for ONNX node: /bert/encoder/layer.1/attention/self/Shape_4\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/Shape_4_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/Shape_4_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/self/Shape_4 [Shape] outputs: [/bert/encoder/layer.1/attention/self/Shape_4_output_0 -> (3)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Constant_8 [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/self/Constant_8 [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/self/Constant_8 [Constant] outputs: [/bert/encoder/layer.1/attention/self/Constant_8_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Gather_4 [Gather]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Shape_4_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Constant_8_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/self/Gather_4 [Gather] inputs: [/bert/encoder/layer.1/attention/self/Shape_4_output_0 -> (3)[INT32]], [/bert/encoder/layer.1/attention/self/Constant_8_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Constant_8_output_0 for ONNX node: /bert/encoder/layer.1/attention/self/Constant_8_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Using Gather axis: 0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Gather_4 for ONNX node: /bert/encoder/layer.1/attention/self/Gather_4\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/Gather_4_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/Gather_4_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/self/Gather_4 [Gather] outputs: [/bert/encoder/layer.1/attention/self/Gather_4_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Shape_5 [Shape]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/query/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/self/Shape_5 [Shape] inputs: [/bert/encoder/layer.1/attention/self/query/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Shape_5 for ONNX node: /bert/encoder/layer.1/attention/self/Shape_5\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/Shape_5_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/Shape_5_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/self/Shape_5 [Shape] outputs: [/bert/encoder/layer.1/attention/self/Shape_5_output_0 -> (3)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Constant_9 [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/self/Constant_9 [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/self/Constant_9 [Constant] outputs: [/bert/encoder/layer.1/attention/self/Constant_9_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Gather_5 [Gather]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Shape_5_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Constant_9_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/self/Gather_5 [Gather] inputs: [/bert/encoder/layer.1/attention/self/Shape_5_output_0 -> (3)[INT32]], [/bert/encoder/layer.1/attention/self/Constant_9_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Constant_9_output_0 for ONNX node: /bert/encoder/layer.1/attention/self/Constant_9_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Using Gather axis: 0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Gather_5 for ONNX node: /bert/encoder/layer.1/attention/self/Gather_5\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/Gather_5_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/Gather_5_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/self/Gather_5 [Gather] outputs: [/bert/encoder/layer.1/attention/self/Gather_5_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Unsqueeze_4 [Unsqueeze]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Gather_4_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/self/Unsqueeze_4 [Unsqueeze] inputs: [/bert/encoder/layer.1/attention/self/Gather_4_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Unsqueeze_4 for ONNX node: /bert/encoder/layer.1/attention/self/Unsqueeze_4\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/Unsqueeze_4_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/Unsqueeze_4_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/self/Unsqueeze_4 [Unsqueeze] outputs: [/bert/encoder/layer.1/attention/self/Unsqueeze_4_output_0 -> (1)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Unsqueeze_5 [Unsqueeze]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Gather_5_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/self/Unsqueeze_5 [Unsqueeze] inputs: [/bert/encoder/layer.1/attention/self/Gather_5_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Unsqueeze_5 for ONNX node: /bert/encoder/layer.1/attention/self/Unsqueeze_5\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/Unsqueeze_5_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/Unsqueeze_5_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/self/Unsqueeze_5 [Unsqueeze] outputs: [/bert/encoder/layer.1/attention/self/Unsqueeze_5_output_0 -> (1)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Constant_10 [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/self/Constant_10 [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/self/Constant_10 [Constant] outputs: [/bert/encoder/layer.1/attention/self/Constant_10_output_0 -> (1)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Constant_11 [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/self/Constant_11 [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/self/Constant_11 [Constant] outputs: [/bert/encoder/layer.1/attention/self/Constant_11_output_0 -> (1)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Concat_2 [Concat]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Unsqueeze_4_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Unsqueeze_5_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Constant_10_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Constant_11_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/self/Concat_2 [Concat] inputs: [/bert/encoder/layer.1/attention/self/Unsqueeze_4_output_0 -> (1)[INT32]], [/bert/encoder/layer.1/attention/self/Unsqueeze_5_output_0 -> (1)[INT32]], [/bert/encoder/layer.1/attention/self/Constant_10_output_0 -> (1)[INT32]], [/bert/encoder/layer.1/attention/self/Constant_11_output_0 -> (1)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Constant_10_output_0 for ONNX node: /bert/encoder/layer.1/attention/self/Constant_10_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Constant_11_output_0 for ONNX node: /bert/encoder/layer.1/attention/self/Constant_11_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Concat_2 for ONNX node: /bert/encoder/layer.1/attention/self/Concat_2\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/Concat_2_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/Concat_2_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/self/Concat_2 [Concat] outputs: [/bert/encoder/layer.1/attention/self/Concat_2_output_0 -> (4)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Reshape_2 [Reshape]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/query/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Concat_2_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/self/Reshape_2 [Reshape] inputs: [/bert/encoder/layer.1/attention/self/query/Add_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.1/attention/self/Concat_2_output_0 -> (4)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Reshape_2 for ONNX node: /bert/encoder/layer.1/attention/self/Reshape_2\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/Reshape_2_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/Reshape_2_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/self/Reshape_2 [Reshape] outputs: [/bert/encoder/layer.1/attention/self/Reshape_2_output_0 -> (-1, -1, 8, 32)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Transpose_1 [Transpose]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Reshape_2_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/self/Transpose_1 [Transpose] inputs: [/bert/encoder/layer.1/attention/self/Reshape_2_output_0 -> (-1, -1, 8, 32)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Transpose_1 for ONNX node: /bert/encoder/layer.1/attention/self/Transpose_1\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/Transpose_1_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/Transpose_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/self/Transpose_1 [Transpose] outputs: [/bert/encoder/layer.1/attention/self/Transpose_1_output_0 -> (-1, 8, -1, 32)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Transpose_2 [Transpose]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Reshape_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/self/Transpose_2 [Transpose] inputs: [/bert/encoder/layer.1/attention/self/Reshape_output_0 -> (-1, -1, 8, 32)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Transpose_2 for ONNX node: /bert/encoder/layer.1/attention/self/Transpose_2\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/Transpose_2_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/Transpose_2_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/self/Transpose_2 [Transpose] outputs: [/bert/encoder/layer.1/attention/self/Transpose_2_output_0 -> (-1, 8, 32, -1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/MatMul [MatMul]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Transpose_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Transpose_2_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/self/MatMul [MatMul] inputs: [/bert/encoder/layer.1/attention/self/Transpose_1_output_0 -> (-1, 8, -1, 32)[FLOAT]], [/bert/encoder/layer.1/attention/self/Transpose_2_output_0 -> (-1, 8, 32, -1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/MatMul for ONNX node: /bert/encoder/layer.1/attention/self/MatMul\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/MatMul_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/MatMul_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/self/MatMul [MatMul] outputs: [/bert/encoder/layer.1/attention/self/MatMul_output_0 -> (-1, 8, -1, -1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Constant_12 [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/self/Constant_12 [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/self/Constant_12 [Constant] outputs: [/bert/encoder/layer.1/attention/self/Constant_12_output_0 -> ()[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Div [Div]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/MatMul_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Constant_12_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/self/Div [Div] inputs: [/bert/encoder/layer.1/attention/self/MatMul_output_0 -> (-1, 8, -1, -1)[FLOAT]], [/bert/encoder/layer.1/attention/self/Constant_12_output_0 -> ()[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Constant_12_output_0 for ONNX node: /bert/encoder/layer.1/attention/self/Constant_12_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Div for ONNX node: /bert/encoder/layer.1/attention/self/Div\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/Div_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/Div_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/self/Div [Div] outputs: [/bert/encoder/layer.1/attention/self/Div_output_0 -> (-1, 8, -1, -1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Add [Add]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Div_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/Mul_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/self/Add [Add] inputs: [/bert/encoder/layer.1/attention/self/Div_output_0 -> (-1, 8, -1, -1)[FLOAT]], [/bert/Mul_output_0 -> (-1, 1, 1, -1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Add for ONNX node: /bert/encoder/layer.1/attention/self/Add\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/Add_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/self/Add [Add] outputs: [/bert/encoder/layer.1/attention/self/Add_output_0 -> (-1, 8, -1, -1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Softmax [Softmax]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/self/Softmax [Softmax] inputs: [/bert/encoder/layer.1/attention/self/Add_output_0 -> (-1, 8, -1, -1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Softmax for ONNX node: /bert/encoder/layer.1/attention/self/Softmax\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/Softmax_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/Softmax_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/self/Softmax [Softmax] outputs: [/bert/encoder/layer.1/attention/self/Softmax_output_0 -> (-1, 8, -1, -1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/MatMul_1 [MatMul]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Softmax_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Transpose_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/self/MatMul_1 [MatMul] inputs: [/bert/encoder/layer.1/attention/self/Softmax_output_0 -> (-1, 8, -1, -1)[FLOAT]], [/bert/encoder/layer.1/attention/self/Transpose_output_0 -> (-1, 8, -1, 32)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/MatMul_1 for ONNX node: /bert/encoder/layer.1/attention/self/MatMul_1\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/MatMul_1_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/MatMul_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/self/MatMul_1 [MatMul] outputs: [/bert/encoder/layer.1/attention/self/MatMul_1_output_0 -> (-1, 8, -1, 32)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Transpose_3 [Transpose]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/MatMul_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/self/Transpose_3 [Transpose] inputs: [/bert/encoder/layer.1/attention/self/MatMul_1_output_0 -> (-1, 8, -1, 32)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Transpose_3 for ONNX node: /bert/encoder/layer.1/attention/self/Transpose_3\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/Transpose_3_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/Transpose_3_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/self/Transpose_3 [Transpose] outputs: [/bert/encoder/layer.1/attention/self/Transpose_3_output_0 -> (-1, -1, 8, 32)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Shape_6 [Shape]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Transpose_3_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/self/Shape_6 [Shape] inputs: [/bert/encoder/layer.1/attention/self/Transpose_3_output_0 -> (-1, -1, 8, 32)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Shape_6 for ONNX node: /bert/encoder/layer.1/attention/self/Shape_6\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/Shape_6_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/Shape_6_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/self/Shape_6 [Shape] outputs: [/bert/encoder/layer.1/attention/self/Shape_6_output_0 -> (4)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Constant_13 [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/self/Constant_13 [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/self/Constant_13 [Constant] outputs: [/bert/encoder/layer.1/attention/self/Constant_13_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Gather_6 [Gather]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Shape_6_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Constant_13_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/self/Gather_6 [Gather] inputs: [/bert/encoder/layer.1/attention/self/Shape_6_output_0 -> (4)[INT32]], [/bert/encoder/layer.1/attention/self/Constant_13_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Constant_13_output_0 for ONNX node: /bert/encoder/layer.1/attention/self/Constant_13_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Using Gather axis: 0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Gather_6 for ONNX node: /bert/encoder/layer.1/attention/self/Gather_6\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/Gather_6_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/Gather_6_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/self/Gather_6 [Gather] outputs: [/bert/encoder/layer.1/attention/self/Gather_6_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Shape_7 [Shape]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Transpose_3_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/self/Shape_7 [Shape] inputs: [/bert/encoder/layer.1/attention/self/Transpose_3_output_0 -> (-1, -1, 8, 32)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Shape_7 for ONNX node: /bert/encoder/layer.1/attention/self/Shape_7\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/Shape_7_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/Shape_7_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/self/Shape_7 [Shape] outputs: [/bert/encoder/layer.1/attention/self/Shape_7_output_0 -> (4)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Constant_14 [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/self/Constant_14 [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/self/Constant_14 [Constant] outputs: [/bert/encoder/layer.1/attention/self/Constant_14_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Gather_7 [Gather]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Shape_7_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Constant_14_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/self/Gather_7 [Gather] inputs: [/bert/encoder/layer.1/attention/self/Shape_7_output_0 -> (4)[INT32]], [/bert/encoder/layer.1/attention/self/Constant_14_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Constant_14_output_0 for ONNX node: /bert/encoder/layer.1/attention/self/Constant_14_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Using Gather axis: 0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Gather_7 for ONNX node: /bert/encoder/layer.1/attention/self/Gather_7\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/Gather_7_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/Gather_7_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/self/Gather_7 [Gather] outputs: [/bert/encoder/layer.1/attention/self/Gather_7_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Unsqueeze_6 [Unsqueeze]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Gather_6_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/self/Unsqueeze_6 [Unsqueeze] inputs: [/bert/encoder/layer.1/attention/self/Gather_6_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Unsqueeze_6 for ONNX node: /bert/encoder/layer.1/attention/self/Unsqueeze_6\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/Unsqueeze_6_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/Unsqueeze_6_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/self/Unsqueeze_6 [Unsqueeze] outputs: [/bert/encoder/layer.1/attention/self/Unsqueeze_6_output_0 -> (1)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Unsqueeze_7 [Unsqueeze]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Gather_7_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/self/Unsqueeze_7 [Unsqueeze] inputs: [/bert/encoder/layer.1/attention/self/Gather_7_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Unsqueeze_7 for ONNX node: /bert/encoder/layer.1/attention/self/Unsqueeze_7\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/Unsqueeze_7_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/Unsqueeze_7_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/self/Unsqueeze_7 [Unsqueeze] outputs: [/bert/encoder/layer.1/attention/self/Unsqueeze_7_output_0 -> (1)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Constant_15 [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/self/Constant_15 [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/self/Constant_15 [Constant] outputs: [/bert/encoder/layer.1/attention/self/Constant_15_output_0 -> (1)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Concat_3 [Concat]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Unsqueeze_6_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Unsqueeze_7_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Constant_15_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/self/Concat_3 [Concat] inputs: [/bert/encoder/layer.1/attention/self/Unsqueeze_6_output_0 -> (1)[INT32]], [/bert/encoder/layer.1/attention/self/Unsqueeze_7_output_0 -> (1)[INT32]], [/bert/encoder/layer.1/attention/self/Constant_15_output_0 -> (1)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Constant_15_output_0 for ONNX node: /bert/encoder/layer.1/attention/self/Constant_15_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Concat_3 for ONNX node: /bert/encoder/layer.1/attention/self/Concat_3\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/Concat_3_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/Concat_3_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/self/Concat_3 [Concat] outputs: [/bert/encoder/layer.1/attention/self/Concat_3_output_0 -> (3)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Reshape_3 [Reshape]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Transpose_3_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Concat_3_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/self/Reshape_3 [Reshape] inputs: [/bert/encoder/layer.1/attention/self/Transpose_3_output_0 -> (-1, -1, 8, 32)[FLOAT]], [/bert/encoder/layer.1/attention/self/Concat_3_output_0 -> (3)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Reshape_3 for ONNX node: /bert/encoder/layer.1/attention/self/Reshape_3\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/Reshape_3_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/Reshape_3_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/self/Reshape_3 [Reshape] outputs: [/bert/encoder/layer.1/attention/self/Reshape_3_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/output/dense/MatMul [MatMul]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Reshape_3_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: onnx::MatMul_816\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/output/dense/MatMul [MatMul] inputs: [/bert/encoder/layer.1/attention/self/Reshape_3_output_0 -> (-1, -1, 256)[FLOAT]], [onnx::MatMul_816 -> (256, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: onnx::MatMul_816 for ONNX node: onnx::MatMul_816\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/output/dense/MatMul for ONNX node: /bert/encoder/layer.1/attention/output/dense/MatMul\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/output/dense/MatMul_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/output/dense/MatMul_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/output/dense/MatMul [MatMul] outputs: [/bert/encoder/layer.1/attention/output/dense/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/output/dense/Add [Add]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: bert.encoder.layer.1.attention.output.dense.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/output/dense/MatMul_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/output/dense/Add [Add] inputs: [bert.encoder.layer.1.attention.output.dense.bias -> (256)[FLOAT]], [/bert/encoder/layer.1/attention/output/dense/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: bert.encoder.layer.1.attention.output.dense.bias for ONNX node: bert.encoder.layer.1.attention.output.dense.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/output/dense/Add for ONNX node: /bert/encoder/layer.1/attention/output/dense/Add\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/output/dense/Add_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/output/dense/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/output/dense/Add [Add] outputs: [/bert/encoder/layer.1/attention/output/dense/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/output/Add [Add]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/output/dense/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.0/output/LayerNorm/Add_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/output/Add [Add] inputs: [/bert/encoder/layer.1/attention/output/dense/Add_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.0/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/output/Add for ONNX node: /bert/encoder/layer.1/attention/output/Add\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/output/Add_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/output/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/output/Add [Add] outputs: [/bert/encoder/layer.1/attention/output/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/output/LayerNorm/ReduceMean [ReduceMean]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/output/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/output/LayerNorm/ReduceMean [ReduceMean] inputs: [/bert/encoder/layer.1/attention/output/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/output/LayerNorm/ReduceMean for ONNX node: /bert/encoder/layer.1/attention/output/LayerNorm/ReduceMean\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/output/LayerNorm/ReduceMean_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/output/LayerNorm/ReduceMean_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/output/LayerNorm/ReduceMean [ReduceMean] outputs: [/bert/encoder/layer.1/attention/output/LayerNorm/ReduceMean_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/output/LayerNorm/Sub [Sub]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/output/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/output/LayerNorm/ReduceMean_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/output/LayerNorm/Sub [Sub] inputs: [/bert/encoder/layer.1/attention/output/Add_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.1/attention/output/LayerNorm/ReduceMean_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/output/LayerNorm/Sub for ONNX node: /bert/encoder/layer.1/attention/output/LayerNorm/Sub\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/output/LayerNorm/Sub_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/output/LayerNorm/Sub_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/output/LayerNorm/Sub [Sub] outputs: [/bert/encoder/layer.1/attention/output/LayerNorm/Sub_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/output/LayerNorm/Constant [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/output/LayerNorm/Constant [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/output/LayerNorm/Constant [Constant] outputs: [/bert/encoder/layer.1/attention/output/LayerNorm/Constant_output_0 -> ()[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/output/LayerNorm/Pow [Pow]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/output/LayerNorm/Sub_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/output/LayerNorm/Constant_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/output/LayerNorm/Pow [Pow] inputs: [/bert/encoder/layer.1/attention/output/LayerNorm/Sub_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.1/attention/output/LayerNorm/Constant_output_0 -> ()[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/output/LayerNorm/Constant_output_0 for ONNX node: /bert/encoder/layer.1/attention/output/LayerNorm/Constant_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/output/LayerNorm/Pow for ONNX node: /bert/encoder/layer.1/attention/output/LayerNorm/Pow\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/output/LayerNorm/Pow_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/output/LayerNorm/Pow_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/output/LayerNorm/Pow [Pow] outputs: [/bert/encoder/layer.1/attention/output/LayerNorm/Pow_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/output/LayerNorm/ReduceMean_1 [ReduceMean]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/output/LayerNorm/Pow_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/output/LayerNorm/ReduceMean_1 [ReduceMean] inputs: [/bert/encoder/layer.1/attention/output/LayerNorm/Pow_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/output/LayerNorm/ReduceMean_1 for ONNX node: /bert/encoder/layer.1/attention/output/LayerNorm/ReduceMean_1\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/output/LayerNorm/ReduceMean_1_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/output/LayerNorm/ReduceMean_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/output/LayerNorm/ReduceMean_1 [ReduceMean] outputs: [/bert/encoder/layer.1/attention/output/LayerNorm/ReduceMean_1_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/output/LayerNorm/Constant_1 [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/output/LayerNorm/Constant_1 [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/output/LayerNorm/Constant_1 [Constant] outputs: [/bert/encoder/layer.1/attention/output/LayerNorm/Constant_1_output_0 -> ()[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/output/LayerNorm/Add [Add]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/output/LayerNorm/ReduceMean_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/output/LayerNorm/Constant_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/output/LayerNorm/Add [Add] inputs: [/bert/encoder/layer.1/attention/output/LayerNorm/ReduceMean_1_output_0 -> (-1, -1, 1)[FLOAT]], [/bert/encoder/layer.1/attention/output/LayerNorm/Constant_1_output_0 -> ()[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/output/LayerNorm/Constant_1_output_0 for ONNX node: /bert/encoder/layer.1/attention/output/LayerNorm/Constant_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/output/LayerNorm/Add for ONNX node: /bert/encoder/layer.1/attention/output/LayerNorm/Add\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/output/LayerNorm/Add_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/output/LayerNorm/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/output/LayerNorm/Add [Add] outputs: [/bert/encoder/layer.1/attention/output/LayerNorm/Add_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/output/LayerNorm/Sqrt [Sqrt]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/output/LayerNorm/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/output/LayerNorm/Sqrt [Sqrt] inputs: [/bert/encoder/layer.1/attention/output/LayerNorm/Add_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/output/LayerNorm/Sqrt for ONNX node: /bert/encoder/layer.1/attention/output/LayerNorm/Sqrt\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/output/LayerNorm/Sqrt_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/output/LayerNorm/Sqrt_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/output/LayerNorm/Sqrt [Sqrt] outputs: [/bert/encoder/layer.1/attention/output/LayerNorm/Sqrt_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/output/LayerNorm/Div [Div]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/output/LayerNorm/Sub_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/output/LayerNorm/Sqrt_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/output/LayerNorm/Div [Div] inputs: [/bert/encoder/layer.1/attention/output/LayerNorm/Sub_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.1/attention/output/LayerNorm/Sqrt_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/output/LayerNorm/Div for ONNX node: /bert/encoder/layer.1/attention/output/LayerNorm/Div\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/output/LayerNorm/Div_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/output/LayerNorm/Div_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/output/LayerNorm/Div [Div] outputs: [/bert/encoder/layer.1/attention/output/LayerNorm/Div_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/output/LayerNorm/Mul [Mul]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/output/LayerNorm/Div_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: bert.encoder.layer.1.attention.output.LayerNorm.weight\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/output/LayerNorm/Mul [Mul] inputs: [/bert/encoder/layer.1/attention/output/LayerNorm/Div_output_0 -> (-1, -1, 256)[FLOAT]], [bert.encoder.layer.1.attention.output.LayerNorm.weight -> (256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: bert.encoder.layer.1.attention.output.LayerNorm.weight for ONNX node: bert.encoder.layer.1.attention.output.LayerNorm.weight\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/output/LayerNorm/Mul for ONNX node: /bert/encoder/layer.1/attention/output/LayerNorm/Mul\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/output/LayerNorm/Mul_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/output/LayerNorm/Mul_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/output/LayerNorm/Mul [Mul] outputs: [/bert/encoder/layer.1/attention/output/LayerNorm/Mul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/output/LayerNorm/Add_1 [Add]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/output/LayerNorm/Mul_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: bert.encoder.layer.1.attention.output.LayerNorm.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/output/LayerNorm/Add_1 [Add] inputs: [/bert/encoder/layer.1/attention/output/LayerNorm/Mul_output_0 -> (-1, -1, 256)[FLOAT]], [bert.encoder.layer.1.attention.output.LayerNorm.bias -> (256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: bert.encoder.layer.1.attention.output.LayerNorm.bias for ONNX node: bert.encoder.layer.1.attention.output.LayerNorm.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/output/LayerNorm/Add_1 for ONNX node: /bert/encoder/layer.1/attention/output/LayerNorm/Add_1\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/output/LayerNorm/Add_1_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/output/LayerNorm/Add_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/attention/output/LayerNorm/Add_1 [Add] outputs: [/bert/encoder/layer.1/attention/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.1/intermediate/dense/MatMul [MatMul]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/output/LayerNorm/Add_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: onnx::MatMul_817\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/intermediate/dense/MatMul [MatMul] inputs: [/bert/encoder/layer.1/attention/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], [onnx::MatMul_817 -> (256, 1024)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: onnx::MatMul_817 for ONNX node: onnx::MatMul_817\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.1/intermediate/dense/MatMul for ONNX node: /bert/encoder/layer.1/intermediate/dense/MatMul\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.1/intermediate/dense/MatMul_output_0 for ONNX tensor: /bert/encoder/layer.1/intermediate/dense/MatMul_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/intermediate/dense/MatMul [MatMul] outputs: [/bert/encoder/layer.1/intermediate/dense/MatMul_output_0 -> (-1, -1, 1024)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.1/intermediate/dense/Add [Add]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: bert.encoder.layer.1.intermediate.dense.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.1/intermediate/dense/MatMul_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/intermediate/dense/Add [Add] inputs: [bert.encoder.layer.1.intermediate.dense.bias -> (1024)[FLOAT]], [/bert/encoder/layer.1/intermediate/dense/MatMul_output_0 -> (-1, -1, 1024)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: bert.encoder.layer.1.intermediate.dense.bias for ONNX node: bert.encoder.layer.1.intermediate.dense.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.1/intermediate/dense/Add for ONNX node: /bert/encoder/layer.1/intermediate/dense/Add\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.1/intermediate/dense/Add_output_0 for ONNX tensor: /bert/encoder/layer.1/intermediate/dense/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/intermediate/dense/Add [Add] outputs: [/bert/encoder/layer.1/intermediate/dense/Add_output_0 -> (-1, -1, 1024)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.1/intermediate/intermediate_act_fn/Constant [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/intermediate/intermediate_act_fn/Constant [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/intermediate/intermediate_act_fn/Constant [Constant] outputs: [/bert/encoder/layer.1/intermediate/intermediate_act_fn/Constant_output_0 -> ()[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.1/intermediate/intermediate_act_fn/Div [Div]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.1/intermediate/dense/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.1/intermediate/intermediate_act_fn/Constant_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/intermediate/intermediate_act_fn/Div [Div] inputs: [/bert/encoder/layer.1/intermediate/dense/Add_output_0 -> (-1, -1, 1024)[FLOAT]], [/bert/encoder/layer.1/intermediate/intermediate_act_fn/Constant_output_0 -> ()[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.1/intermediate/intermediate_act_fn/Constant_output_0 for ONNX node: /bert/encoder/layer.1/intermediate/intermediate_act_fn/Constant_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.1/intermediate/intermediate_act_fn/Div for ONNX node: /bert/encoder/layer.1/intermediate/intermediate_act_fn/Div\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.1/intermediate/intermediate_act_fn/Div_output_0 for ONNX tensor: /bert/encoder/layer.1/intermediate/intermediate_act_fn/Div_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/intermediate/intermediate_act_fn/Div [Div] outputs: [/bert/encoder/layer.1/intermediate/intermediate_act_fn/Div_output_0 -> (-1, -1, 1024)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.1/intermediate/intermediate_act_fn/Erf [Erf]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.1/intermediate/intermediate_act_fn/Div_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/intermediate/intermediate_act_fn/Erf [Erf] inputs: [/bert/encoder/layer.1/intermediate/intermediate_act_fn/Div_output_0 -> (-1, -1, 1024)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.1/intermediate/intermediate_act_fn/Erf for ONNX node: /bert/encoder/layer.1/intermediate/intermediate_act_fn/Erf\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.1/intermediate/intermediate_act_fn/Erf_output_0 for ONNX tensor: /bert/encoder/layer.1/intermediate/intermediate_act_fn/Erf_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/intermediate/intermediate_act_fn/Erf [Erf] outputs: [/bert/encoder/layer.1/intermediate/intermediate_act_fn/Erf_output_0 -> (-1, -1, 1024)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.1/intermediate/intermediate_act_fn/Constant_1 [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/intermediate/intermediate_act_fn/Constant_1 [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/intermediate/intermediate_act_fn/Constant_1 [Constant] outputs: [/bert/encoder/layer.1/intermediate/intermediate_act_fn/Constant_1_output_0 -> ()[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.1/intermediate/intermediate_act_fn/Add [Add]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.1/intermediate/intermediate_act_fn/Erf_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.1/intermediate/intermediate_act_fn/Constant_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/intermediate/intermediate_act_fn/Add [Add] inputs: [/bert/encoder/layer.1/intermediate/intermediate_act_fn/Erf_output_0 -> (-1, -1, 1024)[FLOAT]], [/bert/encoder/layer.1/intermediate/intermediate_act_fn/Constant_1_output_0 -> ()[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.1/intermediate/intermediate_act_fn/Constant_1_output_0 for ONNX node: /bert/encoder/layer.1/intermediate/intermediate_act_fn/Constant_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.1/intermediate/intermediate_act_fn/Add for ONNX node: /bert/encoder/layer.1/intermediate/intermediate_act_fn/Add\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.1/intermediate/intermediate_act_fn/Add_output_0 for ONNX tensor: /bert/encoder/layer.1/intermediate/intermediate_act_fn/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/intermediate/intermediate_act_fn/Add [Add] outputs: [/bert/encoder/layer.1/intermediate/intermediate_act_fn/Add_output_0 -> (-1, -1, 1024)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.1/intermediate/intermediate_act_fn/Mul [Mul]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.1/intermediate/dense/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.1/intermediate/intermediate_act_fn/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/intermediate/intermediate_act_fn/Mul [Mul] inputs: [/bert/encoder/layer.1/intermediate/dense/Add_output_0 -> (-1, -1, 1024)[FLOAT]], [/bert/encoder/layer.1/intermediate/intermediate_act_fn/Add_output_0 -> (-1, -1, 1024)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.1/intermediate/intermediate_act_fn/Mul for ONNX node: /bert/encoder/layer.1/intermediate/intermediate_act_fn/Mul\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.1/intermediate/intermediate_act_fn/Mul_output_0 for ONNX tensor: /bert/encoder/layer.1/intermediate/intermediate_act_fn/Mul_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/intermediate/intermediate_act_fn/Mul [Mul] outputs: [/bert/encoder/layer.1/intermediate/intermediate_act_fn/Mul_output_0 -> (-1, -1, 1024)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.1/intermediate/intermediate_act_fn/Constant_2 [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/intermediate/intermediate_act_fn/Constant_2 [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/intermediate/intermediate_act_fn/Constant_2 [Constant] outputs: [/bert/encoder/layer.1/intermediate/intermediate_act_fn/Constant_2_output_0 -> ()[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.1/intermediate/intermediate_act_fn/Mul_1 [Mul]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.1/intermediate/intermediate_act_fn/Mul_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.1/intermediate/intermediate_act_fn/Constant_2_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/intermediate/intermediate_act_fn/Mul_1 [Mul] inputs: [/bert/encoder/layer.1/intermediate/intermediate_act_fn/Mul_output_0 -> (-1, -1, 1024)[FLOAT]], [/bert/encoder/layer.1/intermediate/intermediate_act_fn/Constant_2_output_0 -> ()[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.1/intermediate/intermediate_act_fn/Constant_2_output_0 for ONNX node: /bert/encoder/layer.1/intermediate/intermediate_act_fn/Constant_2_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.1/intermediate/intermediate_act_fn/Mul_1 for ONNX node: /bert/encoder/layer.1/intermediate/intermediate_act_fn/Mul_1\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.1/intermediate/intermediate_act_fn/Mul_1_output_0 for ONNX tensor: /bert/encoder/layer.1/intermediate/intermediate_act_fn/Mul_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/intermediate/intermediate_act_fn/Mul_1 [Mul] outputs: [/bert/encoder/layer.1/intermediate/intermediate_act_fn/Mul_1_output_0 -> (-1, -1, 1024)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.1/output/dense/MatMul [MatMul]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.1/intermediate/intermediate_act_fn/Mul_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: onnx::MatMul_818\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/output/dense/MatMul [MatMul] inputs: [/bert/encoder/layer.1/intermediate/intermediate_act_fn/Mul_1_output_0 -> (-1, -1, 1024)[FLOAT]], [onnx::MatMul_818 -> (1024, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: onnx::MatMul_818 for ONNX node: onnx::MatMul_818\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.1/output/dense/MatMul for ONNX node: /bert/encoder/layer.1/output/dense/MatMul\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.1/output/dense/MatMul_output_0 for ONNX tensor: /bert/encoder/layer.1/output/dense/MatMul_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/output/dense/MatMul [MatMul] outputs: [/bert/encoder/layer.1/output/dense/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.1/output/dense/Add [Add]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: bert.encoder.layer.1.output.dense.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.1/output/dense/MatMul_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/output/dense/Add [Add] inputs: [bert.encoder.layer.1.output.dense.bias -> (256)[FLOAT]], [/bert/encoder/layer.1/output/dense/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: bert.encoder.layer.1.output.dense.bias for ONNX node: bert.encoder.layer.1.output.dense.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.1/output/dense/Add for ONNX node: /bert/encoder/layer.1/output/dense/Add\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.1/output/dense/Add_output_0 for ONNX tensor: /bert/encoder/layer.1/output/dense/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/output/dense/Add [Add] outputs: [/bert/encoder/layer.1/output/dense/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.1/output/Add [Add]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.1/output/dense/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/output/LayerNorm/Add_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/output/Add [Add] inputs: [/bert/encoder/layer.1/output/dense/Add_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.1/attention/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.1/output/Add for ONNX node: /bert/encoder/layer.1/output/Add\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.1/output/Add_output_0 for ONNX tensor: /bert/encoder/layer.1/output/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/output/Add [Add] outputs: [/bert/encoder/layer.1/output/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.1/output/LayerNorm/ReduceMean [ReduceMean]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.1/output/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/output/LayerNorm/ReduceMean [ReduceMean] inputs: [/bert/encoder/layer.1/output/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.1/output/LayerNorm/ReduceMean for ONNX node: /bert/encoder/layer.1/output/LayerNorm/ReduceMean\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.1/output/LayerNorm/ReduceMean_output_0 for ONNX tensor: /bert/encoder/layer.1/output/LayerNorm/ReduceMean_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/output/LayerNorm/ReduceMean [ReduceMean] outputs: [/bert/encoder/layer.1/output/LayerNorm/ReduceMean_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.1/output/LayerNorm/Sub [Sub]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.1/output/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.1/output/LayerNorm/ReduceMean_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/output/LayerNorm/Sub [Sub] inputs: [/bert/encoder/layer.1/output/Add_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.1/output/LayerNorm/ReduceMean_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.1/output/LayerNorm/Sub for ONNX node: /bert/encoder/layer.1/output/LayerNorm/Sub\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.1/output/LayerNorm/Sub_output_0 for ONNX tensor: /bert/encoder/layer.1/output/LayerNorm/Sub_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/output/LayerNorm/Sub [Sub] outputs: [/bert/encoder/layer.1/output/LayerNorm/Sub_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.1/output/LayerNorm/Constant [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/output/LayerNorm/Constant [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/output/LayerNorm/Constant [Constant] outputs: [/bert/encoder/layer.1/output/LayerNorm/Constant_output_0 -> ()[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.1/output/LayerNorm/Pow [Pow]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.1/output/LayerNorm/Sub_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.1/output/LayerNorm/Constant_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/output/LayerNorm/Pow [Pow] inputs: [/bert/encoder/layer.1/output/LayerNorm/Sub_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.1/output/LayerNorm/Constant_output_0 -> ()[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.1/output/LayerNorm/Constant_output_0 for ONNX node: /bert/encoder/layer.1/output/LayerNorm/Constant_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.1/output/LayerNorm/Pow for ONNX node: /bert/encoder/layer.1/output/LayerNorm/Pow\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.1/output/LayerNorm/Pow_output_0 for ONNX tensor: /bert/encoder/layer.1/output/LayerNorm/Pow_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/output/LayerNorm/Pow [Pow] outputs: [/bert/encoder/layer.1/output/LayerNorm/Pow_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.1/output/LayerNorm/ReduceMean_1 [ReduceMean]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.1/output/LayerNorm/Pow_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/output/LayerNorm/ReduceMean_1 [ReduceMean] inputs: [/bert/encoder/layer.1/output/LayerNorm/Pow_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.1/output/LayerNorm/ReduceMean_1 for ONNX node: /bert/encoder/layer.1/output/LayerNorm/ReduceMean_1\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.1/output/LayerNorm/ReduceMean_1_output_0 for ONNX tensor: /bert/encoder/layer.1/output/LayerNorm/ReduceMean_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/output/LayerNorm/ReduceMean_1 [ReduceMean] outputs: [/bert/encoder/layer.1/output/LayerNorm/ReduceMean_1_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.1/output/LayerNorm/Constant_1 [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/output/LayerNorm/Constant_1 [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/output/LayerNorm/Constant_1 [Constant] outputs: [/bert/encoder/layer.1/output/LayerNorm/Constant_1_output_0 -> ()[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.1/output/LayerNorm/Add [Add]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.1/output/LayerNorm/ReduceMean_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.1/output/LayerNorm/Constant_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/output/LayerNorm/Add [Add] inputs: [/bert/encoder/layer.1/output/LayerNorm/ReduceMean_1_output_0 -> (-1, -1, 1)[FLOAT]], [/bert/encoder/layer.1/output/LayerNorm/Constant_1_output_0 -> ()[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.1/output/LayerNorm/Constant_1_output_0 for ONNX node: /bert/encoder/layer.1/output/LayerNorm/Constant_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.1/output/LayerNorm/Add for ONNX node: /bert/encoder/layer.1/output/LayerNorm/Add\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.1/output/LayerNorm/Add_output_0 for ONNX tensor: /bert/encoder/layer.1/output/LayerNorm/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/output/LayerNorm/Add [Add] outputs: [/bert/encoder/layer.1/output/LayerNorm/Add_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.1/output/LayerNorm/Sqrt [Sqrt]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.1/output/LayerNorm/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/output/LayerNorm/Sqrt [Sqrt] inputs: [/bert/encoder/layer.1/output/LayerNorm/Add_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.1/output/LayerNorm/Sqrt for ONNX node: /bert/encoder/layer.1/output/LayerNorm/Sqrt\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.1/output/LayerNorm/Sqrt_output_0 for ONNX tensor: /bert/encoder/layer.1/output/LayerNorm/Sqrt_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/output/LayerNorm/Sqrt [Sqrt] outputs: [/bert/encoder/layer.1/output/LayerNorm/Sqrt_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.1/output/LayerNorm/Div [Div]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.1/output/LayerNorm/Sub_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.1/output/LayerNorm/Sqrt_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/output/LayerNorm/Div [Div] inputs: [/bert/encoder/layer.1/output/LayerNorm/Sub_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.1/output/LayerNorm/Sqrt_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.1/output/LayerNorm/Div for ONNX node: /bert/encoder/layer.1/output/LayerNorm/Div\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.1/output/LayerNorm/Div_output_0 for ONNX tensor: /bert/encoder/layer.1/output/LayerNorm/Div_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/output/LayerNorm/Div [Div] outputs: [/bert/encoder/layer.1/output/LayerNorm/Div_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.1/output/LayerNorm/Mul [Mul]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.1/output/LayerNorm/Div_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: bert.encoder.layer.1.output.LayerNorm.weight\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/output/LayerNorm/Mul [Mul] inputs: [/bert/encoder/layer.1/output/LayerNorm/Div_output_0 -> (-1, -1, 256)[FLOAT]], [bert.encoder.layer.1.output.LayerNorm.weight -> (256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: bert.encoder.layer.1.output.LayerNorm.weight for ONNX node: bert.encoder.layer.1.output.LayerNorm.weight\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.1/output/LayerNorm/Mul for ONNX node: /bert/encoder/layer.1/output/LayerNorm/Mul\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.1/output/LayerNorm/Mul_output_0 for ONNX tensor: /bert/encoder/layer.1/output/LayerNorm/Mul_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/output/LayerNorm/Mul [Mul] outputs: [/bert/encoder/layer.1/output/LayerNorm/Mul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.1/output/LayerNorm/Add_1 [Add]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.1/output/LayerNorm/Mul_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: bert.encoder.layer.1.output.LayerNorm.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/output/LayerNorm/Add_1 [Add] inputs: [/bert/encoder/layer.1/output/LayerNorm/Mul_output_0 -> (-1, -1, 256)[FLOAT]], [bert.encoder.layer.1.output.LayerNorm.bias -> (256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: bert.encoder.layer.1.output.LayerNorm.bias for ONNX node: bert.encoder.layer.1.output.LayerNorm.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.1/output/LayerNorm/Add_1 for ONNX node: /bert/encoder/layer.1/output/LayerNorm/Add_1\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.1/output/LayerNorm/Add_1_output_0 for ONNX tensor: /bert/encoder/layer.1/output/LayerNorm/Add_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.1/output/LayerNorm/Add_1 [Add] outputs: [/bert/encoder/layer.1/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/query/MatMul [MatMul]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.1/output/LayerNorm/Add_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: onnx::MatMul_819\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/self/query/MatMul [MatMul] inputs: [/bert/encoder/layer.1/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], [onnx::MatMul_819 -> (256, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: onnx::MatMul_819 for ONNX node: onnx::MatMul_819\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/query/MatMul for ONNX node: /bert/encoder/layer.2/attention/self/query/MatMul\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/query/MatMul_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/query/MatMul_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/self/query/MatMul [MatMul] outputs: [/bert/encoder/layer.2/attention/self/query/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/query/Add [Add]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: bert.encoder.layer.2.attention.self.query.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/query/MatMul_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/self/query/Add [Add] inputs: [bert.encoder.layer.2.attention.self.query.bias -> (256)[FLOAT]], [/bert/encoder/layer.2/attention/self/query/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: bert.encoder.layer.2.attention.self.query.bias for ONNX node: bert.encoder.layer.2.attention.self.query.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/query/Add for ONNX node: /bert/encoder/layer.2/attention/self/query/Add\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/query/Add_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/query/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/self/query/Add [Add] outputs: [/bert/encoder/layer.2/attention/self/query/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/key/MatMul [MatMul]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.1/output/LayerNorm/Add_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: onnx::MatMul_820\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/self/key/MatMul [MatMul] inputs: [/bert/encoder/layer.1/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], [onnx::MatMul_820 -> (256, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: onnx::MatMul_820 for ONNX node: onnx::MatMul_820\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/key/MatMul for ONNX node: /bert/encoder/layer.2/attention/self/key/MatMul\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/key/MatMul_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/key/MatMul_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/self/key/MatMul [MatMul] outputs: [/bert/encoder/layer.2/attention/self/key/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/key/Add [Add]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: bert.encoder.layer.2.attention.self.key.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/key/MatMul_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/self/key/Add [Add] inputs: [bert.encoder.layer.2.attention.self.key.bias -> (256)[FLOAT]], [/bert/encoder/layer.2/attention/self/key/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: bert.encoder.layer.2.attention.self.key.bias for ONNX node: bert.encoder.layer.2.attention.self.key.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/key/Add for ONNX node: /bert/encoder/layer.2/attention/self/key/Add\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/key/Add_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/key/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/self/key/Add [Add] outputs: [/bert/encoder/layer.2/attention/self/key/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Shape [Shape]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/key/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/self/Shape [Shape] inputs: [/bert/encoder/layer.2/attention/self/key/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Shape for ONNX node: /bert/encoder/layer.2/attention/self/Shape\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/Shape_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/Shape_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/self/Shape [Shape] outputs: [/bert/encoder/layer.2/attention/self/Shape_output_0 -> (3)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Constant [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/self/Constant [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/self/Constant [Constant] outputs: [/bert/encoder/layer.2/attention/self/Constant_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Gather [Gather]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Shape_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Constant_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/self/Gather [Gather] inputs: [/bert/encoder/layer.2/attention/self/Shape_output_0 -> (3)[INT32]], [/bert/encoder/layer.2/attention/self/Constant_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Constant_output_0 for ONNX node: /bert/encoder/layer.2/attention/self/Constant_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Using Gather axis: 0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Gather for ONNX node: /bert/encoder/layer.2/attention/self/Gather\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/Gather_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/Gather_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/self/Gather [Gather] outputs: [/bert/encoder/layer.2/attention/self/Gather_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Shape_1 [Shape]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/key/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/self/Shape_1 [Shape] inputs: [/bert/encoder/layer.2/attention/self/key/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Shape_1 for ONNX node: /bert/encoder/layer.2/attention/self/Shape_1\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/Shape_1_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/Shape_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/self/Shape_1 [Shape] outputs: [/bert/encoder/layer.2/attention/self/Shape_1_output_0 -> (3)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Constant_1 [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/self/Constant_1 [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/self/Constant_1 [Constant] outputs: [/bert/encoder/layer.2/attention/self/Constant_1_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Gather_1 [Gather]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Shape_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Constant_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/self/Gather_1 [Gather] inputs: [/bert/encoder/layer.2/attention/self/Shape_1_output_0 -> (3)[INT32]], [/bert/encoder/layer.2/attention/self/Constant_1_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Constant_1_output_0 for ONNX node: /bert/encoder/layer.2/attention/self/Constant_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Using Gather axis: 0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Gather_1 for ONNX node: /bert/encoder/layer.2/attention/self/Gather_1\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/Gather_1_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/Gather_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/self/Gather_1 [Gather] outputs: [/bert/encoder/layer.2/attention/self/Gather_1_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Unsqueeze [Unsqueeze]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Gather_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/self/Unsqueeze [Unsqueeze] inputs: [/bert/encoder/layer.2/attention/self/Gather_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Unsqueeze for ONNX node: /bert/encoder/layer.2/attention/self/Unsqueeze\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/Unsqueeze_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/Unsqueeze_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/self/Unsqueeze [Unsqueeze] outputs: [/bert/encoder/layer.2/attention/self/Unsqueeze_output_0 -> (1)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Unsqueeze_1 [Unsqueeze]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Gather_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/self/Unsqueeze_1 [Unsqueeze] inputs: [/bert/encoder/layer.2/attention/self/Gather_1_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Unsqueeze_1 for ONNX node: /bert/encoder/layer.2/attention/self/Unsqueeze_1\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/Unsqueeze_1_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/Unsqueeze_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/self/Unsqueeze_1 [Unsqueeze] outputs: [/bert/encoder/layer.2/attention/self/Unsqueeze_1_output_0 -> (1)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Constant_2 [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/self/Constant_2 [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/self/Constant_2 [Constant] outputs: [/bert/encoder/layer.2/attention/self/Constant_2_output_0 -> (1)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Constant_3 [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/self/Constant_3 [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/self/Constant_3 [Constant] outputs: [/bert/encoder/layer.2/attention/self/Constant_3_output_0 -> (1)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Concat [Concat]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Unsqueeze_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Unsqueeze_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Constant_2_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Constant_3_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/self/Concat [Concat] inputs: [/bert/encoder/layer.2/attention/self/Unsqueeze_output_0 -> (1)[INT32]], [/bert/encoder/layer.2/attention/self/Unsqueeze_1_output_0 -> (1)[INT32]], [/bert/encoder/layer.2/attention/self/Constant_2_output_0 -> (1)[INT32]], [/bert/encoder/layer.2/attention/self/Constant_3_output_0 -> (1)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Constant_2_output_0 for ONNX node: /bert/encoder/layer.2/attention/self/Constant_2_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Constant_3_output_0 for ONNX node: /bert/encoder/layer.2/attention/self/Constant_3_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Concat for ONNX node: /bert/encoder/layer.2/attention/self/Concat\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/Concat_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/Concat_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/self/Concat [Concat] outputs: [/bert/encoder/layer.2/attention/self/Concat_output_0 -> (4)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Reshape [Reshape]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/key/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Concat_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/self/Reshape [Reshape] inputs: [/bert/encoder/layer.2/attention/self/key/Add_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.2/attention/self/Concat_output_0 -> (4)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Reshape for ONNX node: /bert/encoder/layer.2/attention/self/Reshape\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/Reshape_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/Reshape_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/self/Reshape [Reshape] outputs: [/bert/encoder/layer.2/attention/self/Reshape_output_0 -> (-1, -1, 8, 32)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/value/MatMul [MatMul]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.1/output/LayerNorm/Add_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: onnx::MatMul_823\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/self/value/MatMul [MatMul] inputs: [/bert/encoder/layer.1/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], [onnx::MatMul_823 -> (256, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: onnx::MatMul_823 for ONNX node: onnx::MatMul_823\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/value/MatMul for ONNX node: /bert/encoder/layer.2/attention/self/value/MatMul\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/value/MatMul_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/value/MatMul_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/self/value/MatMul [MatMul] outputs: [/bert/encoder/layer.2/attention/self/value/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/value/Add [Add]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: bert.encoder.layer.2.attention.self.value.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/value/MatMul_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/self/value/Add [Add] inputs: [bert.encoder.layer.2.attention.self.value.bias -> (256)[FLOAT]], [/bert/encoder/layer.2/attention/self/value/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: bert.encoder.layer.2.attention.self.value.bias for ONNX node: bert.encoder.layer.2.attention.self.value.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/value/Add for ONNX node: /bert/encoder/layer.2/attention/self/value/Add\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/value/Add_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/value/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/self/value/Add [Add] outputs: [/bert/encoder/layer.2/attention/self/value/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Shape_2 [Shape]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/value/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/self/Shape_2 [Shape] inputs: [/bert/encoder/layer.2/attention/self/value/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Shape_2 for ONNX node: /bert/encoder/layer.2/attention/self/Shape_2\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/Shape_2_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/Shape_2_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/self/Shape_2 [Shape] outputs: [/bert/encoder/layer.2/attention/self/Shape_2_output_0 -> (3)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Constant_4 [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/self/Constant_4 [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/self/Constant_4 [Constant] outputs: [/bert/encoder/layer.2/attention/self/Constant_4_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Gather_2 [Gather]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Shape_2_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Constant_4_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/self/Gather_2 [Gather] inputs: [/bert/encoder/layer.2/attention/self/Shape_2_output_0 -> (3)[INT32]], [/bert/encoder/layer.2/attention/self/Constant_4_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Constant_4_output_0 for ONNX node: /bert/encoder/layer.2/attention/self/Constant_4_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Using Gather axis: 0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Gather_2 for ONNX node: /bert/encoder/layer.2/attention/self/Gather_2\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/Gather_2_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/Gather_2_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/self/Gather_2 [Gather] outputs: [/bert/encoder/layer.2/attention/self/Gather_2_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Shape_3 [Shape]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/value/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/self/Shape_3 [Shape] inputs: [/bert/encoder/layer.2/attention/self/value/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Shape_3 for ONNX node: /bert/encoder/layer.2/attention/self/Shape_3\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/Shape_3_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/Shape_3_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/self/Shape_3 [Shape] outputs: [/bert/encoder/layer.2/attention/self/Shape_3_output_0 -> (3)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Constant_5 [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/self/Constant_5 [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/self/Constant_5 [Constant] outputs: [/bert/encoder/layer.2/attention/self/Constant_5_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Gather_3 [Gather]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Shape_3_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Constant_5_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/self/Gather_3 [Gather] inputs: [/bert/encoder/layer.2/attention/self/Shape_3_output_0 -> (3)[INT32]], [/bert/encoder/layer.2/attention/self/Constant_5_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Constant_5_output_0 for ONNX node: /bert/encoder/layer.2/attention/self/Constant_5_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Using Gather axis: 0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Gather_3 for ONNX node: /bert/encoder/layer.2/attention/self/Gather_3\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/Gather_3_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/Gather_3_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/self/Gather_3 [Gather] outputs: [/bert/encoder/layer.2/attention/self/Gather_3_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Unsqueeze_2 [Unsqueeze]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Gather_2_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/self/Unsqueeze_2 [Unsqueeze] inputs: [/bert/encoder/layer.2/attention/self/Gather_2_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Unsqueeze_2 for ONNX node: /bert/encoder/layer.2/attention/self/Unsqueeze_2\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/Unsqueeze_2_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/Unsqueeze_2_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/self/Unsqueeze_2 [Unsqueeze] outputs: [/bert/encoder/layer.2/attention/self/Unsqueeze_2_output_0 -> (1)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Unsqueeze_3 [Unsqueeze]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Gather_3_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/self/Unsqueeze_3 [Unsqueeze] inputs: [/bert/encoder/layer.2/attention/self/Gather_3_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Unsqueeze_3 for ONNX node: /bert/encoder/layer.2/attention/self/Unsqueeze_3\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/Unsqueeze_3_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/Unsqueeze_3_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/self/Unsqueeze_3 [Unsqueeze] outputs: [/bert/encoder/layer.2/attention/self/Unsqueeze_3_output_0 -> (1)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Constant_6 [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/self/Constant_6 [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/self/Constant_6 [Constant] outputs: [/bert/encoder/layer.2/attention/self/Constant_6_output_0 -> (1)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Constant_7 [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/self/Constant_7 [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/self/Constant_7 [Constant] outputs: [/bert/encoder/layer.2/attention/self/Constant_7_output_0 -> (1)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Concat_1 [Concat]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Unsqueeze_2_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Unsqueeze_3_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Constant_6_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Constant_7_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/self/Concat_1 [Concat] inputs: [/bert/encoder/layer.2/attention/self/Unsqueeze_2_output_0 -> (1)[INT32]], [/bert/encoder/layer.2/attention/self/Unsqueeze_3_output_0 -> (1)[INT32]], [/bert/encoder/layer.2/attention/self/Constant_6_output_0 -> (1)[INT32]], [/bert/encoder/layer.2/attention/self/Constant_7_output_0 -> (1)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Constant_6_output_0 for ONNX node: /bert/encoder/layer.2/attention/self/Constant_6_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Constant_7_output_0 for ONNX node: /bert/encoder/layer.2/attention/self/Constant_7_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Concat_1 for ONNX node: /bert/encoder/layer.2/attention/self/Concat_1\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/Concat_1_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/Concat_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/self/Concat_1 [Concat] outputs: [/bert/encoder/layer.2/attention/self/Concat_1_output_0 -> (4)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Reshape_1 [Reshape]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/value/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Concat_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/self/Reshape_1 [Reshape] inputs: [/bert/encoder/layer.2/attention/self/value/Add_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.2/attention/self/Concat_1_output_0 -> (4)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Reshape_1 for ONNX node: /bert/encoder/layer.2/attention/self/Reshape_1\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/Reshape_1_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/Reshape_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/self/Reshape_1 [Reshape] outputs: [/bert/encoder/layer.2/attention/self/Reshape_1_output_0 -> (-1, -1, 8, 32)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Transpose [Transpose]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Reshape_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/self/Transpose [Transpose] inputs: [/bert/encoder/layer.2/attention/self/Reshape_1_output_0 -> (-1, -1, 8, 32)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Transpose for ONNX node: /bert/encoder/layer.2/attention/self/Transpose\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/Transpose_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/Transpose_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/self/Transpose [Transpose] outputs: [/bert/encoder/layer.2/attention/self/Transpose_output_0 -> (-1, 8, -1, 32)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Shape_4 [Shape]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/query/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/self/Shape_4 [Shape] inputs: [/bert/encoder/layer.2/attention/self/query/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Shape_4 for ONNX node: /bert/encoder/layer.2/attention/self/Shape_4\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/Shape_4_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/Shape_4_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/self/Shape_4 [Shape] outputs: [/bert/encoder/layer.2/attention/self/Shape_4_output_0 -> (3)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Constant_8 [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/self/Constant_8 [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/self/Constant_8 [Constant] outputs: [/bert/encoder/layer.2/attention/self/Constant_8_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Gather_4 [Gather]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Shape_4_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Constant_8_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/self/Gather_4 [Gather] inputs: [/bert/encoder/layer.2/attention/self/Shape_4_output_0 -> (3)[INT32]], [/bert/encoder/layer.2/attention/self/Constant_8_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Constant_8_output_0 for ONNX node: /bert/encoder/layer.2/attention/self/Constant_8_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Using Gather axis: 0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Gather_4 for ONNX node: /bert/encoder/layer.2/attention/self/Gather_4\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/Gather_4_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/Gather_4_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/self/Gather_4 [Gather] outputs: [/bert/encoder/layer.2/attention/self/Gather_4_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Shape_5 [Shape]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/query/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/self/Shape_5 [Shape] inputs: [/bert/encoder/layer.2/attention/self/query/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Shape_5 for ONNX node: /bert/encoder/layer.2/attention/self/Shape_5\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/Shape_5_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/Shape_5_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/self/Shape_5 [Shape] outputs: [/bert/encoder/layer.2/attention/self/Shape_5_output_0 -> (3)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Constant_9 [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/self/Constant_9 [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/self/Constant_9 [Constant] outputs: [/bert/encoder/layer.2/attention/self/Constant_9_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Gather_5 [Gather]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Shape_5_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Constant_9_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/self/Gather_5 [Gather] inputs: [/bert/encoder/layer.2/attention/self/Shape_5_output_0 -> (3)[INT32]], [/bert/encoder/layer.2/attention/self/Constant_9_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Constant_9_output_0 for ONNX node: /bert/encoder/layer.2/attention/self/Constant_9_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Using Gather axis: 0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Gather_5 for ONNX node: /bert/encoder/layer.2/attention/self/Gather_5\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/Gather_5_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/Gather_5_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/self/Gather_5 [Gather] outputs: [/bert/encoder/layer.2/attention/self/Gather_5_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Unsqueeze_4 [Unsqueeze]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Gather_4_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/self/Unsqueeze_4 [Unsqueeze] inputs: [/bert/encoder/layer.2/attention/self/Gather_4_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Unsqueeze_4 for ONNX node: /bert/encoder/layer.2/attention/self/Unsqueeze_4\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/Unsqueeze_4_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/Unsqueeze_4_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/self/Unsqueeze_4 [Unsqueeze] outputs: [/bert/encoder/layer.2/attention/self/Unsqueeze_4_output_0 -> (1)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Unsqueeze_5 [Unsqueeze]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Gather_5_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/self/Unsqueeze_5 [Unsqueeze] inputs: [/bert/encoder/layer.2/attention/self/Gather_5_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Unsqueeze_5 for ONNX node: /bert/encoder/layer.2/attention/self/Unsqueeze_5\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/Unsqueeze_5_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/Unsqueeze_5_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/self/Unsqueeze_5 [Unsqueeze] outputs: [/bert/encoder/layer.2/attention/self/Unsqueeze_5_output_0 -> (1)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Constant_10 [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/self/Constant_10 [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/self/Constant_10 [Constant] outputs: [/bert/encoder/layer.2/attention/self/Constant_10_output_0 -> (1)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Constant_11 [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/self/Constant_11 [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/self/Constant_11 [Constant] outputs: [/bert/encoder/layer.2/attention/self/Constant_11_output_0 -> (1)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Concat_2 [Concat]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Unsqueeze_4_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Unsqueeze_5_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Constant_10_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Constant_11_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/self/Concat_2 [Concat] inputs: [/bert/encoder/layer.2/attention/self/Unsqueeze_4_output_0 -> (1)[INT32]], [/bert/encoder/layer.2/attention/self/Unsqueeze_5_output_0 -> (1)[INT32]], [/bert/encoder/layer.2/attention/self/Constant_10_output_0 -> (1)[INT32]], [/bert/encoder/layer.2/attention/self/Constant_11_output_0 -> (1)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Constant_10_output_0 for ONNX node: /bert/encoder/layer.2/attention/self/Constant_10_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Constant_11_output_0 for ONNX node: /bert/encoder/layer.2/attention/self/Constant_11_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Concat_2 for ONNX node: /bert/encoder/layer.2/attention/self/Concat_2\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/Concat_2_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/Concat_2_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/self/Concat_2 [Concat] outputs: [/bert/encoder/layer.2/attention/self/Concat_2_output_0 -> (4)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Reshape_2 [Reshape]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/query/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Concat_2_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/self/Reshape_2 [Reshape] inputs: [/bert/encoder/layer.2/attention/self/query/Add_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.2/attention/self/Concat_2_output_0 -> (4)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Reshape_2 for ONNX node: /bert/encoder/layer.2/attention/self/Reshape_2\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/Reshape_2_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/Reshape_2_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/self/Reshape_2 [Reshape] outputs: [/bert/encoder/layer.2/attention/self/Reshape_2_output_0 -> (-1, -1, 8, 32)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Transpose_1 [Transpose]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Reshape_2_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/self/Transpose_1 [Transpose] inputs: [/bert/encoder/layer.2/attention/self/Reshape_2_output_0 -> (-1, -1, 8, 32)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Transpose_1 for ONNX node: /bert/encoder/layer.2/attention/self/Transpose_1\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/Transpose_1_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/Transpose_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/self/Transpose_1 [Transpose] outputs: [/bert/encoder/layer.2/attention/self/Transpose_1_output_0 -> (-1, 8, -1, 32)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Transpose_2 [Transpose]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Reshape_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/self/Transpose_2 [Transpose] inputs: [/bert/encoder/layer.2/attention/self/Reshape_output_0 -> (-1, -1, 8, 32)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Transpose_2 for ONNX node: /bert/encoder/layer.2/attention/self/Transpose_2\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/Transpose_2_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/Transpose_2_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/self/Transpose_2 [Transpose] outputs: [/bert/encoder/layer.2/attention/self/Transpose_2_output_0 -> (-1, 8, 32, -1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/MatMul [MatMul]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Transpose_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Transpose_2_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/self/MatMul [MatMul] inputs: [/bert/encoder/layer.2/attention/self/Transpose_1_output_0 -> (-1, 8, -1, 32)[FLOAT]], [/bert/encoder/layer.2/attention/self/Transpose_2_output_0 -> (-1, 8, 32, -1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/MatMul for ONNX node: /bert/encoder/layer.2/attention/self/MatMul\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/MatMul_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/MatMul_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/self/MatMul [MatMul] outputs: [/bert/encoder/layer.2/attention/self/MatMul_output_0 -> (-1, 8, -1, -1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Constant_12 [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/self/Constant_12 [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/self/Constant_12 [Constant] outputs: [/bert/encoder/layer.2/attention/self/Constant_12_output_0 -> ()[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Div [Div]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/MatMul_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Constant_12_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/self/Div [Div] inputs: [/bert/encoder/layer.2/attention/self/MatMul_output_0 -> (-1, 8, -1, -1)[FLOAT]], [/bert/encoder/layer.2/attention/self/Constant_12_output_0 -> ()[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Constant_12_output_0 for ONNX node: /bert/encoder/layer.2/attention/self/Constant_12_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Div for ONNX node: /bert/encoder/layer.2/attention/self/Div\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/Div_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/Div_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/self/Div [Div] outputs: [/bert/encoder/layer.2/attention/self/Div_output_0 -> (-1, 8, -1, -1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Add [Add]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Div_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/Mul_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/self/Add [Add] inputs: [/bert/encoder/layer.2/attention/self/Div_output_0 -> (-1, 8, -1, -1)[FLOAT]], [/bert/Mul_output_0 -> (-1, 1, 1, -1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Add for ONNX node: /bert/encoder/layer.2/attention/self/Add\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/Add_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/self/Add [Add] outputs: [/bert/encoder/layer.2/attention/self/Add_output_0 -> (-1, 8, -1, -1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Softmax [Softmax]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/self/Softmax [Softmax] inputs: [/bert/encoder/layer.2/attention/self/Add_output_0 -> (-1, 8, -1, -1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Softmax for ONNX node: /bert/encoder/layer.2/attention/self/Softmax\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/Softmax_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/Softmax_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/self/Softmax [Softmax] outputs: [/bert/encoder/layer.2/attention/self/Softmax_output_0 -> (-1, 8, -1, -1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/MatMul_1 [MatMul]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Softmax_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Transpose_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/self/MatMul_1 [MatMul] inputs: [/bert/encoder/layer.2/attention/self/Softmax_output_0 -> (-1, 8, -1, -1)[FLOAT]], [/bert/encoder/layer.2/attention/self/Transpose_output_0 -> (-1, 8, -1, 32)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/MatMul_1 for ONNX node: /bert/encoder/layer.2/attention/self/MatMul_1\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/MatMul_1_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/MatMul_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/self/MatMul_1 [MatMul] outputs: [/bert/encoder/layer.2/attention/self/MatMul_1_output_0 -> (-1, 8, -1, 32)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Transpose_3 [Transpose]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/MatMul_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/self/Transpose_3 [Transpose] inputs: [/bert/encoder/layer.2/attention/self/MatMul_1_output_0 -> (-1, 8, -1, 32)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Transpose_3 for ONNX node: /bert/encoder/layer.2/attention/self/Transpose_3\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/Transpose_3_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/Transpose_3_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/self/Transpose_3 [Transpose] outputs: [/bert/encoder/layer.2/attention/self/Transpose_3_output_0 -> (-1, -1, 8, 32)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Shape_6 [Shape]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Transpose_3_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/self/Shape_6 [Shape] inputs: [/bert/encoder/layer.2/attention/self/Transpose_3_output_0 -> (-1, -1, 8, 32)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Shape_6 for ONNX node: /bert/encoder/layer.2/attention/self/Shape_6\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/Shape_6_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/Shape_6_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/self/Shape_6 [Shape] outputs: [/bert/encoder/layer.2/attention/self/Shape_6_output_0 -> (4)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Constant_13 [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/self/Constant_13 [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/self/Constant_13 [Constant] outputs: [/bert/encoder/layer.2/attention/self/Constant_13_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Gather_6 [Gather]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Shape_6_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Constant_13_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/self/Gather_6 [Gather] inputs: [/bert/encoder/layer.2/attention/self/Shape_6_output_0 -> (4)[INT32]], [/bert/encoder/layer.2/attention/self/Constant_13_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Constant_13_output_0 for ONNX node: /bert/encoder/layer.2/attention/self/Constant_13_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Using Gather axis: 0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Gather_6 for ONNX node: /bert/encoder/layer.2/attention/self/Gather_6\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/Gather_6_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/Gather_6_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/self/Gather_6 [Gather] outputs: [/bert/encoder/layer.2/attention/self/Gather_6_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Shape_7 [Shape]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Transpose_3_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/self/Shape_7 [Shape] inputs: [/bert/encoder/layer.2/attention/self/Transpose_3_output_0 -> (-1, -1, 8, 32)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Shape_7 for ONNX node: /bert/encoder/layer.2/attention/self/Shape_7\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/Shape_7_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/Shape_7_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/self/Shape_7 [Shape] outputs: [/bert/encoder/layer.2/attention/self/Shape_7_output_0 -> (4)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Constant_14 [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/self/Constant_14 [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/self/Constant_14 [Constant] outputs: [/bert/encoder/layer.2/attention/self/Constant_14_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Gather_7 [Gather]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Shape_7_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Constant_14_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/self/Gather_7 [Gather] inputs: [/bert/encoder/layer.2/attention/self/Shape_7_output_0 -> (4)[INT32]], [/bert/encoder/layer.2/attention/self/Constant_14_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Constant_14_output_0 for ONNX node: /bert/encoder/layer.2/attention/self/Constant_14_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Using Gather axis: 0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Gather_7 for ONNX node: /bert/encoder/layer.2/attention/self/Gather_7\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/Gather_7_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/Gather_7_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/self/Gather_7 [Gather] outputs: [/bert/encoder/layer.2/attention/self/Gather_7_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Unsqueeze_6 [Unsqueeze]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Gather_6_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/self/Unsqueeze_6 [Unsqueeze] inputs: [/bert/encoder/layer.2/attention/self/Gather_6_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Unsqueeze_6 for ONNX node: /bert/encoder/layer.2/attention/self/Unsqueeze_6\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/Unsqueeze_6_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/Unsqueeze_6_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/self/Unsqueeze_6 [Unsqueeze] outputs: [/bert/encoder/layer.2/attention/self/Unsqueeze_6_output_0 -> (1)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Unsqueeze_7 [Unsqueeze]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Gather_7_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/self/Unsqueeze_7 [Unsqueeze] inputs: [/bert/encoder/layer.2/attention/self/Gather_7_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Unsqueeze_7 for ONNX node: /bert/encoder/layer.2/attention/self/Unsqueeze_7\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/Unsqueeze_7_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/Unsqueeze_7_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/self/Unsqueeze_7 [Unsqueeze] outputs: [/bert/encoder/layer.2/attention/self/Unsqueeze_7_output_0 -> (1)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Constant_15 [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/self/Constant_15 [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/self/Constant_15 [Constant] outputs: [/bert/encoder/layer.2/attention/self/Constant_15_output_0 -> (1)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Concat_3 [Concat]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Unsqueeze_6_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Unsqueeze_7_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Constant_15_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/self/Concat_3 [Concat] inputs: [/bert/encoder/layer.2/attention/self/Unsqueeze_6_output_0 -> (1)[INT32]], [/bert/encoder/layer.2/attention/self/Unsqueeze_7_output_0 -> (1)[INT32]], [/bert/encoder/layer.2/attention/self/Constant_15_output_0 -> (1)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Constant_15_output_0 for ONNX node: /bert/encoder/layer.2/attention/self/Constant_15_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Concat_3 for ONNX node: /bert/encoder/layer.2/attention/self/Concat_3\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/Concat_3_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/Concat_3_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/self/Concat_3 [Concat] outputs: [/bert/encoder/layer.2/attention/self/Concat_3_output_0 -> (3)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Reshape_3 [Reshape]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Transpose_3_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Concat_3_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/self/Reshape_3 [Reshape] inputs: [/bert/encoder/layer.2/attention/self/Transpose_3_output_0 -> (-1, -1, 8, 32)[FLOAT]], [/bert/encoder/layer.2/attention/self/Concat_3_output_0 -> (3)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Reshape_3 for ONNX node: /bert/encoder/layer.2/attention/self/Reshape_3\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/Reshape_3_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/Reshape_3_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/self/Reshape_3 [Reshape] outputs: [/bert/encoder/layer.2/attention/self/Reshape_3_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/output/dense/MatMul [MatMul]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Reshape_3_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: onnx::MatMul_829\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/output/dense/MatMul [MatMul] inputs: [/bert/encoder/layer.2/attention/self/Reshape_3_output_0 -> (-1, -1, 256)[FLOAT]], [onnx::MatMul_829 -> (256, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: onnx::MatMul_829 for ONNX node: onnx::MatMul_829\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/output/dense/MatMul for ONNX node: /bert/encoder/layer.2/attention/output/dense/MatMul\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/output/dense/MatMul_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/output/dense/MatMul_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/output/dense/MatMul [MatMul] outputs: [/bert/encoder/layer.2/attention/output/dense/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/output/dense/Add [Add]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: bert.encoder.layer.2.attention.output.dense.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/output/dense/MatMul_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/output/dense/Add [Add] inputs: [bert.encoder.layer.2.attention.output.dense.bias -> (256)[FLOAT]], [/bert/encoder/layer.2/attention/output/dense/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: bert.encoder.layer.2.attention.output.dense.bias for ONNX node: bert.encoder.layer.2.attention.output.dense.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/output/dense/Add for ONNX node: /bert/encoder/layer.2/attention/output/dense/Add\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/output/dense/Add_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/output/dense/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/output/dense/Add [Add] outputs: [/bert/encoder/layer.2/attention/output/dense/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/output/Add [Add]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/output/dense/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.1/output/LayerNorm/Add_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/output/Add [Add] inputs: [/bert/encoder/layer.2/attention/output/dense/Add_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.1/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/output/Add for ONNX node: /bert/encoder/layer.2/attention/output/Add\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/output/Add_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/output/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/output/Add [Add] outputs: [/bert/encoder/layer.2/attention/output/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/output/LayerNorm/ReduceMean [ReduceMean]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/output/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/output/LayerNorm/ReduceMean [ReduceMean] inputs: [/bert/encoder/layer.2/attention/output/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/output/LayerNorm/ReduceMean for ONNX node: /bert/encoder/layer.2/attention/output/LayerNorm/ReduceMean\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/output/LayerNorm/ReduceMean_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/output/LayerNorm/ReduceMean_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/output/LayerNorm/ReduceMean [ReduceMean] outputs: [/bert/encoder/layer.2/attention/output/LayerNorm/ReduceMean_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/output/LayerNorm/Sub [Sub]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/output/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/output/LayerNorm/ReduceMean_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/output/LayerNorm/Sub [Sub] inputs: [/bert/encoder/layer.2/attention/output/Add_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.2/attention/output/LayerNorm/ReduceMean_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/output/LayerNorm/Sub for ONNX node: /bert/encoder/layer.2/attention/output/LayerNorm/Sub\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/output/LayerNorm/Sub_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/output/LayerNorm/Sub_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/output/LayerNorm/Sub [Sub] outputs: [/bert/encoder/layer.2/attention/output/LayerNorm/Sub_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/output/LayerNorm/Constant [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/output/LayerNorm/Constant [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/output/LayerNorm/Constant [Constant] outputs: [/bert/encoder/layer.2/attention/output/LayerNorm/Constant_output_0 -> ()[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/output/LayerNorm/Pow [Pow]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/output/LayerNorm/Sub_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/output/LayerNorm/Constant_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/output/LayerNorm/Pow [Pow] inputs: [/bert/encoder/layer.2/attention/output/LayerNorm/Sub_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.2/attention/output/LayerNorm/Constant_output_0 -> ()[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/output/LayerNorm/Constant_output_0 for ONNX node: /bert/encoder/layer.2/attention/output/LayerNorm/Constant_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/output/LayerNorm/Pow for ONNX node: /bert/encoder/layer.2/attention/output/LayerNorm/Pow\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/output/LayerNorm/Pow_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/output/LayerNorm/Pow_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/output/LayerNorm/Pow [Pow] outputs: [/bert/encoder/layer.2/attention/output/LayerNorm/Pow_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/output/LayerNorm/ReduceMean_1 [ReduceMean]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/output/LayerNorm/Pow_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/output/LayerNorm/ReduceMean_1 [ReduceMean] inputs: [/bert/encoder/layer.2/attention/output/LayerNorm/Pow_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/output/LayerNorm/ReduceMean_1 for ONNX node: /bert/encoder/layer.2/attention/output/LayerNorm/ReduceMean_1\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/output/LayerNorm/ReduceMean_1_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/output/LayerNorm/ReduceMean_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/output/LayerNorm/ReduceMean_1 [ReduceMean] outputs: [/bert/encoder/layer.2/attention/output/LayerNorm/ReduceMean_1_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/output/LayerNorm/Constant_1 [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/output/LayerNorm/Constant_1 [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/output/LayerNorm/Constant_1 [Constant] outputs: [/bert/encoder/layer.2/attention/output/LayerNorm/Constant_1_output_0 -> ()[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/output/LayerNorm/Add [Add]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/output/LayerNorm/ReduceMean_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/output/LayerNorm/Constant_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/output/LayerNorm/Add [Add] inputs: [/bert/encoder/layer.2/attention/output/LayerNorm/ReduceMean_1_output_0 -> (-1, -1, 1)[FLOAT]], [/bert/encoder/layer.2/attention/output/LayerNorm/Constant_1_output_0 -> ()[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/output/LayerNorm/Constant_1_output_0 for ONNX node: /bert/encoder/layer.2/attention/output/LayerNorm/Constant_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/output/LayerNorm/Add for ONNX node: /bert/encoder/layer.2/attention/output/LayerNorm/Add\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/output/LayerNorm/Add_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/output/LayerNorm/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/output/LayerNorm/Add [Add] outputs: [/bert/encoder/layer.2/attention/output/LayerNorm/Add_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/output/LayerNorm/Sqrt [Sqrt]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/output/LayerNorm/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/output/LayerNorm/Sqrt [Sqrt] inputs: [/bert/encoder/layer.2/attention/output/LayerNorm/Add_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/output/LayerNorm/Sqrt for ONNX node: /bert/encoder/layer.2/attention/output/LayerNorm/Sqrt\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/output/LayerNorm/Sqrt_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/output/LayerNorm/Sqrt_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/output/LayerNorm/Sqrt [Sqrt] outputs: [/bert/encoder/layer.2/attention/output/LayerNorm/Sqrt_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/output/LayerNorm/Div [Div]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/output/LayerNorm/Sub_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/output/LayerNorm/Sqrt_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/output/LayerNorm/Div [Div] inputs: [/bert/encoder/layer.2/attention/output/LayerNorm/Sub_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.2/attention/output/LayerNorm/Sqrt_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/output/LayerNorm/Div for ONNX node: /bert/encoder/layer.2/attention/output/LayerNorm/Div\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/output/LayerNorm/Div_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/output/LayerNorm/Div_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/output/LayerNorm/Div [Div] outputs: [/bert/encoder/layer.2/attention/output/LayerNorm/Div_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/output/LayerNorm/Mul [Mul]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/output/LayerNorm/Div_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: bert.encoder.layer.2.attention.output.LayerNorm.weight\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/output/LayerNorm/Mul [Mul] inputs: [/bert/encoder/layer.2/attention/output/LayerNorm/Div_output_0 -> (-1, -1, 256)[FLOAT]], [bert.encoder.layer.2.attention.output.LayerNorm.weight -> (256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: bert.encoder.layer.2.attention.output.LayerNorm.weight for ONNX node: bert.encoder.layer.2.attention.output.LayerNorm.weight\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/output/LayerNorm/Mul for ONNX node: /bert/encoder/layer.2/attention/output/LayerNorm/Mul\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/output/LayerNorm/Mul_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/output/LayerNorm/Mul_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/output/LayerNorm/Mul [Mul] outputs: [/bert/encoder/layer.2/attention/output/LayerNorm/Mul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/output/LayerNorm/Add_1 [Add]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/output/LayerNorm/Mul_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: bert.encoder.layer.2.attention.output.LayerNorm.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/output/LayerNorm/Add_1 [Add] inputs: [/bert/encoder/layer.2/attention/output/LayerNorm/Mul_output_0 -> (-1, -1, 256)[FLOAT]], [bert.encoder.layer.2.attention.output.LayerNorm.bias -> (256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: bert.encoder.layer.2.attention.output.LayerNorm.bias for ONNX node: bert.encoder.layer.2.attention.output.LayerNorm.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/output/LayerNorm/Add_1 for ONNX node: /bert/encoder/layer.2/attention/output/LayerNorm/Add_1\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/output/LayerNorm/Add_1_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/output/LayerNorm/Add_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/attention/output/LayerNorm/Add_1 [Add] outputs: [/bert/encoder/layer.2/attention/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.2/intermediate/dense/MatMul [MatMul]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/output/LayerNorm/Add_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: onnx::MatMul_830\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/intermediate/dense/MatMul [MatMul] inputs: [/bert/encoder/layer.2/attention/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], [onnx::MatMul_830 -> (256, 1024)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: onnx::MatMul_830 for ONNX node: onnx::MatMul_830\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.2/intermediate/dense/MatMul for ONNX node: /bert/encoder/layer.2/intermediate/dense/MatMul\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.2/intermediate/dense/MatMul_output_0 for ONNX tensor: /bert/encoder/layer.2/intermediate/dense/MatMul_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/intermediate/dense/MatMul [MatMul] outputs: [/bert/encoder/layer.2/intermediate/dense/MatMul_output_0 -> (-1, -1, 1024)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.2/intermediate/dense/Add [Add]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: bert.encoder.layer.2.intermediate.dense.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.2/intermediate/dense/MatMul_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/intermediate/dense/Add [Add] inputs: [bert.encoder.layer.2.intermediate.dense.bias -> (1024)[FLOAT]], [/bert/encoder/layer.2/intermediate/dense/MatMul_output_0 -> (-1, -1, 1024)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: bert.encoder.layer.2.intermediate.dense.bias for ONNX node: bert.encoder.layer.2.intermediate.dense.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.2/intermediate/dense/Add for ONNX node: /bert/encoder/layer.2/intermediate/dense/Add\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.2/intermediate/dense/Add_output_0 for ONNX tensor: /bert/encoder/layer.2/intermediate/dense/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/intermediate/dense/Add [Add] outputs: [/bert/encoder/layer.2/intermediate/dense/Add_output_0 -> (-1, -1, 1024)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.2/intermediate/intermediate_act_fn/Constant [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/intermediate/intermediate_act_fn/Constant [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/intermediate/intermediate_act_fn/Constant [Constant] outputs: [/bert/encoder/layer.2/intermediate/intermediate_act_fn/Constant_output_0 -> ()[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.2/intermediate/intermediate_act_fn/Div [Div]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.2/intermediate/dense/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.2/intermediate/intermediate_act_fn/Constant_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/intermediate/intermediate_act_fn/Div [Div] inputs: [/bert/encoder/layer.2/intermediate/dense/Add_output_0 -> (-1, -1, 1024)[FLOAT]], [/bert/encoder/layer.2/intermediate/intermediate_act_fn/Constant_output_0 -> ()[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.2/intermediate/intermediate_act_fn/Constant_output_0 for ONNX node: /bert/encoder/layer.2/intermediate/intermediate_act_fn/Constant_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.2/intermediate/intermediate_act_fn/Div for ONNX node: /bert/encoder/layer.2/intermediate/intermediate_act_fn/Div\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.2/intermediate/intermediate_act_fn/Div_output_0 for ONNX tensor: /bert/encoder/layer.2/intermediate/intermediate_act_fn/Div_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/intermediate/intermediate_act_fn/Div [Div] outputs: [/bert/encoder/layer.2/intermediate/intermediate_act_fn/Div_output_0 -> (-1, -1, 1024)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.2/intermediate/intermediate_act_fn/Erf [Erf]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.2/intermediate/intermediate_act_fn/Div_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/intermediate/intermediate_act_fn/Erf [Erf] inputs: [/bert/encoder/layer.2/intermediate/intermediate_act_fn/Div_output_0 -> (-1, -1, 1024)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.2/intermediate/intermediate_act_fn/Erf for ONNX node: /bert/encoder/layer.2/intermediate/intermediate_act_fn/Erf\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.2/intermediate/intermediate_act_fn/Erf_output_0 for ONNX tensor: /bert/encoder/layer.2/intermediate/intermediate_act_fn/Erf_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/intermediate/intermediate_act_fn/Erf [Erf] outputs: [/bert/encoder/layer.2/intermediate/intermediate_act_fn/Erf_output_0 -> (-1, -1, 1024)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.2/intermediate/intermediate_act_fn/Constant_1 [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/intermediate/intermediate_act_fn/Constant_1 [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/intermediate/intermediate_act_fn/Constant_1 [Constant] outputs: [/bert/encoder/layer.2/intermediate/intermediate_act_fn/Constant_1_output_0 -> ()[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.2/intermediate/intermediate_act_fn/Add [Add]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.2/intermediate/intermediate_act_fn/Erf_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.2/intermediate/intermediate_act_fn/Constant_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/intermediate/intermediate_act_fn/Add [Add] inputs: [/bert/encoder/layer.2/intermediate/intermediate_act_fn/Erf_output_0 -> (-1, -1, 1024)[FLOAT]], [/bert/encoder/layer.2/intermediate/intermediate_act_fn/Constant_1_output_0 -> ()[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.2/intermediate/intermediate_act_fn/Constant_1_output_0 for ONNX node: /bert/encoder/layer.2/intermediate/intermediate_act_fn/Constant_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.2/intermediate/intermediate_act_fn/Add for ONNX node: /bert/encoder/layer.2/intermediate/intermediate_act_fn/Add\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.2/intermediate/intermediate_act_fn/Add_output_0 for ONNX tensor: /bert/encoder/layer.2/intermediate/intermediate_act_fn/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/intermediate/intermediate_act_fn/Add [Add] outputs: [/bert/encoder/layer.2/intermediate/intermediate_act_fn/Add_output_0 -> (-1, -1, 1024)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.2/intermediate/intermediate_act_fn/Mul [Mul]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.2/intermediate/dense/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.2/intermediate/intermediate_act_fn/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/intermediate/intermediate_act_fn/Mul [Mul] inputs: [/bert/encoder/layer.2/intermediate/dense/Add_output_0 -> (-1, -1, 1024)[FLOAT]], [/bert/encoder/layer.2/intermediate/intermediate_act_fn/Add_output_0 -> (-1, -1, 1024)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.2/intermediate/intermediate_act_fn/Mul for ONNX node: /bert/encoder/layer.2/intermediate/intermediate_act_fn/Mul\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.2/intermediate/intermediate_act_fn/Mul_output_0 for ONNX tensor: /bert/encoder/layer.2/intermediate/intermediate_act_fn/Mul_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/intermediate/intermediate_act_fn/Mul [Mul] outputs: [/bert/encoder/layer.2/intermediate/intermediate_act_fn/Mul_output_0 -> (-1, -1, 1024)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.2/intermediate/intermediate_act_fn/Constant_2 [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/intermediate/intermediate_act_fn/Constant_2 [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/intermediate/intermediate_act_fn/Constant_2 [Constant] outputs: [/bert/encoder/layer.2/intermediate/intermediate_act_fn/Constant_2_output_0 -> ()[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.2/intermediate/intermediate_act_fn/Mul_1 [Mul]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.2/intermediate/intermediate_act_fn/Mul_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.2/intermediate/intermediate_act_fn/Constant_2_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/intermediate/intermediate_act_fn/Mul_1 [Mul] inputs: [/bert/encoder/layer.2/intermediate/intermediate_act_fn/Mul_output_0 -> (-1, -1, 1024)[FLOAT]], [/bert/encoder/layer.2/intermediate/intermediate_act_fn/Constant_2_output_0 -> ()[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.2/intermediate/intermediate_act_fn/Constant_2_output_0 for ONNX node: /bert/encoder/layer.2/intermediate/intermediate_act_fn/Constant_2_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.2/intermediate/intermediate_act_fn/Mul_1 for ONNX node: /bert/encoder/layer.2/intermediate/intermediate_act_fn/Mul_1\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.2/intermediate/intermediate_act_fn/Mul_1_output_0 for ONNX tensor: /bert/encoder/layer.2/intermediate/intermediate_act_fn/Mul_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/intermediate/intermediate_act_fn/Mul_1 [Mul] outputs: [/bert/encoder/layer.2/intermediate/intermediate_act_fn/Mul_1_output_0 -> (-1, -1, 1024)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.2/output/dense/MatMul [MatMul]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.2/intermediate/intermediate_act_fn/Mul_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: onnx::MatMul_831\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/output/dense/MatMul [MatMul] inputs: [/bert/encoder/layer.2/intermediate/intermediate_act_fn/Mul_1_output_0 -> (-1, -1, 1024)[FLOAT]], [onnx::MatMul_831 -> (1024, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: onnx::MatMul_831 for ONNX node: onnx::MatMul_831\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.2/output/dense/MatMul for ONNX node: /bert/encoder/layer.2/output/dense/MatMul\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.2/output/dense/MatMul_output_0 for ONNX tensor: /bert/encoder/layer.2/output/dense/MatMul_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/output/dense/MatMul [MatMul] outputs: [/bert/encoder/layer.2/output/dense/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.2/output/dense/Add [Add]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: bert.encoder.layer.2.output.dense.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.2/output/dense/MatMul_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/output/dense/Add [Add] inputs: [bert.encoder.layer.2.output.dense.bias -> (256)[FLOAT]], [/bert/encoder/layer.2/output/dense/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: bert.encoder.layer.2.output.dense.bias for ONNX node: bert.encoder.layer.2.output.dense.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.2/output/dense/Add for ONNX node: /bert/encoder/layer.2/output/dense/Add\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.2/output/dense/Add_output_0 for ONNX tensor: /bert/encoder/layer.2/output/dense/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/output/dense/Add [Add] outputs: [/bert/encoder/layer.2/output/dense/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.2/output/Add [Add]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.2/output/dense/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/output/LayerNorm/Add_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/output/Add [Add] inputs: [/bert/encoder/layer.2/output/dense/Add_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.2/attention/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.2/output/Add for ONNX node: /bert/encoder/layer.2/output/Add\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.2/output/Add_output_0 for ONNX tensor: /bert/encoder/layer.2/output/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/output/Add [Add] outputs: [/bert/encoder/layer.2/output/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.2/output/LayerNorm/ReduceMean [ReduceMean]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.2/output/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/output/LayerNorm/ReduceMean [ReduceMean] inputs: [/bert/encoder/layer.2/output/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.2/output/LayerNorm/ReduceMean for ONNX node: /bert/encoder/layer.2/output/LayerNorm/ReduceMean\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.2/output/LayerNorm/ReduceMean_output_0 for ONNX tensor: /bert/encoder/layer.2/output/LayerNorm/ReduceMean_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/output/LayerNorm/ReduceMean [ReduceMean] outputs: [/bert/encoder/layer.2/output/LayerNorm/ReduceMean_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.2/output/LayerNorm/Sub [Sub]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.2/output/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.2/output/LayerNorm/ReduceMean_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/output/LayerNorm/Sub [Sub] inputs: [/bert/encoder/layer.2/output/Add_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.2/output/LayerNorm/ReduceMean_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.2/output/LayerNorm/Sub for ONNX node: /bert/encoder/layer.2/output/LayerNorm/Sub\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.2/output/LayerNorm/Sub_output_0 for ONNX tensor: /bert/encoder/layer.2/output/LayerNorm/Sub_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/output/LayerNorm/Sub [Sub] outputs: [/bert/encoder/layer.2/output/LayerNorm/Sub_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.2/output/LayerNorm/Constant [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/output/LayerNorm/Constant [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/output/LayerNorm/Constant [Constant] outputs: [/bert/encoder/layer.2/output/LayerNorm/Constant_output_0 -> ()[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.2/output/LayerNorm/Pow [Pow]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.2/output/LayerNorm/Sub_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.2/output/LayerNorm/Constant_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/output/LayerNorm/Pow [Pow] inputs: [/bert/encoder/layer.2/output/LayerNorm/Sub_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.2/output/LayerNorm/Constant_output_0 -> ()[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.2/output/LayerNorm/Constant_output_0 for ONNX node: /bert/encoder/layer.2/output/LayerNorm/Constant_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.2/output/LayerNorm/Pow for ONNX node: /bert/encoder/layer.2/output/LayerNorm/Pow\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.2/output/LayerNorm/Pow_output_0 for ONNX tensor: /bert/encoder/layer.2/output/LayerNorm/Pow_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/output/LayerNorm/Pow [Pow] outputs: [/bert/encoder/layer.2/output/LayerNorm/Pow_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.2/output/LayerNorm/ReduceMean_1 [ReduceMean]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.2/output/LayerNorm/Pow_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/output/LayerNorm/ReduceMean_1 [ReduceMean] inputs: [/bert/encoder/layer.2/output/LayerNorm/Pow_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.2/output/LayerNorm/ReduceMean_1 for ONNX node: /bert/encoder/layer.2/output/LayerNorm/ReduceMean_1\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.2/output/LayerNorm/ReduceMean_1_output_0 for ONNX tensor: /bert/encoder/layer.2/output/LayerNorm/ReduceMean_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/output/LayerNorm/ReduceMean_1 [ReduceMean] outputs: [/bert/encoder/layer.2/output/LayerNorm/ReduceMean_1_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.2/output/LayerNorm/Constant_1 [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/output/LayerNorm/Constant_1 [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/output/LayerNorm/Constant_1 [Constant] outputs: [/bert/encoder/layer.2/output/LayerNorm/Constant_1_output_0 -> ()[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.2/output/LayerNorm/Add [Add]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.2/output/LayerNorm/ReduceMean_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.2/output/LayerNorm/Constant_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/output/LayerNorm/Add [Add] inputs: [/bert/encoder/layer.2/output/LayerNorm/ReduceMean_1_output_0 -> (-1, -1, 1)[FLOAT]], [/bert/encoder/layer.2/output/LayerNorm/Constant_1_output_0 -> ()[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.2/output/LayerNorm/Constant_1_output_0 for ONNX node: /bert/encoder/layer.2/output/LayerNorm/Constant_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.2/output/LayerNorm/Add for ONNX node: /bert/encoder/layer.2/output/LayerNorm/Add\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.2/output/LayerNorm/Add_output_0 for ONNX tensor: /bert/encoder/layer.2/output/LayerNorm/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/output/LayerNorm/Add [Add] outputs: [/bert/encoder/layer.2/output/LayerNorm/Add_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.2/output/LayerNorm/Sqrt [Sqrt]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.2/output/LayerNorm/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/output/LayerNorm/Sqrt [Sqrt] inputs: [/bert/encoder/layer.2/output/LayerNorm/Add_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.2/output/LayerNorm/Sqrt for ONNX node: /bert/encoder/layer.2/output/LayerNorm/Sqrt\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.2/output/LayerNorm/Sqrt_output_0 for ONNX tensor: /bert/encoder/layer.2/output/LayerNorm/Sqrt_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/output/LayerNorm/Sqrt [Sqrt] outputs: [/bert/encoder/layer.2/output/LayerNorm/Sqrt_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.2/output/LayerNorm/Div [Div]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.2/output/LayerNorm/Sub_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.2/output/LayerNorm/Sqrt_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/output/LayerNorm/Div [Div] inputs: [/bert/encoder/layer.2/output/LayerNorm/Sub_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.2/output/LayerNorm/Sqrt_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.2/output/LayerNorm/Div for ONNX node: /bert/encoder/layer.2/output/LayerNorm/Div\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.2/output/LayerNorm/Div_output_0 for ONNX tensor: /bert/encoder/layer.2/output/LayerNorm/Div_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/output/LayerNorm/Div [Div] outputs: [/bert/encoder/layer.2/output/LayerNorm/Div_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.2/output/LayerNorm/Mul [Mul]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.2/output/LayerNorm/Div_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: bert.encoder.layer.2.output.LayerNorm.weight\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/output/LayerNorm/Mul [Mul] inputs: [/bert/encoder/layer.2/output/LayerNorm/Div_output_0 -> (-1, -1, 256)[FLOAT]], [bert.encoder.layer.2.output.LayerNorm.weight -> (256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: bert.encoder.layer.2.output.LayerNorm.weight for ONNX node: bert.encoder.layer.2.output.LayerNorm.weight\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.2/output/LayerNorm/Mul for ONNX node: /bert/encoder/layer.2/output/LayerNorm/Mul\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.2/output/LayerNorm/Mul_output_0 for ONNX tensor: /bert/encoder/layer.2/output/LayerNorm/Mul_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/output/LayerNorm/Mul [Mul] outputs: [/bert/encoder/layer.2/output/LayerNorm/Mul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.2/output/LayerNorm/Add_1 [Add]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.2/output/LayerNorm/Mul_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: bert.encoder.layer.2.output.LayerNorm.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/output/LayerNorm/Add_1 [Add] inputs: [/bert/encoder/layer.2/output/LayerNorm/Mul_output_0 -> (-1, -1, 256)[FLOAT]], [bert.encoder.layer.2.output.LayerNorm.bias -> (256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: bert.encoder.layer.2.output.LayerNorm.bias for ONNX node: bert.encoder.layer.2.output.LayerNorm.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.2/output/LayerNorm/Add_1 for ONNX node: /bert/encoder/layer.2/output/LayerNorm/Add_1\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.2/output/LayerNorm/Add_1_output_0 for ONNX tensor: /bert/encoder/layer.2/output/LayerNorm/Add_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.2/output/LayerNorm/Add_1 [Add] outputs: [/bert/encoder/layer.2/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/query/MatMul [MatMul]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.2/output/LayerNorm/Add_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: onnx::MatMul_832\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/self/query/MatMul [MatMul] inputs: [/bert/encoder/layer.2/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], [onnx::MatMul_832 -> (256, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: onnx::MatMul_832 for ONNX node: onnx::MatMul_832\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/query/MatMul for ONNX node: /bert/encoder/layer.3/attention/self/query/MatMul\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/query/MatMul_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/query/MatMul_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/self/query/MatMul [MatMul] outputs: [/bert/encoder/layer.3/attention/self/query/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/query/Add [Add]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: bert.encoder.layer.3.attention.self.query.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/query/MatMul_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/self/query/Add [Add] inputs: [bert.encoder.layer.3.attention.self.query.bias -> (256)[FLOAT]], [/bert/encoder/layer.3/attention/self/query/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: bert.encoder.layer.3.attention.self.query.bias for ONNX node: bert.encoder.layer.3.attention.self.query.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/query/Add for ONNX node: /bert/encoder/layer.3/attention/self/query/Add\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/query/Add_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/query/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/self/query/Add [Add] outputs: [/bert/encoder/layer.3/attention/self/query/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/key/MatMul [MatMul]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.2/output/LayerNorm/Add_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: onnx::MatMul_833\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/self/key/MatMul [MatMul] inputs: [/bert/encoder/layer.2/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], [onnx::MatMul_833 -> (256, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: onnx::MatMul_833 for ONNX node: onnx::MatMul_833\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/key/MatMul for ONNX node: /bert/encoder/layer.3/attention/self/key/MatMul\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/key/MatMul_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/key/MatMul_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/self/key/MatMul [MatMul] outputs: [/bert/encoder/layer.3/attention/self/key/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/key/Add [Add]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: bert.encoder.layer.3.attention.self.key.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/key/MatMul_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/self/key/Add [Add] inputs: [bert.encoder.layer.3.attention.self.key.bias -> (256)[FLOAT]], [/bert/encoder/layer.3/attention/self/key/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: bert.encoder.layer.3.attention.self.key.bias for ONNX node: bert.encoder.layer.3.attention.self.key.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/key/Add for ONNX node: /bert/encoder/layer.3/attention/self/key/Add\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/key/Add_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/key/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/self/key/Add [Add] outputs: [/bert/encoder/layer.3/attention/self/key/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Shape [Shape]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/key/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/self/Shape [Shape] inputs: [/bert/encoder/layer.3/attention/self/key/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Shape for ONNX node: /bert/encoder/layer.3/attention/self/Shape\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/Shape_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/Shape_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/self/Shape [Shape] outputs: [/bert/encoder/layer.3/attention/self/Shape_output_0 -> (3)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Constant [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/self/Constant [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/self/Constant [Constant] outputs: [/bert/encoder/layer.3/attention/self/Constant_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Gather [Gather]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Shape_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Constant_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/self/Gather [Gather] inputs: [/bert/encoder/layer.3/attention/self/Shape_output_0 -> (3)[INT32]], [/bert/encoder/layer.3/attention/self/Constant_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Constant_output_0 for ONNX node: /bert/encoder/layer.3/attention/self/Constant_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Using Gather axis: 0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Gather for ONNX node: /bert/encoder/layer.3/attention/self/Gather\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/Gather_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/Gather_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/self/Gather [Gather] outputs: [/bert/encoder/layer.3/attention/self/Gather_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Shape_1 [Shape]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/key/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/self/Shape_1 [Shape] inputs: [/bert/encoder/layer.3/attention/self/key/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Shape_1 for ONNX node: /bert/encoder/layer.3/attention/self/Shape_1\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/Shape_1_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/Shape_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/self/Shape_1 [Shape] outputs: [/bert/encoder/layer.3/attention/self/Shape_1_output_0 -> (3)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Constant_1 [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/self/Constant_1 [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/self/Constant_1 [Constant] outputs: [/bert/encoder/layer.3/attention/self/Constant_1_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Gather_1 [Gather]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Shape_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Constant_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/self/Gather_1 [Gather] inputs: [/bert/encoder/layer.3/attention/self/Shape_1_output_0 -> (3)[INT32]], [/bert/encoder/layer.3/attention/self/Constant_1_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Constant_1_output_0 for ONNX node: /bert/encoder/layer.3/attention/self/Constant_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Using Gather axis: 0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Gather_1 for ONNX node: /bert/encoder/layer.3/attention/self/Gather_1\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/Gather_1_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/Gather_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/self/Gather_1 [Gather] outputs: [/bert/encoder/layer.3/attention/self/Gather_1_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Unsqueeze [Unsqueeze]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Gather_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/self/Unsqueeze [Unsqueeze] inputs: [/bert/encoder/layer.3/attention/self/Gather_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Unsqueeze for ONNX node: /bert/encoder/layer.3/attention/self/Unsqueeze\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/Unsqueeze_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/Unsqueeze_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/self/Unsqueeze [Unsqueeze] outputs: [/bert/encoder/layer.3/attention/self/Unsqueeze_output_0 -> (1)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Unsqueeze_1 [Unsqueeze]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Gather_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/self/Unsqueeze_1 [Unsqueeze] inputs: [/bert/encoder/layer.3/attention/self/Gather_1_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Unsqueeze_1 for ONNX node: /bert/encoder/layer.3/attention/self/Unsqueeze_1\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/Unsqueeze_1_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/Unsqueeze_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/self/Unsqueeze_1 [Unsqueeze] outputs: [/bert/encoder/layer.3/attention/self/Unsqueeze_1_output_0 -> (1)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Constant_2 [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/self/Constant_2 [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/self/Constant_2 [Constant] outputs: [/bert/encoder/layer.3/attention/self/Constant_2_output_0 -> (1)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Constant_3 [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/self/Constant_3 [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/self/Constant_3 [Constant] outputs: [/bert/encoder/layer.3/attention/self/Constant_3_output_0 -> (1)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Concat [Concat]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Unsqueeze_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Unsqueeze_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Constant_2_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Constant_3_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/self/Concat [Concat] inputs: [/bert/encoder/layer.3/attention/self/Unsqueeze_output_0 -> (1)[INT32]], [/bert/encoder/layer.3/attention/self/Unsqueeze_1_output_0 -> (1)[INT32]], [/bert/encoder/layer.3/attention/self/Constant_2_output_0 -> (1)[INT32]], [/bert/encoder/layer.3/attention/self/Constant_3_output_0 -> (1)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Constant_2_output_0 for ONNX node: /bert/encoder/layer.3/attention/self/Constant_2_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Constant_3_output_0 for ONNX node: /bert/encoder/layer.3/attention/self/Constant_3_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Concat for ONNX node: /bert/encoder/layer.3/attention/self/Concat\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/Concat_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/Concat_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/self/Concat [Concat] outputs: [/bert/encoder/layer.3/attention/self/Concat_output_0 -> (4)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Reshape [Reshape]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/key/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Concat_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/self/Reshape [Reshape] inputs: [/bert/encoder/layer.3/attention/self/key/Add_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.3/attention/self/Concat_output_0 -> (4)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Reshape for ONNX node: /bert/encoder/layer.3/attention/self/Reshape\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/Reshape_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/Reshape_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/self/Reshape [Reshape] outputs: [/bert/encoder/layer.3/attention/self/Reshape_output_0 -> (-1, -1, 8, 32)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/value/MatMul [MatMul]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.2/output/LayerNorm/Add_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: onnx::MatMul_836\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/self/value/MatMul [MatMul] inputs: [/bert/encoder/layer.2/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], [onnx::MatMul_836 -> (256, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: onnx::MatMul_836 for ONNX node: onnx::MatMul_836\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/value/MatMul for ONNX node: /bert/encoder/layer.3/attention/self/value/MatMul\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/value/MatMul_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/value/MatMul_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/self/value/MatMul [MatMul] outputs: [/bert/encoder/layer.3/attention/self/value/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/value/Add [Add]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: bert.encoder.layer.3.attention.self.value.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/value/MatMul_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/self/value/Add [Add] inputs: [bert.encoder.layer.3.attention.self.value.bias -> (256)[FLOAT]], [/bert/encoder/layer.3/attention/self/value/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: bert.encoder.layer.3.attention.self.value.bias for ONNX node: bert.encoder.layer.3.attention.self.value.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/value/Add for ONNX node: /bert/encoder/layer.3/attention/self/value/Add\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/value/Add_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/value/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/self/value/Add [Add] outputs: [/bert/encoder/layer.3/attention/self/value/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Shape_2 [Shape]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/value/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/self/Shape_2 [Shape] inputs: [/bert/encoder/layer.3/attention/self/value/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Shape_2 for ONNX node: /bert/encoder/layer.3/attention/self/Shape_2\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/Shape_2_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/Shape_2_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/self/Shape_2 [Shape] outputs: [/bert/encoder/layer.3/attention/self/Shape_2_output_0 -> (3)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Constant_4 [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/self/Constant_4 [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/self/Constant_4 [Constant] outputs: [/bert/encoder/layer.3/attention/self/Constant_4_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Gather_2 [Gather]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Shape_2_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Constant_4_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/self/Gather_2 [Gather] inputs: [/bert/encoder/layer.3/attention/self/Shape_2_output_0 -> (3)[INT32]], [/bert/encoder/layer.3/attention/self/Constant_4_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Constant_4_output_0 for ONNX node: /bert/encoder/layer.3/attention/self/Constant_4_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Using Gather axis: 0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Gather_2 for ONNX node: /bert/encoder/layer.3/attention/self/Gather_2\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/Gather_2_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/Gather_2_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/self/Gather_2 [Gather] outputs: [/bert/encoder/layer.3/attention/self/Gather_2_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Shape_3 [Shape]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/value/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/self/Shape_3 [Shape] inputs: [/bert/encoder/layer.3/attention/self/value/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Shape_3 for ONNX node: /bert/encoder/layer.3/attention/self/Shape_3\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/Shape_3_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/Shape_3_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/self/Shape_3 [Shape] outputs: [/bert/encoder/layer.3/attention/self/Shape_3_output_0 -> (3)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Constant_5 [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/self/Constant_5 [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/self/Constant_5 [Constant] outputs: [/bert/encoder/layer.3/attention/self/Constant_5_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Gather_3 [Gather]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Shape_3_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Constant_5_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/self/Gather_3 [Gather] inputs: [/bert/encoder/layer.3/attention/self/Shape_3_output_0 -> (3)[INT32]], [/bert/encoder/layer.3/attention/self/Constant_5_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Constant_5_output_0 for ONNX node: /bert/encoder/layer.3/attention/self/Constant_5_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Using Gather axis: 0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Gather_3 for ONNX node: /bert/encoder/layer.3/attention/self/Gather_3\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/Gather_3_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/Gather_3_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/self/Gather_3 [Gather] outputs: [/bert/encoder/layer.3/attention/self/Gather_3_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Unsqueeze_2 [Unsqueeze]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Gather_2_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/self/Unsqueeze_2 [Unsqueeze] inputs: [/bert/encoder/layer.3/attention/self/Gather_2_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Unsqueeze_2 for ONNX node: /bert/encoder/layer.3/attention/self/Unsqueeze_2\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/Unsqueeze_2_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/Unsqueeze_2_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/self/Unsqueeze_2 [Unsqueeze] outputs: [/bert/encoder/layer.3/attention/self/Unsqueeze_2_output_0 -> (1)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Unsqueeze_3 [Unsqueeze]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Gather_3_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/self/Unsqueeze_3 [Unsqueeze] inputs: [/bert/encoder/layer.3/attention/self/Gather_3_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Unsqueeze_3 for ONNX node: /bert/encoder/layer.3/attention/self/Unsqueeze_3\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/Unsqueeze_3_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/Unsqueeze_3_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/self/Unsqueeze_3 [Unsqueeze] outputs: [/bert/encoder/layer.3/attention/self/Unsqueeze_3_output_0 -> (1)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Constant_6 [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/self/Constant_6 [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/self/Constant_6 [Constant] outputs: [/bert/encoder/layer.3/attention/self/Constant_6_output_0 -> (1)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Constant_7 [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/self/Constant_7 [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/self/Constant_7 [Constant] outputs: [/bert/encoder/layer.3/attention/self/Constant_7_output_0 -> (1)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Concat_1 [Concat]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Unsqueeze_2_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Unsqueeze_3_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Constant_6_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Constant_7_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/self/Concat_1 [Concat] inputs: [/bert/encoder/layer.3/attention/self/Unsqueeze_2_output_0 -> (1)[INT32]], [/bert/encoder/layer.3/attention/self/Unsqueeze_3_output_0 -> (1)[INT32]], [/bert/encoder/layer.3/attention/self/Constant_6_output_0 -> (1)[INT32]], [/bert/encoder/layer.3/attention/self/Constant_7_output_0 -> (1)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Constant_6_output_0 for ONNX node: /bert/encoder/layer.3/attention/self/Constant_6_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Constant_7_output_0 for ONNX node: /bert/encoder/layer.3/attention/self/Constant_7_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Concat_1 for ONNX node: /bert/encoder/layer.3/attention/self/Concat_1\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/Concat_1_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/Concat_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/self/Concat_1 [Concat] outputs: [/bert/encoder/layer.3/attention/self/Concat_1_output_0 -> (4)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Reshape_1 [Reshape]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/value/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Concat_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/self/Reshape_1 [Reshape] inputs: [/bert/encoder/layer.3/attention/self/value/Add_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.3/attention/self/Concat_1_output_0 -> (4)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Reshape_1 for ONNX node: /bert/encoder/layer.3/attention/self/Reshape_1\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/Reshape_1_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/Reshape_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/self/Reshape_1 [Reshape] outputs: [/bert/encoder/layer.3/attention/self/Reshape_1_output_0 -> (-1, -1, 8, 32)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Transpose [Transpose]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Reshape_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/self/Transpose [Transpose] inputs: [/bert/encoder/layer.3/attention/self/Reshape_1_output_0 -> (-1, -1, 8, 32)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Transpose for ONNX node: /bert/encoder/layer.3/attention/self/Transpose\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/Transpose_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/Transpose_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/self/Transpose [Transpose] outputs: [/bert/encoder/layer.3/attention/self/Transpose_output_0 -> (-1, 8, -1, 32)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Shape_4 [Shape]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/query/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/self/Shape_4 [Shape] inputs: [/bert/encoder/layer.3/attention/self/query/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Shape_4 for ONNX node: /bert/encoder/layer.3/attention/self/Shape_4\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/Shape_4_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/Shape_4_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/self/Shape_4 [Shape] outputs: [/bert/encoder/layer.3/attention/self/Shape_4_output_0 -> (3)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Constant_8 [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/self/Constant_8 [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/self/Constant_8 [Constant] outputs: [/bert/encoder/layer.3/attention/self/Constant_8_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Gather_4 [Gather]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Shape_4_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Constant_8_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/self/Gather_4 [Gather] inputs: [/bert/encoder/layer.3/attention/self/Shape_4_output_0 -> (3)[INT32]], [/bert/encoder/layer.3/attention/self/Constant_8_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Constant_8_output_0 for ONNX node: /bert/encoder/layer.3/attention/self/Constant_8_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Using Gather axis: 0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Gather_4 for ONNX node: /bert/encoder/layer.3/attention/self/Gather_4\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/Gather_4_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/Gather_4_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/self/Gather_4 [Gather] outputs: [/bert/encoder/layer.3/attention/self/Gather_4_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Shape_5 [Shape]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/query/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/self/Shape_5 [Shape] inputs: [/bert/encoder/layer.3/attention/self/query/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Shape_5 for ONNX node: /bert/encoder/layer.3/attention/self/Shape_5\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/Shape_5_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/Shape_5_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/self/Shape_5 [Shape] outputs: [/bert/encoder/layer.3/attention/self/Shape_5_output_0 -> (3)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Constant_9 [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/self/Constant_9 [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/self/Constant_9 [Constant] outputs: [/bert/encoder/layer.3/attention/self/Constant_9_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Gather_5 [Gather]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Shape_5_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Constant_9_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/self/Gather_5 [Gather] inputs: [/bert/encoder/layer.3/attention/self/Shape_5_output_0 -> (3)[INT32]], [/bert/encoder/layer.3/attention/self/Constant_9_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Constant_9_output_0 for ONNX node: /bert/encoder/layer.3/attention/self/Constant_9_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Using Gather axis: 0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Gather_5 for ONNX node: /bert/encoder/layer.3/attention/self/Gather_5\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/Gather_5_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/Gather_5_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/self/Gather_5 [Gather] outputs: [/bert/encoder/layer.3/attention/self/Gather_5_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Unsqueeze_4 [Unsqueeze]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Gather_4_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/self/Unsqueeze_4 [Unsqueeze] inputs: [/bert/encoder/layer.3/attention/self/Gather_4_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Unsqueeze_4 for ONNX node: /bert/encoder/layer.3/attention/self/Unsqueeze_4\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/Unsqueeze_4_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/Unsqueeze_4_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/self/Unsqueeze_4 [Unsqueeze] outputs: [/bert/encoder/layer.3/attention/self/Unsqueeze_4_output_0 -> (1)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Unsqueeze_5 [Unsqueeze]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Gather_5_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/self/Unsqueeze_5 [Unsqueeze] inputs: [/bert/encoder/layer.3/attention/self/Gather_5_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Unsqueeze_5 for ONNX node: /bert/encoder/layer.3/attention/self/Unsqueeze_5\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/Unsqueeze_5_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/Unsqueeze_5_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/self/Unsqueeze_5 [Unsqueeze] outputs: [/bert/encoder/layer.3/attention/self/Unsqueeze_5_output_0 -> (1)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Constant_10 [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/self/Constant_10 [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/self/Constant_10 [Constant] outputs: [/bert/encoder/layer.3/attention/self/Constant_10_output_0 -> (1)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Constant_11 [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/self/Constant_11 [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/self/Constant_11 [Constant] outputs: [/bert/encoder/layer.3/attention/self/Constant_11_output_0 -> (1)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Concat_2 [Concat]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Unsqueeze_4_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Unsqueeze_5_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Constant_10_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Constant_11_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/self/Concat_2 [Concat] inputs: [/bert/encoder/layer.3/attention/self/Unsqueeze_4_output_0 -> (1)[INT32]], [/bert/encoder/layer.3/attention/self/Unsqueeze_5_output_0 -> (1)[INT32]], [/bert/encoder/layer.3/attention/self/Constant_10_output_0 -> (1)[INT32]], [/bert/encoder/layer.3/attention/self/Constant_11_output_0 -> (1)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Constant_10_output_0 for ONNX node: /bert/encoder/layer.3/attention/self/Constant_10_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Constant_11_output_0 for ONNX node: /bert/encoder/layer.3/attention/self/Constant_11_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Concat_2 for ONNX node: /bert/encoder/layer.3/attention/self/Concat_2\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/Concat_2_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/Concat_2_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/self/Concat_2 [Concat] outputs: [/bert/encoder/layer.3/attention/self/Concat_2_output_0 -> (4)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Reshape_2 [Reshape]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/query/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Concat_2_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/self/Reshape_2 [Reshape] inputs: [/bert/encoder/layer.3/attention/self/query/Add_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.3/attention/self/Concat_2_output_0 -> (4)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Reshape_2 for ONNX node: /bert/encoder/layer.3/attention/self/Reshape_2\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/Reshape_2_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/Reshape_2_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/self/Reshape_2 [Reshape] outputs: [/bert/encoder/layer.3/attention/self/Reshape_2_output_0 -> (-1, -1, 8, 32)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Transpose_1 [Transpose]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Reshape_2_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/self/Transpose_1 [Transpose] inputs: [/bert/encoder/layer.3/attention/self/Reshape_2_output_0 -> (-1, -1, 8, 32)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Transpose_1 for ONNX node: /bert/encoder/layer.3/attention/self/Transpose_1\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/Transpose_1_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/Transpose_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/self/Transpose_1 [Transpose] outputs: [/bert/encoder/layer.3/attention/self/Transpose_1_output_0 -> (-1, 8, -1, 32)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Transpose_2 [Transpose]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Reshape_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/self/Transpose_2 [Transpose] inputs: [/bert/encoder/layer.3/attention/self/Reshape_output_0 -> (-1, -1, 8, 32)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Transpose_2 for ONNX node: /bert/encoder/layer.3/attention/self/Transpose_2\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/Transpose_2_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/Transpose_2_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/self/Transpose_2 [Transpose] outputs: [/bert/encoder/layer.3/attention/self/Transpose_2_output_0 -> (-1, 8, 32, -1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/MatMul [MatMul]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Transpose_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Transpose_2_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/self/MatMul [MatMul] inputs: [/bert/encoder/layer.3/attention/self/Transpose_1_output_0 -> (-1, 8, -1, 32)[FLOAT]], [/bert/encoder/layer.3/attention/self/Transpose_2_output_0 -> (-1, 8, 32, -1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/MatMul for ONNX node: /bert/encoder/layer.3/attention/self/MatMul\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/MatMul_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/MatMul_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/self/MatMul [MatMul] outputs: [/bert/encoder/layer.3/attention/self/MatMul_output_0 -> (-1, 8, -1, -1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Constant_12 [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/self/Constant_12 [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/self/Constant_12 [Constant] outputs: [/bert/encoder/layer.3/attention/self/Constant_12_output_0 -> ()[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Div [Div]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/MatMul_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Constant_12_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/self/Div [Div] inputs: [/bert/encoder/layer.3/attention/self/MatMul_output_0 -> (-1, 8, -1, -1)[FLOAT]], [/bert/encoder/layer.3/attention/self/Constant_12_output_0 -> ()[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Constant_12_output_0 for ONNX node: /bert/encoder/layer.3/attention/self/Constant_12_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Div for ONNX node: /bert/encoder/layer.3/attention/self/Div\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/Div_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/Div_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/self/Div [Div] outputs: [/bert/encoder/layer.3/attention/self/Div_output_0 -> (-1, 8, -1, -1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Add [Add]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Div_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/Mul_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/self/Add [Add] inputs: [/bert/encoder/layer.3/attention/self/Div_output_0 -> (-1, 8, -1, -1)[FLOAT]], [/bert/Mul_output_0 -> (-1, 1, 1, -1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Add for ONNX node: /bert/encoder/layer.3/attention/self/Add\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/Add_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/self/Add [Add] outputs: [/bert/encoder/layer.3/attention/self/Add_output_0 -> (-1, 8, -1, -1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Softmax [Softmax]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/self/Softmax [Softmax] inputs: [/bert/encoder/layer.3/attention/self/Add_output_0 -> (-1, 8, -1, -1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Softmax for ONNX node: /bert/encoder/layer.3/attention/self/Softmax\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/Softmax_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/Softmax_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/self/Softmax [Softmax] outputs: [/bert/encoder/layer.3/attention/self/Softmax_output_0 -> (-1, 8, -1, -1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/MatMul_1 [MatMul]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Softmax_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Transpose_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/self/MatMul_1 [MatMul] inputs: [/bert/encoder/layer.3/attention/self/Softmax_output_0 -> (-1, 8, -1, -1)[FLOAT]], [/bert/encoder/layer.3/attention/self/Transpose_output_0 -> (-1, 8, -1, 32)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/MatMul_1 for ONNX node: /bert/encoder/layer.3/attention/self/MatMul_1\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/MatMul_1_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/MatMul_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/self/MatMul_1 [MatMul] outputs: [/bert/encoder/layer.3/attention/self/MatMul_1_output_0 -> (-1, 8, -1, 32)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Transpose_3 [Transpose]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/MatMul_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/self/Transpose_3 [Transpose] inputs: [/bert/encoder/layer.3/attention/self/MatMul_1_output_0 -> (-1, 8, -1, 32)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Transpose_3 for ONNX node: /bert/encoder/layer.3/attention/self/Transpose_3\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/Transpose_3_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/Transpose_3_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/self/Transpose_3 [Transpose] outputs: [/bert/encoder/layer.3/attention/self/Transpose_3_output_0 -> (-1, -1, 8, 32)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Shape_6 [Shape]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Transpose_3_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/self/Shape_6 [Shape] inputs: [/bert/encoder/layer.3/attention/self/Transpose_3_output_0 -> (-1, -1, 8, 32)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Shape_6 for ONNX node: /bert/encoder/layer.3/attention/self/Shape_6\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/Shape_6_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/Shape_6_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/self/Shape_6 [Shape] outputs: [/bert/encoder/layer.3/attention/self/Shape_6_output_0 -> (4)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Constant_13 [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/self/Constant_13 [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/self/Constant_13 [Constant] outputs: [/bert/encoder/layer.3/attention/self/Constant_13_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Gather_6 [Gather]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Shape_6_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Constant_13_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/self/Gather_6 [Gather] inputs: [/bert/encoder/layer.3/attention/self/Shape_6_output_0 -> (4)[INT32]], [/bert/encoder/layer.3/attention/self/Constant_13_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Constant_13_output_0 for ONNX node: /bert/encoder/layer.3/attention/self/Constant_13_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Using Gather axis: 0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Gather_6 for ONNX node: /bert/encoder/layer.3/attention/self/Gather_6\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/Gather_6_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/Gather_6_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/self/Gather_6 [Gather] outputs: [/bert/encoder/layer.3/attention/self/Gather_6_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Shape_7 [Shape]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Transpose_3_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/self/Shape_7 [Shape] inputs: [/bert/encoder/layer.3/attention/self/Transpose_3_output_0 -> (-1, -1, 8, 32)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Shape_7 for ONNX node: /bert/encoder/layer.3/attention/self/Shape_7\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/Shape_7_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/Shape_7_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/self/Shape_7 [Shape] outputs: [/bert/encoder/layer.3/attention/self/Shape_7_output_0 -> (4)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Constant_14 [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/self/Constant_14 [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/self/Constant_14 [Constant] outputs: [/bert/encoder/layer.3/attention/self/Constant_14_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Gather_7 [Gather]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Shape_7_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Constant_14_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/self/Gather_7 [Gather] inputs: [/bert/encoder/layer.3/attention/self/Shape_7_output_0 -> (4)[INT32]], [/bert/encoder/layer.3/attention/self/Constant_14_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Constant_14_output_0 for ONNX node: /bert/encoder/layer.3/attention/self/Constant_14_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Using Gather axis: 0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Gather_7 for ONNX node: /bert/encoder/layer.3/attention/self/Gather_7\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/Gather_7_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/Gather_7_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/self/Gather_7 [Gather] outputs: [/bert/encoder/layer.3/attention/self/Gather_7_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Unsqueeze_6 [Unsqueeze]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Gather_6_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/self/Unsqueeze_6 [Unsqueeze] inputs: [/bert/encoder/layer.3/attention/self/Gather_6_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Unsqueeze_6 for ONNX node: /bert/encoder/layer.3/attention/self/Unsqueeze_6\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/Unsqueeze_6_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/Unsqueeze_6_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/self/Unsqueeze_6 [Unsqueeze] outputs: [/bert/encoder/layer.3/attention/self/Unsqueeze_6_output_0 -> (1)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Unsqueeze_7 [Unsqueeze]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Gather_7_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/self/Unsqueeze_7 [Unsqueeze] inputs: [/bert/encoder/layer.3/attention/self/Gather_7_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Unsqueeze_7 for ONNX node: /bert/encoder/layer.3/attention/self/Unsqueeze_7\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/Unsqueeze_7_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/Unsqueeze_7_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/self/Unsqueeze_7 [Unsqueeze] outputs: [/bert/encoder/layer.3/attention/self/Unsqueeze_7_output_0 -> (1)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Constant_15 [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/self/Constant_15 [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/self/Constant_15 [Constant] outputs: [/bert/encoder/layer.3/attention/self/Constant_15_output_0 -> (1)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Concat_3 [Concat]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Unsqueeze_6_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Unsqueeze_7_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Constant_15_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/self/Concat_3 [Concat] inputs: [/bert/encoder/layer.3/attention/self/Unsqueeze_6_output_0 -> (1)[INT32]], [/bert/encoder/layer.3/attention/self/Unsqueeze_7_output_0 -> (1)[INT32]], [/bert/encoder/layer.3/attention/self/Constant_15_output_0 -> (1)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Constant_15_output_0 for ONNX node: /bert/encoder/layer.3/attention/self/Constant_15_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Concat_3 for ONNX node: /bert/encoder/layer.3/attention/self/Concat_3\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/Concat_3_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/Concat_3_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/self/Concat_3 [Concat] outputs: [/bert/encoder/layer.3/attention/self/Concat_3_output_0 -> (3)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Reshape_3 [Reshape]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Transpose_3_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Concat_3_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/self/Reshape_3 [Reshape] inputs: [/bert/encoder/layer.3/attention/self/Transpose_3_output_0 -> (-1, -1, 8, 32)[FLOAT]], [/bert/encoder/layer.3/attention/self/Concat_3_output_0 -> (3)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Reshape_3 for ONNX node: /bert/encoder/layer.3/attention/self/Reshape_3\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/Reshape_3_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/Reshape_3_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/self/Reshape_3 [Reshape] outputs: [/bert/encoder/layer.3/attention/self/Reshape_3_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/output/dense/MatMul [MatMul]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Reshape_3_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: onnx::MatMul_842\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/output/dense/MatMul [MatMul] inputs: [/bert/encoder/layer.3/attention/self/Reshape_3_output_0 -> (-1, -1, 256)[FLOAT]], [onnx::MatMul_842 -> (256, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: onnx::MatMul_842 for ONNX node: onnx::MatMul_842\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/output/dense/MatMul for ONNX node: /bert/encoder/layer.3/attention/output/dense/MatMul\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/output/dense/MatMul_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/output/dense/MatMul_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/output/dense/MatMul [MatMul] outputs: [/bert/encoder/layer.3/attention/output/dense/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/output/dense/Add [Add]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: bert.encoder.layer.3.attention.output.dense.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/output/dense/MatMul_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/output/dense/Add [Add] inputs: [bert.encoder.layer.3.attention.output.dense.bias -> (256)[FLOAT]], [/bert/encoder/layer.3/attention/output/dense/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: bert.encoder.layer.3.attention.output.dense.bias for ONNX node: bert.encoder.layer.3.attention.output.dense.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/output/dense/Add for ONNX node: /bert/encoder/layer.3/attention/output/dense/Add\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/output/dense/Add_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/output/dense/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/output/dense/Add [Add] outputs: [/bert/encoder/layer.3/attention/output/dense/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/output/Add [Add]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/output/dense/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.2/output/LayerNorm/Add_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/output/Add [Add] inputs: [/bert/encoder/layer.3/attention/output/dense/Add_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.2/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/output/Add for ONNX node: /bert/encoder/layer.3/attention/output/Add\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/output/Add_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/output/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/output/Add [Add] outputs: [/bert/encoder/layer.3/attention/output/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/output/LayerNorm/ReduceMean [ReduceMean]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/output/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/output/LayerNorm/ReduceMean [ReduceMean] inputs: [/bert/encoder/layer.3/attention/output/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/output/LayerNorm/ReduceMean for ONNX node: /bert/encoder/layer.3/attention/output/LayerNorm/ReduceMean\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/output/LayerNorm/ReduceMean_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/output/LayerNorm/ReduceMean_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/output/LayerNorm/ReduceMean [ReduceMean] outputs: [/bert/encoder/layer.3/attention/output/LayerNorm/ReduceMean_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/output/LayerNorm/Sub [Sub]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/output/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/output/LayerNorm/ReduceMean_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/output/LayerNorm/Sub [Sub] inputs: [/bert/encoder/layer.3/attention/output/Add_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.3/attention/output/LayerNorm/ReduceMean_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/output/LayerNorm/Sub for ONNX node: /bert/encoder/layer.3/attention/output/LayerNorm/Sub\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/output/LayerNorm/Sub_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/output/LayerNorm/Sub_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/output/LayerNorm/Sub [Sub] outputs: [/bert/encoder/layer.3/attention/output/LayerNorm/Sub_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/output/LayerNorm/Constant [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/output/LayerNorm/Constant [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/output/LayerNorm/Constant [Constant] outputs: [/bert/encoder/layer.3/attention/output/LayerNorm/Constant_output_0 -> ()[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/output/LayerNorm/Pow [Pow]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/output/LayerNorm/Sub_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/output/LayerNorm/Constant_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/output/LayerNorm/Pow [Pow] inputs: [/bert/encoder/layer.3/attention/output/LayerNorm/Sub_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.3/attention/output/LayerNorm/Constant_output_0 -> ()[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/output/LayerNorm/Constant_output_0 for ONNX node: /bert/encoder/layer.3/attention/output/LayerNorm/Constant_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/output/LayerNorm/Pow for ONNX node: /bert/encoder/layer.3/attention/output/LayerNorm/Pow\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/output/LayerNorm/Pow_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/output/LayerNorm/Pow_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/output/LayerNorm/Pow [Pow] outputs: [/bert/encoder/layer.3/attention/output/LayerNorm/Pow_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/output/LayerNorm/ReduceMean_1 [ReduceMean]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/output/LayerNorm/Pow_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/output/LayerNorm/ReduceMean_1 [ReduceMean] inputs: [/bert/encoder/layer.3/attention/output/LayerNorm/Pow_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/output/LayerNorm/ReduceMean_1 for ONNX node: /bert/encoder/layer.3/attention/output/LayerNorm/ReduceMean_1\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/output/LayerNorm/ReduceMean_1_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/output/LayerNorm/ReduceMean_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/output/LayerNorm/ReduceMean_1 [ReduceMean] outputs: [/bert/encoder/layer.3/attention/output/LayerNorm/ReduceMean_1_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/output/LayerNorm/Constant_1 [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/output/LayerNorm/Constant_1 [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/output/LayerNorm/Constant_1 [Constant] outputs: [/bert/encoder/layer.3/attention/output/LayerNorm/Constant_1_output_0 -> ()[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/output/LayerNorm/Add [Add]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/output/LayerNorm/ReduceMean_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/output/LayerNorm/Constant_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/output/LayerNorm/Add [Add] inputs: [/bert/encoder/layer.3/attention/output/LayerNorm/ReduceMean_1_output_0 -> (-1, -1, 1)[FLOAT]], [/bert/encoder/layer.3/attention/output/LayerNorm/Constant_1_output_0 -> ()[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/output/LayerNorm/Constant_1_output_0 for ONNX node: /bert/encoder/layer.3/attention/output/LayerNorm/Constant_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/output/LayerNorm/Add for ONNX node: /bert/encoder/layer.3/attention/output/LayerNorm/Add\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/output/LayerNorm/Add_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/output/LayerNorm/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/output/LayerNorm/Add [Add] outputs: [/bert/encoder/layer.3/attention/output/LayerNorm/Add_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/output/LayerNorm/Sqrt [Sqrt]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/output/LayerNorm/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/output/LayerNorm/Sqrt [Sqrt] inputs: [/bert/encoder/layer.3/attention/output/LayerNorm/Add_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/output/LayerNorm/Sqrt for ONNX node: /bert/encoder/layer.3/attention/output/LayerNorm/Sqrt\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/output/LayerNorm/Sqrt_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/output/LayerNorm/Sqrt_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/output/LayerNorm/Sqrt [Sqrt] outputs: [/bert/encoder/layer.3/attention/output/LayerNorm/Sqrt_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/output/LayerNorm/Div [Div]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/output/LayerNorm/Sub_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/output/LayerNorm/Sqrt_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/output/LayerNorm/Div [Div] inputs: [/bert/encoder/layer.3/attention/output/LayerNorm/Sub_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.3/attention/output/LayerNorm/Sqrt_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/output/LayerNorm/Div for ONNX node: /bert/encoder/layer.3/attention/output/LayerNorm/Div\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/output/LayerNorm/Div_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/output/LayerNorm/Div_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/output/LayerNorm/Div [Div] outputs: [/bert/encoder/layer.3/attention/output/LayerNorm/Div_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/output/LayerNorm/Mul [Mul]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/output/LayerNorm/Div_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: bert.encoder.layer.3.attention.output.LayerNorm.weight\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/output/LayerNorm/Mul [Mul] inputs: [/bert/encoder/layer.3/attention/output/LayerNorm/Div_output_0 -> (-1, -1, 256)[FLOAT]], [bert.encoder.layer.3.attention.output.LayerNorm.weight -> (256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: bert.encoder.layer.3.attention.output.LayerNorm.weight for ONNX node: bert.encoder.layer.3.attention.output.LayerNorm.weight\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/output/LayerNorm/Mul for ONNX node: /bert/encoder/layer.3/attention/output/LayerNorm/Mul\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/output/LayerNorm/Mul_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/output/LayerNorm/Mul_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/output/LayerNorm/Mul [Mul] outputs: [/bert/encoder/layer.3/attention/output/LayerNorm/Mul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/output/LayerNorm/Add_1 [Add]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/output/LayerNorm/Mul_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: bert.encoder.layer.3.attention.output.LayerNorm.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/output/LayerNorm/Add_1 [Add] inputs: [/bert/encoder/layer.3/attention/output/LayerNorm/Mul_output_0 -> (-1, -1, 256)[FLOAT]], [bert.encoder.layer.3.attention.output.LayerNorm.bias -> (256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: bert.encoder.layer.3.attention.output.LayerNorm.bias for ONNX node: bert.encoder.layer.3.attention.output.LayerNorm.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/output/LayerNorm/Add_1 for ONNX node: /bert/encoder/layer.3/attention/output/LayerNorm/Add_1\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/output/LayerNorm/Add_1_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/output/LayerNorm/Add_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/attention/output/LayerNorm/Add_1 [Add] outputs: [/bert/encoder/layer.3/attention/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.3/intermediate/dense/MatMul [MatMul]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/output/LayerNorm/Add_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: onnx::MatMul_843\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/intermediate/dense/MatMul [MatMul] inputs: [/bert/encoder/layer.3/attention/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], [onnx::MatMul_843 -> (256, 1024)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: onnx::MatMul_843 for ONNX node: onnx::MatMul_843\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.3/intermediate/dense/MatMul for ONNX node: /bert/encoder/layer.3/intermediate/dense/MatMul\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.3/intermediate/dense/MatMul_output_0 for ONNX tensor: /bert/encoder/layer.3/intermediate/dense/MatMul_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/intermediate/dense/MatMul [MatMul] outputs: [/bert/encoder/layer.3/intermediate/dense/MatMul_output_0 -> (-1, -1, 1024)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.3/intermediate/dense/Add [Add]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: bert.encoder.layer.3.intermediate.dense.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.3/intermediate/dense/MatMul_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/intermediate/dense/Add [Add] inputs: [bert.encoder.layer.3.intermediate.dense.bias -> (1024)[FLOAT]], [/bert/encoder/layer.3/intermediate/dense/MatMul_output_0 -> (-1, -1, 1024)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: bert.encoder.layer.3.intermediate.dense.bias for ONNX node: bert.encoder.layer.3.intermediate.dense.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.3/intermediate/dense/Add for ONNX node: /bert/encoder/layer.3/intermediate/dense/Add\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.3/intermediate/dense/Add_output_0 for ONNX tensor: /bert/encoder/layer.3/intermediate/dense/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/intermediate/dense/Add [Add] outputs: [/bert/encoder/layer.3/intermediate/dense/Add_output_0 -> (-1, -1, 1024)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.3/intermediate/intermediate_act_fn/Constant [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/intermediate/intermediate_act_fn/Constant [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/intermediate/intermediate_act_fn/Constant [Constant] outputs: [/bert/encoder/layer.3/intermediate/intermediate_act_fn/Constant_output_0 -> ()[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.3/intermediate/intermediate_act_fn/Div [Div]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.3/intermediate/dense/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.3/intermediate/intermediate_act_fn/Constant_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/intermediate/intermediate_act_fn/Div [Div] inputs: [/bert/encoder/layer.3/intermediate/dense/Add_output_0 -> (-1, -1, 1024)[FLOAT]], [/bert/encoder/layer.3/intermediate/intermediate_act_fn/Constant_output_0 -> ()[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.3/intermediate/intermediate_act_fn/Constant_output_0 for ONNX node: /bert/encoder/layer.3/intermediate/intermediate_act_fn/Constant_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.3/intermediate/intermediate_act_fn/Div for ONNX node: /bert/encoder/layer.3/intermediate/intermediate_act_fn/Div\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.3/intermediate/intermediate_act_fn/Div_output_0 for ONNX tensor: /bert/encoder/layer.3/intermediate/intermediate_act_fn/Div_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/intermediate/intermediate_act_fn/Div [Div] outputs: [/bert/encoder/layer.3/intermediate/intermediate_act_fn/Div_output_0 -> (-1, -1, 1024)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.3/intermediate/intermediate_act_fn/Erf [Erf]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.3/intermediate/intermediate_act_fn/Div_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/intermediate/intermediate_act_fn/Erf [Erf] inputs: [/bert/encoder/layer.3/intermediate/intermediate_act_fn/Div_output_0 -> (-1, -1, 1024)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.3/intermediate/intermediate_act_fn/Erf for ONNX node: /bert/encoder/layer.3/intermediate/intermediate_act_fn/Erf\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.3/intermediate/intermediate_act_fn/Erf_output_0 for ONNX tensor: /bert/encoder/layer.3/intermediate/intermediate_act_fn/Erf_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/intermediate/intermediate_act_fn/Erf [Erf] outputs: [/bert/encoder/layer.3/intermediate/intermediate_act_fn/Erf_output_0 -> (-1, -1, 1024)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.3/intermediate/intermediate_act_fn/Constant_1 [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/intermediate/intermediate_act_fn/Constant_1 [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/intermediate/intermediate_act_fn/Constant_1 [Constant] outputs: [/bert/encoder/layer.3/intermediate/intermediate_act_fn/Constant_1_output_0 -> ()[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.3/intermediate/intermediate_act_fn/Add [Add]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.3/intermediate/intermediate_act_fn/Erf_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.3/intermediate/intermediate_act_fn/Constant_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/intermediate/intermediate_act_fn/Add [Add] inputs: [/bert/encoder/layer.3/intermediate/intermediate_act_fn/Erf_output_0 -> (-1, -1, 1024)[FLOAT]], [/bert/encoder/layer.3/intermediate/intermediate_act_fn/Constant_1_output_0 -> ()[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.3/intermediate/intermediate_act_fn/Constant_1_output_0 for ONNX node: /bert/encoder/layer.3/intermediate/intermediate_act_fn/Constant_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.3/intermediate/intermediate_act_fn/Add for ONNX node: /bert/encoder/layer.3/intermediate/intermediate_act_fn/Add\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.3/intermediate/intermediate_act_fn/Add_output_0 for ONNX tensor: /bert/encoder/layer.3/intermediate/intermediate_act_fn/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/intermediate/intermediate_act_fn/Add [Add] outputs: [/bert/encoder/layer.3/intermediate/intermediate_act_fn/Add_output_0 -> (-1, -1, 1024)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.3/intermediate/intermediate_act_fn/Mul [Mul]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.3/intermediate/dense/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.3/intermediate/intermediate_act_fn/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/intermediate/intermediate_act_fn/Mul [Mul] inputs: [/bert/encoder/layer.3/intermediate/dense/Add_output_0 -> (-1, -1, 1024)[FLOAT]], [/bert/encoder/layer.3/intermediate/intermediate_act_fn/Add_output_0 -> (-1, -1, 1024)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.3/intermediate/intermediate_act_fn/Mul for ONNX node: /bert/encoder/layer.3/intermediate/intermediate_act_fn/Mul\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.3/intermediate/intermediate_act_fn/Mul_output_0 for ONNX tensor: /bert/encoder/layer.3/intermediate/intermediate_act_fn/Mul_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/intermediate/intermediate_act_fn/Mul [Mul] outputs: [/bert/encoder/layer.3/intermediate/intermediate_act_fn/Mul_output_0 -> (-1, -1, 1024)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.3/intermediate/intermediate_act_fn/Constant_2 [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/intermediate/intermediate_act_fn/Constant_2 [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/intermediate/intermediate_act_fn/Constant_2 [Constant] outputs: [/bert/encoder/layer.3/intermediate/intermediate_act_fn/Constant_2_output_0 -> ()[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.3/intermediate/intermediate_act_fn/Mul_1 [Mul]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.3/intermediate/intermediate_act_fn/Mul_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.3/intermediate/intermediate_act_fn/Constant_2_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/intermediate/intermediate_act_fn/Mul_1 [Mul] inputs: [/bert/encoder/layer.3/intermediate/intermediate_act_fn/Mul_output_0 -> (-1, -1, 1024)[FLOAT]], [/bert/encoder/layer.3/intermediate/intermediate_act_fn/Constant_2_output_0 -> ()[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.3/intermediate/intermediate_act_fn/Constant_2_output_0 for ONNX node: /bert/encoder/layer.3/intermediate/intermediate_act_fn/Constant_2_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.3/intermediate/intermediate_act_fn/Mul_1 for ONNX node: /bert/encoder/layer.3/intermediate/intermediate_act_fn/Mul_1\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.3/intermediate/intermediate_act_fn/Mul_1_output_0 for ONNX tensor: /bert/encoder/layer.3/intermediate/intermediate_act_fn/Mul_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/intermediate/intermediate_act_fn/Mul_1 [Mul] outputs: [/bert/encoder/layer.3/intermediate/intermediate_act_fn/Mul_1_output_0 -> (-1, -1, 1024)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.3/output/dense/MatMul [MatMul]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.3/intermediate/intermediate_act_fn/Mul_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: onnx::MatMul_844\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/output/dense/MatMul [MatMul] inputs: [/bert/encoder/layer.3/intermediate/intermediate_act_fn/Mul_1_output_0 -> (-1, -1, 1024)[FLOAT]], [onnx::MatMul_844 -> (1024, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: onnx::MatMul_844 for ONNX node: onnx::MatMul_844\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.3/output/dense/MatMul for ONNX node: /bert/encoder/layer.3/output/dense/MatMul\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.3/output/dense/MatMul_output_0 for ONNX tensor: /bert/encoder/layer.3/output/dense/MatMul_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/output/dense/MatMul [MatMul] outputs: [/bert/encoder/layer.3/output/dense/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.3/output/dense/Add [Add]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: bert.encoder.layer.3.output.dense.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.3/output/dense/MatMul_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/output/dense/Add [Add] inputs: [bert.encoder.layer.3.output.dense.bias -> (256)[FLOAT]], [/bert/encoder/layer.3/output/dense/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: bert.encoder.layer.3.output.dense.bias for ONNX node: bert.encoder.layer.3.output.dense.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.3/output/dense/Add for ONNX node: /bert/encoder/layer.3/output/dense/Add\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.3/output/dense/Add_output_0 for ONNX tensor: /bert/encoder/layer.3/output/dense/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/output/dense/Add [Add] outputs: [/bert/encoder/layer.3/output/dense/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.3/output/Add [Add]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.3/output/dense/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/output/LayerNorm/Add_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/output/Add [Add] inputs: [/bert/encoder/layer.3/output/dense/Add_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.3/attention/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.3/output/Add for ONNX node: /bert/encoder/layer.3/output/Add\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.3/output/Add_output_0 for ONNX tensor: /bert/encoder/layer.3/output/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/output/Add [Add] outputs: [/bert/encoder/layer.3/output/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.3/output/LayerNorm/ReduceMean [ReduceMean]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.3/output/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/output/LayerNorm/ReduceMean [ReduceMean] inputs: [/bert/encoder/layer.3/output/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.3/output/LayerNorm/ReduceMean for ONNX node: /bert/encoder/layer.3/output/LayerNorm/ReduceMean\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.3/output/LayerNorm/ReduceMean_output_0 for ONNX tensor: /bert/encoder/layer.3/output/LayerNorm/ReduceMean_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/output/LayerNorm/ReduceMean [ReduceMean] outputs: [/bert/encoder/layer.3/output/LayerNorm/ReduceMean_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.3/output/LayerNorm/Sub [Sub]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.3/output/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.3/output/LayerNorm/ReduceMean_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/output/LayerNorm/Sub [Sub] inputs: [/bert/encoder/layer.3/output/Add_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.3/output/LayerNorm/ReduceMean_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.3/output/LayerNorm/Sub for ONNX node: /bert/encoder/layer.3/output/LayerNorm/Sub\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.3/output/LayerNorm/Sub_output_0 for ONNX tensor: /bert/encoder/layer.3/output/LayerNorm/Sub_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/output/LayerNorm/Sub [Sub] outputs: [/bert/encoder/layer.3/output/LayerNorm/Sub_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.3/output/LayerNorm/Constant [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/output/LayerNorm/Constant [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/output/LayerNorm/Constant [Constant] outputs: [/bert/encoder/layer.3/output/LayerNorm/Constant_output_0 -> ()[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.3/output/LayerNorm/Pow [Pow]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.3/output/LayerNorm/Sub_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.3/output/LayerNorm/Constant_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/output/LayerNorm/Pow [Pow] inputs: [/bert/encoder/layer.3/output/LayerNorm/Sub_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.3/output/LayerNorm/Constant_output_0 -> ()[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.3/output/LayerNorm/Constant_output_0 for ONNX node: /bert/encoder/layer.3/output/LayerNorm/Constant_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.3/output/LayerNorm/Pow for ONNX node: /bert/encoder/layer.3/output/LayerNorm/Pow\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.3/output/LayerNorm/Pow_output_0 for ONNX tensor: /bert/encoder/layer.3/output/LayerNorm/Pow_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/output/LayerNorm/Pow [Pow] outputs: [/bert/encoder/layer.3/output/LayerNorm/Pow_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.3/output/LayerNorm/ReduceMean_1 [ReduceMean]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.3/output/LayerNorm/Pow_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/output/LayerNorm/ReduceMean_1 [ReduceMean] inputs: [/bert/encoder/layer.3/output/LayerNorm/Pow_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.3/output/LayerNorm/ReduceMean_1 for ONNX node: /bert/encoder/layer.3/output/LayerNorm/ReduceMean_1\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.3/output/LayerNorm/ReduceMean_1_output_0 for ONNX tensor: /bert/encoder/layer.3/output/LayerNorm/ReduceMean_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/output/LayerNorm/ReduceMean_1 [ReduceMean] outputs: [/bert/encoder/layer.3/output/LayerNorm/ReduceMean_1_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.3/output/LayerNorm/Constant_1 [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/output/LayerNorm/Constant_1 [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/output/LayerNorm/Constant_1 [Constant] outputs: [/bert/encoder/layer.3/output/LayerNorm/Constant_1_output_0 -> ()[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.3/output/LayerNorm/Add [Add]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.3/output/LayerNorm/ReduceMean_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.3/output/LayerNorm/Constant_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/output/LayerNorm/Add [Add] inputs: [/bert/encoder/layer.3/output/LayerNorm/ReduceMean_1_output_0 -> (-1, -1, 1)[FLOAT]], [/bert/encoder/layer.3/output/LayerNorm/Constant_1_output_0 -> ()[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.3/output/LayerNorm/Constant_1_output_0 for ONNX node: /bert/encoder/layer.3/output/LayerNorm/Constant_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.3/output/LayerNorm/Add for ONNX node: /bert/encoder/layer.3/output/LayerNorm/Add\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.3/output/LayerNorm/Add_output_0 for ONNX tensor: /bert/encoder/layer.3/output/LayerNorm/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/output/LayerNorm/Add [Add] outputs: [/bert/encoder/layer.3/output/LayerNorm/Add_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.3/output/LayerNorm/Sqrt [Sqrt]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.3/output/LayerNorm/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/output/LayerNorm/Sqrt [Sqrt] inputs: [/bert/encoder/layer.3/output/LayerNorm/Add_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.3/output/LayerNorm/Sqrt for ONNX node: /bert/encoder/layer.3/output/LayerNorm/Sqrt\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.3/output/LayerNorm/Sqrt_output_0 for ONNX tensor: /bert/encoder/layer.3/output/LayerNorm/Sqrt_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/output/LayerNorm/Sqrt [Sqrt] outputs: [/bert/encoder/layer.3/output/LayerNorm/Sqrt_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.3/output/LayerNorm/Div [Div]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.3/output/LayerNorm/Sub_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.3/output/LayerNorm/Sqrt_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/output/LayerNorm/Div [Div] inputs: [/bert/encoder/layer.3/output/LayerNorm/Sub_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.3/output/LayerNorm/Sqrt_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.3/output/LayerNorm/Div for ONNX node: /bert/encoder/layer.3/output/LayerNorm/Div\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.3/output/LayerNorm/Div_output_0 for ONNX tensor: /bert/encoder/layer.3/output/LayerNorm/Div_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/output/LayerNorm/Div [Div] outputs: [/bert/encoder/layer.3/output/LayerNorm/Div_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.3/output/LayerNorm/Mul [Mul]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.3/output/LayerNorm/Div_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: bert.encoder.layer.3.output.LayerNorm.weight\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/output/LayerNorm/Mul [Mul] inputs: [/bert/encoder/layer.3/output/LayerNorm/Div_output_0 -> (-1, -1, 256)[FLOAT]], [bert.encoder.layer.3.output.LayerNorm.weight -> (256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: bert.encoder.layer.3.output.LayerNorm.weight for ONNX node: bert.encoder.layer.3.output.LayerNorm.weight\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.3/output/LayerNorm/Mul for ONNX node: /bert/encoder/layer.3/output/LayerNorm/Mul\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.3/output/LayerNorm/Mul_output_0 for ONNX tensor: /bert/encoder/layer.3/output/LayerNorm/Mul_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/output/LayerNorm/Mul [Mul] outputs: [/bert/encoder/layer.3/output/LayerNorm/Mul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.3/output/LayerNorm/Add_1 [Add]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.3/output/LayerNorm/Mul_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: bert.encoder.layer.3.output.LayerNorm.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/output/LayerNorm/Add_1 [Add] inputs: [/bert/encoder/layer.3/output/LayerNorm/Mul_output_0 -> (-1, -1, 256)[FLOAT]], [bert.encoder.layer.3.output.LayerNorm.bias -> (256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: bert.encoder.layer.3.output.LayerNorm.bias for ONNX node: bert.encoder.layer.3.output.LayerNorm.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.3/output/LayerNorm/Add_1 for ONNX node: /bert/encoder/layer.3/output/LayerNorm/Add_1\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.3/output/LayerNorm/Add_1_output_0 for ONNX tensor: /bert/encoder/layer.3/output/LayerNorm/Add_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.3/output/LayerNorm/Add_1 [Add] outputs: [/bert/encoder/layer.3/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/query/MatMul [MatMul]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.3/output/LayerNorm/Add_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: onnx::MatMul_845\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/self/query/MatMul [MatMul] inputs: [/bert/encoder/layer.3/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], [onnx::MatMul_845 -> (256, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: onnx::MatMul_845 for ONNX node: onnx::MatMul_845\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/query/MatMul for ONNX node: /bert/encoder/layer.4/attention/self/query/MatMul\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/query/MatMul_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/query/MatMul_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/self/query/MatMul [MatMul] outputs: [/bert/encoder/layer.4/attention/self/query/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/query/Add [Add]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: bert.encoder.layer.4.attention.self.query.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/query/MatMul_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/self/query/Add [Add] inputs: [bert.encoder.layer.4.attention.self.query.bias -> (256)[FLOAT]], [/bert/encoder/layer.4/attention/self/query/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: bert.encoder.layer.4.attention.self.query.bias for ONNX node: bert.encoder.layer.4.attention.self.query.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/query/Add for ONNX node: /bert/encoder/layer.4/attention/self/query/Add\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/query/Add_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/query/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/self/query/Add [Add] outputs: [/bert/encoder/layer.4/attention/self/query/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/key/MatMul [MatMul]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.3/output/LayerNorm/Add_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: onnx::MatMul_846\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/self/key/MatMul [MatMul] inputs: [/bert/encoder/layer.3/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], [onnx::MatMul_846 -> (256, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: onnx::MatMul_846 for ONNX node: onnx::MatMul_846\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/key/MatMul for ONNX node: /bert/encoder/layer.4/attention/self/key/MatMul\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/key/MatMul_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/key/MatMul_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/self/key/MatMul [MatMul] outputs: [/bert/encoder/layer.4/attention/self/key/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/key/Add [Add]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: bert.encoder.layer.4.attention.self.key.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/key/MatMul_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/self/key/Add [Add] inputs: [bert.encoder.layer.4.attention.self.key.bias -> (256)[FLOAT]], [/bert/encoder/layer.4/attention/self/key/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: bert.encoder.layer.4.attention.self.key.bias for ONNX node: bert.encoder.layer.4.attention.self.key.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/key/Add for ONNX node: /bert/encoder/layer.4/attention/self/key/Add\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/key/Add_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/key/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/self/key/Add [Add] outputs: [/bert/encoder/layer.4/attention/self/key/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Shape [Shape]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/key/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/self/Shape [Shape] inputs: [/bert/encoder/layer.4/attention/self/key/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Shape for ONNX node: /bert/encoder/layer.4/attention/self/Shape\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/Shape_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/Shape_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/self/Shape [Shape] outputs: [/bert/encoder/layer.4/attention/self/Shape_output_0 -> (3)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Constant [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/self/Constant [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/self/Constant [Constant] outputs: [/bert/encoder/layer.4/attention/self/Constant_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Gather [Gather]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Shape_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Constant_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/self/Gather [Gather] inputs: [/bert/encoder/layer.4/attention/self/Shape_output_0 -> (3)[INT32]], [/bert/encoder/layer.4/attention/self/Constant_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Constant_output_0 for ONNX node: /bert/encoder/layer.4/attention/self/Constant_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Using Gather axis: 0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Gather for ONNX node: /bert/encoder/layer.4/attention/self/Gather\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/Gather_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/Gather_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/self/Gather [Gather] outputs: [/bert/encoder/layer.4/attention/self/Gather_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Shape_1 [Shape]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/key/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/self/Shape_1 [Shape] inputs: [/bert/encoder/layer.4/attention/self/key/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Shape_1 for ONNX node: /bert/encoder/layer.4/attention/self/Shape_1\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/Shape_1_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/Shape_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/self/Shape_1 [Shape] outputs: [/bert/encoder/layer.4/attention/self/Shape_1_output_0 -> (3)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Constant_1 [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/self/Constant_1 [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/self/Constant_1 [Constant] outputs: [/bert/encoder/layer.4/attention/self/Constant_1_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Gather_1 [Gather]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Shape_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Constant_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/self/Gather_1 [Gather] inputs: [/bert/encoder/layer.4/attention/self/Shape_1_output_0 -> (3)[INT32]], [/bert/encoder/layer.4/attention/self/Constant_1_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Constant_1_output_0 for ONNX node: /bert/encoder/layer.4/attention/self/Constant_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Using Gather axis: 0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Gather_1 for ONNX node: /bert/encoder/layer.4/attention/self/Gather_1\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/Gather_1_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/Gather_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/self/Gather_1 [Gather] outputs: [/bert/encoder/layer.4/attention/self/Gather_1_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Unsqueeze [Unsqueeze]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Gather_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/self/Unsqueeze [Unsqueeze] inputs: [/bert/encoder/layer.4/attention/self/Gather_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Unsqueeze for ONNX node: /bert/encoder/layer.4/attention/self/Unsqueeze\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/Unsqueeze_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/Unsqueeze_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/self/Unsqueeze [Unsqueeze] outputs: [/bert/encoder/layer.4/attention/self/Unsqueeze_output_0 -> (1)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Unsqueeze_1 [Unsqueeze]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Gather_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/self/Unsqueeze_1 [Unsqueeze] inputs: [/bert/encoder/layer.4/attention/self/Gather_1_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Unsqueeze_1 for ONNX node: /bert/encoder/layer.4/attention/self/Unsqueeze_1\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/Unsqueeze_1_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/Unsqueeze_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/self/Unsqueeze_1 [Unsqueeze] outputs: [/bert/encoder/layer.4/attention/self/Unsqueeze_1_output_0 -> (1)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Constant_2 [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/self/Constant_2 [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/self/Constant_2 [Constant] outputs: [/bert/encoder/layer.4/attention/self/Constant_2_output_0 -> (1)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Constant_3 [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/self/Constant_3 [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/self/Constant_3 [Constant] outputs: [/bert/encoder/layer.4/attention/self/Constant_3_output_0 -> (1)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Concat [Concat]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Unsqueeze_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Unsqueeze_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Constant_2_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Constant_3_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/self/Concat [Concat] inputs: [/bert/encoder/layer.4/attention/self/Unsqueeze_output_0 -> (1)[INT32]], [/bert/encoder/layer.4/attention/self/Unsqueeze_1_output_0 -> (1)[INT32]], [/bert/encoder/layer.4/attention/self/Constant_2_output_0 -> (1)[INT32]], [/bert/encoder/layer.4/attention/self/Constant_3_output_0 -> (1)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Constant_2_output_0 for ONNX node: /bert/encoder/layer.4/attention/self/Constant_2_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Constant_3_output_0 for ONNX node: /bert/encoder/layer.4/attention/self/Constant_3_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Concat for ONNX node: /bert/encoder/layer.4/attention/self/Concat\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/Concat_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/Concat_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/self/Concat [Concat] outputs: [/bert/encoder/layer.4/attention/self/Concat_output_0 -> (4)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Reshape [Reshape]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/key/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Concat_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/self/Reshape [Reshape] inputs: [/bert/encoder/layer.4/attention/self/key/Add_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.4/attention/self/Concat_output_0 -> (4)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Reshape for ONNX node: /bert/encoder/layer.4/attention/self/Reshape\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/Reshape_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/Reshape_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/self/Reshape [Reshape] outputs: [/bert/encoder/layer.4/attention/self/Reshape_output_0 -> (-1, -1, 8, 32)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/value/MatMul [MatMul]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.3/output/LayerNorm/Add_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: onnx::MatMul_849\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/self/value/MatMul [MatMul] inputs: [/bert/encoder/layer.3/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], [onnx::MatMul_849 -> (256, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: onnx::MatMul_849 for ONNX node: onnx::MatMul_849\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/value/MatMul for ONNX node: /bert/encoder/layer.4/attention/self/value/MatMul\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/value/MatMul_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/value/MatMul_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/self/value/MatMul [MatMul] outputs: [/bert/encoder/layer.4/attention/self/value/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/value/Add [Add]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: bert.encoder.layer.4.attention.self.value.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/value/MatMul_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/self/value/Add [Add] inputs: [bert.encoder.layer.4.attention.self.value.bias -> (256)[FLOAT]], [/bert/encoder/layer.4/attention/self/value/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: bert.encoder.layer.4.attention.self.value.bias for ONNX node: bert.encoder.layer.4.attention.self.value.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/value/Add for ONNX node: /bert/encoder/layer.4/attention/self/value/Add\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/value/Add_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/value/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/self/value/Add [Add] outputs: [/bert/encoder/layer.4/attention/self/value/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Shape_2 [Shape]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/value/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/self/Shape_2 [Shape] inputs: [/bert/encoder/layer.4/attention/self/value/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Shape_2 for ONNX node: /bert/encoder/layer.4/attention/self/Shape_2\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/Shape_2_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/Shape_2_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/self/Shape_2 [Shape] outputs: [/bert/encoder/layer.4/attention/self/Shape_2_output_0 -> (3)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Constant_4 [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/self/Constant_4 [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/self/Constant_4 [Constant] outputs: [/bert/encoder/layer.4/attention/self/Constant_4_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Gather_2 [Gather]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Shape_2_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Constant_4_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/self/Gather_2 [Gather] inputs: [/bert/encoder/layer.4/attention/self/Shape_2_output_0 -> (3)[INT32]], [/bert/encoder/layer.4/attention/self/Constant_4_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Constant_4_output_0 for ONNX node: /bert/encoder/layer.4/attention/self/Constant_4_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Using Gather axis: 0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Gather_2 for ONNX node: /bert/encoder/layer.4/attention/self/Gather_2\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/Gather_2_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/Gather_2_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/self/Gather_2 [Gather] outputs: [/bert/encoder/layer.4/attention/self/Gather_2_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Shape_3 [Shape]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/value/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/self/Shape_3 [Shape] inputs: [/bert/encoder/layer.4/attention/self/value/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Shape_3 for ONNX node: /bert/encoder/layer.4/attention/self/Shape_3\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/Shape_3_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/Shape_3_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/self/Shape_3 [Shape] outputs: [/bert/encoder/layer.4/attention/self/Shape_3_output_0 -> (3)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Constant_5 [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/self/Constant_5 [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/self/Constant_5 [Constant] outputs: [/bert/encoder/layer.4/attention/self/Constant_5_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Gather_3 [Gather]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Shape_3_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Constant_5_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/self/Gather_3 [Gather] inputs: [/bert/encoder/layer.4/attention/self/Shape_3_output_0 -> (3)[INT32]], [/bert/encoder/layer.4/attention/self/Constant_5_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Constant_5_output_0 for ONNX node: /bert/encoder/layer.4/attention/self/Constant_5_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Using Gather axis: 0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Gather_3 for ONNX node: /bert/encoder/layer.4/attention/self/Gather_3\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/Gather_3_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/Gather_3_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/self/Gather_3 [Gather] outputs: [/bert/encoder/layer.4/attention/self/Gather_3_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Unsqueeze_2 [Unsqueeze]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Gather_2_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/self/Unsqueeze_2 [Unsqueeze] inputs: [/bert/encoder/layer.4/attention/self/Gather_2_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Unsqueeze_2 for ONNX node: /bert/encoder/layer.4/attention/self/Unsqueeze_2\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/Unsqueeze_2_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/Unsqueeze_2_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/self/Unsqueeze_2 [Unsqueeze] outputs: [/bert/encoder/layer.4/attention/self/Unsqueeze_2_output_0 -> (1)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Unsqueeze_3 [Unsqueeze]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Gather_3_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/self/Unsqueeze_3 [Unsqueeze] inputs: [/bert/encoder/layer.4/attention/self/Gather_3_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Unsqueeze_3 for ONNX node: /bert/encoder/layer.4/attention/self/Unsqueeze_3\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/Unsqueeze_3_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/Unsqueeze_3_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/self/Unsqueeze_3 [Unsqueeze] outputs: [/bert/encoder/layer.4/attention/self/Unsqueeze_3_output_0 -> (1)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Constant_6 [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/self/Constant_6 [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/self/Constant_6 [Constant] outputs: [/bert/encoder/layer.4/attention/self/Constant_6_output_0 -> (1)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Constant_7 [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/self/Constant_7 [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/self/Constant_7 [Constant] outputs: [/bert/encoder/layer.4/attention/self/Constant_7_output_0 -> (1)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Concat_1 [Concat]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Unsqueeze_2_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Unsqueeze_3_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Constant_6_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Constant_7_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/self/Concat_1 [Concat] inputs: [/bert/encoder/layer.4/attention/self/Unsqueeze_2_output_0 -> (1)[INT32]], [/bert/encoder/layer.4/attention/self/Unsqueeze_3_output_0 -> (1)[INT32]], [/bert/encoder/layer.4/attention/self/Constant_6_output_0 -> (1)[INT32]], [/bert/encoder/layer.4/attention/self/Constant_7_output_0 -> (1)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Constant_6_output_0 for ONNX node: /bert/encoder/layer.4/attention/self/Constant_6_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Constant_7_output_0 for ONNX node: /bert/encoder/layer.4/attention/self/Constant_7_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Concat_1 for ONNX node: /bert/encoder/layer.4/attention/self/Concat_1\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/Concat_1_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/Concat_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/self/Concat_1 [Concat] outputs: [/bert/encoder/layer.4/attention/self/Concat_1_output_0 -> (4)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Reshape_1 [Reshape]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/value/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Concat_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/self/Reshape_1 [Reshape] inputs: [/bert/encoder/layer.4/attention/self/value/Add_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.4/attention/self/Concat_1_output_0 -> (4)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Reshape_1 for ONNX node: /bert/encoder/layer.4/attention/self/Reshape_1\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/Reshape_1_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/Reshape_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/self/Reshape_1 [Reshape] outputs: [/bert/encoder/layer.4/attention/self/Reshape_1_output_0 -> (-1, -1, 8, 32)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Transpose [Transpose]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Reshape_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/self/Transpose [Transpose] inputs: [/bert/encoder/layer.4/attention/self/Reshape_1_output_0 -> (-1, -1, 8, 32)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Transpose for ONNX node: /bert/encoder/layer.4/attention/self/Transpose\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/Transpose_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/Transpose_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/self/Transpose [Transpose] outputs: [/bert/encoder/layer.4/attention/self/Transpose_output_0 -> (-1, 8, -1, 32)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Shape_4 [Shape]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/query/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/self/Shape_4 [Shape] inputs: [/bert/encoder/layer.4/attention/self/query/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Shape_4 for ONNX node: /bert/encoder/layer.4/attention/self/Shape_4\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/Shape_4_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/Shape_4_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/self/Shape_4 [Shape] outputs: [/bert/encoder/layer.4/attention/self/Shape_4_output_0 -> (3)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Constant_8 [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/self/Constant_8 [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/self/Constant_8 [Constant] outputs: [/bert/encoder/layer.4/attention/self/Constant_8_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Gather_4 [Gather]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Shape_4_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Constant_8_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/self/Gather_4 [Gather] inputs: [/bert/encoder/layer.4/attention/self/Shape_4_output_0 -> (3)[INT32]], [/bert/encoder/layer.4/attention/self/Constant_8_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Constant_8_output_0 for ONNX node: /bert/encoder/layer.4/attention/self/Constant_8_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Using Gather axis: 0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Gather_4 for ONNX node: /bert/encoder/layer.4/attention/self/Gather_4\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/Gather_4_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/Gather_4_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/self/Gather_4 [Gather] outputs: [/bert/encoder/layer.4/attention/self/Gather_4_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Shape_5 [Shape]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/query/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/self/Shape_5 [Shape] inputs: [/bert/encoder/layer.4/attention/self/query/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Shape_5 for ONNX node: /bert/encoder/layer.4/attention/self/Shape_5\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/Shape_5_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/Shape_5_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/self/Shape_5 [Shape] outputs: [/bert/encoder/layer.4/attention/self/Shape_5_output_0 -> (3)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Constant_9 [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/self/Constant_9 [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/self/Constant_9 [Constant] outputs: [/bert/encoder/layer.4/attention/self/Constant_9_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Gather_5 [Gather]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Shape_5_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Constant_9_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/self/Gather_5 [Gather] inputs: [/bert/encoder/layer.4/attention/self/Shape_5_output_0 -> (3)[INT32]], [/bert/encoder/layer.4/attention/self/Constant_9_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Constant_9_output_0 for ONNX node: /bert/encoder/layer.4/attention/self/Constant_9_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Using Gather axis: 0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Gather_5 for ONNX node: /bert/encoder/layer.4/attention/self/Gather_5\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/Gather_5_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/Gather_5_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/self/Gather_5 [Gather] outputs: [/bert/encoder/layer.4/attention/self/Gather_5_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Unsqueeze_4 [Unsqueeze]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Gather_4_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/self/Unsqueeze_4 [Unsqueeze] inputs: [/bert/encoder/layer.4/attention/self/Gather_4_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Unsqueeze_4 for ONNX node: /bert/encoder/layer.4/attention/self/Unsqueeze_4\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/Unsqueeze_4_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/Unsqueeze_4_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/self/Unsqueeze_4 [Unsqueeze] outputs: [/bert/encoder/layer.4/attention/self/Unsqueeze_4_output_0 -> (1)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Unsqueeze_5 [Unsqueeze]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Gather_5_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/self/Unsqueeze_5 [Unsqueeze] inputs: [/bert/encoder/layer.4/attention/self/Gather_5_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Unsqueeze_5 for ONNX node: /bert/encoder/layer.4/attention/self/Unsqueeze_5\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/Unsqueeze_5_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/Unsqueeze_5_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/self/Unsqueeze_5 [Unsqueeze] outputs: [/bert/encoder/layer.4/attention/self/Unsqueeze_5_output_0 -> (1)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Constant_10 [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/self/Constant_10 [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/self/Constant_10 [Constant] outputs: [/bert/encoder/layer.4/attention/self/Constant_10_output_0 -> (1)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Constant_11 [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/self/Constant_11 [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/self/Constant_11 [Constant] outputs: [/bert/encoder/layer.4/attention/self/Constant_11_output_0 -> (1)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Concat_2 [Concat]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Unsqueeze_4_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Unsqueeze_5_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Constant_10_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Constant_11_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/self/Concat_2 [Concat] inputs: [/bert/encoder/layer.4/attention/self/Unsqueeze_4_output_0 -> (1)[INT32]], [/bert/encoder/layer.4/attention/self/Unsqueeze_5_output_0 -> (1)[INT32]], [/bert/encoder/layer.4/attention/self/Constant_10_output_0 -> (1)[INT32]], [/bert/encoder/layer.4/attention/self/Constant_11_output_0 -> (1)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Constant_10_output_0 for ONNX node: /bert/encoder/layer.4/attention/self/Constant_10_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Constant_11_output_0 for ONNX node: /bert/encoder/layer.4/attention/self/Constant_11_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Concat_2 for ONNX node: /bert/encoder/layer.4/attention/self/Concat_2\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/Concat_2_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/Concat_2_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/self/Concat_2 [Concat] outputs: [/bert/encoder/layer.4/attention/self/Concat_2_output_0 -> (4)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Reshape_2 [Reshape]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/query/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Concat_2_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/self/Reshape_2 [Reshape] inputs: [/bert/encoder/layer.4/attention/self/query/Add_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.4/attention/self/Concat_2_output_0 -> (4)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Reshape_2 for ONNX node: /bert/encoder/layer.4/attention/self/Reshape_2\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/Reshape_2_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/Reshape_2_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/self/Reshape_2 [Reshape] outputs: [/bert/encoder/layer.4/attention/self/Reshape_2_output_0 -> (-1, -1, 8, 32)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Transpose_1 [Transpose]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Reshape_2_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/self/Transpose_1 [Transpose] inputs: [/bert/encoder/layer.4/attention/self/Reshape_2_output_0 -> (-1, -1, 8, 32)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Transpose_1 for ONNX node: /bert/encoder/layer.4/attention/self/Transpose_1\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/Transpose_1_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/Transpose_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/self/Transpose_1 [Transpose] outputs: [/bert/encoder/layer.4/attention/self/Transpose_1_output_0 -> (-1, 8, -1, 32)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Transpose_2 [Transpose]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Reshape_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/self/Transpose_2 [Transpose] inputs: [/bert/encoder/layer.4/attention/self/Reshape_output_0 -> (-1, -1, 8, 32)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Transpose_2 for ONNX node: /bert/encoder/layer.4/attention/self/Transpose_2\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/Transpose_2_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/Transpose_2_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/self/Transpose_2 [Transpose] outputs: [/bert/encoder/layer.4/attention/self/Transpose_2_output_0 -> (-1, 8, 32, -1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/MatMul [MatMul]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Transpose_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Transpose_2_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/self/MatMul [MatMul] inputs: [/bert/encoder/layer.4/attention/self/Transpose_1_output_0 -> (-1, 8, -1, 32)[FLOAT]], [/bert/encoder/layer.4/attention/self/Transpose_2_output_0 -> (-1, 8, 32, -1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/MatMul for ONNX node: /bert/encoder/layer.4/attention/self/MatMul\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/MatMul_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/MatMul_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/self/MatMul [MatMul] outputs: [/bert/encoder/layer.4/attention/self/MatMul_output_0 -> (-1, 8, -1, -1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Constant_12 [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/self/Constant_12 [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/self/Constant_12 [Constant] outputs: [/bert/encoder/layer.4/attention/self/Constant_12_output_0 -> ()[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Div [Div]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/MatMul_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Constant_12_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/self/Div [Div] inputs: [/bert/encoder/layer.4/attention/self/MatMul_output_0 -> (-1, 8, -1, -1)[FLOAT]], [/bert/encoder/layer.4/attention/self/Constant_12_output_0 -> ()[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Constant_12_output_0 for ONNX node: /bert/encoder/layer.4/attention/self/Constant_12_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Div for ONNX node: /bert/encoder/layer.4/attention/self/Div\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/Div_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/Div_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/self/Div [Div] outputs: [/bert/encoder/layer.4/attention/self/Div_output_0 -> (-1, 8, -1, -1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Add [Add]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Div_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/Mul_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/self/Add [Add] inputs: [/bert/encoder/layer.4/attention/self/Div_output_0 -> (-1, 8, -1, -1)[FLOAT]], [/bert/Mul_output_0 -> (-1, 1, 1, -1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Add for ONNX node: /bert/encoder/layer.4/attention/self/Add\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/Add_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/self/Add [Add] outputs: [/bert/encoder/layer.4/attention/self/Add_output_0 -> (-1, 8, -1, -1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Softmax [Softmax]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/self/Softmax [Softmax] inputs: [/bert/encoder/layer.4/attention/self/Add_output_0 -> (-1, 8, -1, -1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Softmax for ONNX node: /bert/encoder/layer.4/attention/self/Softmax\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/Softmax_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/Softmax_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/self/Softmax [Softmax] outputs: [/bert/encoder/layer.4/attention/self/Softmax_output_0 -> (-1, 8, -1, -1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/MatMul_1 [MatMul]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Softmax_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Transpose_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/self/MatMul_1 [MatMul] inputs: [/bert/encoder/layer.4/attention/self/Softmax_output_0 -> (-1, 8, -1, -1)[FLOAT]], [/bert/encoder/layer.4/attention/self/Transpose_output_0 -> (-1, 8, -1, 32)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/MatMul_1 for ONNX node: /bert/encoder/layer.4/attention/self/MatMul_1\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/MatMul_1_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/MatMul_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/self/MatMul_1 [MatMul] outputs: [/bert/encoder/layer.4/attention/self/MatMul_1_output_0 -> (-1, 8, -1, 32)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Transpose_3 [Transpose]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/MatMul_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/self/Transpose_3 [Transpose] inputs: [/bert/encoder/layer.4/attention/self/MatMul_1_output_0 -> (-1, 8, -1, 32)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Transpose_3 for ONNX node: /bert/encoder/layer.4/attention/self/Transpose_3\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/Transpose_3_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/Transpose_3_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/self/Transpose_3 [Transpose] outputs: [/bert/encoder/layer.4/attention/self/Transpose_3_output_0 -> (-1, -1, 8, 32)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Shape_6 [Shape]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Transpose_3_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/self/Shape_6 [Shape] inputs: [/bert/encoder/layer.4/attention/self/Transpose_3_output_0 -> (-1, -1, 8, 32)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Shape_6 for ONNX node: /bert/encoder/layer.4/attention/self/Shape_6\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/Shape_6_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/Shape_6_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/self/Shape_6 [Shape] outputs: [/bert/encoder/layer.4/attention/self/Shape_6_output_0 -> (4)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Constant_13 [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/self/Constant_13 [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/self/Constant_13 [Constant] outputs: [/bert/encoder/layer.4/attention/self/Constant_13_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Gather_6 [Gather]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Shape_6_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Constant_13_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/self/Gather_6 [Gather] inputs: [/bert/encoder/layer.4/attention/self/Shape_6_output_0 -> (4)[INT32]], [/bert/encoder/layer.4/attention/self/Constant_13_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Constant_13_output_0 for ONNX node: /bert/encoder/layer.4/attention/self/Constant_13_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Using Gather axis: 0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Gather_6 for ONNX node: /bert/encoder/layer.4/attention/self/Gather_6\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/Gather_6_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/Gather_6_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/self/Gather_6 [Gather] outputs: [/bert/encoder/layer.4/attention/self/Gather_6_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Shape_7 [Shape]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Transpose_3_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/self/Shape_7 [Shape] inputs: [/bert/encoder/layer.4/attention/self/Transpose_3_output_0 -> (-1, -1, 8, 32)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Shape_7 for ONNX node: /bert/encoder/layer.4/attention/self/Shape_7\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/Shape_7_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/Shape_7_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/self/Shape_7 [Shape] outputs: [/bert/encoder/layer.4/attention/self/Shape_7_output_0 -> (4)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Constant_14 [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/self/Constant_14 [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/self/Constant_14 [Constant] outputs: [/bert/encoder/layer.4/attention/self/Constant_14_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Gather_7 [Gather]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Shape_7_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Constant_14_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/self/Gather_7 [Gather] inputs: [/bert/encoder/layer.4/attention/self/Shape_7_output_0 -> (4)[INT32]], [/bert/encoder/layer.4/attention/self/Constant_14_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Constant_14_output_0 for ONNX node: /bert/encoder/layer.4/attention/self/Constant_14_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Using Gather axis: 0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Gather_7 for ONNX node: /bert/encoder/layer.4/attention/self/Gather_7\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/Gather_7_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/Gather_7_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/self/Gather_7 [Gather] outputs: [/bert/encoder/layer.4/attention/self/Gather_7_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Unsqueeze_6 [Unsqueeze]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Gather_6_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/self/Unsqueeze_6 [Unsqueeze] inputs: [/bert/encoder/layer.4/attention/self/Gather_6_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Unsqueeze_6 for ONNX node: /bert/encoder/layer.4/attention/self/Unsqueeze_6\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/Unsqueeze_6_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/Unsqueeze_6_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/self/Unsqueeze_6 [Unsqueeze] outputs: [/bert/encoder/layer.4/attention/self/Unsqueeze_6_output_0 -> (1)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Unsqueeze_7 [Unsqueeze]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Gather_7_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/self/Unsqueeze_7 [Unsqueeze] inputs: [/bert/encoder/layer.4/attention/self/Gather_7_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Unsqueeze_7 for ONNX node: /bert/encoder/layer.4/attention/self/Unsqueeze_7\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/Unsqueeze_7_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/Unsqueeze_7_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/self/Unsqueeze_7 [Unsqueeze] outputs: [/bert/encoder/layer.4/attention/self/Unsqueeze_7_output_0 -> (1)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Constant_15 [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/self/Constant_15 [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/self/Constant_15 [Constant] outputs: [/bert/encoder/layer.4/attention/self/Constant_15_output_0 -> (1)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Concat_3 [Concat]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Unsqueeze_6_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Unsqueeze_7_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Constant_15_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/self/Concat_3 [Concat] inputs: [/bert/encoder/layer.4/attention/self/Unsqueeze_6_output_0 -> (1)[INT32]], [/bert/encoder/layer.4/attention/self/Unsqueeze_7_output_0 -> (1)[INT32]], [/bert/encoder/layer.4/attention/self/Constant_15_output_0 -> (1)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Constant_15_output_0 for ONNX node: /bert/encoder/layer.4/attention/self/Constant_15_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Concat_3 for ONNX node: /bert/encoder/layer.4/attention/self/Concat_3\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/Concat_3_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/Concat_3_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/self/Concat_3 [Concat] outputs: [/bert/encoder/layer.4/attention/self/Concat_3_output_0 -> (3)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Reshape_3 [Reshape]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Transpose_3_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Concat_3_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/self/Reshape_3 [Reshape] inputs: [/bert/encoder/layer.4/attention/self/Transpose_3_output_0 -> (-1, -1, 8, 32)[FLOAT]], [/bert/encoder/layer.4/attention/self/Concat_3_output_0 -> (3)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Reshape_3 for ONNX node: /bert/encoder/layer.4/attention/self/Reshape_3\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/Reshape_3_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/Reshape_3_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/self/Reshape_3 [Reshape] outputs: [/bert/encoder/layer.4/attention/self/Reshape_3_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/output/dense/MatMul [MatMul]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Reshape_3_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: onnx::MatMul_855\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/output/dense/MatMul [MatMul] inputs: [/bert/encoder/layer.4/attention/self/Reshape_3_output_0 -> (-1, -1, 256)[FLOAT]], [onnx::MatMul_855 -> (256, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: onnx::MatMul_855 for ONNX node: onnx::MatMul_855\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/output/dense/MatMul for ONNX node: /bert/encoder/layer.4/attention/output/dense/MatMul\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/output/dense/MatMul_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/output/dense/MatMul_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/output/dense/MatMul [MatMul] outputs: [/bert/encoder/layer.4/attention/output/dense/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/output/dense/Add [Add]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: bert.encoder.layer.4.attention.output.dense.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/output/dense/MatMul_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/output/dense/Add [Add] inputs: [bert.encoder.layer.4.attention.output.dense.bias -> (256)[FLOAT]], [/bert/encoder/layer.4/attention/output/dense/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: bert.encoder.layer.4.attention.output.dense.bias for ONNX node: bert.encoder.layer.4.attention.output.dense.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/output/dense/Add for ONNX node: /bert/encoder/layer.4/attention/output/dense/Add\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/output/dense/Add_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/output/dense/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/output/dense/Add [Add] outputs: [/bert/encoder/layer.4/attention/output/dense/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/output/Add [Add]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/output/dense/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.3/output/LayerNorm/Add_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/output/Add [Add] inputs: [/bert/encoder/layer.4/attention/output/dense/Add_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.3/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/output/Add for ONNX node: /bert/encoder/layer.4/attention/output/Add\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/output/Add_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/output/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/output/Add [Add] outputs: [/bert/encoder/layer.4/attention/output/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/output/LayerNorm/ReduceMean [ReduceMean]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/output/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/output/LayerNorm/ReduceMean [ReduceMean] inputs: [/bert/encoder/layer.4/attention/output/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/output/LayerNorm/ReduceMean for ONNX node: /bert/encoder/layer.4/attention/output/LayerNorm/ReduceMean\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/output/LayerNorm/ReduceMean_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/output/LayerNorm/ReduceMean_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/output/LayerNorm/ReduceMean [ReduceMean] outputs: [/bert/encoder/layer.4/attention/output/LayerNorm/ReduceMean_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/output/LayerNorm/Sub [Sub]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/output/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/output/LayerNorm/ReduceMean_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/output/LayerNorm/Sub [Sub] inputs: [/bert/encoder/layer.4/attention/output/Add_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.4/attention/output/LayerNorm/ReduceMean_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/output/LayerNorm/Sub for ONNX node: /bert/encoder/layer.4/attention/output/LayerNorm/Sub\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/output/LayerNorm/Sub_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/output/LayerNorm/Sub_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/output/LayerNorm/Sub [Sub] outputs: [/bert/encoder/layer.4/attention/output/LayerNorm/Sub_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/output/LayerNorm/Constant [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/output/LayerNorm/Constant [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/output/LayerNorm/Constant [Constant] outputs: [/bert/encoder/layer.4/attention/output/LayerNorm/Constant_output_0 -> ()[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/output/LayerNorm/Pow [Pow]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/output/LayerNorm/Sub_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/output/LayerNorm/Constant_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/output/LayerNorm/Pow [Pow] inputs: [/bert/encoder/layer.4/attention/output/LayerNorm/Sub_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.4/attention/output/LayerNorm/Constant_output_0 -> ()[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/output/LayerNorm/Constant_output_0 for ONNX node: /bert/encoder/layer.4/attention/output/LayerNorm/Constant_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/output/LayerNorm/Pow for ONNX node: /bert/encoder/layer.4/attention/output/LayerNorm/Pow\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/output/LayerNorm/Pow_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/output/LayerNorm/Pow_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/output/LayerNorm/Pow [Pow] outputs: [/bert/encoder/layer.4/attention/output/LayerNorm/Pow_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/output/LayerNorm/ReduceMean_1 [ReduceMean]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/output/LayerNorm/Pow_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/output/LayerNorm/ReduceMean_1 [ReduceMean] inputs: [/bert/encoder/layer.4/attention/output/LayerNorm/Pow_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/output/LayerNorm/ReduceMean_1 for ONNX node: /bert/encoder/layer.4/attention/output/LayerNorm/ReduceMean_1\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/output/LayerNorm/ReduceMean_1_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/output/LayerNorm/ReduceMean_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/output/LayerNorm/ReduceMean_1 [ReduceMean] outputs: [/bert/encoder/layer.4/attention/output/LayerNorm/ReduceMean_1_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/output/LayerNorm/Constant_1 [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/output/LayerNorm/Constant_1 [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/output/LayerNorm/Constant_1 [Constant] outputs: [/bert/encoder/layer.4/attention/output/LayerNorm/Constant_1_output_0 -> ()[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/output/LayerNorm/Add [Add]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/output/LayerNorm/ReduceMean_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/output/LayerNorm/Constant_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/output/LayerNorm/Add [Add] inputs: [/bert/encoder/layer.4/attention/output/LayerNorm/ReduceMean_1_output_0 -> (-1, -1, 1)[FLOAT]], [/bert/encoder/layer.4/attention/output/LayerNorm/Constant_1_output_0 -> ()[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/output/LayerNorm/Constant_1_output_0 for ONNX node: /bert/encoder/layer.4/attention/output/LayerNorm/Constant_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/output/LayerNorm/Add for ONNX node: /bert/encoder/layer.4/attention/output/LayerNorm/Add\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/output/LayerNorm/Add_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/output/LayerNorm/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/output/LayerNorm/Add [Add] outputs: [/bert/encoder/layer.4/attention/output/LayerNorm/Add_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/output/LayerNorm/Sqrt [Sqrt]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/output/LayerNorm/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/output/LayerNorm/Sqrt [Sqrt] inputs: [/bert/encoder/layer.4/attention/output/LayerNorm/Add_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/output/LayerNorm/Sqrt for ONNX node: /bert/encoder/layer.4/attention/output/LayerNorm/Sqrt\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/output/LayerNorm/Sqrt_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/output/LayerNorm/Sqrt_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/output/LayerNorm/Sqrt [Sqrt] outputs: [/bert/encoder/layer.4/attention/output/LayerNorm/Sqrt_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/output/LayerNorm/Div [Div]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/output/LayerNorm/Sub_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/output/LayerNorm/Sqrt_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/output/LayerNorm/Div [Div] inputs: [/bert/encoder/layer.4/attention/output/LayerNorm/Sub_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.4/attention/output/LayerNorm/Sqrt_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/output/LayerNorm/Div for ONNX node: /bert/encoder/layer.4/attention/output/LayerNorm/Div\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/output/LayerNorm/Div_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/output/LayerNorm/Div_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/output/LayerNorm/Div [Div] outputs: [/bert/encoder/layer.4/attention/output/LayerNorm/Div_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/output/LayerNorm/Mul [Mul]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/output/LayerNorm/Div_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: bert.encoder.layer.4.attention.output.LayerNorm.weight\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/output/LayerNorm/Mul [Mul] inputs: [/bert/encoder/layer.4/attention/output/LayerNorm/Div_output_0 -> (-1, -1, 256)[FLOAT]], [bert.encoder.layer.4.attention.output.LayerNorm.weight -> (256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: bert.encoder.layer.4.attention.output.LayerNorm.weight for ONNX node: bert.encoder.layer.4.attention.output.LayerNorm.weight\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/output/LayerNorm/Mul for ONNX node: /bert/encoder/layer.4/attention/output/LayerNorm/Mul\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/output/LayerNorm/Mul_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/output/LayerNorm/Mul_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/output/LayerNorm/Mul [Mul] outputs: [/bert/encoder/layer.4/attention/output/LayerNorm/Mul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/output/LayerNorm/Add_1 [Add]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/output/LayerNorm/Mul_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: bert.encoder.layer.4.attention.output.LayerNorm.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/output/LayerNorm/Add_1 [Add] inputs: [/bert/encoder/layer.4/attention/output/LayerNorm/Mul_output_0 -> (-1, -1, 256)[FLOAT]], [bert.encoder.layer.4.attention.output.LayerNorm.bias -> (256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: bert.encoder.layer.4.attention.output.LayerNorm.bias for ONNX node: bert.encoder.layer.4.attention.output.LayerNorm.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/output/LayerNorm/Add_1 for ONNX node: /bert/encoder/layer.4/attention/output/LayerNorm/Add_1\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/output/LayerNorm/Add_1_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/output/LayerNorm/Add_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/attention/output/LayerNorm/Add_1 [Add] outputs: [/bert/encoder/layer.4/attention/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.4/intermediate/dense/MatMul [MatMul]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/output/LayerNorm/Add_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: onnx::MatMul_856\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/intermediate/dense/MatMul [MatMul] inputs: [/bert/encoder/layer.4/attention/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], [onnx::MatMul_856 -> (256, 1024)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: onnx::MatMul_856 for ONNX node: onnx::MatMul_856\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.4/intermediate/dense/MatMul for ONNX node: /bert/encoder/layer.4/intermediate/dense/MatMul\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.4/intermediate/dense/MatMul_output_0 for ONNX tensor: /bert/encoder/layer.4/intermediate/dense/MatMul_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/intermediate/dense/MatMul [MatMul] outputs: [/bert/encoder/layer.4/intermediate/dense/MatMul_output_0 -> (-1, -1, 1024)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.4/intermediate/dense/Add [Add]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: bert.encoder.layer.4.intermediate.dense.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.4/intermediate/dense/MatMul_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/intermediate/dense/Add [Add] inputs: [bert.encoder.layer.4.intermediate.dense.bias -> (1024)[FLOAT]], [/bert/encoder/layer.4/intermediate/dense/MatMul_output_0 -> (-1, -1, 1024)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: bert.encoder.layer.4.intermediate.dense.bias for ONNX node: bert.encoder.layer.4.intermediate.dense.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.4/intermediate/dense/Add for ONNX node: /bert/encoder/layer.4/intermediate/dense/Add\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.4/intermediate/dense/Add_output_0 for ONNX tensor: /bert/encoder/layer.4/intermediate/dense/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/intermediate/dense/Add [Add] outputs: [/bert/encoder/layer.4/intermediate/dense/Add_output_0 -> (-1, -1, 1024)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.4/intermediate/intermediate_act_fn/Constant [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/intermediate/intermediate_act_fn/Constant [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/intermediate/intermediate_act_fn/Constant [Constant] outputs: [/bert/encoder/layer.4/intermediate/intermediate_act_fn/Constant_output_0 -> ()[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.4/intermediate/intermediate_act_fn/Div [Div]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.4/intermediate/dense/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.4/intermediate/intermediate_act_fn/Constant_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/intermediate/intermediate_act_fn/Div [Div] inputs: [/bert/encoder/layer.4/intermediate/dense/Add_output_0 -> (-1, -1, 1024)[FLOAT]], [/bert/encoder/layer.4/intermediate/intermediate_act_fn/Constant_output_0 -> ()[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.4/intermediate/intermediate_act_fn/Constant_output_0 for ONNX node: /bert/encoder/layer.4/intermediate/intermediate_act_fn/Constant_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.4/intermediate/intermediate_act_fn/Div for ONNX node: /bert/encoder/layer.4/intermediate/intermediate_act_fn/Div\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.4/intermediate/intermediate_act_fn/Div_output_0 for ONNX tensor: /bert/encoder/layer.4/intermediate/intermediate_act_fn/Div_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/intermediate/intermediate_act_fn/Div [Div] outputs: [/bert/encoder/layer.4/intermediate/intermediate_act_fn/Div_output_0 -> (-1, -1, 1024)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.4/intermediate/intermediate_act_fn/Erf [Erf]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.4/intermediate/intermediate_act_fn/Div_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/intermediate/intermediate_act_fn/Erf [Erf] inputs: [/bert/encoder/layer.4/intermediate/intermediate_act_fn/Div_output_0 -> (-1, -1, 1024)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.4/intermediate/intermediate_act_fn/Erf for ONNX node: /bert/encoder/layer.4/intermediate/intermediate_act_fn/Erf\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.4/intermediate/intermediate_act_fn/Erf_output_0 for ONNX tensor: /bert/encoder/layer.4/intermediate/intermediate_act_fn/Erf_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/intermediate/intermediate_act_fn/Erf [Erf] outputs: [/bert/encoder/layer.4/intermediate/intermediate_act_fn/Erf_output_0 -> (-1, -1, 1024)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.4/intermediate/intermediate_act_fn/Constant_1 [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/intermediate/intermediate_act_fn/Constant_1 [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/intermediate/intermediate_act_fn/Constant_1 [Constant] outputs: [/bert/encoder/layer.4/intermediate/intermediate_act_fn/Constant_1_output_0 -> ()[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.4/intermediate/intermediate_act_fn/Add [Add]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.4/intermediate/intermediate_act_fn/Erf_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.4/intermediate/intermediate_act_fn/Constant_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/intermediate/intermediate_act_fn/Add [Add] inputs: [/bert/encoder/layer.4/intermediate/intermediate_act_fn/Erf_output_0 -> (-1, -1, 1024)[FLOAT]], [/bert/encoder/layer.4/intermediate/intermediate_act_fn/Constant_1_output_0 -> ()[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.4/intermediate/intermediate_act_fn/Constant_1_output_0 for ONNX node: /bert/encoder/layer.4/intermediate/intermediate_act_fn/Constant_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.4/intermediate/intermediate_act_fn/Add for ONNX node: /bert/encoder/layer.4/intermediate/intermediate_act_fn/Add\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.4/intermediate/intermediate_act_fn/Add_output_0 for ONNX tensor: /bert/encoder/layer.4/intermediate/intermediate_act_fn/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/intermediate/intermediate_act_fn/Add [Add] outputs: [/bert/encoder/layer.4/intermediate/intermediate_act_fn/Add_output_0 -> (-1, -1, 1024)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.4/intermediate/intermediate_act_fn/Mul [Mul]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.4/intermediate/dense/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.4/intermediate/intermediate_act_fn/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/intermediate/intermediate_act_fn/Mul [Mul] inputs: [/bert/encoder/layer.4/intermediate/dense/Add_output_0 -> (-1, -1, 1024)[FLOAT]], [/bert/encoder/layer.4/intermediate/intermediate_act_fn/Add_output_0 -> (-1, -1, 1024)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.4/intermediate/intermediate_act_fn/Mul for ONNX node: /bert/encoder/layer.4/intermediate/intermediate_act_fn/Mul\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.4/intermediate/intermediate_act_fn/Mul_output_0 for ONNX tensor: /bert/encoder/layer.4/intermediate/intermediate_act_fn/Mul_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/intermediate/intermediate_act_fn/Mul [Mul] outputs: [/bert/encoder/layer.4/intermediate/intermediate_act_fn/Mul_output_0 -> (-1, -1, 1024)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.4/intermediate/intermediate_act_fn/Constant_2 [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/intermediate/intermediate_act_fn/Constant_2 [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/intermediate/intermediate_act_fn/Constant_2 [Constant] outputs: [/bert/encoder/layer.4/intermediate/intermediate_act_fn/Constant_2_output_0 -> ()[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.4/intermediate/intermediate_act_fn/Mul_1 [Mul]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.4/intermediate/intermediate_act_fn/Mul_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.4/intermediate/intermediate_act_fn/Constant_2_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/intermediate/intermediate_act_fn/Mul_1 [Mul] inputs: [/bert/encoder/layer.4/intermediate/intermediate_act_fn/Mul_output_0 -> (-1, -1, 1024)[FLOAT]], [/bert/encoder/layer.4/intermediate/intermediate_act_fn/Constant_2_output_0 -> ()[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.4/intermediate/intermediate_act_fn/Constant_2_output_0 for ONNX node: /bert/encoder/layer.4/intermediate/intermediate_act_fn/Constant_2_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.4/intermediate/intermediate_act_fn/Mul_1 for ONNX node: /bert/encoder/layer.4/intermediate/intermediate_act_fn/Mul_1\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.4/intermediate/intermediate_act_fn/Mul_1_output_0 for ONNX tensor: /bert/encoder/layer.4/intermediate/intermediate_act_fn/Mul_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/intermediate/intermediate_act_fn/Mul_1 [Mul] outputs: [/bert/encoder/layer.4/intermediate/intermediate_act_fn/Mul_1_output_0 -> (-1, -1, 1024)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.4/output/dense/MatMul [MatMul]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.4/intermediate/intermediate_act_fn/Mul_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: onnx::MatMul_857\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/output/dense/MatMul [MatMul] inputs: [/bert/encoder/layer.4/intermediate/intermediate_act_fn/Mul_1_output_0 -> (-1, -1, 1024)[FLOAT]], [onnx::MatMul_857 -> (1024, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: onnx::MatMul_857 for ONNX node: onnx::MatMul_857\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.4/output/dense/MatMul for ONNX node: /bert/encoder/layer.4/output/dense/MatMul\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.4/output/dense/MatMul_output_0 for ONNX tensor: /bert/encoder/layer.4/output/dense/MatMul_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/output/dense/MatMul [MatMul] outputs: [/bert/encoder/layer.4/output/dense/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.4/output/dense/Add [Add]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: bert.encoder.layer.4.output.dense.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.4/output/dense/MatMul_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/output/dense/Add [Add] inputs: [bert.encoder.layer.4.output.dense.bias -> (256)[FLOAT]], [/bert/encoder/layer.4/output/dense/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: bert.encoder.layer.4.output.dense.bias for ONNX node: bert.encoder.layer.4.output.dense.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.4/output/dense/Add for ONNX node: /bert/encoder/layer.4/output/dense/Add\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.4/output/dense/Add_output_0 for ONNX tensor: /bert/encoder/layer.4/output/dense/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/output/dense/Add [Add] outputs: [/bert/encoder/layer.4/output/dense/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.4/output/Add [Add]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.4/output/dense/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/output/LayerNorm/Add_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/output/Add [Add] inputs: [/bert/encoder/layer.4/output/dense/Add_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.4/attention/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.4/output/Add for ONNX node: /bert/encoder/layer.4/output/Add\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.4/output/Add_output_0 for ONNX tensor: /bert/encoder/layer.4/output/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/output/Add [Add] outputs: [/bert/encoder/layer.4/output/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.4/output/LayerNorm/ReduceMean [ReduceMean]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.4/output/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/output/LayerNorm/ReduceMean [ReduceMean] inputs: [/bert/encoder/layer.4/output/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.4/output/LayerNorm/ReduceMean for ONNX node: /bert/encoder/layer.4/output/LayerNorm/ReduceMean\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.4/output/LayerNorm/ReduceMean_output_0 for ONNX tensor: /bert/encoder/layer.4/output/LayerNorm/ReduceMean_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/output/LayerNorm/ReduceMean [ReduceMean] outputs: [/bert/encoder/layer.4/output/LayerNorm/ReduceMean_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.4/output/LayerNorm/Sub [Sub]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.4/output/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.4/output/LayerNorm/ReduceMean_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/output/LayerNorm/Sub [Sub] inputs: [/bert/encoder/layer.4/output/Add_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.4/output/LayerNorm/ReduceMean_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.4/output/LayerNorm/Sub for ONNX node: /bert/encoder/layer.4/output/LayerNorm/Sub\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.4/output/LayerNorm/Sub_output_0 for ONNX tensor: /bert/encoder/layer.4/output/LayerNorm/Sub_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/output/LayerNorm/Sub [Sub] outputs: [/bert/encoder/layer.4/output/LayerNorm/Sub_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.4/output/LayerNorm/Constant [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/output/LayerNorm/Constant [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/output/LayerNorm/Constant [Constant] outputs: [/bert/encoder/layer.4/output/LayerNorm/Constant_output_0 -> ()[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.4/output/LayerNorm/Pow [Pow]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.4/output/LayerNorm/Sub_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.4/output/LayerNorm/Constant_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/output/LayerNorm/Pow [Pow] inputs: [/bert/encoder/layer.4/output/LayerNorm/Sub_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.4/output/LayerNorm/Constant_output_0 -> ()[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.4/output/LayerNorm/Constant_output_0 for ONNX node: /bert/encoder/layer.4/output/LayerNorm/Constant_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.4/output/LayerNorm/Pow for ONNX node: /bert/encoder/layer.4/output/LayerNorm/Pow\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.4/output/LayerNorm/Pow_output_0 for ONNX tensor: /bert/encoder/layer.4/output/LayerNorm/Pow_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/output/LayerNorm/Pow [Pow] outputs: [/bert/encoder/layer.4/output/LayerNorm/Pow_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.4/output/LayerNorm/ReduceMean_1 [ReduceMean]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.4/output/LayerNorm/Pow_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/output/LayerNorm/ReduceMean_1 [ReduceMean] inputs: [/bert/encoder/layer.4/output/LayerNorm/Pow_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.4/output/LayerNorm/ReduceMean_1 for ONNX node: /bert/encoder/layer.4/output/LayerNorm/ReduceMean_1\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.4/output/LayerNorm/ReduceMean_1_output_0 for ONNX tensor: /bert/encoder/layer.4/output/LayerNorm/ReduceMean_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/output/LayerNorm/ReduceMean_1 [ReduceMean] outputs: [/bert/encoder/layer.4/output/LayerNorm/ReduceMean_1_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.4/output/LayerNorm/Constant_1 [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/output/LayerNorm/Constant_1 [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/output/LayerNorm/Constant_1 [Constant] outputs: [/bert/encoder/layer.4/output/LayerNorm/Constant_1_output_0 -> ()[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.4/output/LayerNorm/Add [Add]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.4/output/LayerNorm/ReduceMean_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.4/output/LayerNorm/Constant_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/output/LayerNorm/Add [Add] inputs: [/bert/encoder/layer.4/output/LayerNorm/ReduceMean_1_output_0 -> (-1, -1, 1)[FLOAT]], [/bert/encoder/layer.4/output/LayerNorm/Constant_1_output_0 -> ()[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.4/output/LayerNorm/Constant_1_output_0 for ONNX node: /bert/encoder/layer.4/output/LayerNorm/Constant_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.4/output/LayerNorm/Add for ONNX node: /bert/encoder/layer.4/output/LayerNorm/Add\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.4/output/LayerNorm/Add_output_0 for ONNX tensor: /bert/encoder/layer.4/output/LayerNorm/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/output/LayerNorm/Add [Add] outputs: [/bert/encoder/layer.4/output/LayerNorm/Add_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.4/output/LayerNorm/Sqrt [Sqrt]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.4/output/LayerNorm/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/output/LayerNorm/Sqrt [Sqrt] inputs: [/bert/encoder/layer.4/output/LayerNorm/Add_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.4/output/LayerNorm/Sqrt for ONNX node: /bert/encoder/layer.4/output/LayerNorm/Sqrt\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.4/output/LayerNorm/Sqrt_output_0 for ONNX tensor: /bert/encoder/layer.4/output/LayerNorm/Sqrt_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/output/LayerNorm/Sqrt [Sqrt] outputs: [/bert/encoder/layer.4/output/LayerNorm/Sqrt_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.4/output/LayerNorm/Div [Div]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.4/output/LayerNorm/Sub_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.4/output/LayerNorm/Sqrt_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/output/LayerNorm/Div [Div] inputs: [/bert/encoder/layer.4/output/LayerNorm/Sub_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.4/output/LayerNorm/Sqrt_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.4/output/LayerNorm/Div for ONNX node: /bert/encoder/layer.4/output/LayerNorm/Div\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.4/output/LayerNorm/Div_output_0 for ONNX tensor: /bert/encoder/layer.4/output/LayerNorm/Div_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/output/LayerNorm/Div [Div] outputs: [/bert/encoder/layer.4/output/LayerNorm/Div_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.4/output/LayerNorm/Mul [Mul]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.4/output/LayerNorm/Div_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: bert.encoder.layer.4.output.LayerNorm.weight\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/output/LayerNorm/Mul [Mul] inputs: [/bert/encoder/layer.4/output/LayerNorm/Div_output_0 -> (-1, -1, 256)[FLOAT]], [bert.encoder.layer.4.output.LayerNorm.weight -> (256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: bert.encoder.layer.4.output.LayerNorm.weight for ONNX node: bert.encoder.layer.4.output.LayerNorm.weight\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.4/output/LayerNorm/Mul for ONNX node: /bert/encoder/layer.4/output/LayerNorm/Mul\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.4/output/LayerNorm/Mul_output_0 for ONNX tensor: /bert/encoder/layer.4/output/LayerNorm/Mul_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/output/LayerNorm/Mul [Mul] outputs: [/bert/encoder/layer.4/output/LayerNorm/Mul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.4/output/LayerNorm/Add_1 [Add]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.4/output/LayerNorm/Mul_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: bert.encoder.layer.4.output.LayerNorm.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/output/LayerNorm/Add_1 [Add] inputs: [/bert/encoder/layer.4/output/LayerNorm/Mul_output_0 -> (-1, -1, 256)[FLOAT]], [bert.encoder.layer.4.output.LayerNorm.bias -> (256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: bert.encoder.layer.4.output.LayerNorm.bias for ONNX node: bert.encoder.layer.4.output.LayerNorm.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.4/output/LayerNorm/Add_1 for ONNX node: /bert/encoder/layer.4/output/LayerNorm/Add_1\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.4/output/LayerNorm/Add_1_output_0 for ONNX tensor: /bert/encoder/layer.4/output/LayerNorm/Add_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.4/output/LayerNorm/Add_1 [Add] outputs: [/bert/encoder/layer.4/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/query/MatMul [MatMul]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.4/output/LayerNorm/Add_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: onnx::MatMul_858\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/self/query/MatMul [MatMul] inputs: [/bert/encoder/layer.4/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], [onnx::MatMul_858 -> (256, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: onnx::MatMul_858 for ONNX node: onnx::MatMul_858\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/query/MatMul for ONNX node: /bert/encoder/layer.5/attention/self/query/MatMul\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/query/MatMul_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/query/MatMul_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/self/query/MatMul [MatMul] outputs: [/bert/encoder/layer.5/attention/self/query/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/query/Add [Add]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: bert.encoder.layer.5.attention.self.query.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/query/MatMul_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/self/query/Add [Add] inputs: [bert.encoder.layer.5.attention.self.query.bias -> (256)[FLOAT]], [/bert/encoder/layer.5/attention/self/query/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: bert.encoder.layer.5.attention.self.query.bias for ONNX node: bert.encoder.layer.5.attention.self.query.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/query/Add for ONNX node: /bert/encoder/layer.5/attention/self/query/Add\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/query/Add_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/query/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/self/query/Add [Add] outputs: [/bert/encoder/layer.5/attention/self/query/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/key/MatMul [MatMul]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.4/output/LayerNorm/Add_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: onnx::MatMul_859\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/self/key/MatMul [MatMul] inputs: [/bert/encoder/layer.4/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], [onnx::MatMul_859 -> (256, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: onnx::MatMul_859 for ONNX node: onnx::MatMul_859\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/key/MatMul for ONNX node: /bert/encoder/layer.5/attention/self/key/MatMul\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/key/MatMul_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/key/MatMul_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/self/key/MatMul [MatMul] outputs: [/bert/encoder/layer.5/attention/self/key/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/key/Add [Add]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: bert.encoder.layer.5.attention.self.key.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/key/MatMul_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/self/key/Add [Add] inputs: [bert.encoder.layer.5.attention.self.key.bias -> (256)[FLOAT]], [/bert/encoder/layer.5/attention/self/key/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: bert.encoder.layer.5.attention.self.key.bias for ONNX node: bert.encoder.layer.5.attention.self.key.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/key/Add for ONNX node: /bert/encoder/layer.5/attention/self/key/Add\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/key/Add_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/key/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/self/key/Add [Add] outputs: [/bert/encoder/layer.5/attention/self/key/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Shape [Shape]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/key/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/self/Shape [Shape] inputs: [/bert/encoder/layer.5/attention/self/key/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Shape for ONNX node: /bert/encoder/layer.5/attention/self/Shape\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/Shape_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/Shape_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/self/Shape [Shape] outputs: [/bert/encoder/layer.5/attention/self/Shape_output_0 -> (3)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Constant [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/self/Constant [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/self/Constant [Constant] outputs: [/bert/encoder/layer.5/attention/self/Constant_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Gather [Gather]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Shape_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Constant_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/self/Gather [Gather] inputs: [/bert/encoder/layer.5/attention/self/Shape_output_0 -> (3)[INT32]], [/bert/encoder/layer.5/attention/self/Constant_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Constant_output_0 for ONNX node: /bert/encoder/layer.5/attention/self/Constant_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Using Gather axis: 0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Gather for ONNX node: /bert/encoder/layer.5/attention/self/Gather\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/Gather_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/Gather_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/self/Gather [Gather] outputs: [/bert/encoder/layer.5/attention/self/Gather_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Shape_1 [Shape]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/key/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/self/Shape_1 [Shape] inputs: [/bert/encoder/layer.5/attention/self/key/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Shape_1 for ONNX node: /bert/encoder/layer.5/attention/self/Shape_1\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/Shape_1_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/Shape_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/self/Shape_1 [Shape] outputs: [/bert/encoder/layer.5/attention/self/Shape_1_output_0 -> (3)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Constant_1 [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/self/Constant_1 [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/self/Constant_1 [Constant] outputs: [/bert/encoder/layer.5/attention/self/Constant_1_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Gather_1 [Gather]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Shape_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Constant_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/self/Gather_1 [Gather] inputs: [/bert/encoder/layer.5/attention/self/Shape_1_output_0 -> (3)[INT32]], [/bert/encoder/layer.5/attention/self/Constant_1_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Constant_1_output_0 for ONNX node: /bert/encoder/layer.5/attention/self/Constant_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Using Gather axis: 0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Gather_1 for ONNX node: /bert/encoder/layer.5/attention/self/Gather_1\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/Gather_1_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/Gather_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/self/Gather_1 [Gather] outputs: [/bert/encoder/layer.5/attention/self/Gather_1_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Unsqueeze [Unsqueeze]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Gather_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/self/Unsqueeze [Unsqueeze] inputs: [/bert/encoder/layer.5/attention/self/Gather_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Unsqueeze for ONNX node: /bert/encoder/layer.5/attention/self/Unsqueeze\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/Unsqueeze_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/Unsqueeze_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/self/Unsqueeze [Unsqueeze] outputs: [/bert/encoder/layer.5/attention/self/Unsqueeze_output_0 -> (1)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Unsqueeze_1 [Unsqueeze]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Gather_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/self/Unsqueeze_1 [Unsqueeze] inputs: [/bert/encoder/layer.5/attention/self/Gather_1_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Unsqueeze_1 for ONNX node: /bert/encoder/layer.5/attention/self/Unsqueeze_1\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/Unsqueeze_1_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/Unsqueeze_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/self/Unsqueeze_1 [Unsqueeze] outputs: [/bert/encoder/layer.5/attention/self/Unsqueeze_1_output_0 -> (1)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Constant_2 [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/self/Constant_2 [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/self/Constant_2 [Constant] outputs: [/bert/encoder/layer.5/attention/self/Constant_2_output_0 -> (1)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Constant_3 [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/self/Constant_3 [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/self/Constant_3 [Constant] outputs: [/bert/encoder/layer.5/attention/self/Constant_3_output_0 -> (1)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Concat [Concat]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Unsqueeze_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Unsqueeze_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Constant_2_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Constant_3_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/self/Concat [Concat] inputs: [/bert/encoder/layer.5/attention/self/Unsqueeze_output_0 -> (1)[INT32]], [/bert/encoder/layer.5/attention/self/Unsqueeze_1_output_0 -> (1)[INT32]], [/bert/encoder/layer.5/attention/self/Constant_2_output_0 -> (1)[INT32]], [/bert/encoder/layer.5/attention/self/Constant_3_output_0 -> (1)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Constant_2_output_0 for ONNX node: /bert/encoder/layer.5/attention/self/Constant_2_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Constant_3_output_0 for ONNX node: /bert/encoder/layer.5/attention/self/Constant_3_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Concat for ONNX node: /bert/encoder/layer.5/attention/self/Concat\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/Concat_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/Concat_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/self/Concat [Concat] outputs: [/bert/encoder/layer.5/attention/self/Concat_output_0 -> (4)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Reshape [Reshape]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/key/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Concat_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/self/Reshape [Reshape] inputs: [/bert/encoder/layer.5/attention/self/key/Add_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.5/attention/self/Concat_output_0 -> (4)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Reshape for ONNX node: /bert/encoder/layer.5/attention/self/Reshape\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/Reshape_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/Reshape_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/self/Reshape [Reshape] outputs: [/bert/encoder/layer.5/attention/self/Reshape_output_0 -> (-1, -1, 8, 32)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/value/MatMul [MatMul]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.4/output/LayerNorm/Add_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: onnx::MatMul_862\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/self/value/MatMul [MatMul] inputs: [/bert/encoder/layer.4/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], [onnx::MatMul_862 -> (256, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: onnx::MatMul_862 for ONNX node: onnx::MatMul_862\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/value/MatMul for ONNX node: /bert/encoder/layer.5/attention/self/value/MatMul\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/value/MatMul_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/value/MatMul_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/self/value/MatMul [MatMul] outputs: [/bert/encoder/layer.5/attention/self/value/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/value/Add [Add]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: bert.encoder.layer.5.attention.self.value.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/value/MatMul_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/self/value/Add [Add] inputs: [bert.encoder.layer.5.attention.self.value.bias -> (256)[FLOAT]], [/bert/encoder/layer.5/attention/self/value/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: bert.encoder.layer.5.attention.self.value.bias for ONNX node: bert.encoder.layer.5.attention.self.value.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/value/Add for ONNX node: /bert/encoder/layer.5/attention/self/value/Add\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/value/Add_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/value/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/self/value/Add [Add] outputs: [/bert/encoder/layer.5/attention/self/value/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Shape_2 [Shape]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/value/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/self/Shape_2 [Shape] inputs: [/bert/encoder/layer.5/attention/self/value/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Shape_2 for ONNX node: /bert/encoder/layer.5/attention/self/Shape_2\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/Shape_2_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/Shape_2_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/self/Shape_2 [Shape] outputs: [/bert/encoder/layer.5/attention/self/Shape_2_output_0 -> (3)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Constant_4 [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/self/Constant_4 [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/self/Constant_4 [Constant] outputs: [/bert/encoder/layer.5/attention/self/Constant_4_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Gather_2 [Gather]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Shape_2_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Constant_4_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/self/Gather_2 [Gather] inputs: [/bert/encoder/layer.5/attention/self/Shape_2_output_0 -> (3)[INT32]], [/bert/encoder/layer.5/attention/self/Constant_4_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Constant_4_output_0 for ONNX node: /bert/encoder/layer.5/attention/self/Constant_4_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Using Gather axis: 0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Gather_2 for ONNX node: /bert/encoder/layer.5/attention/self/Gather_2\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/Gather_2_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/Gather_2_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/self/Gather_2 [Gather] outputs: [/bert/encoder/layer.5/attention/self/Gather_2_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Shape_3 [Shape]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/value/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/self/Shape_3 [Shape] inputs: [/bert/encoder/layer.5/attention/self/value/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Shape_3 for ONNX node: /bert/encoder/layer.5/attention/self/Shape_3\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/Shape_3_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/Shape_3_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/self/Shape_3 [Shape] outputs: [/bert/encoder/layer.5/attention/self/Shape_3_output_0 -> (3)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Constant_5 [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/self/Constant_5 [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/self/Constant_5 [Constant] outputs: [/bert/encoder/layer.5/attention/self/Constant_5_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Gather_3 [Gather]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Shape_3_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Constant_5_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/self/Gather_3 [Gather] inputs: [/bert/encoder/layer.5/attention/self/Shape_3_output_0 -> (3)[INT32]], [/bert/encoder/layer.5/attention/self/Constant_5_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Constant_5_output_0 for ONNX node: /bert/encoder/layer.5/attention/self/Constant_5_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Using Gather axis: 0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Gather_3 for ONNX node: /bert/encoder/layer.5/attention/self/Gather_3\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/Gather_3_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/Gather_3_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/self/Gather_3 [Gather] outputs: [/bert/encoder/layer.5/attention/self/Gather_3_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Unsqueeze_2 [Unsqueeze]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Gather_2_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/self/Unsqueeze_2 [Unsqueeze] inputs: [/bert/encoder/layer.5/attention/self/Gather_2_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Unsqueeze_2 for ONNX node: /bert/encoder/layer.5/attention/self/Unsqueeze_2\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/Unsqueeze_2_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/Unsqueeze_2_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/self/Unsqueeze_2 [Unsqueeze] outputs: [/bert/encoder/layer.5/attention/self/Unsqueeze_2_output_0 -> (1)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Unsqueeze_3 [Unsqueeze]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Gather_3_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/self/Unsqueeze_3 [Unsqueeze] inputs: [/bert/encoder/layer.5/attention/self/Gather_3_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Unsqueeze_3 for ONNX node: /bert/encoder/layer.5/attention/self/Unsqueeze_3\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/Unsqueeze_3_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/Unsqueeze_3_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/self/Unsqueeze_3 [Unsqueeze] outputs: [/bert/encoder/layer.5/attention/self/Unsqueeze_3_output_0 -> (1)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Constant_6 [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/self/Constant_6 [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/self/Constant_6 [Constant] outputs: [/bert/encoder/layer.5/attention/self/Constant_6_output_0 -> (1)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Constant_7 [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/self/Constant_7 [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/self/Constant_7 [Constant] outputs: [/bert/encoder/layer.5/attention/self/Constant_7_output_0 -> (1)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Concat_1 [Concat]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Unsqueeze_2_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Unsqueeze_3_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Constant_6_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Constant_7_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/self/Concat_1 [Concat] inputs: [/bert/encoder/layer.5/attention/self/Unsqueeze_2_output_0 -> (1)[INT32]], [/bert/encoder/layer.5/attention/self/Unsqueeze_3_output_0 -> (1)[INT32]], [/bert/encoder/layer.5/attention/self/Constant_6_output_0 -> (1)[INT32]], [/bert/encoder/layer.5/attention/self/Constant_7_output_0 -> (1)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Constant_6_output_0 for ONNX node: /bert/encoder/layer.5/attention/self/Constant_6_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Constant_7_output_0 for ONNX node: /bert/encoder/layer.5/attention/self/Constant_7_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Concat_1 for ONNX node: /bert/encoder/layer.5/attention/self/Concat_1\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/Concat_1_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/Concat_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/self/Concat_1 [Concat] outputs: [/bert/encoder/layer.5/attention/self/Concat_1_output_0 -> (4)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Reshape_1 [Reshape]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/value/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Concat_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/self/Reshape_1 [Reshape] inputs: [/bert/encoder/layer.5/attention/self/value/Add_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.5/attention/self/Concat_1_output_0 -> (4)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Reshape_1 for ONNX node: /bert/encoder/layer.5/attention/self/Reshape_1\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/Reshape_1_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/Reshape_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/self/Reshape_1 [Reshape] outputs: [/bert/encoder/layer.5/attention/self/Reshape_1_output_0 -> (-1, -1, 8, 32)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Transpose [Transpose]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Reshape_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/self/Transpose [Transpose] inputs: [/bert/encoder/layer.5/attention/self/Reshape_1_output_0 -> (-1, -1, 8, 32)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Transpose for ONNX node: /bert/encoder/layer.5/attention/self/Transpose\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/Transpose_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/Transpose_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/self/Transpose [Transpose] outputs: [/bert/encoder/layer.5/attention/self/Transpose_output_0 -> (-1, 8, -1, 32)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Shape_4 [Shape]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/query/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/self/Shape_4 [Shape] inputs: [/bert/encoder/layer.5/attention/self/query/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Shape_4 for ONNX node: /bert/encoder/layer.5/attention/self/Shape_4\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/Shape_4_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/Shape_4_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/self/Shape_4 [Shape] outputs: [/bert/encoder/layer.5/attention/self/Shape_4_output_0 -> (3)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Constant_8 [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/self/Constant_8 [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/self/Constant_8 [Constant] outputs: [/bert/encoder/layer.5/attention/self/Constant_8_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Gather_4 [Gather]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Shape_4_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Constant_8_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/self/Gather_4 [Gather] inputs: [/bert/encoder/layer.5/attention/self/Shape_4_output_0 -> (3)[INT32]], [/bert/encoder/layer.5/attention/self/Constant_8_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Constant_8_output_0 for ONNX node: /bert/encoder/layer.5/attention/self/Constant_8_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Using Gather axis: 0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Gather_4 for ONNX node: /bert/encoder/layer.5/attention/self/Gather_4\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/Gather_4_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/Gather_4_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/self/Gather_4 [Gather] outputs: [/bert/encoder/layer.5/attention/self/Gather_4_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Shape_5 [Shape]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/query/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/self/Shape_5 [Shape] inputs: [/bert/encoder/layer.5/attention/self/query/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Shape_5 for ONNX node: /bert/encoder/layer.5/attention/self/Shape_5\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/Shape_5_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/Shape_5_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/self/Shape_5 [Shape] outputs: [/bert/encoder/layer.5/attention/self/Shape_5_output_0 -> (3)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Constant_9 [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/self/Constant_9 [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/self/Constant_9 [Constant] outputs: [/bert/encoder/layer.5/attention/self/Constant_9_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Gather_5 [Gather]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Shape_5_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Constant_9_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/self/Gather_5 [Gather] inputs: [/bert/encoder/layer.5/attention/self/Shape_5_output_0 -> (3)[INT32]], [/bert/encoder/layer.5/attention/self/Constant_9_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Constant_9_output_0 for ONNX node: /bert/encoder/layer.5/attention/self/Constant_9_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Using Gather axis: 0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Gather_5 for ONNX node: /bert/encoder/layer.5/attention/self/Gather_5\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/Gather_5_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/Gather_5_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/self/Gather_5 [Gather] outputs: [/bert/encoder/layer.5/attention/self/Gather_5_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Unsqueeze_4 [Unsqueeze]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Gather_4_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/self/Unsqueeze_4 [Unsqueeze] inputs: [/bert/encoder/layer.5/attention/self/Gather_4_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Unsqueeze_4 for ONNX node: /bert/encoder/layer.5/attention/self/Unsqueeze_4\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/Unsqueeze_4_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/Unsqueeze_4_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/self/Unsqueeze_4 [Unsqueeze] outputs: [/bert/encoder/layer.5/attention/self/Unsqueeze_4_output_0 -> (1)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Unsqueeze_5 [Unsqueeze]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Gather_5_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/self/Unsqueeze_5 [Unsqueeze] inputs: [/bert/encoder/layer.5/attention/self/Gather_5_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Unsqueeze_5 for ONNX node: /bert/encoder/layer.5/attention/self/Unsqueeze_5\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/Unsqueeze_5_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/Unsqueeze_5_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/self/Unsqueeze_5 [Unsqueeze] outputs: [/bert/encoder/layer.5/attention/self/Unsqueeze_5_output_0 -> (1)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Constant_10 [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/self/Constant_10 [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/self/Constant_10 [Constant] outputs: [/bert/encoder/layer.5/attention/self/Constant_10_output_0 -> (1)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Constant_11 [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/self/Constant_11 [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/self/Constant_11 [Constant] outputs: [/bert/encoder/layer.5/attention/self/Constant_11_output_0 -> (1)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Concat_2 [Concat]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Unsqueeze_4_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Unsqueeze_5_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Constant_10_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Constant_11_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/self/Concat_2 [Concat] inputs: [/bert/encoder/layer.5/attention/self/Unsqueeze_4_output_0 -> (1)[INT32]], [/bert/encoder/layer.5/attention/self/Unsqueeze_5_output_0 -> (1)[INT32]], [/bert/encoder/layer.5/attention/self/Constant_10_output_0 -> (1)[INT32]], [/bert/encoder/layer.5/attention/self/Constant_11_output_0 -> (1)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Constant_10_output_0 for ONNX node: /bert/encoder/layer.5/attention/self/Constant_10_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Constant_11_output_0 for ONNX node: /bert/encoder/layer.5/attention/self/Constant_11_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Concat_2 for ONNX node: /bert/encoder/layer.5/attention/self/Concat_2\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/Concat_2_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/Concat_2_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/self/Concat_2 [Concat] outputs: [/bert/encoder/layer.5/attention/self/Concat_2_output_0 -> (4)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Reshape_2 [Reshape]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/query/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Concat_2_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/self/Reshape_2 [Reshape] inputs: [/bert/encoder/layer.5/attention/self/query/Add_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.5/attention/self/Concat_2_output_0 -> (4)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Reshape_2 for ONNX node: /bert/encoder/layer.5/attention/self/Reshape_2\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/Reshape_2_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/Reshape_2_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/self/Reshape_2 [Reshape] outputs: [/bert/encoder/layer.5/attention/self/Reshape_2_output_0 -> (-1, -1, 8, 32)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Transpose_1 [Transpose]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Reshape_2_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/self/Transpose_1 [Transpose] inputs: [/bert/encoder/layer.5/attention/self/Reshape_2_output_0 -> (-1, -1, 8, 32)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Transpose_1 for ONNX node: /bert/encoder/layer.5/attention/self/Transpose_1\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/Transpose_1_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/Transpose_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/self/Transpose_1 [Transpose] outputs: [/bert/encoder/layer.5/attention/self/Transpose_1_output_0 -> (-1, 8, -1, 32)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Transpose_2 [Transpose]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Reshape_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/self/Transpose_2 [Transpose] inputs: [/bert/encoder/layer.5/attention/self/Reshape_output_0 -> (-1, -1, 8, 32)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Transpose_2 for ONNX node: /bert/encoder/layer.5/attention/self/Transpose_2\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/Transpose_2_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/Transpose_2_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/self/Transpose_2 [Transpose] outputs: [/bert/encoder/layer.5/attention/self/Transpose_2_output_0 -> (-1, 8, 32, -1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/MatMul [MatMul]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Transpose_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Transpose_2_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/self/MatMul [MatMul] inputs: [/bert/encoder/layer.5/attention/self/Transpose_1_output_0 -> (-1, 8, -1, 32)[FLOAT]], [/bert/encoder/layer.5/attention/self/Transpose_2_output_0 -> (-1, 8, 32, -1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/MatMul for ONNX node: /bert/encoder/layer.5/attention/self/MatMul\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/MatMul_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/MatMul_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/self/MatMul [MatMul] outputs: [/bert/encoder/layer.5/attention/self/MatMul_output_0 -> (-1, 8, -1, -1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Constant_12 [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/self/Constant_12 [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/self/Constant_12 [Constant] outputs: [/bert/encoder/layer.5/attention/self/Constant_12_output_0 -> ()[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Div [Div]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/MatMul_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Constant_12_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/self/Div [Div] inputs: [/bert/encoder/layer.5/attention/self/MatMul_output_0 -> (-1, 8, -1, -1)[FLOAT]], [/bert/encoder/layer.5/attention/self/Constant_12_output_0 -> ()[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Constant_12_output_0 for ONNX node: /bert/encoder/layer.5/attention/self/Constant_12_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Div for ONNX node: /bert/encoder/layer.5/attention/self/Div\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/Div_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/Div_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/self/Div [Div] outputs: [/bert/encoder/layer.5/attention/self/Div_output_0 -> (-1, 8, -1, -1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Add [Add]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Div_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/Mul_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/self/Add [Add] inputs: [/bert/encoder/layer.5/attention/self/Div_output_0 -> (-1, 8, -1, -1)[FLOAT]], [/bert/Mul_output_0 -> (-1, 1, 1, -1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Add for ONNX node: /bert/encoder/layer.5/attention/self/Add\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/Add_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/self/Add [Add] outputs: [/bert/encoder/layer.5/attention/self/Add_output_0 -> (-1, 8, -1, -1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Softmax [Softmax]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/self/Softmax [Softmax] inputs: [/bert/encoder/layer.5/attention/self/Add_output_0 -> (-1, 8, -1, -1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Softmax for ONNX node: /bert/encoder/layer.5/attention/self/Softmax\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/Softmax_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/Softmax_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/self/Softmax [Softmax] outputs: [/bert/encoder/layer.5/attention/self/Softmax_output_0 -> (-1, 8, -1, -1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/MatMul_1 [MatMul]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Softmax_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Transpose_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/self/MatMul_1 [MatMul] inputs: [/bert/encoder/layer.5/attention/self/Softmax_output_0 -> (-1, 8, -1, -1)[FLOAT]], [/bert/encoder/layer.5/attention/self/Transpose_output_0 -> (-1, 8, -1, 32)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/MatMul_1 for ONNX node: /bert/encoder/layer.5/attention/self/MatMul_1\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/MatMul_1_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/MatMul_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/self/MatMul_1 [MatMul] outputs: [/bert/encoder/layer.5/attention/self/MatMul_1_output_0 -> (-1, 8, -1, 32)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Transpose_3 [Transpose]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/MatMul_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/self/Transpose_3 [Transpose] inputs: [/bert/encoder/layer.5/attention/self/MatMul_1_output_0 -> (-1, 8, -1, 32)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Transpose_3 for ONNX node: /bert/encoder/layer.5/attention/self/Transpose_3\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/Transpose_3_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/Transpose_3_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/self/Transpose_3 [Transpose] outputs: [/bert/encoder/layer.5/attention/self/Transpose_3_output_0 -> (-1, -1, 8, 32)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Shape_6 [Shape]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Transpose_3_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/self/Shape_6 [Shape] inputs: [/bert/encoder/layer.5/attention/self/Transpose_3_output_0 -> (-1, -1, 8, 32)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Shape_6 for ONNX node: /bert/encoder/layer.5/attention/self/Shape_6\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/Shape_6_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/Shape_6_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/self/Shape_6 [Shape] outputs: [/bert/encoder/layer.5/attention/self/Shape_6_output_0 -> (4)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Constant_13 [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/self/Constant_13 [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/self/Constant_13 [Constant] outputs: [/bert/encoder/layer.5/attention/self/Constant_13_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Gather_6 [Gather]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Shape_6_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Constant_13_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/self/Gather_6 [Gather] inputs: [/bert/encoder/layer.5/attention/self/Shape_6_output_0 -> (4)[INT32]], [/bert/encoder/layer.5/attention/self/Constant_13_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Constant_13_output_0 for ONNX node: /bert/encoder/layer.5/attention/self/Constant_13_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Using Gather axis: 0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Gather_6 for ONNX node: /bert/encoder/layer.5/attention/self/Gather_6\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/Gather_6_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/Gather_6_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/self/Gather_6 [Gather] outputs: [/bert/encoder/layer.5/attention/self/Gather_6_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Shape_7 [Shape]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Transpose_3_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/self/Shape_7 [Shape] inputs: [/bert/encoder/layer.5/attention/self/Transpose_3_output_0 -> (-1, -1, 8, 32)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Shape_7 for ONNX node: /bert/encoder/layer.5/attention/self/Shape_7\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/Shape_7_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/Shape_7_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/self/Shape_7 [Shape] outputs: [/bert/encoder/layer.5/attention/self/Shape_7_output_0 -> (4)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Constant_14 [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/self/Constant_14 [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/self/Constant_14 [Constant] outputs: [/bert/encoder/layer.5/attention/self/Constant_14_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Gather_7 [Gather]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Shape_7_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Constant_14_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/self/Gather_7 [Gather] inputs: [/bert/encoder/layer.5/attention/self/Shape_7_output_0 -> (4)[INT32]], [/bert/encoder/layer.5/attention/self/Constant_14_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Constant_14_output_0 for ONNX node: /bert/encoder/layer.5/attention/self/Constant_14_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Using Gather axis: 0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Gather_7 for ONNX node: /bert/encoder/layer.5/attention/self/Gather_7\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/Gather_7_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/Gather_7_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/self/Gather_7 [Gather] outputs: [/bert/encoder/layer.5/attention/self/Gather_7_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Unsqueeze_6 [Unsqueeze]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Gather_6_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/self/Unsqueeze_6 [Unsqueeze] inputs: [/bert/encoder/layer.5/attention/self/Gather_6_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Unsqueeze_6 for ONNX node: /bert/encoder/layer.5/attention/self/Unsqueeze_6\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/Unsqueeze_6_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/Unsqueeze_6_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/self/Unsqueeze_6 [Unsqueeze] outputs: [/bert/encoder/layer.5/attention/self/Unsqueeze_6_output_0 -> (1)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Unsqueeze_7 [Unsqueeze]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Gather_7_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/self/Unsqueeze_7 [Unsqueeze] inputs: [/bert/encoder/layer.5/attention/self/Gather_7_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Unsqueeze_7 for ONNX node: /bert/encoder/layer.5/attention/self/Unsqueeze_7\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/Unsqueeze_7_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/Unsqueeze_7_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/self/Unsqueeze_7 [Unsqueeze] outputs: [/bert/encoder/layer.5/attention/self/Unsqueeze_7_output_0 -> (1)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Constant_15 [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/self/Constant_15 [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/self/Constant_15 [Constant] outputs: [/bert/encoder/layer.5/attention/self/Constant_15_output_0 -> (1)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Concat_3 [Concat]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Unsqueeze_6_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Unsqueeze_7_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Constant_15_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/self/Concat_3 [Concat] inputs: [/bert/encoder/layer.5/attention/self/Unsqueeze_6_output_0 -> (1)[INT32]], [/bert/encoder/layer.5/attention/self/Unsqueeze_7_output_0 -> (1)[INT32]], [/bert/encoder/layer.5/attention/self/Constant_15_output_0 -> (1)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Constant_15_output_0 for ONNX node: /bert/encoder/layer.5/attention/self/Constant_15_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Concat_3 for ONNX node: /bert/encoder/layer.5/attention/self/Concat_3\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/Concat_3_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/Concat_3_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/self/Concat_3 [Concat] outputs: [/bert/encoder/layer.5/attention/self/Concat_3_output_0 -> (3)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Reshape_3 [Reshape]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Transpose_3_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Concat_3_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/self/Reshape_3 [Reshape] inputs: [/bert/encoder/layer.5/attention/self/Transpose_3_output_0 -> (-1, -1, 8, 32)[FLOAT]], [/bert/encoder/layer.5/attention/self/Concat_3_output_0 -> (3)[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Reshape_3 for ONNX node: /bert/encoder/layer.5/attention/self/Reshape_3\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/Reshape_3_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/Reshape_3_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/self/Reshape_3 [Reshape] outputs: [/bert/encoder/layer.5/attention/self/Reshape_3_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/output/dense/MatMul [MatMul]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Reshape_3_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: onnx::MatMul_868\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/output/dense/MatMul [MatMul] inputs: [/bert/encoder/layer.5/attention/self/Reshape_3_output_0 -> (-1, -1, 256)[FLOAT]], [onnx::MatMul_868 -> (256, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: onnx::MatMul_868 for ONNX node: onnx::MatMul_868\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/output/dense/MatMul for ONNX node: /bert/encoder/layer.5/attention/output/dense/MatMul\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/output/dense/MatMul_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/output/dense/MatMul_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/output/dense/MatMul [MatMul] outputs: [/bert/encoder/layer.5/attention/output/dense/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/output/dense/Add [Add]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: bert.encoder.layer.5.attention.output.dense.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/output/dense/MatMul_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/output/dense/Add [Add] inputs: [bert.encoder.layer.5.attention.output.dense.bias -> (256)[FLOAT]], [/bert/encoder/layer.5/attention/output/dense/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: bert.encoder.layer.5.attention.output.dense.bias for ONNX node: bert.encoder.layer.5.attention.output.dense.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/output/dense/Add for ONNX node: /bert/encoder/layer.5/attention/output/dense/Add\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/output/dense/Add_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/output/dense/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/output/dense/Add [Add] outputs: [/bert/encoder/layer.5/attention/output/dense/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/output/Add [Add]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/output/dense/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.4/output/LayerNorm/Add_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/output/Add [Add] inputs: [/bert/encoder/layer.5/attention/output/dense/Add_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.4/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/output/Add for ONNX node: /bert/encoder/layer.5/attention/output/Add\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/output/Add_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/output/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/output/Add [Add] outputs: [/bert/encoder/layer.5/attention/output/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/output/LayerNorm/ReduceMean [ReduceMean]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/output/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/output/LayerNorm/ReduceMean [ReduceMean] inputs: [/bert/encoder/layer.5/attention/output/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/output/LayerNorm/ReduceMean for ONNX node: /bert/encoder/layer.5/attention/output/LayerNorm/ReduceMean\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/output/LayerNorm/ReduceMean_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/output/LayerNorm/ReduceMean_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/output/LayerNorm/ReduceMean [ReduceMean] outputs: [/bert/encoder/layer.5/attention/output/LayerNorm/ReduceMean_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/output/LayerNorm/Sub [Sub]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/output/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/output/LayerNorm/ReduceMean_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/output/LayerNorm/Sub [Sub] inputs: [/bert/encoder/layer.5/attention/output/Add_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.5/attention/output/LayerNorm/ReduceMean_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/output/LayerNorm/Sub for ONNX node: /bert/encoder/layer.5/attention/output/LayerNorm/Sub\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/output/LayerNorm/Sub_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/output/LayerNorm/Sub_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/output/LayerNorm/Sub [Sub] outputs: [/bert/encoder/layer.5/attention/output/LayerNorm/Sub_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/output/LayerNorm/Constant [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/output/LayerNorm/Constant [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/output/LayerNorm/Constant [Constant] outputs: [/bert/encoder/layer.5/attention/output/LayerNorm/Constant_output_0 -> ()[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/output/LayerNorm/Pow [Pow]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/output/LayerNorm/Sub_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/output/LayerNorm/Constant_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/output/LayerNorm/Pow [Pow] inputs: [/bert/encoder/layer.5/attention/output/LayerNorm/Sub_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.5/attention/output/LayerNorm/Constant_output_0 -> ()[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/output/LayerNorm/Constant_output_0 for ONNX node: /bert/encoder/layer.5/attention/output/LayerNorm/Constant_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/output/LayerNorm/Pow for ONNX node: /bert/encoder/layer.5/attention/output/LayerNorm/Pow\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/output/LayerNorm/Pow_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/output/LayerNorm/Pow_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/output/LayerNorm/Pow [Pow] outputs: [/bert/encoder/layer.5/attention/output/LayerNorm/Pow_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/output/LayerNorm/ReduceMean_1 [ReduceMean]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/output/LayerNorm/Pow_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/output/LayerNorm/ReduceMean_1 [ReduceMean] inputs: [/bert/encoder/layer.5/attention/output/LayerNorm/Pow_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/output/LayerNorm/ReduceMean_1 for ONNX node: /bert/encoder/layer.5/attention/output/LayerNorm/ReduceMean_1\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/output/LayerNorm/ReduceMean_1_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/output/LayerNorm/ReduceMean_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/output/LayerNorm/ReduceMean_1 [ReduceMean] outputs: [/bert/encoder/layer.5/attention/output/LayerNorm/ReduceMean_1_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/output/LayerNorm/Constant_1 [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/output/LayerNorm/Constant_1 [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/output/LayerNorm/Constant_1 [Constant] outputs: [/bert/encoder/layer.5/attention/output/LayerNorm/Constant_1_output_0 -> ()[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/output/LayerNorm/Add [Add]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/output/LayerNorm/ReduceMean_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/output/LayerNorm/Constant_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/output/LayerNorm/Add [Add] inputs: [/bert/encoder/layer.5/attention/output/LayerNorm/ReduceMean_1_output_0 -> (-1, -1, 1)[FLOAT]], [/bert/encoder/layer.5/attention/output/LayerNorm/Constant_1_output_0 -> ()[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/output/LayerNorm/Constant_1_output_0 for ONNX node: /bert/encoder/layer.5/attention/output/LayerNorm/Constant_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/output/LayerNorm/Add for ONNX node: /bert/encoder/layer.5/attention/output/LayerNorm/Add\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/output/LayerNorm/Add_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/output/LayerNorm/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/output/LayerNorm/Add [Add] outputs: [/bert/encoder/layer.5/attention/output/LayerNorm/Add_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/output/LayerNorm/Sqrt [Sqrt]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/output/LayerNorm/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/output/LayerNorm/Sqrt [Sqrt] inputs: [/bert/encoder/layer.5/attention/output/LayerNorm/Add_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/output/LayerNorm/Sqrt for ONNX node: /bert/encoder/layer.5/attention/output/LayerNorm/Sqrt\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/output/LayerNorm/Sqrt_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/output/LayerNorm/Sqrt_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/output/LayerNorm/Sqrt [Sqrt] outputs: [/bert/encoder/layer.5/attention/output/LayerNorm/Sqrt_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/output/LayerNorm/Div [Div]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/output/LayerNorm/Sub_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/output/LayerNorm/Sqrt_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/output/LayerNorm/Div [Div] inputs: [/bert/encoder/layer.5/attention/output/LayerNorm/Sub_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.5/attention/output/LayerNorm/Sqrt_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/output/LayerNorm/Div for ONNX node: /bert/encoder/layer.5/attention/output/LayerNorm/Div\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/output/LayerNorm/Div_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/output/LayerNorm/Div_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/output/LayerNorm/Div [Div] outputs: [/bert/encoder/layer.5/attention/output/LayerNorm/Div_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/output/LayerNorm/Mul [Mul]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/output/LayerNorm/Div_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: bert.encoder.layer.5.attention.output.LayerNorm.weight\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/output/LayerNorm/Mul [Mul] inputs: [/bert/encoder/layer.5/attention/output/LayerNorm/Div_output_0 -> (-1, -1, 256)[FLOAT]], [bert.encoder.layer.5.attention.output.LayerNorm.weight -> (256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: bert.encoder.layer.5.attention.output.LayerNorm.weight for ONNX node: bert.encoder.layer.5.attention.output.LayerNorm.weight\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/output/LayerNorm/Mul for ONNX node: /bert/encoder/layer.5/attention/output/LayerNorm/Mul\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/output/LayerNorm/Mul_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/output/LayerNorm/Mul_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/output/LayerNorm/Mul [Mul] outputs: [/bert/encoder/layer.5/attention/output/LayerNorm/Mul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/output/LayerNorm/Add_1 [Add]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/output/LayerNorm/Mul_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: bert.encoder.layer.5.attention.output.LayerNorm.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/output/LayerNorm/Add_1 [Add] inputs: [/bert/encoder/layer.5/attention/output/LayerNorm/Mul_output_0 -> (-1, -1, 256)[FLOAT]], [bert.encoder.layer.5.attention.output.LayerNorm.bias -> (256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: bert.encoder.layer.5.attention.output.LayerNorm.bias for ONNX node: bert.encoder.layer.5.attention.output.LayerNorm.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/output/LayerNorm/Add_1 for ONNX node: /bert/encoder/layer.5/attention/output/LayerNorm/Add_1\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/output/LayerNorm/Add_1_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/output/LayerNorm/Add_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/attention/output/LayerNorm/Add_1 [Add] outputs: [/bert/encoder/layer.5/attention/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.5/intermediate/dense/MatMul [MatMul]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/output/LayerNorm/Add_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: onnx::MatMul_869\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/intermediate/dense/MatMul [MatMul] inputs: [/bert/encoder/layer.5/attention/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], [onnx::MatMul_869 -> (256, 1024)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: onnx::MatMul_869 for ONNX node: onnx::MatMul_869\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.5/intermediate/dense/MatMul for ONNX node: /bert/encoder/layer.5/intermediate/dense/MatMul\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.5/intermediate/dense/MatMul_output_0 for ONNX tensor: /bert/encoder/layer.5/intermediate/dense/MatMul_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/intermediate/dense/MatMul [MatMul] outputs: [/bert/encoder/layer.5/intermediate/dense/MatMul_output_0 -> (-1, -1, 1024)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.5/intermediate/dense/Add [Add]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: bert.encoder.layer.5.intermediate.dense.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.5/intermediate/dense/MatMul_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/intermediate/dense/Add [Add] inputs: [bert.encoder.layer.5.intermediate.dense.bias -> (1024)[FLOAT]], [/bert/encoder/layer.5/intermediate/dense/MatMul_output_0 -> (-1, -1, 1024)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: bert.encoder.layer.5.intermediate.dense.bias for ONNX node: bert.encoder.layer.5.intermediate.dense.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.5/intermediate/dense/Add for ONNX node: /bert/encoder/layer.5/intermediate/dense/Add\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.5/intermediate/dense/Add_output_0 for ONNX tensor: /bert/encoder/layer.5/intermediate/dense/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/intermediate/dense/Add [Add] outputs: [/bert/encoder/layer.5/intermediate/dense/Add_output_0 -> (-1, -1, 1024)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.5/intermediate/intermediate_act_fn/Constant [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/intermediate/intermediate_act_fn/Constant [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/intermediate/intermediate_act_fn/Constant [Constant] outputs: [/bert/encoder/layer.5/intermediate/intermediate_act_fn/Constant_output_0 -> ()[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.5/intermediate/intermediate_act_fn/Div [Div]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.5/intermediate/dense/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.5/intermediate/intermediate_act_fn/Constant_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/intermediate/intermediate_act_fn/Div [Div] inputs: [/bert/encoder/layer.5/intermediate/dense/Add_output_0 -> (-1, -1, 1024)[FLOAT]], [/bert/encoder/layer.5/intermediate/intermediate_act_fn/Constant_output_0 -> ()[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.5/intermediate/intermediate_act_fn/Constant_output_0 for ONNX node: /bert/encoder/layer.5/intermediate/intermediate_act_fn/Constant_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.5/intermediate/intermediate_act_fn/Div for ONNX node: /bert/encoder/layer.5/intermediate/intermediate_act_fn/Div\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.5/intermediate/intermediate_act_fn/Div_output_0 for ONNX tensor: /bert/encoder/layer.5/intermediate/intermediate_act_fn/Div_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/intermediate/intermediate_act_fn/Div [Div] outputs: [/bert/encoder/layer.5/intermediate/intermediate_act_fn/Div_output_0 -> (-1, -1, 1024)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.5/intermediate/intermediate_act_fn/Erf [Erf]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.5/intermediate/intermediate_act_fn/Div_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/intermediate/intermediate_act_fn/Erf [Erf] inputs: [/bert/encoder/layer.5/intermediate/intermediate_act_fn/Div_output_0 -> (-1, -1, 1024)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.5/intermediate/intermediate_act_fn/Erf for ONNX node: /bert/encoder/layer.5/intermediate/intermediate_act_fn/Erf\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.5/intermediate/intermediate_act_fn/Erf_output_0 for ONNX tensor: /bert/encoder/layer.5/intermediate/intermediate_act_fn/Erf_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/intermediate/intermediate_act_fn/Erf [Erf] outputs: [/bert/encoder/layer.5/intermediate/intermediate_act_fn/Erf_output_0 -> (-1, -1, 1024)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.5/intermediate/intermediate_act_fn/Constant_1 [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/intermediate/intermediate_act_fn/Constant_1 [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/intermediate/intermediate_act_fn/Constant_1 [Constant] outputs: [/bert/encoder/layer.5/intermediate/intermediate_act_fn/Constant_1_output_0 -> ()[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.5/intermediate/intermediate_act_fn/Add [Add]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.5/intermediate/intermediate_act_fn/Erf_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.5/intermediate/intermediate_act_fn/Constant_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/intermediate/intermediate_act_fn/Add [Add] inputs: [/bert/encoder/layer.5/intermediate/intermediate_act_fn/Erf_output_0 -> (-1, -1, 1024)[FLOAT]], [/bert/encoder/layer.5/intermediate/intermediate_act_fn/Constant_1_output_0 -> ()[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.5/intermediate/intermediate_act_fn/Constant_1_output_0 for ONNX node: /bert/encoder/layer.5/intermediate/intermediate_act_fn/Constant_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.5/intermediate/intermediate_act_fn/Add for ONNX node: /bert/encoder/layer.5/intermediate/intermediate_act_fn/Add\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.5/intermediate/intermediate_act_fn/Add_output_0 for ONNX tensor: /bert/encoder/layer.5/intermediate/intermediate_act_fn/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/intermediate/intermediate_act_fn/Add [Add] outputs: [/bert/encoder/layer.5/intermediate/intermediate_act_fn/Add_output_0 -> (-1, -1, 1024)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.5/intermediate/intermediate_act_fn/Mul [Mul]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.5/intermediate/dense/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.5/intermediate/intermediate_act_fn/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/intermediate/intermediate_act_fn/Mul [Mul] inputs: [/bert/encoder/layer.5/intermediate/dense/Add_output_0 -> (-1, -1, 1024)[FLOAT]], [/bert/encoder/layer.5/intermediate/intermediate_act_fn/Add_output_0 -> (-1, -1, 1024)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.5/intermediate/intermediate_act_fn/Mul for ONNX node: /bert/encoder/layer.5/intermediate/intermediate_act_fn/Mul\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.5/intermediate/intermediate_act_fn/Mul_output_0 for ONNX tensor: /bert/encoder/layer.5/intermediate/intermediate_act_fn/Mul_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/intermediate/intermediate_act_fn/Mul [Mul] outputs: [/bert/encoder/layer.5/intermediate/intermediate_act_fn/Mul_output_0 -> (-1, -1, 1024)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.5/intermediate/intermediate_act_fn/Constant_2 [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/intermediate/intermediate_act_fn/Constant_2 [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/intermediate/intermediate_act_fn/Constant_2 [Constant] outputs: [/bert/encoder/layer.5/intermediate/intermediate_act_fn/Constant_2_output_0 -> ()[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.5/intermediate/intermediate_act_fn/Mul_1 [Mul]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.5/intermediate/intermediate_act_fn/Mul_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.5/intermediate/intermediate_act_fn/Constant_2_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/intermediate/intermediate_act_fn/Mul_1 [Mul] inputs: [/bert/encoder/layer.5/intermediate/intermediate_act_fn/Mul_output_0 -> (-1, -1, 1024)[FLOAT]], [/bert/encoder/layer.5/intermediate/intermediate_act_fn/Constant_2_output_0 -> ()[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.5/intermediate/intermediate_act_fn/Constant_2_output_0 for ONNX node: /bert/encoder/layer.5/intermediate/intermediate_act_fn/Constant_2_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.5/intermediate/intermediate_act_fn/Mul_1 for ONNX node: /bert/encoder/layer.5/intermediate/intermediate_act_fn/Mul_1\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.5/intermediate/intermediate_act_fn/Mul_1_output_0 for ONNX tensor: /bert/encoder/layer.5/intermediate/intermediate_act_fn/Mul_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/intermediate/intermediate_act_fn/Mul_1 [Mul] outputs: [/bert/encoder/layer.5/intermediate/intermediate_act_fn/Mul_1_output_0 -> (-1, -1, 1024)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.5/output/dense/MatMul [MatMul]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.5/intermediate/intermediate_act_fn/Mul_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: onnx::MatMul_870\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/output/dense/MatMul [MatMul] inputs: [/bert/encoder/layer.5/intermediate/intermediate_act_fn/Mul_1_output_0 -> (-1, -1, 1024)[FLOAT]], [onnx::MatMul_870 -> (1024, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: onnx::MatMul_870 for ONNX node: onnx::MatMul_870\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.5/output/dense/MatMul for ONNX node: /bert/encoder/layer.5/output/dense/MatMul\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.5/output/dense/MatMul_output_0 for ONNX tensor: /bert/encoder/layer.5/output/dense/MatMul_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/output/dense/MatMul [MatMul] outputs: [/bert/encoder/layer.5/output/dense/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.5/output/dense/Add [Add]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: bert.encoder.layer.5.output.dense.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.5/output/dense/MatMul_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/output/dense/Add [Add] inputs: [bert.encoder.layer.5.output.dense.bias -> (256)[FLOAT]], [/bert/encoder/layer.5/output/dense/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: bert.encoder.layer.5.output.dense.bias for ONNX node: bert.encoder.layer.5.output.dense.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.5/output/dense/Add for ONNX node: /bert/encoder/layer.5/output/dense/Add\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.5/output/dense/Add_output_0 for ONNX tensor: /bert/encoder/layer.5/output/dense/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/output/dense/Add [Add] outputs: [/bert/encoder/layer.5/output/dense/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.5/output/Add [Add]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.5/output/dense/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/output/LayerNorm/Add_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/output/Add [Add] inputs: [/bert/encoder/layer.5/output/dense/Add_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.5/attention/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.5/output/Add for ONNX node: /bert/encoder/layer.5/output/Add\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.5/output/Add_output_0 for ONNX tensor: /bert/encoder/layer.5/output/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/output/Add [Add] outputs: [/bert/encoder/layer.5/output/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.5/output/LayerNorm/ReduceMean [ReduceMean]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.5/output/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/output/LayerNorm/ReduceMean [ReduceMean] inputs: [/bert/encoder/layer.5/output/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.5/output/LayerNorm/ReduceMean for ONNX node: /bert/encoder/layer.5/output/LayerNorm/ReduceMean\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.5/output/LayerNorm/ReduceMean_output_0 for ONNX tensor: /bert/encoder/layer.5/output/LayerNorm/ReduceMean_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/output/LayerNorm/ReduceMean [ReduceMean] outputs: [/bert/encoder/layer.5/output/LayerNorm/ReduceMean_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.5/output/LayerNorm/Sub [Sub]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.5/output/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.5/output/LayerNorm/ReduceMean_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/output/LayerNorm/Sub [Sub] inputs: [/bert/encoder/layer.5/output/Add_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.5/output/LayerNorm/ReduceMean_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.5/output/LayerNorm/Sub for ONNX node: /bert/encoder/layer.5/output/LayerNorm/Sub\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.5/output/LayerNorm/Sub_output_0 for ONNX tensor: /bert/encoder/layer.5/output/LayerNorm/Sub_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/output/LayerNorm/Sub [Sub] outputs: [/bert/encoder/layer.5/output/LayerNorm/Sub_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.5/output/LayerNorm/Constant [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/output/LayerNorm/Constant [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/output/LayerNorm/Constant [Constant] outputs: [/bert/encoder/layer.5/output/LayerNorm/Constant_output_0 -> ()[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.5/output/LayerNorm/Pow [Pow]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.5/output/LayerNorm/Sub_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.5/output/LayerNorm/Constant_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/output/LayerNorm/Pow [Pow] inputs: [/bert/encoder/layer.5/output/LayerNorm/Sub_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.5/output/LayerNorm/Constant_output_0 -> ()[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.5/output/LayerNorm/Constant_output_0 for ONNX node: /bert/encoder/layer.5/output/LayerNorm/Constant_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.5/output/LayerNorm/Pow for ONNX node: /bert/encoder/layer.5/output/LayerNorm/Pow\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.5/output/LayerNorm/Pow_output_0 for ONNX tensor: /bert/encoder/layer.5/output/LayerNorm/Pow_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/output/LayerNorm/Pow [Pow] outputs: [/bert/encoder/layer.5/output/LayerNorm/Pow_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.5/output/LayerNorm/ReduceMean_1 [ReduceMean]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.5/output/LayerNorm/Pow_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/output/LayerNorm/ReduceMean_1 [ReduceMean] inputs: [/bert/encoder/layer.5/output/LayerNorm/Pow_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.5/output/LayerNorm/ReduceMean_1 for ONNX node: /bert/encoder/layer.5/output/LayerNorm/ReduceMean_1\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.5/output/LayerNorm/ReduceMean_1_output_0 for ONNX tensor: /bert/encoder/layer.5/output/LayerNorm/ReduceMean_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/output/LayerNorm/ReduceMean_1 [ReduceMean] outputs: [/bert/encoder/layer.5/output/LayerNorm/ReduceMean_1_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.5/output/LayerNorm/Constant_1 [Constant]\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/output/LayerNorm/Constant_1 [Constant] inputs: \n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/output/LayerNorm/Constant_1 [Constant] outputs: [/bert/encoder/layer.5/output/LayerNorm/Constant_1_output_0 -> ()[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.5/output/LayerNorm/Add [Add]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.5/output/LayerNorm/ReduceMean_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.5/output/LayerNorm/Constant_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/output/LayerNorm/Add [Add] inputs: [/bert/encoder/layer.5/output/LayerNorm/ReduceMean_1_output_0 -> (-1, -1, 1)[FLOAT]], [/bert/encoder/layer.5/output/LayerNorm/Constant_1_output_0 -> ()[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.5/output/LayerNorm/Constant_1_output_0 for ONNX node: /bert/encoder/layer.5/output/LayerNorm/Constant_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.5/output/LayerNorm/Add for ONNX node: /bert/encoder/layer.5/output/LayerNorm/Add\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.5/output/LayerNorm/Add_output_0 for ONNX tensor: /bert/encoder/layer.5/output/LayerNorm/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/output/LayerNorm/Add [Add] outputs: [/bert/encoder/layer.5/output/LayerNorm/Add_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.5/output/LayerNorm/Sqrt [Sqrt]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.5/output/LayerNorm/Add_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/output/LayerNorm/Sqrt [Sqrt] inputs: [/bert/encoder/layer.5/output/LayerNorm/Add_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.5/output/LayerNorm/Sqrt for ONNX node: /bert/encoder/layer.5/output/LayerNorm/Sqrt\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.5/output/LayerNorm/Sqrt_output_0 for ONNX tensor: /bert/encoder/layer.5/output/LayerNorm/Sqrt_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/output/LayerNorm/Sqrt [Sqrt] outputs: [/bert/encoder/layer.5/output/LayerNorm/Sqrt_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.5/output/LayerNorm/Div [Div]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.5/output/LayerNorm/Sub_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.5/output/LayerNorm/Sqrt_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/output/LayerNorm/Div [Div] inputs: [/bert/encoder/layer.5/output/LayerNorm/Sub_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.5/output/LayerNorm/Sqrt_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.5/output/LayerNorm/Div for ONNX node: /bert/encoder/layer.5/output/LayerNorm/Div\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.5/output/LayerNorm/Div_output_0 for ONNX tensor: /bert/encoder/layer.5/output/LayerNorm/Div_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/output/LayerNorm/Div [Div] outputs: [/bert/encoder/layer.5/output/LayerNorm/Div_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.5/output/LayerNorm/Mul [Mul]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.5/output/LayerNorm/Div_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: bert.encoder.layer.5.output.LayerNorm.weight\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/output/LayerNorm/Mul [Mul] inputs: [/bert/encoder/layer.5/output/LayerNorm/Div_output_0 -> (-1, -1, 256)[FLOAT]], [bert.encoder.layer.5.output.LayerNorm.weight -> (256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: bert.encoder.layer.5.output.LayerNorm.weight for ONNX node: bert.encoder.layer.5.output.LayerNorm.weight\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.5/output/LayerNorm/Mul for ONNX node: /bert/encoder/layer.5/output/LayerNorm/Mul\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.5/output/LayerNorm/Mul_output_0 for ONNX tensor: /bert/encoder/layer.5/output/LayerNorm/Mul_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/output/LayerNorm/Mul [Mul] outputs: [/bert/encoder/layer.5/output/LayerNorm/Mul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/encoder/layer.5/output/LayerNorm/Add_1 [Add]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.5/output/LayerNorm/Mul_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: bert.encoder.layer.5.output.LayerNorm.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/output/LayerNorm/Add_1 [Add] inputs: [/bert/encoder/layer.5/output/LayerNorm/Mul_output_0 -> (-1, -1, 256)[FLOAT]], [bert.encoder.layer.5.output.LayerNorm.bias -> (256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: bert.encoder.layer.5.output.LayerNorm.bias for ONNX node: bert.encoder.layer.5.output.LayerNorm.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/encoder/layer.5/output/LayerNorm/Add_1 for ONNX node: /bert/encoder/layer.5/output/LayerNorm/Add_1\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/encoder/layer.5/output/LayerNorm/Add_1_output_0 for ONNX tensor: /bert/encoder/layer.5/output/LayerNorm/Add_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/encoder/layer.5/output/LayerNorm/Add_1 [Add] outputs: [/bert/encoder/layer.5/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/pooler/Gather [Gather]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/encoder/layer.5/output/LayerNorm/Add_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/Constant_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/pooler/Gather [Gather] inputs: [/bert/encoder/layer.5/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/Constant_output_0 -> ()[INT32]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/Constant_output_0 for ONNX node: /bert/Constant_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Using Gather axis: 1\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/pooler/Gather for ONNX node: /bert/pooler/Gather\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/pooler/Gather_output_0 for ONNX tensor: /bert/pooler/Gather_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/pooler/Gather [Gather] outputs: [/bert/pooler/Gather_output_0 -> (-1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/pooler/dense/Gemm [Gemm]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/pooler/Gather_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: bert.pooler.dense.weight\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: bert.pooler.dense.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/pooler/dense/Gemm [Gemm] inputs: [/bert/pooler/Gather_output_0 -> (-1, 256)[FLOAT]], [bert.pooler.dense.weight -> (256, 256)[FLOAT]], [bert.pooler.dense.bias -> (256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: bert.pooler.dense.weight for ONNX node: bert.pooler.dense.weight\n",
      "[01/20/2023-00:15:59] [V] [TRT] Using opA: 0 opB: 1\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/pooler/dense/Gemm for ONNX node: /bert/pooler/dense/Gemm\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: bert.pooler.dense.bias for ONNX node: bert.pooler.dense.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/pooler/dense/Gemm_output_0 for ONNX tensor: /bert/pooler/dense/Gemm_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/pooler/dense/Gemm [Gemm] outputs: [/bert/pooler/dense/Gemm_output_0 -> (-1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /bert/pooler/activation/Tanh [Tanh]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/pooler/dense/Gemm_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/pooler/activation/Tanh [Tanh] inputs: [/bert/pooler/dense/Gemm_output_0 -> (-1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /bert/pooler/activation/Tanh for ONNX node: /bert/pooler/activation/Tanh\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: /bert/pooler/activation/Tanh_output_0 for ONNX tensor: /bert/pooler/activation/Tanh_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] /bert/pooler/activation/Tanh [Tanh] outputs: [/bert/pooler/activation/Tanh_output_0 -> (-1, 256)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Parsing node: /classifier/Gemm [Gemm]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: /bert/pooler/activation/Tanh_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: classifier.weight\n",
      "[01/20/2023-00:15:59] [V] [TRT] Searching for input: classifier.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] /classifier/Gemm [Gemm] inputs: [/bert/pooler/activation/Tanh_output_0 -> (-1, 256)[FLOAT]], [classifier.weight -> (6, 256)[FLOAT]], [classifier.bias -> (6)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: classifier.weight for ONNX node: classifier.weight\n",
      "[01/20/2023-00:15:59] [V] [TRT] Using opA: 0 opB: 1\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: /classifier/Gemm for ONNX node: /classifier/Gemm\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering layer: classifier.bias for ONNX node: classifier.bias\n",
      "[01/20/2023-00:15:59] [V] [TRT] Registering tensor: logits_129 for ONNX tensor: logits\n",
      "[01/20/2023-00:15:59] [V] [TRT] /classifier/Gemm [Gemm] outputs: [logits -> (-1, 6)[FLOAT]], \n",
      "[01/20/2023-00:15:59] [V] [TRT] Marking logits_129 as output: logits\n",
      "[01/20/2023-00:15:59] [I] Finish parsing network model\n",
      "[01/20/2023-00:15:59] [V] [TRT] Original: 649 layers\n",
      "[01/20/2023-00:15:59] [V] [TRT] After dead-layer removal: 649 layers\n",
      "[01/20/2023-00:15:59] [V] [TRT] Applying generic optimizations to the graph for inference.\n",
      "[01/20/2023-00:15:59] [V] [TRT] Running: ConstShuffleFusion on /bert/Constant_1_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] ConstShuffleFusion: Fusing /bert/Constant_1_output_0 with (Unnamed Layer* 14) [Shuffle]\n",
      "[01/20/2023-00:15:59] [V] [TRT] Running: ConstShuffleFusion on /bert/Constant_2_output_0\n",
      "[01/20/2023-00:15:59] [V] [TRT] ConstShuffleFusion: Fusing /bert/Constant_2_output_0 with (Unnamed Layer* 17) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on /bert/embeddings/LayerNorm/Constant_output_0\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing /bert/embeddings/LayerNorm/Constant_output_0 with (Unnamed Layer* 51) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on /bert/embeddings/LayerNorm/Constant_1_output_0\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing /bert/embeddings/LayerNorm/Constant_1_output_0 with (Unnamed Layer* 55) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on bert.embeddings.LayerNorm.weight\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing bert.embeddings.LayerNorm.weight with (Unnamed Layer* 60) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on bert.embeddings.LayerNorm.bias\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing bert.embeddings.LayerNorm.bias with (Unnamed Layer* 63) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on onnx::MatMul_793\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing onnx::MatMul_793 with (Unnamed Layer* 66) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.0.attention.self.query.bias\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.0.attention.self.query.bias with (Unnamed Layer* 69) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on onnx::MatMul_794\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing onnx::MatMul_794 with (Unnamed Layer* 72) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.0.attention.self.key.bias\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.0.attention.self.key.bias with (Unnamed Layer* 75) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on onnx::MatMul_797\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing onnx::MatMul_797 with (Unnamed Layer* 90) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.0.attention.self.value.bias\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.0.attention.self.value.bias with (Unnamed Layer* 93) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.0/attention/self/Constant_12_output_0\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.0/attention/self/Constant_12_output_0 with (Unnamed Layer* 124) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on onnx::MatMul_803\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing onnx::MatMul_803 with (Unnamed Layer* 156) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.0.attention.output.dense.bias\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.0.attention.output.dense.bias with (Unnamed Layer* 159) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.0/attention/output/LayerNorm/Constant_output_0\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.0/attention/output/LayerNorm/Constant_output_0 with (Unnamed Layer* 165) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.0/attention/output/LayerNorm/Constant_1_output_0\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.0/attention/output/LayerNorm/Constant_1_output_0 with (Unnamed Layer* 169) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.0.attention.output.LayerNorm.weight\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.0.attention.output.LayerNorm.weight with (Unnamed Layer* 174) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.0.attention.output.LayerNorm.bias\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.0.attention.output.LayerNorm.bias with (Unnamed Layer* 177) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on onnx::MatMul_804\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing onnx::MatMul_804 with (Unnamed Layer* 180) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.0.intermediate.dense.bias\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.0.intermediate.dense.bias with (Unnamed Layer* 183) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.0/intermediate/intermediate_act_fn/Constant_output_0\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.0/intermediate/intermediate_act_fn/Constant_output_0 with (Unnamed Layer* 186) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.0/intermediate/intermediate_act_fn/Constant_1_output_0\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.0/intermediate/intermediate_act_fn/Constant_1_output_0 with (Unnamed Layer* 190) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.0/intermediate/intermediate_act_fn/Constant_2_output_0\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.0/intermediate/intermediate_act_fn/Constant_2_output_0 with (Unnamed Layer* 194) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on onnx::MatMul_805\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing onnx::MatMul_805 with (Unnamed Layer* 197) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.0.output.dense.bias\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.0.output.dense.bias with (Unnamed Layer* 200) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.0/output/LayerNorm/Constant_output_0\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.0/output/LayerNorm/Constant_output_0 with (Unnamed Layer* 206) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.0/output/LayerNorm/Constant_1_output_0\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.0/output/LayerNorm/Constant_1_output_0 with (Unnamed Layer* 210) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.0.output.LayerNorm.weight\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.0.output.LayerNorm.weight with (Unnamed Layer* 215) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.0.output.LayerNorm.bias\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.0.output.LayerNorm.bias with (Unnamed Layer* 218) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on onnx::MatMul_806\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing onnx::MatMul_806 with (Unnamed Layer* 221) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.1.attention.self.query.bias\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.1.attention.self.query.bias with (Unnamed Layer* 224) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on onnx::MatMul_807\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing onnx::MatMul_807 with (Unnamed Layer* 227) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.1.attention.self.key.bias\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.1.attention.self.key.bias with (Unnamed Layer* 230) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on onnx::MatMul_810\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing onnx::MatMul_810 with (Unnamed Layer* 245) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.1.attention.self.value.bias\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.1.attention.self.value.bias with (Unnamed Layer* 248) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.1/attention/self/Constant_12_output_0\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.1/attention/self/Constant_12_output_0 with (Unnamed Layer* 279) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on onnx::MatMul_816\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing onnx::MatMul_816 with (Unnamed Layer* 311) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.1.attention.output.dense.bias\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.1.attention.output.dense.bias with (Unnamed Layer* 314) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.1/attention/output/LayerNorm/Constant_output_0\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.1/attention/output/LayerNorm/Constant_output_0 with (Unnamed Layer* 320) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.1/attention/output/LayerNorm/Constant_1_output_0\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.1/attention/output/LayerNorm/Constant_1_output_0 with (Unnamed Layer* 324) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.1.attention.output.LayerNorm.weight\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.1.attention.output.LayerNorm.weight with (Unnamed Layer* 329) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.1.attention.output.LayerNorm.bias\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.1.attention.output.LayerNorm.bias with (Unnamed Layer* 332) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on onnx::MatMul_817\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing onnx::MatMul_817 with (Unnamed Layer* 335) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.1.intermediate.dense.bias\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.1.intermediate.dense.bias with (Unnamed Layer* 338) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.1/intermediate/intermediate_act_fn/Constant_output_0\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.1/intermediate/intermediate_act_fn/Constant_output_0 with (Unnamed Layer* 341) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.1/intermediate/intermediate_act_fn/Constant_1_output_0\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.1/intermediate/intermediate_act_fn/Constant_1_output_0 with (Unnamed Layer* 345) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.1/intermediate/intermediate_act_fn/Constant_2_output_0\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.1/intermediate/intermediate_act_fn/Constant_2_output_0 with (Unnamed Layer* 349) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on onnx::MatMul_818\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing onnx::MatMul_818 with (Unnamed Layer* 352) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.1.output.dense.bias\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.1.output.dense.bias with (Unnamed Layer* 355) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.1/output/LayerNorm/Constant_output_0\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.1/output/LayerNorm/Constant_output_0 with (Unnamed Layer* 361) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.1/output/LayerNorm/Constant_1_output_0\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.1/output/LayerNorm/Constant_1_output_0 with (Unnamed Layer* 365) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.1.output.LayerNorm.weight\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.1.output.LayerNorm.weight with (Unnamed Layer* 370) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.1.output.LayerNorm.bias\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.1.output.LayerNorm.bias with (Unnamed Layer* 373) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on onnx::MatMul_819\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing onnx::MatMul_819 with (Unnamed Layer* 376) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.2.attention.self.query.bias\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.2.attention.self.query.bias with (Unnamed Layer* 379) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on onnx::MatMul_820\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing onnx::MatMul_820 with (Unnamed Layer* 382) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.2.attention.self.key.bias\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.2.attention.self.key.bias with (Unnamed Layer* 385) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on onnx::MatMul_823\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing onnx::MatMul_823 with (Unnamed Layer* 400) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.2.attention.self.value.bias\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.2.attention.self.value.bias with (Unnamed Layer* 403) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.2/attention/self/Constant_12_output_0\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.2/attention/self/Constant_12_output_0 with (Unnamed Layer* 434) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on onnx::MatMul_829\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing onnx::MatMul_829 with (Unnamed Layer* 466) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.2.attention.output.dense.bias\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.2.attention.output.dense.bias with (Unnamed Layer* 469) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.2/attention/output/LayerNorm/Constant_output_0\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.2/attention/output/LayerNorm/Constant_output_0 with (Unnamed Layer* 475) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.2/attention/output/LayerNorm/Constant_1_output_0\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.2/attention/output/LayerNorm/Constant_1_output_0 with (Unnamed Layer* 479) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.2.attention.output.LayerNorm.weight\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.2.attention.output.LayerNorm.weight with (Unnamed Layer* 484) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.2.attention.output.LayerNorm.bias\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.2.attention.output.LayerNorm.bias with (Unnamed Layer* 487) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on onnx::MatMul_830\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing onnx::MatMul_830 with (Unnamed Layer* 490) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.2.intermediate.dense.bias\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.2.intermediate.dense.bias with (Unnamed Layer* 493) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.2/intermediate/intermediate_act_fn/Constant_output_0\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.2/intermediate/intermediate_act_fn/Constant_output_0 with (Unnamed Layer* 496) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.2/intermediate/intermediate_act_fn/Constant_1_output_0\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.2/intermediate/intermediate_act_fn/Constant_1_output_0 with (Unnamed Layer* 500) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.2/intermediate/intermediate_act_fn/Constant_2_output_0\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.2/intermediate/intermediate_act_fn/Constant_2_output_0 with (Unnamed Layer* 504) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on onnx::MatMul_831\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing onnx::MatMul_831 with (Unnamed Layer* 507) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.2.output.dense.bias\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.2.output.dense.bias with (Unnamed Layer* 510) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.2/output/LayerNorm/Constant_output_0\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.2/output/LayerNorm/Constant_output_0 with (Unnamed Layer* 516) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.2/output/LayerNorm/Constant_1_output_0\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.2/output/LayerNorm/Constant_1_output_0 with (Unnamed Layer* 520) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.2.output.LayerNorm.weight\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.2.output.LayerNorm.weight with (Unnamed Layer* 525) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.2.output.LayerNorm.bias\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.2.output.LayerNorm.bias with (Unnamed Layer* 528) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on onnx::MatMul_832\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing onnx::MatMul_832 with (Unnamed Layer* 531) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.3.attention.self.query.bias\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.3.attention.self.query.bias with (Unnamed Layer* 534) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on onnx::MatMul_833\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing onnx::MatMul_833 with (Unnamed Layer* 537) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.3.attention.self.key.bias\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.3.attention.self.key.bias with (Unnamed Layer* 540) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on onnx::MatMul_836\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing onnx::MatMul_836 with (Unnamed Layer* 555) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.3.attention.self.value.bias\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.3.attention.self.value.bias with (Unnamed Layer* 558) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.3/attention/self/Constant_12_output_0\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.3/attention/self/Constant_12_output_0 with (Unnamed Layer* 589) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on onnx::MatMul_842\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing onnx::MatMul_842 with (Unnamed Layer* 621) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.3.attention.output.dense.bias\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.3.attention.output.dense.bias with (Unnamed Layer* 624) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.3/attention/output/LayerNorm/Constant_output_0\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.3/attention/output/LayerNorm/Constant_output_0 with (Unnamed Layer* 630) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.3/attention/output/LayerNorm/Constant_1_output_0\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.3/attention/output/LayerNorm/Constant_1_output_0 with (Unnamed Layer* 634) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.3.attention.output.LayerNorm.weight\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.3.attention.output.LayerNorm.weight with (Unnamed Layer* 639) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.3.attention.output.LayerNorm.bias\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.3.attention.output.LayerNorm.bias with (Unnamed Layer* 642) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on onnx::MatMul_843\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing onnx::MatMul_843 with (Unnamed Layer* 645) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.3.intermediate.dense.bias\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.3.intermediate.dense.bias with (Unnamed Layer* 648) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.3/intermediate/intermediate_act_fn/Constant_output_0\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.3/intermediate/intermediate_act_fn/Constant_output_0 with (Unnamed Layer* 651) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.3/intermediate/intermediate_act_fn/Constant_1_output_0\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.3/intermediate/intermediate_act_fn/Constant_1_output_0 with (Unnamed Layer* 655) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.3/intermediate/intermediate_act_fn/Constant_2_output_0\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.3/intermediate/intermediate_act_fn/Constant_2_output_0 with (Unnamed Layer* 659) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on onnx::MatMul_844\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing onnx::MatMul_844 with (Unnamed Layer* 662) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.3.output.dense.bias\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.3.output.dense.bias with (Unnamed Layer* 665) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.3/output/LayerNorm/Constant_output_0\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.3/output/LayerNorm/Constant_output_0 with (Unnamed Layer* 671) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.3/output/LayerNorm/Constant_1_output_0\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.3/output/LayerNorm/Constant_1_output_0 with (Unnamed Layer* 675) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.3.output.LayerNorm.weight\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.3.output.LayerNorm.weight with (Unnamed Layer* 680) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.3.output.LayerNorm.bias\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.3.output.LayerNorm.bias with (Unnamed Layer* 683) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on onnx::MatMul_845\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing onnx::MatMul_845 with (Unnamed Layer* 686) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.4.attention.self.query.bias\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.4.attention.self.query.bias with (Unnamed Layer* 689) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on onnx::MatMul_846\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing onnx::MatMul_846 with (Unnamed Layer* 692) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.4.attention.self.key.bias\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.4.attention.self.key.bias with (Unnamed Layer* 695) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on onnx::MatMul_849\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing onnx::MatMul_849 with (Unnamed Layer* 710) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.4.attention.self.value.bias\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.4.attention.self.value.bias with (Unnamed Layer* 713) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.4/attention/self/Constant_12_output_0\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.4/attention/self/Constant_12_output_0 with (Unnamed Layer* 744) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on onnx::MatMul_855\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing onnx::MatMul_855 with (Unnamed Layer* 776) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.4.attention.output.dense.bias\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.4.attention.output.dense.bias with (Unnamed Layer* 779) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.4/attention/output/LayerNorm/Constant_output_0\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.4/attention/output/LayerNorm/Constant_output_0 with (Unnamed Layer* 785) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.4/attention/output/LayerNorm/Constant_1_output_0\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.4/attention/output/LayerNorm/Constant_1_output_0 with (Unnamed Layer* 789) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.4.attention.output.LayerNorm.weight\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.4.attention.output.LayerNorm.weight with (Unnamed Layer* 794) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.4.attention.output.LayerNorm.bias\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.4.attention.output.LayerNorm.bias with (Unnamed Layer* 797) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on onnx::MatMul_856\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing onnx::MatMul_856 with (Unnamed Layer* 800) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.4.intermediate.dense.bias\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.4.intermediate.dense.bias with (Unnamed Layer* 803) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.4/intermediate/intermediate_act_fn/Constant_output_0\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.4/intermediate/intermediate_act_fn/Constant_output_0 with (Unnamed Layer* 806) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.4/intermediate/intermediate_act_fn/Constant_1_output_0\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.4/intermediate/intermediate_act_fn/Constant_1_output_0 with (Unnamed Layer* 810) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.4/intermediate/intermediate_act_fn/Constant_2_output_0\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.4/intermediate/intermediate_act_fn/Constant_2_output_0 with (Unnamed Layer* 814) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on onnx::MatMul_857\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing onnx::MatMul_857 with (Unnamed Layer* 817) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.4.output.dense.bias\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.4.output.dense.bias with (Unnamed Layer* 820) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.4/output/LayerNorm/Constant_output_0\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.4/output/LayerNorm/Constant_output_0 with (Unnamed Layer* 826) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.4/output/LayerNorm/Constant_1_output_0\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.4/output/LayerNorm/Constant_1_output_0 with (Unnamed Layer* 830) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.4.output.LayerNorm.weight\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.4.output.LayerNorm.weight with (Unnamed Layer* 835) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.4.output.LayerNorm.bias\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.4.output.LayerNorm.bias with (Unnamed Layer* 838) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on onnx::MatMul_858\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing onnx::MatMul_858 with (Unnamed Layer* 841) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.5.attention.self.query.bias\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.5.attention.self.query.bias with (Unnamed Layer* 844) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on onnx::MatMul_859\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing onnx::MatMul_859 with (Unnamed Layer* 847) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.5.attention.self.key.bias\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.5.attention.self.key.bias with (Unnamed Layer* 850) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on onnx::MatMul_862\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing onnx::MatMul_862 with (Unnamed Layer* 865) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.5.attention.self.value.bias\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.5.attention.self.value.bias with (Unnamed Layer* 868) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.5/attention/self/Constant_12_output_0\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.5/attention/self/Constant_12_output_0 with (Unnamed Layer* 899) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ShuffleShuffleFusion on /bert/Unsqueeze\n",
      "[01/20/2023-00:16:00] [V] [TRT] ShuffleShuffleFusion: Fusing /bert/Unsqueeze with /bert/Unsqueeze_1\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ShuffleShuffleFusion on /bert/encoder/layer.0/attention/self/Reshape_2\n",
      "[01/20/2023-00:16:00] [V] [TRT] ShuffleShuffleFusion: Fusing /bert/encoder/layer.0/attention/self/Reshape_2 with /bert/encoder/layer.0/attention/self/Transpose_1\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ShuffleShuffleFusion on /bert/encoder/layer.0/attention/self/Reshape\n",
      "[01/20/2023-00:16:00] [V] [TRT] ShuffleShuffleFusion: Fusing /bert/encoder/layer.0/attention/self/Reshape with /bert/encoder/layer.0/attention/self/Transpose_2\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ShuffleShuffleFusion on /bert/encoder/layer.0/attention/self/Reshape_1\n",
      "[01/20/2023-00:16:00] [V] [TRT] ShuffleShuffleFusion: Fusing /bert/encoder/layer.0/attention/self/Reshape_1 with /bert/encoder/layer.0/attention/self/Transpose\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ShuffleShuffleFusion on /bert/encoder/layer.0/attention/self/Transpose_3\n",
      "[01/20/2023-00:16:00] [V] [TRT] ShuffleShuffleFusion: Fusing /bert/encoder/layer.0/attention/self/Transpose_3 with /bert/encoder/layer.0/attention/self/Reshape_3\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ShuffleShuffleFusion on /bert/encoder/layer.1/attention/self/Reshape_2\n",
      "[01/20/2023-00:16:00] [V] [TRT] ShuffleShuffleFusion: Fusing /bert/encoder/layer.1/attention/self/Reshape_2 with /bert/encoder/layer.1/attention/self/Transpose_1\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ShuffleShuffleFusion on /bert/encoder/layer.1/attention/self/Reshape\n",
      "[01/20/2023-00:16:00] [V] [TRT] ShuffleShuffleFusion: Fusing /bert/encoder/layer.1/attention/self/Reshape with /bert/encoder/layer.1/attention/self/Transpose_2\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ShuffleShuffleFusion on /bert/encoder/layer.1/attention/self/Reshape_1\n",
      "[01/20/2023-00:16:00] [V] [TRT] ShuffleShuffleFusion: Fusing /bert/encoder/layer.1/attention/self/Reshape_1 with /bert/encoder/layer.1/attention/self/Transpose\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ShuffleShuffleFusion on /bert/encoder/layer.1/attention/self/Transpose_3\n",
      "[01/20/2023-00:16:00] [V] [TRT] ShuffleShuffleFusion: Fusing /bert/encoder/layer.1/attention/self/Transpose_3 with /bert/encoder/layer.1/attention/self/Reshape_3\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ShuffleShuffleFusion on /bert/encoder/layer.2/attention/self/Reshape_2\n",
      "[01/20/2023-00:16:00] [V] [TRT] ShuffleShuffleFusion: Fusing /bert/encoder/layer.2/attention/self/Reshape_2 with /bert/encoder/layer.2/attention/self/Transpose_1\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ShuffleShuffleFusion on /bert/encoder/layer.2/attention/self/Reshape\n",
      "[01/20/2023-00:16:00] [V] [TRT] ShuffleShuffleFusion: Fusing /bert/encoder/layer.2/attention/self/Reshape with /bert/encoder/layer.2/attention/self/Transpose_2\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ShuffleShuffleFusion on /bert/encoder/layer.2/attention/self/Reshape_1\n",
      "[01/20/2023-00:16:00] [V] [TRT] ShuffleShuffleFusion: Fusing /bert/encoder/layer.2/attention/self/Reshape_1 with /bert/encoder/layer.2/attention/self/Transpose\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ShuffleShuffleFusion on /bert/encoder/layer.2/attention/self/Transpose_3\n",
      "[01/20/2023-00:16:00] [V] [TRT] ShuffleShuffleFusion: Fusing /bert/encoder/layer.2/attention/self/Transpose_3 with /bert/encoder/layer.2/attention/self/Reshape_3\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ShuffleShuffleFusion on /bert/encoder/layer.3/attention/self/Reshape_2\n",
      "[01/20/2023-00:16:00] [V] [TRT] ShuffleShuffleFusion: Fusing /bert/encoder/layer.3/attention/self/Reshape_2 with /bert/encoder/layer.3/attention/self/Transpose_1\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ShuffleShuffleFusion on /bert/encoder/layer.3/attention/self/Reshape\n",
      "[01/20/2023-00:16:00] [V] [TRT] ShuffleShuffleFusion: Fusing /bert/encoder/layer.3/attention/self/Reshape with /bert/encoder/layer.3/attention/self/Transpose_2\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ShuffleShuffleFusion on /bert/encoder/layer.3/attention/self/Reshape_1\n",
      "[01/20/2023-00:16:00] [V] [TRT] ShuffleShuffleFusion: Fusing /bert/encoder/layer.3/attention/self/Reshape_1 with /bert/encoder/layer.3/attention/self/Transpose\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ShuffleShuffleFusion on /bert/encoder/layer.3/attention/self/Transpose_3\n",
      "[01/20/2023-00:16:00] [V] [TRT] ShuffleShuffleFusion: Fusing /bert/encoder/layer.3/attention/self/Transpose_3 with /bert/encoder/layer.3/attention/self/Reshape_3\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ShuffleShuffleFusion on /bert/encoder/layer.4/attention/self/Reshape_2\n",
      "[01/20/2023-00:16:00] [V] [TRT] ShuffleShuffleFusion: Fusing /bert/encoder/layer.4/attention/self/Reshape_2 with /bert/encoder/layer.4/attention/self/Transpose_1\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ShuffleShuffleFusion on /bert/encoder/layer.4/attention/self/Reshape\n",
      "[01/20/2023-00:16:00] [V] [TRT] ShuffleShuffleFusion: Fusing /bert/encoder/layer.4/attention/self/Reshape with /bert/encoder/layer.4/attention/self/Transpose_2\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ShuffleShuffleFusion on /bert/encoder/layer.4/attention/self/Reshape_1\n",
      "[01/20/2023-00:16:00] [V] [TRT] ShuffleShuffleFusion: Fusing /bert/encoder/layer.4/attention/self/Reshape_1 with /bert/encoder/layer.4/attention/self/Transpose\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ShuffleShuffleFusion on /bert/encoder/layer.4/attention/self/Transpose_3\n",
      "[01/20/2023-00:16:00] [V] [TRT] ShuffleShuffleFusion: Fusing /bert/encoder/layer.4/attention/self/Transpose_3 with /bert/encoder/layer.4/attention/self/Reshape_3\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ShuffleShuffleFusion on /bert/encoder/layer.5/attention/self/Reshape_2\n",
      "[01/20/2023-00:16:00] [V] [TRT] ShuffleShuffleFusion: Fusing /bert/encoder/layer.5/attention/self/Reshape_2 with /bert/encoder/layer.5/attention/self/Transpose_1\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ShuffleShuffleFusion on /bert/encoder/layer.5/attention/self/Reshape\n",
      "[01/20/2023-00:16:00] [V] [TRT] ShuffleShuffleFusion: Fusing /bert/encoder/layer.5/attention/self/Reshape with /bert/encoder/layer.5/attention/self/Transpose_2\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ShuffleShuffleFusion on /bert/encoder/layer.5/attention/self/Reshape_1\n",
      "[01/20/2023-00:16:00] [V] [TRT] ShuffleShuffleFusion: Fusing /bert/encoder/layer.5/attention/self/Reshape_1 with /bert/encoder/layer.5/attention/self/Transpose\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ShuffleShuffleFusion on /bert/encoder/layer.5/attention/self/Transpose_3\n",
      "[01/20/2023-00:16:00] [V] [TRT] ShuffleShuffleFusion: Fusing /bert/encoder/layer.5/attention/self/Transpose_3 with /bert/encoder/layer.5/attention/self/Reshape_3\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on onnx::MatMul_868\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing onnx::MatMul_868 with (Unnamed Layer* 931) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.5.attention.output.dense.bias\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.5.attention.output.dense.bias with (Unnamed Layer* 934) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.5/attention/output/LayerNorm/Constant_output_0\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.5/attention/output/LayerNorm/Constant_output_0 with (Unnamed Layer* 940) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.5/attention/output/LayerNorm/Constant_1_output_0\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.5/attention/output/LayerNorm/Constant_1_output_0 with (Unnamed Layer* 944) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.5.attention.output.LayerNorm.weight\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.5.attention.output.LayerNorm.weight with (Unnamed Layer* 949) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.5.attention.output.LayerNorm.bias\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.5.attention.output.LayerNorm.bias with (Unnamed Layer* 952) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on onnx::MatMul_869\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing onnx::MatMul_869 with (Unnamed Layer* 955) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.5.intermediate.dense.bias\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.5.intermediate.dense.bias with (Unnamed Layer* 958) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.5/intermediate/intermediate_act_fn/Constant_output_0\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.5/intermediate/intermediate_act_fn/Constant_output_0 with (Unnamed Layer* 961) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.5/intermediate/intermediate_act_fn/Constant_1_output_0\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.5/intermediate/intermediate_act_fn/Constant_1_output_0 with (Unnamed Layer* 965) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.5/intermediate/intermediate_act_fn/Constant_2_output_0\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.5/intermediate/intermediate_act_fn/Constant_2_output_0 with (Unnamed Layer* 969) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on onnx::MatMul_870\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing onnx::MatMul_870 with (Unnamed Layer* 972) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.5.output.dense.bias\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.5.output.dense.bias with (Unnamed Layer* 975) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.5/output/LayerNorm/Constant_output_0\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.5/output/LayerNorm/Constant_output_0 with (Unnamed Layer* 981) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.5/output/LayerNorm/Constant_1_output_0\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.5/output/LayerNorm/Constant_1_output_0 with (Unnamed Layer* 985) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.5.output.LayerNorm.weight\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.5.output.LayerNorm.weight with (Unnamed Layer* 990) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.5.output.LayerNorm.bias\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.5.output.LayerNorm.bias with (Unnamed Layer* 993) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on bert.pooler.dense.bias\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing bert.pooler.dense.bias with (Unnamed Layer* 1000) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Running: ConstShuffleFusion on classifier.bias\n",
      "[01/20/2023-00:16:00] [V] [TRT] ConstShuffleFusion: Fusing classifier.bias with (Unnamed Layer* 1006) [Shuffle]\n",
      "[01/20/2023-00:16:00] [V] [TRT] Found /bert/encoder/layer.0/attention/self/query/MatMul to be part of self-attention pattern.\n",
      "[01/20/2023-00:16:00] [V] [TRT] Found /bert/encoder/layer.0/attention/self/key/MatMul to be part of self-attention pattern.\n",
      "[01/20/2023-00:16:00] [V] [TRT] Found /bert/encoder/layer.0/attention/self/value/MatMul to be part of self-attention pattern.\n",
      "[01/20/2023-00:16:00] [V] [TRT] Found /bert/encoder/layer.0/attention/self/MatMul to be part of self-attention pattern.\n",
      "[01/20/2023-00:16:00] [V] [TRT] Found /bert/encoder/layer.0/attention/self/Softmax to be part of self-attention pattern.\n",
      "[01/20/2023-00:16:00] [V] [TRT] Found /bert/encoder/layer.0/attention/self/MatMul_1 to be part of self-attention pattern.\n",
      "[01/20/2023-00:16:00] [V] [TRT] Found /bert/encoder/layer.1/attention/self/query/MatMul to be part of self-attention pattern.\n",
      "[01/20/2023-00:16:00] [V] [TRT] Found /bert/encoder/layer.1/attention/self/key/MatMul to be part of self-attention pattern.\n",
      "[01/20/2023-00:16:00] [V] [TRT] Found /bert/encoder/layer.1/attention/self/value/MatMul to be part of self-attention pattern.\n",
      "[01/20/2023-00:16:00] [V] [TRT] Found /bert/encoder/layer.1/attention/self/MatMul to be part of self-attention pattern.\n",
      "[01/20/2023-00:16:00] [V] [TRT] Found /bert/encoder/layer.1/attention/self/Softmax to be part of self-attention pattern.\n",
      "[01/20/2023-00:16:00] [V] [TRT] Found /bert/encoder/layer.1/attention/self/MatMul_1 to be part of self-attention pattern.\n",
      "[01/20/2023-00:16:00] [V] [TRT] Found /bert/encoder/layer.2/attention/self/query/MatMul to be part of self-attention pattern.\n",
      "[01/20/2023-00:16:00] [V] [TRT] Found /bert/encoder/layer.2/attention/self/key/MatMul to be part of self-attention pattern.\n",
      "[01/20/2023-00:16:00] [V] [TRT] Found /bert/encoder/layer.2/attention/self/value/MatMul to be part of self-attention pattern.\n",
      "[01/20/2023-00:16:00] [V] [TRT] Found /bert/encoder/layer.2/attention/self/MatMul to be part of self-attention pattern.\n",
      "[01/20/2023-00:16:00] [V] [TRT] Found /bert/encoder/layer.2/attention/self/Softmax to be part of self-attention pattern.\n",
      "[01/20/2023-00:16:00] [V] [TRT] Found /bert/encoder/layer.2/attention/self/MatMul_1 to be part of self-attention pattern.\n",
      "[01/20/2023-00:16:00] [V] [TRT] Found /bert/encoder/layer.3/attention/self/query/MatMul to be part of self-attention pattern.\n",
      "[01/20/2023-00:16:00] [V] [TRT] Found /bert/encoder/layer.3/attention/self/key/MatMul to be part of self-attention pattern.\n",
      "[01/20/2023-00:16:00] [V] [TRT] Found /bert/encoder/layer.3/attention/self/value/MatMul to be part of self-attention pattern.\n",
      "[01/20/2023-00:16:00] [V] [TRT] Found /bert/encoder/layer.3/attention/self/MatMul to be part of self-attention pattern.\n",
      "[01/20/2023-00:16:00] [V] [TRT] Found /bert/encoder/layer.3/attention/self/Softmax to be part of self-attention pattern.\n",
      "[01/20/2023-00:16:00] [V] [TRT] Found /bert/encoder/layer.3/attention/self/MatMul_1 to be part of self-attention pattern.\n",
      "[01/20/2023-00:16:00] [V] [TRT] Found /bert/encoder/layer.4/attention/self/query/MatMul to be part of self-attention pattern.\n",
      "[01/20/2023-00:16:00] [V] [TRT] Found /bert/encoder/layer.4/attention/self/key/MatMul to be part of self-attention pattern.\n",
      "[01/20/2023-00:16:00] [V] [TRT] Found /bert/encoder/layer.4/attention/self/value/MatMul to be part of self-attention pattern.\n",
      "[01/20/2023-00:16:00] [V] [TRT] Found /bert/encoder/layer.4/attention/self/MatMul to be part of self-attention pattern.\n",
      "[01/20/2023-00:16:00] [V] [TRT] Found /bert/encoder/layer.4/attention/self/Softmax to be part of self-attention pattern.\n",
      "[01/20/2023-00:16:00] [V] [TRT] Found /bert/encoder/layer.4/attention/self/MatMul_1 to be part of self-attention pattern.\n",
      "[01/20/2023-00:16:00] [V] [TRT] Found /bert/encoder/layer.5/attention/self/query/MatMul to be part of self-attention pattern.\n",
      "[01/20/2023-00:16:00] [V] [TRT] Found /bert/encoder/layer.5/attention/self/key/MatMul to be part of self-attention pattern.\n",
      "[01/20/2023-00:16:00] [V] [TRT] Found /bert/encoder/layer.5/attention/self/value/MatMul to be part of self-attention pattern.\n",
      "[01/20/2023-00:16:00] [V] [TRT] Found /bert/encoder/layer.5/attention/self/MatMul to be part of self-attention pattern.\n",
      "[01/20/2023-00:16:00] [V] [TRT] Found /bert/encoder/layer.5/attention/self/Softmax to be part of self-attention pattern.\n",
      "[01/20/2023-00:16:00] [V] [TRT] Found /bert/encoder/layer.5/attention/self/MatMul_1 to be part of self-attention pattern.\n",
      "[01/20/2023-00:16:00] [V] [TRT] Found and reassigned Myelin backends for Self-Attention nodes\n",
      "[01/20/2023-00:16:00] [V] [TRT] After Myelin optimization: 1 layers\n",
      "[01/20/2023-00:16:00] [V] [TRT] Applying ScaleNodes fusions.\n",
      "[01/20/2023-00:16:00] [V] [TRT] After scale fusion: 1 layers\n",
      "[01/20/2023-00:16:00] [V] [TRT] After dupe layer removal: 1 layers\n",
      "[01/20/2023-00:16:00] [V] [TRT] After final dead-layer removal: 1 layers\n",
      "[01/20/2023-00:16:00] [V] [TRT] After tensor merging: 1 layers\n",
      "[01/20/2023-00:16:00] [V] [TRT] After vertical fusions: 1 layers\n",
      "[01/20/2023-00:16:00] [V] [TRT] After dupe layer removal: 1 layers\n",
      "[01/20/2023-00:16:00] [V] [TRT] After final dead-layer removal: 1 layers\n",
      "[01/20/2023-00:16:00] [V] [TRT] After tensor merging: 1 layers\n",
      "[01/20/2023-00:16:00] [V] [TRT] After slice removal: 1 layers\n",
      "[01/20/2023-00:16:00] [V] [TRT] After concat removal: 1 layers\n",
      "[01/20/2023-00:16:00] [V] [TRT] Trying to split Reshape and strided tensor\n",
      "[01/20/2023-00:16:00] [V] [TRT] Graph construction and optimization completed in 0.191952 seconds.\n",
      "[01/20/2023-00:16:00] [V] [TRT] Trying to load shared library libcublas.so.11\n",
      "[01/20/2023-00:16:00] [V] [TRT] Loaded shared library libcublas.so.11\n",
      "[01/20/2023-00:16:00] [V] [TRT] Using cublas as plugin tactic source\n",
      "[01/20/2023-00:16:00] [V] [TRT] Trying to load shared library libcublasLt.so.11\n",
      "[01/20/2023-00:16:00] [V] [TRT] Loaded shared library libcublasLt.so.11\n",
      "[01/20/2023-00:16:00] [V] [TRT] Using cublasLt as core library tactic source\n",
      "[01/20/2023-00:16:00] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +6, GPU +10, now: CPU 580, GPU 378 (MiB)\n",
      "[01/20/2023-00:16:00] [V] [TRT] Trying to load shared library libcudnn.so.8\n",
      "[01/20/2023-00:16:00] [V] [TRT] Loaded shared library libcudnn.so.8\n",
      "[01/20/2023-00:16:00] [V] [TRT] Using cuDNN as plugin tactic source\n",
      "[01/20/2023-00:16:00] [V] [TRT] Using cuDNN as core library tactic source\n",
      "[01/20/2023-00:16:00] [I] [TRT] [MemUsageChange] Init cuDNN: CPU +2, GPU +10, now: CPU 582, GPU 388 (MiB)\n",
      "[01/20/2023-00:16:00] [I] [TRT] Local timing cache in use. Profiling results in this builder pass will not be stored.\n",
      "[01/20/2023-00:16:00] [V] [TRT] Constructing optimization profile number 0 [1/1].\n",
      "[01/20/2023-00:16:00] [V] [TRT] Reserving memory for host IO tensors. Host: 0 bytes\n",
      "[01/20/2023-00:16:00] [V] [TRT] =============== Computing reformatting costs: \n",
      "[01/20/2023-00:16:00] [V] [TRT] *************** Autotuning Reformat: Half(6,1) -> Float(6,1) ***************\n",
      "[01/20/2023-00:16:00] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> logits) (Reformat)\n",
      "[01/20/2023-00:16:00] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00420114\n",
      "[01/20/2023-00:16:00] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0100059\n",
      "[01/20/2023-00:16:00] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00433565\n",
      "[01/20/2023-00:16:00] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00420114\n",
      "[01/20/2023-00:16:00] [V] [TRT] =============== Computing costs for \n",
      "[01/20/2023-00:16:00] [V] [TRT] *************** Autotuning format combination:  -> Int32() ***************\n",
      "[01/20/2023-00:16:00] [V] [TRT] --------------- Timing Runner: [HostToDeviceCopy 0] (ShapeHostToDevice)\n",
      "[01/20/2023-00:16:00] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00372091\n",
      "[01/20/2023-00:16:00] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00372091\n",
      "[01/20/2023-00:16:00] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: ShapeHostToDevice Tactic: 0x0000000000000000\n",
      "[01/20/2023-00:16:00] [V] [TRT] =============== Computing costs for \n",
      "[01/20/2023-00:16:00] [V] [TRT] *************** Autotuning format combination: Int32(128,1), Int32(128,1), Int32(128,1), Int32() -> Float(6,1) ***************\n",
      "[01/20/2023-00:16:00] [V] [TRT] --------------- Timing Runner: {ForeignNode[bert.embeddings.position_embeddings.weight...(Unnamed Layer* 1007) [ElementWise]]} (Myelin)\n",
      "[01/20/2023-00:16:03] [V] [TRT]  (foreignNode) Set user's cuda kernel library\n",
      "[01/20/2023-00:16:03] [V] [TRT]  (foreignNode) Pass fuse_conv_padding is currently skipped for dynamic shapes\n",
      "[01/20/2023-00:16:03] [V] [TRT]  (foreignNode) Pass pad_conv_channel is currently skipped for dynamic shapes\n",
      "[01/20/2023-00:16:03] [V] [TRT]  (foreignNode) Pass fuse_conv_padding is currently skipped for dynamic shapes\n",
      "[01/20/2023-00:16:03] [V] [TRT]  (foreignNode) Pass pad_conv_channel is currently skipped for dynamic shapes\n",
      "[01/20/2023-00:16:06] [V] [TRT]  (foreignNode) Set user's cuda kernel library\n",
      "[01/20/2023-00:16:06] [V] [TRT]  (foreignNode) Pass fuse_conv_padding is currently skipped for dynamic shapes\n",
      "[01/20/2023-00:16:06] [V] [TRT]  (foreignNode) Pass pad_conv_channel is currently skipped for dynamic shapes\n",
      "[01/20/2023-00:16:06] [V] [TRT]  (foreignNode) Pass fuse_conv_padding is currently skipped for dynamic shapes\n",
      "[01/20/2023-00:16:06] [V] [TRT]  (foreignNode) Pass pad_conv_channel is currently skipped for dynamic shapes\n",
      "[01/20/2023-00:16:09] [V] [TRT]  (foreignNode) Set user's cuda kernel library\n",
      "[01/20/2023-00:16:09] [V] [TRT]  (foreignNode) Pass fuse_conv_padding is currently skipped for dynamic shapes\n",
      "[01/20/2023-00:16:09] [V] [TRT]  (foreignNode) Pass pad_conv_channel is currently skipped for dynamic shapes\n",
      "[01/20/2023-00:16:09] [V] [TRT]  (foreignNode) Pass fuse_conv_padding is currently skipped for dynamic shapes\n",
      "[01/20/2023-00:16:09] [V] [TRT]  (foreignNode) Pass pad_conv_channel is currently skipped for dynamic shapes\n",
      "[01/20/2023-00:16:12] [V] [TRT]  (foreignNode) Set user's cuda kernel library\n",
      "[01/20/2023-00:16:12] [V] [TRT]  (foreignNode) Pass fuse_conv_padding is currently skipped for dynamic shapes\n",
      "[01/20/2023-00:16:12] [V] [TRT]  (foreignNode) Pass pad_conv_channel is currently skipped for dynamic shapes\n",
      "[01/20/2023-00:16:12] [V] [TRT]  (foreignNode) Pass fuse_conv_padding is currently skipped for dynamic shapes\n",
      "[01/20/2023-00:16:12] [V] [TRT]  (foreignNode) Pass pad_conv_channel is currently skipped for dynamic shapes\n",
      "[01/20/2023-00:16:15] [V] [TRT]  (foreignNode) Set user's cuda kernel library\n",
      "[01/20/2023-00:16:15] [V] [TRT]  (foreignNode) Pass fuse_conv_padding is currently skipped for dynamic shapes\n",
      "[01/20/2023-00:16:15] [V] [TRT]  (foreignNode) Pass pad_conv_channel is currently skipped for dynamic shapes\n",
      "[01/20/2023-00:16:15] [V] [TRT]  (foreignNode) Pass fuse_conv_padding is currently skipped for dynamic shapes\n",
      "[01/20/2023-00:16:15] [V] [TRT]  (foreignNode) Pass pad_conv_channel is currently skipped for dynamic shapes\n",
      "[01/20/2023-00:16:18] [V] [TRT]  (foreignNode) Set user's cuda kernel library\n",
      "[01/20/2023-00:16:18] [V] [TRT]  (foreignNode) Pass fuse_conv_padding is currently skipped for dynamic shapes\n",
      "[01/20/2023-00:16:18] [V] [TRT]  (foreignNode) Pass pad_conv_channel is currently skipped for dynamic shapes\n",
      "[01/20/2023-00:16:18] [V] [TRT]  (foreignNode) Pass fuse_conv_padding is currently skipped for dynamic shapes\n",
      "[01/20/2023-00:16:18] [V] [TRT]  (foreignNode) Pass pad_conv_channel is currently skipped for dynamic shapes\n",
      "[01/20/2023-00:16:21] [V] [TRT]  (foreignNode) Set user's cuda kernel library\n",
      "[01/20/2023-00:16:21] [V] [TRT]  (foreignNode) Pass fuse_conv_padding is currently skipped for dynamic shapes\n",
      "[01/20/2023-00:16:21] [V] [TRT]  (foreignNode) Pass pad_conv_channel is currently skipped for dynamic shapes\n",
      "[01/20/2023-00:16:21] [V] [TRT]  (foreignNode) Pass fuse_conv_padding is currently skipped for dynamic shapes\n",
      "[01/20/2023-00:16:21] [V] [TRT]  (foreignNode) Pass pad_conv_channel is currently skipped for dynamic shapes\n",
      "[01/20/2023-00:16:24] [V] [TRT]  (foreignNode) Set user's cuda kernel library\n",
      "[01/20/2023-00:16:24] [V] [TRT]  (foreignNode) Pass fuse_conv_padding is currently skipped for dynamic shapes\n",
      "[01/20/2023-00:16:24] [V] [TRT]  (foreignNode) Pass pad_conv_channel is currently skipped for dynamic shapes\n",
      "[01/20/2023-00:16:24] [V] [TRT]  (foreignNode) Pass fuse_conv_padding is currently skipped for dynamic shapes\n",
      "[01/20/2023-00:16:24] [V] [TRT]  (foreignNode) Pass pad_conv_channel is currently skipped for dynamic shapes\n",
      "[01/20/2023-00:16:27] [V] [TRT]  (foreignNode) Set user's cuda kernel library\n",
      "[01/20/2023-00:16:27] [V] [TRT]  (foreignNode) Pass fuse_conv_padding is currently skipped for dynamic shapes\n",
      "[01/20/2023-00:16:27] [V] [TRT]  (foreignNode) Pass pad_conv_channel is currently skipped for dynamic shapes\n",
      "[01/20/2023-00:16:27] [V] [TRT]  (foreignNode) Pass fuse_conv_padding is currently skipped for dynamic shapes\n",
      "[01/20/2023-00:16:27] [V] [TRT]  (foreignNode) Pass pad_conv_channel is currently skipped for dynamic shapes\n",
      "[01/20/2023-00:16:28] [V] [TRT]  (foreignNode) Set user's cuda kernel library\n",
      "[01/20/2023-00:16:28] [V] [TRT]  (foreignNode) Pass fuse_conv_padding is currently skipped for dynamic shapes\n",
      "[01/20/2023-00:16:28] [V] [TRT]  (foreignNode) Pass pad_conv_channel is currently skipped for dynamic shapes\n",
      "[01/20/2023-00:16:28] [V] [TRT]  (foreignNode) Pass fuse_conv_padding is currently skipped for dynamic shapes\n",
      "[01/20/2023-00:16:28] [V] [TRT]  (foreignNode) Pass pad_conv_channel is currently skipped for dynamic shapes\n",
      "[01/20/2023-00:16:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 1.92219\n",
      "[01/20/2023-00:16:29] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 1.92219\n",
      "[01/20/2023-00:16:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Myelin Tactic: 0x0000000000000000\n",
      "[01/20/2023-00:16:29] [V] [TRT] *************** Autotuning format combination: Int32(128,1), Int32(128,1), Int32(128,1), Int32() -> Half(6,1) ***************\n",
      "[01/20/2023-00:16:29] [V] [TRT] --------------- Timing Runner: {ForeignNode[bert.embeddings.position_embeddings.weight...(Unnamed Layer* 1007) [ElementWise]]} (Myelin)\n",
      "[01/20/2023-00:17:46] [V] [TRT]  (foreignNode) Set user's cuda kernel library\n",
      "[01/20/2023-00:17:46] [V] [TRT]  (foreignNode) Pass fuse_conv_padding is currently skipped for dynamic shapes\n",
      "[01/20/2023-00:17:46] [V] [TRT]  (foreignNode) Pass pad_conv_channel is currently skipped for dynamic shapes\n",
      "[01/20/2023-00:17:46] [V] [TRT]  (foreignNode) Pass fuse_conv_padding is currently skipped for dynamic shapes\n",
      "[01/20/2023-00:17:46] [V] [TRT]  (foreignNode) Pass pad_conv_channel is currently skipped for dynamic shapes\n",
      "[01/20/2023-00:19:05] [V] [TRT]  (foreignNode) Set user's cuda kernel library\n",
      "[01/20/2023-00:19:05] [V] [TRT]  (foreignNode) Pass fuse_conv_padding is currently skipped for dynamic shapes\n",
      "[01/20/2023-00:19:05] [V] [TRT]  (foreignNode) Pass pad_conv_channel is currently skipped for dynamic shapes\n",
      "[01/20/2023-00:19:05] [V] [TRT]  (foreignNode) Pass fuse_conv_padding is currently skipped for dynamic shapes\n",
      "[01/20/2023-00:19:05] [V] [TRT]  (foreignNode) Pass pad_conv_channel is currently skipped for dynamic shapes\n",
      "[01/20/2023-00:20:21] [V] [TRT]  (foreignNode) Set user's cuda kernel library\n",
      "[01/20/2023-00:20:21] [V] [TRT]  (foreignNode) Pass fuse_conv_padding is currently skipped for dynamic shapes\n",
      "[01/20/2023-00:20:21] [V] [TRT]  (foreignNode) Pass pad_conv_channel is currently skipped for dynamic shapes\n",
      "[01/20/2023-00:20:21] [V] [TRT]  (foreignNode) Pass fuse_conv_padding is currently skipped for dynamic shapes\n",
      "[01/20/2023-00:20:21] [V] [TRT]  (foreignNode) Pass pad_conv_channel is currently skipped for dynamic shapes\n",
      "[01/20/2023-00:21:24] [V] [TRT]  (foreignNode) Set user's cuda kernel library\n",
      "[01/20/2023-00:21:24] [V] [TRT]  (foreignNode) Pass fuse_conv_padding is currently skipped for dynamic shapes\n",
      "[01/20/2023-00:21:24] [V] [TRT]  (foreignNode) Pass pad_conv_channel is currently skipped for dynamic shapes\n",
      "[01/20/2023-00:21:24] [V] [TRT]  (foreignNode) Pass fuse_conv_padding is currently skipped for dynamic shapes\n",
      "[01/20/2023-00:21:24] [V] [TRT]  (foreignNode) Pass pad_conv_channel is currently skipped for dynamic shapes\n",
      "[01/20/2023-00:22:31] [V] [TRT]  (foreignNode) Set user's cuda kernel library\n",
      "[01/20/2023-00:22:31] [V] [TRT]  (foreignNode) Pass fuse_conv_padding is currently skipped for dynamic shapes\n",
      "[01/20/2023-00:22:31] [V] [TRT]  (foreignNode) Pass pad_conv_channel is currently skipped for dynamic shapes\n",
      "[01/20/2023-00:22:31] [V] [TRT]  (foreignNode) Pass fuse_conv_padding is currently skipped for dynamic shapes\n",
      "[01/20/2023-00:22:31] [V] [TRT]  (foreignNode) Pass pad_conv_channel is currently skipped for dynamic shapes\n",
      "[01/20/2023-00:23:36] [V] [TRT]  (foreignNode) Set user's cuda kernel library\n",
      "[01/20/2023-00:23:36] [V] [TRT]  (foreignNode) Pass fuse_conv_padding is currently skipped for dynamic shapes\n",
      "[01/20/2023-00:23:36] [V] [TRT]  (foreignNode) Pass pad_conv_channel is currently skipped for dynamic shapes\n",
      "[01/20/2023-00:23:36] [V] [TRT]  (foreignNode) Pass fuse_conv_padding is currently skipped for dynamic shapes\n",
      "[01/20/2023-00:23:36] [V] [TRT]  (foreignNode) Pass pad_conv_channel is currently skipped for dynamic shapes\n",
      "[01/20/2023-00:24:39] [V] [TRT]  (foreignNode) Set user's cuda kernel library\n",
      "[01/20/2023-00:24:39] [V] [TRT]  (foreignNode) Pass fuse_conv_padding is currently skipped for dynamic shapes\n",
      "[01/20/2023-00:24:39] [V] [TRT]  (foreignNode) Pass pad_conv_channel is currently skipped for dynamic shapes\n",
      "[01/20/2023-00:24:39] [V] [TRT]  (foreignNode) Pass fuse_conv_padding is currently skipped for dynamic shapes\n",
      "[01/20/2023-00:24:39] [V] [TRT]  (foreignNode) Pass pad_conv_channel is currently skipped for dynamic shapes\n",
      "[01/20/2023-00:25:40] [V] [TRT]  (foreignNode) Set user's cuda kernel library\n",
      "[01/20/2023-00:25:40] [V] [TRT]  (foreignNode) Pass fuse_conv_padding is currently skipped for dynamic shapes\n",
      "[01/20/2023-00:25:40] [V] [TRT]  (foreignNode) Pass pad_conv_channel is currently skipped for dynamic shapes\n",
      "[01/20/2023-00:25:40] [V] [TRT]  (foreignNode) Pass fuse_conv_padding is currently skipped for dynamic shapes\n",
      "[01/20/2023-00:25:40] [V] [TRT]  (foreignNode) Pass pad_conv_channel is currently skipped for dynamic shapes\n",
      "[01/20/2023-00:26:39] [V] [TRT]  (foreignNode) Set user's cuda kernel library\n",
      "[01/20/2023-00:26:39] [V] [TRT]  (foreignNode) Pass fuse_conv_padding is currently skipped for dynamic shapes\n",
      "[01/20/2023-00:26:39] [V] [TRT]  (foreignNode) Pass pad_conv_channel is currently skipped for dynamic shapes\n",
      "[01/20/2023-00:26:39] [V] [TRT]  (foreignNode) Pass fuse_conv_padding is currently skipped for dynamic shapes\n",
      "[01/20/2023-00:26:39] [V] [TRT]  (foreignNode) Pass pad_conv_channel is currently skipped for dynamic shapes\n",
      "[01/20/2023-00:26:55] [V] [TRT]  (foreignNode) Set user's cuda kernel library\n",
      "[01/20/2023-00:26:55] [V] [TRT]  (foreignNode) Pass fuse_conv_padding is currently skipped for dynamic shapes\n",
      "[01/20/2023-00:26:55] [V] [TRT]  (foreignNode) Pass pad_conv_channel is currently skipped for dynamic shapes\n",
      "[01/20/2023-00:26:55] [V] [TRT]  (foreignNode) Pass fuse_conv_padding is currently skipped for dynamic shapes\n",
      "[01/20/2023-00:26:55] [V] [TRT]  (foreignNode) Pass pad_conv_channel is currently skipped for dynamic shapes\n",
      "[01/20/2023-00:26:56] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.854162\n",
      "[01/20/2023-00:26:57] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.854162\n",
      "[01/20/2023-00:26:57] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Myelin Tactic: 0x0000000000000000\n",
      "[01/20/2023-00:26:57] [V] [TRT] Adding reformat layer: Reformatted Output Tensor 0 to {ForeignNode[bert.embeddings.position_embeddings.weight...(Unnamed Layer* 1007) [ElementWise]]} (logits) from Half(6,1) to Float(6,1)\n",
      "[01/20/2023-00:26:57] [V] [TRT] Formats and tactics selection completed in 656.929 seconds.\n",
      "[01/20/2023-00:26:57] [V] [TRT] After reformat layers: 3 layers\n",
      "[01/20/2023-00:26:57] [V] [TRT] Total number of blocks in pre-optimized block assignment: 3\n",
      "[01/20/2023-00:26:57] [I] [TRT] Total Activation Memory: 14680067584\n",
      "[01/20/2023-00:26:57] [I] [TRT] Detected 3 inputs and 1 output network tensors.\n",
      "[01/20/2023-00:26:58] [V] [TRT] Layer: [HostToDeviceCopy 0] Host Persistent: 4 Device Persistent: 0 Scratch Memory: 0\n",
      "[01/20/2023-00:26:58] [V] [TRT] Layer: {ForeignNode[bert.embeddings.position_embeddings.weight...(Unnamed Layer* 1007) [ElementWise]]} Host Persistent: 240 Device Persistent: 0 Scratch Memory: 191242240\n",
      "[01/20/2023-00:26:58] [V] [TRT] Skipped printing memory information for 1 layers with 0 memory size i.e. Host Persistent + Device Persistent + Scratch Memory == 0.\n",
      "[01/20/2023-00:26:58] [I] [TRT] Total Host Persistent Memory: 256\n",
      "[01/20/2023-00:26:58] [I] [TRT] Total Device Persistent Memory: 0\n",
      "[01/20/2023-00:26:58] [I] [TRT] Total Scratch Memory: 191242240\n",
      "[01/20/2023-00:26:58] [I] [TRT] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 24 MiB, GPU 526 MiB\n",
      "[01/20/2023-00:26:58] [I] [TRT] [BlockAssignment] Started assigning block shifts. This will take 3 steps to complete.\n",
      "[01/20/2023-00:26:58] [I] [TRT] [BlockAssignment] Algorithm ShiftNTopDown took 0.044461ms to assign 3 blocks to 3 nodes requiring 191245824 bytes.\n",
      "[01/20/2023-00:26:58] [V] [TRT] Total number of blocks in optimized block assignment: 3\n",
      "[01/20/2023-00:26:58] [I] [TRT] Total Activation Memory: 191245824\n",
      "[01/20/2023-00:26:58] [V] [TRT] Total number of generated kernels selected for the engine: 0\n",
      "[01/20/2023-00:26:58] [V] [TRT] Disabling unused tactic source: CUDNN\n",
      "[01/20/2023-00:26:58] [V] [TRT] Disabling unused tactic source: CUBLAS, CUBLAS_LT\n",
      "[01/20/2023-00:26:58] [V] [TRT] Disabling unused tactic source: EDGE_MASK_CONVOLUTIONS\n",
      "[01/20/2023-00:26:58] [V] [TRT] Disabling unused tactic source: JIT_CONVOLUTIONS\n",
      "[01/20/2023-00:26:58] [V] [TRT] Engine generation completed in 658.768 seconds.\n",
      "[01/20/2023-00:26:58] [W] [TRT] TensorRT encountered issues when converting weights between types and that could affect accuracy.\n",
      "[01/20/2023-00:26:58] [W] [TRT] If this is not the desired behavior, please modify the weights or retrain with regularization to adjust the magnitude of the weights.\n",
      "[01/20/2023-00:26:58] [W] [TRT] Check verbose logs for the list of affected weights.\n",
      "[01/20/2023-00:26:58] [W] [TRT] - 59 weights are affected by this issue: Detected subnormal FP16 values.\n",
      "[01/20/2023-00:26:58] [V] [TRT]   List of affected weights: bert_embeddings_position_embeddings_weight_constant, bert_embeddings_token_type_embeddings_weight_constant, bert_embeddings_word_embeddings_weight_constant, bert_encoder_layer_0_attention_self_key_bias _ (Unnamed Layer_ 75) [Shuffle]_constant, bert_encoder_layer_1_attention_self_value_bias _ (Unnamed Layer_ 248) [Shuffle]_constant, bert_encoder_layer_1_intermediate_dense_bias _ (Unnamed Layer_ 338) [Shuffle]_constant, bert_encoder_layer_1_output_dense_bias _ (Unnamed Layer_ 355) [Shuffle]_constant, bert_encoder_layer_2_attention_self_key_bias _ (Unnamed Layer_ 385) [Shuffle]_constant, bert_encoder_layer_2_attention_self_value_bias _ (Unnamed Layer_ 403) [Shuffle]_constant, bert_encoder_layer_2_intermediate_dense_bias _ (Unnamed Layer_ 493) [Shuffle]_constant, bert_encoder_layer_3_attention_self_key_bias _ (Unnamed Layer_ 540) [Shuffle]_constant, bert_encoder_layer_4_attention_self_value_bias _ (Unnamed Layer_ 713) [Shuffle]_constant, bert_encoder_layer_4_intermediate_dense_bias _ (Unnamed Layer_ 803) [Shuffle]_constant, bert_encoder_layer_5_attention_output_LayerNorm_bias _ (Unnamed Layer_ 952) [Shuffle]_constant, bert_encoder_layer_5_attention_output_dense_bias _ (Unnamed Layer_ 934) [Shuffle]_constant, bert_encoder_layer_5_attention_self_key_bias _ (Unnamed Layer_ 850) [Shuffle]_constant, bert_encoder_layer_5_intermediate_dense_bias _ (Unnamed Layer_ 958) [Shuffle]_constant, bert_encoder_layer_5_output_LayerNorm_bias _ (Unnamed Layer_ 993) [Shuffle]_constant, bert_encoder_layer_5_output_dense_bias _ (Unnamed Layer_ 975) [Shuffle]_constant, bert_pooler_dense_bias _ (Unnamed Layer_ 1000) [Shuffle]_constant, bert_pooler_dense_weight_constant, classifier_bias _ (Unnamed Layer_ 1006) [Shuffle]_constant, classifier_weight_constant, onnx__MatMul_793 _ (Unnamed Layer_ 66) [Shuffle]_constant, onnx__MatMul_794 _ (Unnamed Layer_ 72) [Shuffle]_constant, onnx__MatMul_797 _ (Unnamed Layer_ 90) [Shuffle]_constant, onnx__MatMul_803 _ (Unnamed Layer_ 156) [Shuffle]_constant, onnx__MatMul_804 _ (Unnamed Layer_ 180) [Shuffle]_constant, onnx__MatMul_805 _ (Unnamed Layer_ 197) [Shuffle]_constant, onnx__MatMul_806 _ (Unnamed Layer_ 221) [Shuffle]_constant, onnx__MatMul_807 _ (Unnamed Layer_ 227) [Shuffle]_constant, onnx__MatMul_810 _ (Unnamed Layer_ 245) [Shuffle]_constant, onnx__MatMul_816 _ (Unnamed Layer_ 311) [Shuffle]_constant, onnx__MatMul_817 _ (Unnamed Layer_ 335) [Shuffle]_constant, onnx__MatMul_818 _ (Unnamed Layer_ 352) [Shuffle]_constant, onnx__MatMul_819 _ (Unnamed Layer_ 376) [Shuffle]_constant, onnx__MatMul_820 _ (Unnamed Layer_ 382) [Shuffle]_constant, onnx__MatMul_823 _ (Unnamed Layer_ 400) [Shuffle]_constant, onnx__MatMul_829 _ (Unnamed Layer_ 466) [Shuffle]_constant, onnx__MatMul_830 _ (Unnamed Layer_ 490) [Shuffle]_constant, onnx__MatMul_831 _ (Unnamed Layer_ 507) [Shuffle]_constant, onnx__MatMul_832 _ (Unnamed Layer_ 531) [Shuffle]_constant, onnx__MatMul_833 _ (Unnamed Layer_ 537) [Shuffle]_constant, onnx__MatMul_836 _ (Unnamed Layer_ 555) [Shuffle]_constant, onnx__MatMul_842 _ (Unnamed Layer_ 621) [Shuffle]_constant, onnx__MatMul_843 _ (Unnamed Layer_ 645) [Shuffle]_constant, onnx__MatMul_844 _ (Unnamed Layer_ 662) [Shuffle]_constant, onnx__MatMul_845 _ (Unnamed Layer_ 686) [Shuffle]_constant, onnx__MatMul_846 _ (Unnamed Layer_ 692) [Shuffle]_constant, onnx__MatMul_849 _ (Unnamed Layer_ 710) [Shuffle]_constant, onnx__MatMul_855 _ (Unnamed Layer_ 776) [Shuffle]_constant, onnx__MatMul_856 _ (Unnamed Layer_ 800) [Shuffle]_constant, onnx__MatMul_857 _ (Unnamed Layer_ 817) [Shuffle]_constant, onnx__MatMul_858 _ (Unnamed Layer_ 841) [Shuffle]_constant, onnx__MatMul_859 _ (Unnamed Layer_ 847) [Shuffle]_constant, onnx__MatMul_862 _ (Unnamed Layer_ 865) [Shuffle]_constant, onnx__MatMul_868 _ (Unnamed Layer_ 931) [Shuffle]_constant, onnx__MatMul_869 _ (Unnamed Layer_ 955) [Shuffle]_constant, onnx__MatMul_870 _ (Unnamed Layer_ 972) [Shuffle]_constant\n",
      "[01/20/2023-00:26:58] [W] [TRT] - 18 weights are affected by this issue: Detected values less than smallest positive FP16 subnormal value and converted them to the FP16 minimum subnormalized value.\n",
      "[01/20/2023-00:26[01/20/2023-00:26:58] [V] [TRT]   List of affected weights: /bert/embeddings/LayerNorm/Constant_1_output_0 + (Unnamed Layer* 55) [Shuffle], /bert/encoder/layer.0/attention/output/LayerNorm/Constant_1_output_0 + (Unnamed Layer* 169) [Shuffle], /bert/encoder/layer.0/output/LayerNorm/Constant_1_output_0 + (Unnamed Layer* 210) [Shuffle], /bert/encoder/layer.1/attention/output/LayerNorm/Constant_1_output_0 + (Unnamed Layer* 324) [Shuffle], /bert/encoder/layer.1/output/LayerNorm/Constant_1_output_0 + (Unnamed Layer* 365) [Shuffle], /bert/encoder/layer.2/attention/output/LayerNorm/Constant_1_output_0 + (Unnamed Layer* 479) [Shuffle], /bert/encoder/layer.2/output/LayerNorm/Constant_1_output_0 + (Unnamed Layer* 520) [Shuffle], /bert/encoder/layer.3/attention/output/LayerNorm/Constant_1_output_0 + (Unnamed Layer* 634) [Shuffle], /bert/encoder/layer.3/output/LayerNorm/Constant_1_output_0 + (Unnamed Layer* 675) [Shuffle], /bert/encoder/layer.4/attention/output/LayerNorm/Constant_1_output_0 + (Unnamed Layer* 789) [Shuffle], /bert/encoder/layer.4/output/LayerNorm/Constant_1_output_0 + (Unnamed Layer* 830) [Shuffle], /bert/encoder/layer.5/attention/output/LayerNorm/Constant_1_output_0 + (Unnamed Layer* 944) [Shuffle], /bert/encoder/layer.5/output/LayerNorm/Constant_1_output_0 + (Unnamed Layer* 985) [Shuffle], bert_embeddings_word_embeddings_weight_constant, onnx__MatMul_830 _ (Unnamed Layer_ 490) [Shuffle]_constant, onnx__MatMul_845 _ (Unnamed Layer_ 686) [Shuffle]_constant, onnx__MatMul_869 _ (Unnamed Layer_ 955) [Shuffle]_constant, onnx__MatMul_870 _ (Unnamed Layer_ 972) [Shuffle]_constant\n",
      ":58] [W] [TRT] - 1 weights are affected by this issue: Detected finite FP32 values which would overflow in FP16 and converted them to the closest finite FP16 value.\n",
      "[01/20/2023-00:26:58] [V] [TRT]   List of affected weights: /bert/Constant_2_output_0 + (Unnamed Layer* 17) [Shuffle]\n",
      "[01/20/2023-00:26:58] [V] [TRT] Deleting timing cache: 1 entries, served 0 hits since creation.\n",
      "[01/20/2023-00:26:58] [V] [TRT] Engine Layer Information:\n",
      "Layer(ShapeHostToDevice): [HostToDeviceCopy 0], Tactic: 0x0000000000000000,  -> token_type_ids[implicit padding mask tensor 0] (Int32[])\n",
      "Layer(Myelin): {ForeignNode[bert.embeddings.position_embeddings.weight...(Unnamed Layer* 1007) [ElementWise]]}, Tactic: 0x0000000000000000, token_type_ids (Int32[-1,128]), input_ids (Int32[-1,128]), attention_mask (Int32[-1,128]), token_type_ids[implicit padding mask tensor 0] (Int32[]) -> Reformatted Output Tensor 0 to {ForeignNode[bert.embeddings.position_embeddings.weight...(Unnamed Layer* 1007) [ElementWise]]} (Half[-1,6])\n",
      "Layer(Reformat): Reformatting CopyNode for Output Tensor 0 to {ForeignNode[bert.embeddings.position_embeddings.weight...(Unnamed Layer* 1007) [ElementWise]]}, Tactic: 0x00000000000003e8, Reformatted Output Tensor 0 to {ForeignNode[bert.embeddings.position_embeddings.weight...(Unnamed Layer* 1007) [ElementWise]]} (Half[-1,6]) -> logits (Float[-1,6])\n",
      "[01/20/2023-00:26:58] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in building engine: CPU +24, GPU +32, now: CPU 24, GPU 32 (MiB)\n",
      "[01/20/2023-00:26:58] [I] Engine built in 662.079 sec.\n",
      "[01/20/2023-00:26:59] [I] [TRT] Loaded engine size: 36 MiB\n",
      "[01/20/2023-00:26:59] [V] [TRT] Deserialization required 12042 microseconds.\n",
      "[01/20/2023-00:26:59] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in engine deserialization: CPU +0, GPU +27, now: CPU 0, GPU 27 (MiB)\n",
      "[01/20/2023-00:26:59] [I] Engine deserialized in 0.0124075 sec.\n",
      "[01/20/2023-00:26:59] [V] [TRT] Total per-runner device persistent memory is 0\n",
      "[01/20/2023-00:26:59] [V] [TRT] Total per-runner host persistent memory is 256\n",
      "[01/20/2023-00:26:59] [V] [TRT] Allocated activation device memory of size 191245824\n",
      "[01/20/2023-00:26:59] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +182, now: CPU 0, GPU 209 (MiB)\n",
      "[01/20/2023-00:26:59] [V] [TRT] CUDA lazy loading is enabled.\n",
      "[01/20/2023-00:26:59] [I] Setting persistentCacheLimit to 0 bytes.\n",
      "[01/20/2023-00:26:59] [V] Using enqueueV3.\n",
      "[01/20/2023-00:26:59] [I] Using random values for input input_ids\n",
      "[01/20/2023-00:26:59] [I] Created input binding for input_ids with dimensions 16x128\n",
      "[01/20/2023-00:26:59] [I] Using random values for input attention_mask\n",
      "[01/20/2023-00:26:59] [I] Created input binding for attention_mask with dimensions 16x128\n",
      "[01/20/2023-00:26:59] [I] Using random values for input token_type_ids\n",
      "[01/20/2023-00:26:59] [I] Created input binding for token_type_ids with dimensions 16x128\n",
      "[01/20/2023-00:26:59] [I] Using random values for output logits\n",
      "[01/20/2023-00:26:59] [I] Created output binding for logits with dimensions 16x6\n",
      "[01/20/2023-00:26:59] [I] Starting inference\n",
      "[01/20/2023-00:27:03] [I] Warmup completed 205 queries over 200 ms\n",
      "[01/20/2023-00:27:03] [I] Timing trace has 3233 queries over 3.00154 s\n",
      "[01/20/2023-00:27:03] [I] \n",
      "[01/20/2023-00:27:03] [I] === Trace details ===\n",
      "[01/20/2023-00:27:03] [I] Trace averages of 10 runs:\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.929825 ms - Host latency: 1.04485 ms (enqueue 0.926662 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.896078 ms - Host latency: 0.923833 ms (enqueue 0.89328 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.888507 ms - Host latency: 0.905621 ms (enqueue 0.885519 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.887535 ms - Host latency: 0.903867 ms (enqueue 0.884541 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.889003 ms - Host latency: 0.905333 ms (enqueue 0.885866 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.891161 ms - Host latency: 0.907632 ms (enqueue 0.888126 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.88775 ms - Host latency: 0.904056 ms (enqueue 0.884686 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.889423 ms - Host latency: 0.906839 ms (enqueue 0.886578 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.88627 ms - Host latency: 0.902158 ms (enqueue 0.883075 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.887625 ms - Host latency: 0.903653 ms (enqueue 0.884433 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.888928 ms - Host latency: 0.904974 ms (enqueue 0.887396 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.874274 ms - Host latency: 0.888809 ms (enqueue 0.878104 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.871832 ms - Host latency: 0.886328 ms (enqueue 0.875211 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.87388 ms - Host latency: 0.888568 ms (enqueue 0.875098 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.870914 ms - Host latency: 0.885284 ms (enqueue 0.874951 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.873682 ms - Host latency: 0.888251 ms (enqueue 0.877093 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.870602 ms - Host latency: 0.885077 ms (enqueue 0.873923 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.877567 ms - Host latency: 0.891904 ms (enqueue 0.880786 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.870917 ms - Host latency: 0.885385 ms (enqueue 0.874445 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.871838 ms - Host latency: 0.886273 ms (enqueue 0.87576 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.877341 ms - Host latency: 0.892377 ms (enqueue 0.881079 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.877051 ms - Host latency: 0.892194 ms (enqueue 0.879681 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.870193 ms - Host latency: 0.884699 ms (enqueue 0.874088 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.876941 ms - Host latency: 0.891421 ms (enqueue 0.881232 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.871942 ms - Host latency: 0.88642 ms (enqueue 0.875259 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.883298 ms - Host latency: 0.899188 ms (enqueue 0.883044 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.889227 ms - Host latency: 0.906564 ms (enqueue 0.886081 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.888339 ms - Host latency: 0.904538 ms (enqueue 0.885248 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.894357 ms - Host latency: 0.910944 ms (enqueue 0.889084 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.886234 ms - Host latency: 0.902637 ms (enqueue 0.883322 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.891599 ms - Host latency: 0.907602 ms (enqueue 0.888879 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.887451 ms - Host latency: 0.903452 ms (enqueue 0.884473 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.887915 ms - Host latency: 0.90423 ms (enqueue 0.884967 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.886365 ms - Host latency: 0.902496 ms (enqueue 0.883563 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.886469 ms - Host latency: 0.902179 ms (enqueue 0.883459 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.886676 ms - Host latency: 0.902594 ms (enqueue 0.883429 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.889313 ms - Host latency: 0.905463 ms (enqueue 0.886182 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.890009 ms - Host latency: 0.907648 ms (enqueue 0.887158 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.875183 ms - Host latency: 0.892413 ms (enqueue 0.878204 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.882196 ms - Host latency: 0.897186 ms (enqueue 0.884875 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.877856 ms - Host latency: 0.892468 ms (enqueue 0.882098 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.876135 ms - Host latency: 0.890656 ms (enqueue 0.875513 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.87337 ms - Host latency: 0.887799 ms (enqueue 0.875854 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.879218 ms - Host latency: 0.894073 ms (enqueue 0.881683 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.888489 ms - Host latency: 0.905798 ms (enqueue 0.887787 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.873584 ms - Host latency: 0.888275 ms (enqueue 0.87688 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.872443 ms - Host latency: 0.887115 ms (enqueue 0.875562 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.871033 ms - Host latency: 0.88551 ms (enqueue 0.874853 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.874701 ms - Host latency: 0.889398 ms (enqueue 0.878241 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.878278 ms - Host latency: 0.892651 ms (enqueue 0.876617 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.874176 ms - Host latency: 0.888532 ms (enqueue 0.878143 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.873376 ms - Host latency: 0.887683 ms (enqueue 0.877234 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.884729 ms - Host latency: 0.904401 ms (enqueue 0.883814 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.891376 ms - Host latency: 0.908594 ms (enqueue 0.888098 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.890149 ms - Host latency: 0.906415 ms (enqueue 0.887067 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.891077 ms - Host latency: 0.906824 ms (enqueue 0.888062 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.886969 ms - Host latency: 0.902942 ms (enqueue 0.883954 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.888013 ms - Host latency: 0.904382 ms (enqueue 0.884436 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.88996 ms - Host latency: 0.908368 ms (enqueue 0.884405 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.889691 ms - Host latency: 0.906097 ms (enqueue 0.886279 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.886725 ms - Host latency: 0.903937 ms (enqueue 0.883551 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.886987 ms - Host latency: 0.903082 ms (enqueue 0.884113 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.886389 ms - Host latency: 0.902533 ms (enqueue 0.883258 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.889624 ms - Host latency: 0.905524 ms (enqueue 0.886298 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.889209 ms - Host latency: 0.905548 ms (enqueue 0.885931 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.877563 ms - Host latency: 0.895282 ms (enqueue 0.880231 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.872742 ms - Host latency: 0.891449 ms (enqueue 0.875458 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.870825 ms - Host latency: 0.885199 ms (enqueue 0.874689 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.871417 ms - Host latency: 0.885791 ms (enqueue 0.875433 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.871735 ms - Host latency: 0.886224 ms (enqueue 0.875488 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.875 ms - Host latency: 0.889496 ms (enqueue 0.878247 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.876337 ms - Host latency: 0.890918 ms (enqueue 0.879529 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.876624 ms - Host latency: 0.891223 ms (enqueue 0.878223 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.873041 ms - Host latency: 0.890051 ms (enqueue 0.876843 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.872235 ms - Host latency: 0.886603 ms (enqueue 0.875232 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.878687 ms - Host latency: 0.893732 ms (enqueue 0.880737 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.872034 ms - Host latency: 0.886536 ms (enqueue 0.875763 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.870404 ms - Host latency: 0.88479 ms (enqueue 0.874054 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.871942 ms - Host latency: 0.886426 ms (enqueue 0.875677 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.880133 ms - Host latency: 0.895013 ms (enqueue 0.881793 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.887585 ms - Host latency: 0.903394 ms (enqueue 0.884418 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.893231 ms - Host latency: 0.910156 ms (enqueue 0.888251 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.888837 ms - Host latency: 0.905121 ms (enqueue 0.885889 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.890088 ms - Host latency: 0.906177 ms (enqueue 0.886865 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.887884 ms - Host latency: 0.90415 ms (enqueue 0.884943 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.887097 ms - Host latency: 0.90307 ms (enqueue 0.883978 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.891479 ms - Host latency: 0.907269 ms (enqueue 0.88833 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.886774 ms - Host latency: 0.903168 ms (enqueue 0.883765 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.887323 ms - Host latency: 0.903174 ms (enqueue 0.884631 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.887329 ms - Host latency: 0.903357 ms (enqueue 0.884338 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.886914 ms - Host latency: 0.902808 ms (enqueue 0.883862 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.89259 ms - Host latency: 0.908936 ms (enqueue 0.889343 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.882434 ms - Host latency: 0.897852 ms (enqueue 0.882874 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.872327 ms - Host latency: 0.886816 ms (enqueue 0.875586 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.87428 ms - Host latency: 0.888672 ms (enqueue 0.877625 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.872656 ms - Host latency: 0.887048 ms (enqueue 0.875928 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.87345 ms - Host latency: 0.890478 ms (enqueue 0.876953 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.871411 ms - Host latency: 0.885974 ms (enqueue 0.875513 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.871228 ms - Host latency: 0.885779 ms (enqueue 0.874585 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.871655 ms - Host latency: 0.88623 ms (enqueue 0.875525 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.875232 ms - Host latency: 0.889624 ms (enqueue 0.87898 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.873352 ms - Host latency: 0.887756 ms (enqueue 0.877356 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.871533 ms - Host latency: 0.89082 ms (enqueue 0.874438 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.874756 ms - Host latency: 0.889233 ms (enqueue 0.878955 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.872119 ms - Host latency: 0.886487 ms (enqueue 0.875476 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.871826 ms - Host latency: 0.886279 ms (enqueue 0.875269 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.87124 ms - Host latency: 0.885742 ms (enqueue 0.874744 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.887988 ms - Host latency: 0.904749 ms (enqueue 0.885425 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.89082 ms - Host latency: 0.913269 ms (enqueue 0.887671 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.887854 ms - Host latency: 0.903943 ms (enqueue 0.884729 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.889392 ms - Host latency: 0.908459 ms (enqueue 0.886414 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.887622 ms - Host latency: 0.904211 ms (enqueue 0.884607 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.891968 ms - Host latency: 0.908167 ms (enqueue 0.88894 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.893628 ms - Host latency: 0.909814 ms (enqueue 0.89054 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.888843 ms - Host latency: 0.906702 ms (enqueue 0.88584 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.886572 ms - Host latency: 0.902661 ms (enqueue 0.883594 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.891272 ms - Host latency: 0.90708 ms (enqueue 0.888037 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.887354 ms - Host latency: 0.903516 ms (enqueue 0.884351 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.887891 ms - Host latency: 0.907397 ms (enqueue 0.884741 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.885669 ms - Host latency: 0.901428 ms (enqueue 0.884998 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.873462 ms - Host latency: 0.887769 ms (enqueue 0.876111 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.870789 ms - Host latency: 0.885046 ms (enqueue 0.87467 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.87207 ms - Host latency: 0.889441 ms (enqueue 0.875696 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.873572 ms - Host latency: 0.890735 ms (enqueue 0.876074 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.873987 ms - Host latency: 0.888696 ms (enqueue 0.877649 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.874353 ms - Host latency: 0.89093 ms (enqueue 0.876978 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.877344 ms - Host latency: 0.892468 ms (enqueue 0.88042 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.872864 ms - Host latency: 0.887195 ms (enqueue 0.876794 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.872034 ms - Host latency: 0.886621 ms (enqueue 0.875391 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.874695 ms - Host latency: 0.889331 ms (enqueue 0.878943 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.8724 ms - Host latency: 0.886914 ms (enqueue 0.876819 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.870789 ms - Host latency: 0.885168 ms (enqueue 0.874536 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.870947 ms - Host latency: 0.886658 ms (enqueue 0.875134 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.873059 ms - Host latency: 0.89314 ms (enqueue 0.87594 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.88728 ms - Host latency: 0.903638 ms (enqueue 0.885364 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.888562 ms - Host latency: 0.904797 ms (enqueue 0.885242 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.888794 ms - Host latency: 0.9052 ms (enqueue 0.885376 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.8875 ms - Host latency: 0.903687 ms (enqueue 0.884229 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.890698 ms - Host latency: 0.907141 ms (enqueue 0.885864 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.887756 ms - Host latency: 0.903955 ms (enqueue 0.884619 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.885547 ms - Host latency: 0.901733 ms (enqueue 0.882642 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.890076 ms - Host latency: 0.907349 ms (enqueue 0.886951 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.887634 ms - Host latency: 0.903748 ms (enqueue 0.884729 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.886157 ms - Host latency: 0.902539 ms (enqueue 0.883105 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.888184 ms - Host latency: 0.904309 ms (enqueue 0.885071 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.887695 ms - Host latency: 0.90387 ms (enqueue 0.884473 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.888501 ms - Host latency: 0.904492 ms (enqueue 0.887073 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.87616 ms - Host latency: 0.890772 ms (enqueue 0.879578 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.873157 ms - Host latency: 0.887793 ms (enqueue 0.875879 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.871631 ms - Host latency: 0.886206 ms (enqueue 0.875635 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.872534 ms - Host latency: 0.887048 ms (enqueue 0.875256 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.87113 ms - Host latency: 0.885657 ms (enqueue 0.87511 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.874988 ms - Host latency: 0.890051 ms (enqueue 0.878198 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.878564 ms - Host latency: 0.893994 ms (enqueue 0.881104 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.871631 ms - Host latency: 0.885962 ms (enqueue 0.875708 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.871033 ms - Host latency: 0.885547 ms (enqueue 0.874756 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.873987 ms - Host latency: 0.888452 ms (enqueue 0.87699 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.873389 ms - Host latency: 0.891089 ms (enqueue 0.875867 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.876147 ms - Host latency: 0.891174 ms (enqueue 0.879382 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.872241 ms - Host latency: 0.886621 ms (enqueue 0.876038 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.871533 ms - Host latency: 0.886096 ms (enqueue 0.875232 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.878271 ms - Host latency: 0.893884 ms (enqueue 0.879675 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.888708 ms - Host latency: 0.905188 ms (enqueue 0.88584 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.889673 ms - Host latency: 0.906213 ms (enqueue 0.886365 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.886841 ms - Host latency: 0.902869 ms (enqueue 0.88396 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.886951 ms - Host latency: 0.903076 ms (enqueue 0.884094 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.886841 ms - Host latency: 0.902893 ms (enqueue 0.883667 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.889709 ms - Host latency: 0.905811 ms (enqueue 0.886609 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.887366 ms - Host latency: 0.903833 ms (enqueue 0.884265 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.886206 ms - Host latency: 0.902466 ms (enqueue 0.883301 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.887463 ms - Host latency: 0.903845 ms (enqueue 0.884302 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.887012 ms - Host latency: 0.903369 ms (enqueue 0.884094 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.888855 ms - Host latency: 0.905273 ms (enqueue 0.885584 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.887708 ms - Host latency: 0.903857 ms (enqueue 0.884631 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.878052 ms - Host latency: 0.893152 ms (enqueue 0.879773 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.870728 ms - Host latency: 0.885083 ms (enqueue 0.87395 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.871838 ms - Host latency: 0.886279 ms (enqueue 0.875439 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.87334 ms - Host latency: 0.890149 ms (enqueue 0.875818 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.876135 ms - Host latency: 0.890515 ms (enqueue 0.879248 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.876648 ms - Host latency: 0.891443 ms (enqueue 0.880994 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.873779 ms - Host latency: 0.888086 ms (enqueue 0.877893 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.871118 ms - Host latency: 0.885486 ms (enqueue 0.874097 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.872314 ms - Host latency: 0.886841 ms (enqueue 0.875769 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.871423 ms - Host latency: 0.886157 ms (enqueue 0.874963 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.872913 ms - Host latency: 0.889417 ms (enqueue 0.876172 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.872351 ms - Host latency: 0.886938 ms (enqueue 0.875781 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.874634 ms - Host latency: 0.893201 ms (enqueue 0.877014 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.878442 ms - Host latency: 0.892749 ms (enqueue 0.881689 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.874377 ms - Host latency: 0.889294 ms (enqueue 0.877441 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.889026 ms - Host latency: 0.905408 ms (enqueue 0.88584 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.890259 ms - Host latency: 0.907056 ms (enqueue 0.886768 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.893494 ms - Host latency: 0.909546 ms (enqueue 0.890173 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.887341 ms - Host latency: 0.903198 ms (enqueue 0.884521 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.888782 ms - Host latency: 0.907056 ms (enqueue 0.885742 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.887549 ms - Host latency: 0.903662 ms (enqueue 0.884644 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.890076 ms - Host latency: 0.90658 ms (enqueue 0.88689 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.887598 ms - Host latency: 0.903906 ms (enqueue 0.884473 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.884998 ms - Host latency: 0.901221 ms (enqueue 0.882117 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.886475 ms - Host latency: 0.9026 ms (enqueue 0.883398 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.888892 ms - Host latency: 0.905371 ms (enqueue 0.885767 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.888013 ms - Host latency: 0.904321 ms (enqueue 0.884766 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.884912 ms - Host latency: 0.902319 ms (enqueue 0.884302 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.871655 ms - Host latency: 0.886108 ms (enqueue 0.87583 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.872437 ms - Host latency: 0.886816 ms (enqueue 0.875806 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.87395 ms - Host latency: 0.890723 ms (enqueue 0.877393 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.873779 ms - Host latency: 0.89021 ms (enqueue 0.876489 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.878711 ms - Host latency: 0.893701 ms (enqueue 0.882422 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.87207 ms - Host latency: 0.886743 ms (enqueue 0.875269 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.871533 ms - Host latency: 0.885864 ms (enqueue 0.875537 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.871362 ms - Host latency: 0.885962 ms (enqueue 0.874658 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.873779 ms - Host latency: 0.888306 ms (enqueue 0.877515 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.874194 ms - Host latency: 0.888696 ms (enqueue 0.877808 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.879492 ms - Host latency: 0.89436 ms (enqueue 0.883374 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.874194 ms - Host latency: 0.888794 ms (enqueue 0.877539 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.870459 ms - Host latency: 0.884985 ms (enqueue 0.874609 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.871655 ms - Host latency: 0.886279 ms (enqueue 0.875122 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.885205 ms - Host latency: 0.902197 ms (enqueue 0.883936 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.88894 ms - Host latency: 0.905493 ms (enqueue 0.88562 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.886108 ms - Host latency: 0.902197 ms (enqueue 0.882959 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.889771 ms - Host latency: 0.907056 ms (enqueue 0.886621 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.885986 ms - Host latency: 0.901929 ms (enqueue 0.88291 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.886621 ms - Host latency: 0.902515 ms (enqueue 0.883594 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.888916 ms - Host latency: 0.908179 ms (enqueue 0.885718 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.889746 ms - Host latency: 0.906812 ms (enqueue 0.886279 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.886572 ms - Host latency: 0.902563 ms (enqueue 0.883301 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.884961 ms - Host latency: 0.90061 ms (enqueue 0.882105 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.888989 ms - Host latency: 0.905005 ms (enqueue 0.885986 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.888086 ms - Host latency: 0.904321 ms (enqueue 0.884961 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.888892 ms - Host latency: 0.907422 ms (enqueue 0.885913 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.87666 ms - Host latency: 0.891211 ms (enqueue 0.880566 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.871509 ms - Host latency: 0.886035 ms (enqueue 0.87478 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.871997 ms - Host latency: 0.886426 ms (enqueue 0.875391 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.87124 ms - Host latency: 0.88562 ms (enqueue 0.875269 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.873999 ms - Host latency: 0.888623 ms (enqueue 0.87749 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.873315 ms - Host latency: 0.887988 ms (enqueue 0.876709 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.872363 ms - Host latency: 0.886865 ms (enqueue 0.875537 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.870605 ms - Host latency: 0.885156 ms (enqueue 0.874756 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.871997 ms - Host latency: 0.886353 ms (enqueue 0.87644 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.871411 ms - Host latency: 0.885864 ms (enqueue 0.87522 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.874805 ms - Host latency: 0.889575 ms (enqueue 0.878613 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.870776 ms - Host latency: 0.885229 ms (enqueue 0.874683 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.871436 ms - Host latency: 0.886182 ms (enqueue 0.874585 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.872314 ms - Host latency: 0.886963 ms (enqueue 0.875635 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.878564 ms - Host latency: 0.893384 ms (enqueue 0.881689 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.89248 ms - Host latency: 0.909326 ms (enqueue 0.889453 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.887793 ms - Host latency: 0.903955 ms (enqueue 0.884595 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.891553 ms - Host latency: 0.907837 ms (enqueue 0.888428 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.886768 ms - Host latency: 0.903076 ms (enqueue 0.883594 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.886719 ms - Host latency: 0.905103 ms (enqueue 0.883716 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.887769 ms - Host latency: 0.904224 ms (enqueue 0.884912 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.886792 ms - Host latency: 0.903003 ms (enqueue 0.883667 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.888354 ms - Host latency: 0.904272 ms (enqueue 0.885522 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.887061 ms - Host latency: 0.902954 ms (enqueue 0.883984 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.886963 ms - Host latency: 0.902808 ms (enqueue 0.884058 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.887329 ms - Host latency: 0.90332 ms (enqueue 0.88396 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.895264 ms - Host latency: 0.912207 ms (enqueue 0.891528 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.881592 ms - Host latency: 0.89751 ms (enqueue 0.881348 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.870874 ms - Host latency: 0.885352 ms (enqueue 0.874512 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.873145 ms - Host latency: 0.8875 ms (enqueue 0.8771 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.872412 ms - Host latency: 0.887817 ms (enqueue 0.87627 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.870923 ms - Host latency: 0.885449 ms (enqueue 0.875269 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.886084 ms - Host latency: 0.906055 ms (enqueue 0.88606 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.878711 ms - Host latency: 0.893701 ms (enqueue 0.880591 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.87146 ms - Host latency: 0.885913 ms (enqueue 0.875342 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.876953 ms - Host latency: 0.891699 ms (enqueue 0.880615 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.871216 ms - Host latency: 0.88584 ms (enqueue 0.875757 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.875464 ms - Host latency: 0.890527 ms (enqueue 0.878418 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.877661 ms - Host latency: 0.892163 ms (enqueue 0.881421 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.873071 ms - Host latency: 0.890967 ms (enqueue 0.877295 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.872119 ms - Host latency: 0.88667 ms (enqueue 0.875562 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.873364 ms - Host latency: 0.888452 ms (enqueue 0.875903 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.891504 ms - Host latency: 0.907642 ms (enqueue 0.889185 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.892407 ms - Host latency: 0.909277 ms (enqueue 0.888867 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.888989 ms - Host latency: 0.905029 ms (enqueue 0.885596 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.890796 ms - Host latency: 0.908716 ms (enqueue 0.887646 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.886353 ms - Host latency: 0.902417 ms (enqueue 0.88352 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.887891 ms - Host latency: 0.904077 ms (enqueue 0.885059 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.889941 ms - Host latency: 0.906641 ms (enqueue 0.886963 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.88623 ms - Host latency: 0.902637 ms (enqueue 0.883667 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.8875 ms - Host latency: 0.90437 ms (enqueue 0.884155 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.887183 ms - Host latency: 0.903491 ms (enqueue 0.883862 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.887646 ms - Host latency: 0.904077 ms (enqueue 0.884619 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.892773 ms - Host latency: 0.909326 ms (enqueue 0.889404 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.886133 ms - Host latency: 0.901929 ms (enqueue 0.884692 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.870483 ms - Host latency: 0.884863 ms (enqueue 0.874316 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.872021 ms - Host latency: 0.886694 ms (enqueue 0.876172 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.872461 ms - Host latency: 0.886987 ms (enqueue 0.876196 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.877222 ms - Host latency: 0.891724 ms (enqueue 0.881494 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.878662 ms - Host latency: 0.893677 ms (enqueue 0.881372 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.872803 ms - Host latency: 0.887256 ms (enqueue 0.876733 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.873486 ms - Host latency: 0.888159 ms (enqueue 0.877783 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.873169 ms - Host latency: 0.887622 ms (enqueue 0.875195 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.872363 ms - Host latency: 0.889893 ms (enqueue 0.875732 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.874853 ms - Host latency: 0.889844 ms (enqueue 0.876953 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.875244 ms - Host latency: 0.889697 ms (enqueue 0.878784 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.872656 ms - Host latency: 0.88728 ms (enqueue 0.876367 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.875781 ms - Host latency: 0.894312 ms (enqueue 0.878906 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.875024 ms - Host latency: 0.889697 ms (enqueue 0.877271 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.894019 ms - Host latency: 0.910693 ms (enqueue 0.89231 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.893188 ms - Host latency: 0.910156 ms (enqueue 0.88999 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.890478 ms - Host latency: 0.907471 ms (enqueue 0.887109 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.893384 ms - Host latency: 0.91023 ms (enqueue 0.889941 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.888159 ms - Host latency: 0.904932 ms (enqueue 0.885181 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.89248 ms - Host latency: 0.909985 ms (enqueue 0.889209 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.891016 ms - Host latency: 0.9073 ms (enqueue 0.887939 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.886816 ms - Host latency: 0.902637 ms (enqueue 0.883887 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.886475 ms - Host latency: 0.902441 ms (enqueue 0.883472 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.889478 ms - Host latency: 0.905078 ms (enqueue 0.886426 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.886792 ms - Host latency: 0.902954 ms (enqueue 0.883618 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.89126 ms - Host latency: 0.910034 ms (enqueue 0.888428 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.887744 ms - Host latency: 0.903955 ms (enqueue 0.885278 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.872144 ms - Host latency: 0.887036 ms (enqueue 0.875928 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.871436 ms - Host latency: 0.886011 ms (enqueue 0.875317 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.877539 ms - Host latency: 0.892285 ms (enqueue 0.878955 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.872144 ms - Host latency: 0.886645 ms (enqueue 0.876123 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.877246 ms - Host latency: 0.892261 ms (enqueue 0.87981 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.874927 ms - Host latency: 0.889331 ms (enqueue 0.878491 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.872754 ms - Host latency: 0.890625 ms (enqueue 0.875854 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.876318 ms - Host latency: 0.890796 ms (enqueue 0.880298 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.872217 ms - Host latency: 0.88689 ms (enqueue 0.87605 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.87207 ms - Host latency: 0.886475 ms (enqueue 0.876245 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.875879 ms - Host latency: 0.890747 ms (enqueue 0.878857 ms)\n",
      "[01/20/2023-00:27:03] [I] Average on 10 runs - GPU latency: 0.870386 ms - Host latency: 0.884961 ms (enqueue 0.874121 ms)\n",
      "[01/20/2023-00:27:03] [I] \n",
      "[01/20/2023-00:27:03] [I] === Performance summary ===\n",
      "[01/20/2023-00:27:03] [I] Throughput: 1077.11 qps\n",
      "[01/20/2023-00:27:03] [I] Latency: min = 0.878418 ms, max = 1.10229 ms, mean = 0.896966 ms, median = 0.898438 ms, percentile(90%) = 0.908813 ms, percentile(95%) = 0.914795 ms, percentile(99%) = 0.935547 ms\n",
      "[01/20/2023-00:27:03] [I] Enqueue Time: min = 0.868408 ms, max = 0.969833 ms, mean = 0.881234 ms, median = 0.880676 ms, percentile(90%) = 0.888672 ms, percentile(95%) = 0.893066 ms, percentile(99%) = 0.910217 ms\n",
      "[01/20/2023-00:27:03] [I] H2D Latency: min = 0.00952148 ms, max = 0.0569 ms, mean = 0.0112097 ms, median = 0.0106201 ms, percentile(90%) = 0.0115967 ms, percentile(95%) = 0.0117798 ms, percentile(99%) = 0.0302734 ms\n",
      "[01/20/2023-00:27:03] [I] GPU Compute Time: min = 0.864258 ms, max = 0.972794 ms, mean = 0.880896 ms, median = 0.882568 ms, percentile(90%) = 0.891846 ms, percentile(95%) = 0.895996 ms, percentile(99%) = 0.916443 ms\n",
      "[01/20/2023-00:27:03] [I] D2H Latency: min = 0.00341797 ms, max = 0.0741425 ms, mean = 0.00485631 ms, median = 0.00439453 ms, percentile(90%) = 0.00537109 ms, percentile(95%) = 0.00585938 ms, percentile(99%) = 0.0090332 ms\n",
      "[01/20/2023-00:27:03] [W] * Throughput may be bound by Enqueue Time rather than GPU Compute and the GPU may be under-utilized.\n",
      "[01/20/2023-00:27:03] [W]   If not already in use, --useCudaGraph (utilize CUDA graphs where possible) may increase the throughput.\n",
      "[01/20/2023-00:27:03] [W] * GPU compute time is unstable, with coefficient of variance = 1.18585%.\n",
      "[01/20/2023-00:27:03] [W]   If not already in use, locking GPU clock frequency or adding --useSpinWait may improve the stability.\n",
      "[01/20/2023-00:27:03] [I] Total Host Walltime: 3.00154 s\n",
      "[01/20/2023-00:27:03] [I] Total GPU Compute Time: 2.84794 s\n",
      "[01/20/2023-00:27:03] [I] Explanations of the performance metrics are printed in the verbose logs.\n",
      "[01/20/2023-00:27:03] [V] \n",
      "[01/20/2023-00:27:03] [V] === Explanations of the performance metrics ===\n",
      "[01/20/2023-00:27:03] [V] Total Host Walltime: the host walltime from when the first query (after warmups) is enqueued to when the last query is completed.\n",
      "[01/20/2023-00:27:03] [V] GPU Compute Time: the GPU latency to execute the kernels for a query.\n",
      "[01/20/2023-00:27:03] [V] Total GPU Compute Time: the summation of the GPU Compute Time of all the queries. If this is significantly shorter than Total Host Walltime, the GPU may be under-utilized because of host-side overheads or data transfers.\n",
      "[01/20/2023-00:27:03] [V] Throughput: the observed throughput computed by dividing the number of queries by the Total Host Walltime. If this is significantly lower than the reciprocal of GPU Compute Time, the GPU may be under-utilized because of host-side overheads or data transfers.\n",
      "[01/20/2023-00:27:03] [V] Enqueue Time: the host latency to enqueue a query. If this is longer than GPU Compute Time, the GPU may be under-utilized.\n",
      "[01/20/2023-00:27:03] [V] H2D Latency: the latency for host-to-device data transfers for input tensors of a single query.\n",
      "[01/20/2023-00:27:03] [V] D2H Latency: the latency for device-to-host data transfers for output tensors of a single query.\n",
      "[01/20/2023-00:27:03] [V] Latency: the summation of H2D Latency, GPU Compute Time, and D2H Latency. This is the latency to infer a single query.\n",
      "[01/20/2023-00:27:03] [I] \n",
      "&&&& PASSED TensorRT.trtexec [TensorRT v8501] # trtexec --onnx=/workspace/onnx/model.onnx --saveEngine=/workspace/model.plan --minShapes=input_ids:1x128,attention_mask:1x128,token_type_ids:1x128 --optShapes=input_ids:16x128,attention_mask:16x128,token_type_ids:16x128 --maxShapes=input_ids:224x128,attention_mask:224x128,token_type_ids:224x128 --fp16 --verbose --memPoolSize=workspace:14000\n",
      "Finished exporting all models...\n"
     ]
    }
   ],
   "source": [
    "!docker run --gpus=all --rm -it --ipc=host --ulimit memlock=-1 --ulimit stack=67108864 \\\n",
    "            -v `pwd`/workspace:/workspace -w /workspace nvcr.io/nvidia/pytorch:22.12-py3 \\\n",
    "            /bin/bash generate_model_trt.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3610b257-20d2-4f16-8f05-e482d42608a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p model_repository/xdistilbert_trt/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "440d9fdb-b6d0-40fd-bd29-96a53a6a1971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting model_repository/xdistilbert_trt/config.pbtxt\n"
     ]
    }
   ],
   "source": [
    "%%writefile model_repository/xdistilbert_trt/config.pbtxt\n",
    "name: \"xdistilbert_trt\"\n",
    "backend: \"tensorrt\"\n",
    "max_batch_size: 224\n",
    "input [\n",
    "  {\n",
    "    name: \"input_ids\"\n",
    "    data_type: TYPE_INT32\n",
    "    dims: [128]\n",
    "  },\n",
    "  {\n",
    "    name: \"attention_mask\"\n",
    "    data_type: TYPE_INT32\n",
    "    dims: [128]\n",
    "  },\n",
    "  {\n",
    "    name: \"token_type_ids\"\n",
    "    data_type: TYPE_INT32\n",
    "    dims: [128]\n",
    "  }\n",
    "]\n",
    "output [\n",
    "  {\n",
    "    name: \"logits\"\n",
    "    data_type: TYPE_FP32\n",
    "    dims: [6]\n",
    "  }\n",
    "]\n",
    "instance_group {\n",
    "  count: 1\n",
    "  kind: KIND_GPU\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d67ee3-e301-4edb-a6d4-d0b1f35ad2b3",
   "metadata": {},
   "source": [
    "### Export model artifacts to S3 <a class=\"anchor\" id=\"export-to-s3\"></a>\n",
    "\n",
    "SageMaker expects the model artifacts in below format, it should also satisfy Triton container requirements such as model name, version, config.pbtxt files etc. `tar` the folder containing the model file and upload it to s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "55fb9432-5c5f-449e-88c3-11d1d842af41",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p model_repository/xdistilbert_pt/1/\n",
    "!cp -f workspace/model.pt model_repository/xdistilbert_pt/1/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5022a48f-5d52-4697-8b12-f00fc297f420",
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -C model_repository -czf $pytorch_model_file_name xdistilbert_pt\n",
    "model_uri_pt = sagemaker_session.upload_data(path=pytorch_model_file_name, key_prefix=prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c6f5a7b9-416e-40aa-be62-d956d52146f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Model S3 location: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_pt.tar.gz\n"
     ]
    }
   ],
   "source": [
    "print(f\"PyTorch Model S3 location: {model_uri_pt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d8f302c9-f4a1-449a-b381-834100100f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p model_repository/xdistilbert_trt/1/\n",
    "!cp -f workspace/model.plan model_repository/xdistilbert_trt/1/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "296c069a-2fad-4e22-891a-cf0a05920327",
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -C model_repository -czf $tensorrt_model_file_name xdistilbert_trt\n",
    "model_uri_trt = sagemaker_session.upload_data(path=tensorrt_model_file_name, key_prefix=prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0d49ab86-fcb1-467b-96a9-4ce518914b18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorRT Model S3 location: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz\n"
     ]
    }
   ],
   "source": [
    "print(f\"TensorRT Model S3 location: {model_uri_trt}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cab8f41-08e5-4999-98e7-92ee2852940d",
   "metadata": {},
   "source": [
    "### Deploy Models with MME <a class=\"anchor\" id=\"deploy-models-with-mme\"></a>\n",
    "\n",
    "We will now deploy xtreme distilBERT model with different framework backends i.e. PyTorch, TensorRT to SageMaker MME.\n",
    "\n",
    "\n",
    "<div class=\"alert alert-info\"> <strong> Note </strong>\n",
    "you can deploy 1000s of models. The models can use same framework. They can also use different frameworks as shown in this note.\n",
    "</div>\n",
    "\n",
    "We will use AWS SDK for Python (Boto) APIs [create_model](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/sagemaker.html#SageMaker.Client.create_model), [create_endpoint_config](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/sagemaker.html#SageMaker.Client.create_endpoint_config) and [create_endpoint](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/sagemaker.html#SageMaker.Client.create_endpoint) to create a mulit-model endpoint."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca1f6b1-c210-484f-8bfb-4c05f84be0d3",
   "metadata": {},
   "source": [
    "### Define the serving container  <a class=\"anchor\" id=\"define-container-def\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400c2773-10f6-4b18-bf8b-6a974ae2daf2",
   "metadata": {},
   "source": [
    " In the container definition, define the `ModelDataUrl` to specify the S3 directory that contains all the models that SageMaker multi-model endpoint will use to load  and serve predictions. Set `Mode` to `MultiModel` to indicates SageMaker would create the endpoint with MME container specifications. We set the container with an image that supports deploying multi-model endpoints with GPU, see MME [container images](https://docs.aws.amazon.com/sagemaker/latest/dg/multi-model-endpoints.html#multi-model-support) for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6379000a-3116-4ed4-851b-a041e4cfb3bf",
   "metadata": {},
   "source": [
    "### SageMaker Triton Container Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25758107-1d7a-4085-8a6a-908844f03ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# account mapping for SageMaker MME Triton Image\n",
    "account_id_map = {\n",
    "    \"us-east-1\": \"785573368785\",\n",
    "    \"us-east-2\": \"007439368137\",\n",
    "    \"us-west-1\": \"710691900526\",\n",
    "    \"us-west-2\": \"301217895009\",\n",
    "    \"eu-west-1\": \"802834080501\",\n",
    "    \"eu-west-2\": \"205493899709\",\n",
    "    \"eu-west-3\": \"254080097072\",\n",
    "    \"eu-north-1\": \"601324751636\",\n",
    "    \"eu-south-1\": \"966458181534\",\n",
    "    \"eu-central-1\": \"746233611703\",\n",
    "    \"ap-east-1\": \"110948597952\",\n",
    "    \"ap-south-1\": \"763008648453\",\n",
    "    \"ap-northeast-1\": \"941853720454\",\n",
    "    \"ap-northeast-2\": \"151534178276\",\n",
    "    \"ap-southeast-1\": \"324986816169\",\n",
    "    \"ap-southeast-2\": \"355873309152\",\n",
    "    \"cn-northwest-1\": \"474822919863\",\n",
    "    \"cn-north-1\": \"472730292857\",\n",
    "    \"sa-east-1\": \"756306329178\",\n",
    "    \"ca-central-1\": \"464438896020\",\n",
    "    \"me-south-1\": \"836785723513\",\n",
    "    \"af-south-1\": \"774647643957\",\n",
    "}\n",
    "\n",
    "region = boto3.Session().region_name\n",
    "if region not in account_id_map.keys():\n",
    "    raise (\"UNSUPPORTED REGION\")\n",
    "\n",
    "base = \"amazonaws.com.cn\" if region.startswith(\"cn-\") else \"amazonaws.com\"\n",
    "mme_triton_image_uri = (\n",
    "    \"{account_id}.dkr.ecr.{region}.{base}/sagemaker-tritonserver:22.12-py3\".format(\n",
    "        account_id=account_id_map[region], region=region, base=base\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53b00914-a237-4455-a08c-d79b3715cac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "container = {\"Image\": mme_triton_image_uri, \"ModelDataUrl\": model_data_url, \"Mode\": \"MultiModel\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e28483-e6cf-4769-b6f3-4ccaa61471ec",
   "metadata": {},
   "source": [
    "### Create a MME object <a class=\"anchor\" id=\"create-mme-model-obj\"></a>\n",
    "\n",
    "Using the SageMaker boto3 client, create the model using [create_model](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/sagemaker.html#SageMaker.Client.create_model) API. We will pass the container definition to the create model API along with ModelName and ExecutionRoleArn.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2077c860-1ef6-42f6-b10b-c77e075d2be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Arn: arn:aws:sagemaker:us-west-2:354625738399:model/mme-gpu-mdl-2023-01-20-02-09-04\n"
     ]
    }
   ],
   "source": [
    "create_model_response = sm_client.create_model(\n",
    "    ModelName=sm_model_name, ExecutionRoleArn=role, PrimaryContainer=container\n",
    ")\n",
    "\n",
    "print(\"Model Arn: \" + create_model_response[\"ModelArn\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a8e07e-1410-471e-9c2c-10e0c23db00f",
   "metadata": {},
   "source": [
    "### Define configuration for the MME<a class=\"anchor\" id=\"config-mme\"></a>\n",
    "\n",
    "Create a multi-model endpoint configuration using [create_endpoint_config](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/sagemaker.html#SageMaker.Client.create_endpoint_config) boto3 API. Specify an accelerated GPU computing instance in InstanceType (we will use the same instance type that we are using to host our SageMaker Notebook). We recommend configuring your endpoints with at least two instances with real-life use-cases. This allows SageMaker to provide a highly available set of predictions across multiple Availability Zones for the models.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1b55e160-8aa0-4ef7-84f5-cb975df99f4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint Config Arn: arn:aws:sagemaker:us-west-2:354625738399:endpoint-config/mme-gpu-epc-2023-01-20-02-09-04\n"
     ]
    }
   ],
   "source": [
    "create_endpoint_config_response = sm_client.create_endpoint_config(\n",
    "    EndpointConfigName=endpoint_config_name,\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            \"InstanceType\": instance_type,\n",
    "            \"InitialVariantWeight\": 1,\n",
    "            \"InitialInstanceCount\": 1,\n",
    "            \"ModelName\": sm_model_name,\n",
    "            \"VariantName\": \"AllTraffic\",\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(\"Endpoint Config Arn: \" + create_endpoint_config_response[\"EndpointConfigArn\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21943aee-7692-4048-9a47-256d8e21c112",
   "metadata": {},
   "source": [
    "### Create MME  <a class=\"anchor\" id=\"create-mme\"></a>\n",
    "\n",
    "Using the above endpoint configuration we create a new sagemaker endpoint and wait for the deployment to finish. The status will change to **InService** once the deployment is successful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1fc49275-e1c2-46c3-a8be-9e193c271262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint Arn: arn:aws:sagemaker:us-west-2:354625738399:endpoint/mme-gpu-ep-2023-01-20-02-09-04\n"
     ]
    }
   ],
   "source": [
    "create_endpoint_response = sm_client.create_endpoint(\n",
    "    EndpointName=endpoint_name, EndpointConfigName=endpoint_config_name\n",
    ")\n",
    "\n",
    "print(\"Endpoint Arn: \" + create_endpoint_response[\"EndpointArn\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7404e50c-9f66-4b27-9b9a-714f474cc1d9",
   "metadata": {},
   "source": [
    "### Describe MME <a class=\"anchor\" id=\"describe-mme\"></a>\n",
    "\n",
    "Now, we check the status of the endpoint using `describe_endpoint`. This step will take about 5 mins to complete and you should see \"Status: InService\" message before you proceed to next cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1d7ac9f8-8ba9-4f37-a2cb-7dc6d428885d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: InService\n",
      "Arn: arn:aws:sagemaker:us-west-2:354625738399:endpoint/mme-gpu-ep-2023-01-20-02-09-04\n",
      "Status: InService\n"
     ]
    }
   ],
   "source": [
    "resp = sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "status = resp[\"EndpointStatus\"]\n",
    "print(\"Status: \" + status)\n",
    "\n",
    "while status == \"Creating\":\n",
    "    time.sleep(60)\n",
    "    resp = sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "    status = resp[\"EndpointStatus\"]\n",
    "    print(\"Status: \" + status)\n",
    "\n",
    "print(\"Arn: \" + resp[\"EndpointArn\"])\n",
    "print(\"Status: \" + status)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1a0ed6-ff2d-46cb-a396-4beef96b58d9",
   "metadata": {},
   "source": [
    "## Helper functions to prepare Input Payload <a class=\"anchor\" id=\"helper-functions\"></a>\n",
    "\n",
    "The following method transforms a sample image we will be using for inference into the payload that can be sent for inference to the Triton server. These will be used by PyTorch and TensorRT efficientnet_b0 computer vision models.\n",
    "\n",
    "The `tritonclient` package provides utility methods to generate the payload without having to know the details of the specification. We'll use the following methods to convert our inference request into a binary format which provides lower latencies for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "daae74d9-1058-4686-9f36-e297277d26e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tritonclient.http as httpclient\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer_name = \"bergum/xtremedistil-emotion\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "\n",
    "def tokenize_text(tokenizer, text):\n",
    "    MAX_LEN = 128\n",
    "    tokenized_text = tokenizer(text, padding='max_length', max_length=MAX_LEN, add_special_tokens=True, return_tensors='np')\n",
    "    return tokenized_text.input_ids, tokenized_text.attention_mask, tokenized_text.token_type_ids\n",
    "\n",
    "def _get_sample_tokenized_text_binary(text, input_names, output_names):\n",
    "    inputs = []\n",
    "    outputs = []\n",
    "    input_ids, attention_mask, token_type_ids = tokenize_text(tokenizer, text)\n",
    "    inputs.append(httpclient.InferInput(input_names[0], input_ids.shape, \"INT32\"))\n",
    "    inputs.append(httpclient.InferInput(input_names[1], attention_mask.shape, \"INT32\"))\n",
    "    inputs.append(httpclient.InferInput(input_names[2], token_type_ids.shape, \"INT32\"))\n",
    "\n",
    "    inputs[0].set_data_from_numpy(input_ids.astype(np.int32), binary_data=True)\n",
    "    inputs[1].set_data_from_numpy(attention_mask.astype(np.int32), binary_data=True)\n",
    "    inputs[2].set_data_from_numpy(token_type_ids.astype(np.int32), binary_data=True)\n",
    "    \n",
    "    outputs.append(httpclient.InferRequestedOutput(output_names[0], binary_data=True))\n",
    "    request_body, header_length = httpclient.InferenceServerClient.generate_request_body(\n",
    "        inputs, outputs=outputs\n",
    "    )\n",
    "    return request_body, header_length\n",
    "\n",
    "def get_sample_tokenized_text_binary_pt(text):\n",
    "    return _get_sample_tokenized_text_binary(text, [\"INPUT__0\", \"INPUT__1\", \"INPUT__2\"], [\"OUTPUT__0\"])\n",
    "\n",
    "\n",
    "def get_sample_tokenized_text_binary_trt(text):\n",
    "    return _get_sample_tokenized_text_binary(text, [\"input_ids\", \"attention_mask\", \"token_type_ids\"], [\"logits\"])\n",
    "\n",
    "def get_predictions(logits):\n",
    "    CLASSES = [\"SADNESS\", \"JOY\", \"LOVE\", \"ANGER\", \"FEAR\", \"SURPRISE\"]\n",
    "    predictions = []\n",
    "    for i in range(len(logits)):\n",
    "        pred_class_idx = np.argmax(logits[i])\n",
    "        predictions.append(CLASSES[pred_class_idx])\n",
    "    return predictions;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8887d53d-d9b4-41bf-ab74-07a86cecd04c",
   "metadata": {},
   "source": [
    "## Invoke target model on Multi Model Endpoint\n",
    "\n",
    "Once the endpoint is successfully created, we can send inference request to multi-model endpoint using invoke_enpoint API. We specify the TargetModel in the invocation call and pass in the payload for each model type. Sample invocation for PyTorch model and TensorRT model is shown below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef06a05c-ae58-484c-9fed-4c9584795c7f",
   "metadata": {},
   "source": [
    "### Invoke PyTorch Model <a class=\"anchor\" id=\"invoke-pytorch-model\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f4ab429b-5b9c-4edd-9ff7-5f974dd35924",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = \"I really enjoyed deploying thousands of NLP models using Triton on SageMaker Multi-Model Endpoint\"\n",
    "request_body, header_length = get_sample_tokenized_text_binary_pt(sample_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "72a804a1-216c-4a60-b6fd-403e66581459",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = runtime_sm_client.invoke_endpoint(EndpointName=endpoint_name,\n",
    "                                  ContentType='application/vnd.sagemaker-triton.binary+json;json-header-size={}'.format(header_length),\n",
    "                                  Body=request_body,\n",
    "                                  TargetModel='xdistilbert_pt.tar.gz')\n",
    "\n",
    "# Parse json header size length from the response\n",
    "header_length_prefix = \"application/vnd.sagemaker-triton.binary+json;json-header-size=\"\n",
    "header_length_str = response['ContentType'][len(header_length_prefix):]\n",
    "output_name = \"OUTPUT__0\"\n",
    "# Read response body\n",
    "result = httpclient.InferenceServerClient.parse_response_body(\n",
    "    response['Body'].read(), header_length=int(header_length_str))\n",
    "logits = result.as_numpy(output_name)\n",
    "predictions = get_predictions(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "79bc6330-8b84-4e38-ab5a-f0218c0f0d8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['JOY']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41729b83-9921-4f26-b7cf-74f9f81365fc",
   "metadata": {},
   "source": [
    "### Invoke TensorRT Model <a class=\"anchor\" id=\"invoke-tensorrt-model\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "097ea610-e5c1-431c-8168-1a11c3a1fcb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "request_body, header_length = get_sample_tokenized_text_binary_trt(sample_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "90afb76a-72ac-49b0-ae6d-313976bf94f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = runtime_sm_client.invoke_endpoint(EndpointName=endpoint_name,\n",
    "                                  ContentType='application/vnd.sagemaker-triton.binary+json;json-header-size={}'.format(header_length),\n",
    "                                  Body=request_body,\n",
    "                                  TargetModel='xdistilbert_trt.tar.gz')\n",
    "\n",
    "# Parse json header size length from the response\n",
    "header_length_prefix = \"application/vnd.sagemaker-triton.binary+json;json-header-size=\"\n",
    "header_length_str = response['ContentType'][len(header_length_prefix):]\n",
    "output_name = \"logits\"\n",
    "# Read response body\n",
    "result = httpclient.InferenceServerClient.parse_response_body(\n",
    "    response['Body'].read(), header_length=int(header_length_str))\n",
    "logits = result.as_numpy(output_name)\n",
    "predictions = get_predictions(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d9a7bfa5-80ca-477e-9ce5-c6bf545e2a96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['JOY']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05aa3d1a-c0f2-4809-a7e2-71056556c864",
   "metadata": {},
   "source": [
    "# Deploying 1000 Models to GPUs using MME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132f67b3-0eb6-4ead-8851-c89b2628cb1c",
   "metadata": {},
   "source": [
    "Let's say you have thousand customer-specific distilBERT models which are a mixture of frequently and infrequently accessed models coming from different frameworks (PyTorch, TensorFlow, ONNX, TensorRT) and let's assume most of which have stringent latency requirements.\n",
    "\n",
    "Deploying these 1000 models on GPU instances like `g5.xlarge` (price: `$1/hr`) using Single-Model Endpoints would take ~1000 instances costing you `$1,000`/hour.\n",
    "\n",
    "By leveraging Triton on SageMaker MME, you can deploy these models behind one MME endpoint which can autoscale the number of GPU instances automatically and end up using ~100x lower instances and thus cost would be reduced by ~100x. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccedb827-b9e7-4b54-98f4-f3effa813bc5",
   "metadata": {},
   "source": [
    "## Create 1000 models to be loaded to SageMaker MME\n",
    "\n",
    "This step will take around 10 minutes to complete as we are copying 1000 files to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7fd99243-9f2e-4954-8ec8-d9b9c8301ddb",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer1.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer2.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer3.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer4.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer5.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer6.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer7.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer8.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer9.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer10.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer11.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer12.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer13.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer14.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer15.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer16.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer17.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer18.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer19.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer20.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer21.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer22.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer23.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer24.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer25.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer26.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer27.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer28.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer29.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer30.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer31.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer32.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer33.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer34.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer35.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer36.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer37.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer38.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer39.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer40.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer41.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer42.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer43.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer44.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer45.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer46.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer47.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer48.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer49.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer50.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer51.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer52.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer53.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer54.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer55.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer56.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer57.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer58.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer59.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer60.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer61.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer62.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer63.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer64.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer65.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer66.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer67.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer68.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer69.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer70.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer71.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer72.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer73.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer74.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer75.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer76.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer77.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer78.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer79.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer80.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer81.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer82.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer83.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer84.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer85.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer86.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer87.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer88.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer89.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer90.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer91.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer92.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer93.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer94.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer95.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer96.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer97.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer98.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer99.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer100.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer101.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer102.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer103.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer104.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer105.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer106.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer107.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer108.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer109.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer110.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer111.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer112.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer113.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer114.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer115.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer116.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer117.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer118.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer119.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer120.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer121.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer122.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer123.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer124.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer125.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer126.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer127.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer128.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer129.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer130.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer131.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer132.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer133.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer134.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer135.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer136.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer137.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer138.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer139.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer140.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer141.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer142.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer143.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer144.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer145.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer146.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer147.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer148.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer149.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer150.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer151.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer152.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer153.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer154.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer155.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer156.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer157.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer158.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer159.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer160.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer161.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer162.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer163.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer164.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer165.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer166.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer167.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer168.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer169.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer170.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer171.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer172.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer173.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer174.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer175.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer176.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer177.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer178.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer179.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer180.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer181.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer182.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer183.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer184.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer185.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer186.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer187.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer188.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer189.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer190.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer191.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer192.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer193.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer194.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer195.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer196.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer197.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer198.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer199.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer200.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer201.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer202.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer203.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer204.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer205.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer206.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer207.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer208.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer209.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer210.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer211.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer212.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer213.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer214.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer215.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer216.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer217.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer218.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer219.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer220.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer221.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer222.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer223.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer224.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer225.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer226.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer227.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer228.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer229.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer230.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer231.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer232.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer233.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer234.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer235.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer236.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer237.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer238.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer239.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer240.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer241.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer242.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer243.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer244.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer245.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer246.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer247.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer248.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer249.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer250.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer251.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer252.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer253.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer254.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer255.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer256.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer257.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer258.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer259.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer260.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer261.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer262.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer263.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer264.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer265.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer266.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer267.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer268.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer269.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer270.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer271.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer272.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer273.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer274.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer275.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer276.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer277.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer278.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer279.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer280.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer281.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer282.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer283.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer284.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer285.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer286.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer287.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer288.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer289.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer290.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer291.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer292.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer293.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer294.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer295.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer296.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer297.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer298.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer299.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer300.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer301.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer302.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer303.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer304.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer305.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer306.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer307.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer308.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer309.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer310.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer311.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer312.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer313.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer314.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer315.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer316.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer317.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer318.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer319.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer320.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer321.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer322.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer323.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer324.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer325.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer326.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer327.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer328.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer329.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer330.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer331.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer332.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer333.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer334.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer335.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer336.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer337.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer338.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer339.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer340.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer341.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer342.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer343.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer344.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer345.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer346.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer347.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer348.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer349.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer350.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer351.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer352.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer353.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer354.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer355.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer356.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer357.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer358.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer359.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer360.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer361.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer362.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer363.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer364.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer365.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer366.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer367.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer368.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer369.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer370.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer371.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer372.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer373.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer374.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer375.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer376.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer377.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer378.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer379.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer380.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer381.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer382.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer383.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer384.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer385.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer386.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer387.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer388.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer389.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer390.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer391.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer392.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer393.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer394.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer395.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer396.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer397.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer398.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer399.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer400.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer401.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer402.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer403.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer404.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer405.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer406.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer407.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer408.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer409.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer410.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer411.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer412.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer413.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer414.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer415.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer416.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer417.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer418.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer419.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer420.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer421.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer422.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer423.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer424.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer425.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer426.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer427.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer428.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer429.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer430.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer431.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer432.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer433.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer434.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer435.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer436.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer437.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer438.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer439.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer440.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer441.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer442.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer443.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer444.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer445.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer446.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer447.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer448.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer449.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer450.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer451.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer452.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer453.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer454.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer455.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer456.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer457.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer458.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer459.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer460.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer461.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer462.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer463.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer464.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer465.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer466.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer467.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer468.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer469.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer470.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer471.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer472.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer473.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer474.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer475.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer476.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer477.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer478.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer479.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer480.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer481.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer482.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer483.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer484.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer485.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer486.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer487.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer488.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer489.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer490.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer491.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer492.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer493.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer494.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer495.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer496.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer497.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer498.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer499.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer500.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer501.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer502.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer503.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer504.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer505.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer506.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer507.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer508.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer509.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer510.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer511.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer512.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer513.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer514.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer515.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer516.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer517.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer518.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer519.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer520.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer521.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer522.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer523.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer524.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer525.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer526.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer527.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer528.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer529.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer530.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer531.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer532.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer533.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer534.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer535.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer536.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer537.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer538.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer539.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer540.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer541.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer542.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer543.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer544.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer545.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer546.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer547.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer548.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer549.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer550.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer551.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer552.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer553.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer554.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer555.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer556.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer557.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer558.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer559.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer560.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer561.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer562.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer563.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer564.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer565.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer566.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer567.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer568.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer569.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer570.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer571.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer572.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer573.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer574.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer575.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer576.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer577.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer578.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer579.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer580.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer581.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer582.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer583.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer584.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer585.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer586.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer587.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer588.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer589.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer590.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer591.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer592.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer593.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer594.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer595.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer596.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer597.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer598.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer599.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer600.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer601.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer602.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer603.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer604.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer605.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer606.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer607.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer608.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer609.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer610.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer611.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer612.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer613.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer614.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer615.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer616.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer617.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer618.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer619.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer620.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer621.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer622.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer623.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer624.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer625.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer626.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer627.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer628.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer629.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer630.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer631.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer632.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer633.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer634.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer635.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer636.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer637.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer638.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer639.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer640.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer641.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer642.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer643.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer644.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer645.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer646.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer647.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer648.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer649.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer650.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer651.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer652.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer653.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer654.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer655.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer656.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer657.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer658.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer659.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer660.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer661.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer662.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer663.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer664.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer665.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer666.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer667.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer668.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer669.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer670.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer671.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer672.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer673.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer674.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer675.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer676.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer677.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer678.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer679.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer680.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer681.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer682.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer683.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer684.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer685.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer686.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer687.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer688.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer689.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer690.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer691.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer692.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer693.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer694.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer695.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer696.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer697.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer698.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer699.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer700.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer701.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer702.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer703.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer704.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer705.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer706.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer707.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer708.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer709.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer710.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer711.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer712.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer713.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer714.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer715.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer716.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer717.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer718.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer719.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer720.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer721.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer722.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer723.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer724.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer725.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer726.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer727.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer728.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer729.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer730.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer731.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer732.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer733.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer734.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer735.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer736.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer737.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer738.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer739.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer740.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer741.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer742.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer743.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer744.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer745.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer746.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer747.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer748.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer749.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer750.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer751.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer752.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer753.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer754.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer755.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer756.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer757.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer758.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer759.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer760.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer761.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer762.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer763.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer764.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer765.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer766.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer767.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer768.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer769.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer770.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer771.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer772.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer773.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer774.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer775.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer776.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer777.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer778.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer779.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer780.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer781.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer782.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer783.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer784.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer785.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer786.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer787.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer788.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer789.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer790.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer791.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer792.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer793.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer794.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer795.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer796.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer797.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer798.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer799.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer800.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer801.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer802.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer803.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer804.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer805.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer806.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer807.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer808.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer809.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer810.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer811.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer812.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer813.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer814.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer815.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer816.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer817.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer818.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer819.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer820.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer821.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer822.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer823.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer824.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer825.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer826.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer827.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer828.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer829.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer830.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer831.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer832.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer833.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer834.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer835.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer836.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer837.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer838.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer839.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer840.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer841.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer842.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer843.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer844.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer845.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer846.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer847.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer848.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer849.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer850.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer851.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer852.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer853.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer854.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer855.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer856.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer857.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer858.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer859.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer860.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer861.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer862.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer863.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer864.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer865.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer866.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer867.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer868.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer869.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer870.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer871.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer872.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer873.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer874.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer875.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer876.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer877.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer878.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer879.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer880.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer881.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer882.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer883.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer884.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer885.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer886.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer887.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer888.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer889.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer890.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer891.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer892.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer893.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer894.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer895.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer896.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer897.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer898.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer899.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer900.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer901.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer902.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer903.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer904.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer905.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer906.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer907.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer908.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer909.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer910.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer911.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer912.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer913.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer914.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer915.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer916.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer917.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer918.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer919.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer920.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer921.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer922.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer923.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer924.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer925.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer926.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer927.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer928.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer929.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer930.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer931.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer932.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer933.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer934.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer935.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer936.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer937.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer938.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer939.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer940.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer941.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer942.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer943.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer944.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer945.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer946.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer947.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer948.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer949.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer950.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer951.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer952.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer953.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer954.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer955.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer956.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer957.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer958.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer959.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer960.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer961.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer962.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer963.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer964.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer965.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer966.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer967.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer968.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer969.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer970.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer971.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer972.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer973.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer974.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer975.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer976.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer977.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer978.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer979.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer980.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer981.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer982.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer983.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer984.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer985.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer986.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer987.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer988.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer989.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer990.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer991.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer992.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer993.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer994.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer995.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer996.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer997.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer998.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer999.tar.gz\n",
      "copy: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz to s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_customer1000.tar.gz\n"
     ]
    }
   ],
   "source": [
    "NUM_MODELS = 1000\n",
    "for i in range(1, NUM_MODELS+1):\n",
    "    customer_model_name = f\"xdistilbert_customer{i}.tar.gz\"\n",
    "    model_copy = f\"{model_data_url}{customer_model_name}\"\n",
    "    !aws s3 cp $model_data_url$tensorrt_model_file_name $model_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "25d3899f-eaf1-4e65-b213-0c37a0e983e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delete: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz\n",
      "delete: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_pt.tar.gz\n",
      "delete: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt_v0.tar.gz\n",
      "delete: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_pt_v0.tar.gz\n"
     ]
    }
   ],
   "source": [
    "# !aws s3 rm $model_data_url --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf62ede8-5e19-4dc7-9cb8-aaa8756b829d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-20 01:12:07   29235288 xdistilbert_customer1.tar.gz\n",
      "2023-01-20 01:12:16   29235288 xdistilbert_customer10.tar.gz\n",
      "2023-01-20 01:13:49   29235288 xdistilbert_customer100.tar.gz\n",
      "2023-01-20 01:29:24   29235288 xdistilbert_customer1000.tar.gz\n",
      "2023-01-20 01:13:49   29235288 xdistilbert_customer101.tar.gz\n",
      "2023-01-20 01:13:51   29235288 xdistilbert_customer102.tar.gz\n",
      "2023-01-20 01:13:52   29235288 xdistilbert_customer103.tar.gz\n",
      "2023-01-20 01:13:52   29235288 xdistilbert_customer104.tar.gz\n",
      "2023-01-20 01:13:53   29235288 xdistilbert_customer105.tar.gz\n",
      "2023-01-20 01:13:55   29235288 xdistilbert_customer106.tar.gz\n",
      "2023-01-20 01:13:55   29235288 xdistilbert_customer107.tar.gz\n",
      "2023-01-20 01:13:56   29235288 xdistilbert_customer108.tar.gz\n",
      "2023-01-20 01:13:57   29235288 xdistilbert_customer109.tar.gz\n",
      "2023-01-20 01:12:17   29235288 xdistilbert_customer11.tar.gz\n",
      "2023-01-20 01:13:58   29235288 xdistilbert_customer110.tar.gz\n",
      "2023-01-20 01:13:59   29235288 xdistilbert_customer111.tar.gz\n",
      "2023-01-20 01:14:01   29235288 xdistilbert_customer112.tar.gz\n",
      "2023-01-20 01:14:02   29235288 xdistilbert_customer113.tar.gz\n",
      "2023-01-20 01:14:03   29235288 xdistilbert_customer114.tar.gz\n",
      "2023-01-20 01:14:04   29235288 xdistilbert_customer115.tar.gz\n",
      "2023-01-20 01:14:05   29235288 xdistilbert_customer116.tar.gz\n",
      "2023-01-20 01:14:06   29235288 xdistilbert_customer117.tar.gz\n",
      "2023-01-20 01:14:08   29235288 xdistilbert_customer118.tar.gz\n",
      "2023-01-20 01:14:09   29235288 xdistilbert_customer119.tar.gz\n",
      "2023-01-20 01:12:18   29235288 xdistilbert_customer12.tar.gz\n",
      "2023-01-20 01:14:10   29235288 xdistilbert_customer120.tar.gz\n",
      "2023-01-20 01:14:11   29235288 xdistilbert_customer121.tar.gz\n",
      "2023-01-20 01:14:12   29235288 xdistilbert_customer122.tar.gz\n",
      "2023-01-20 01:14:13   29235288 xdistilbert_customer123.tar.gz\n",
      "2023-01-20 01:14:14   29235288 xdistilbert_customer124.tar.gz\n",
      "2023-01-20 01:14:15   29235288 xdistilbert_customer125.tar.gz\n",
      "2023-01-20 01:14:18   29235288 xdistilbert_customer126.tar.gz\n",
      "2023-01-20 01:14:19   29235288 xdistilbert_customer127.tar.gz\n",
      "2023-01-20 01:14:20   29235288 xdistilbert_customer128.tar.gz\n",
      "2023-01-20 01:14:21   29235288 xdistilbert_customer129.tar.gz\n",
      "2023-01-20 01:12:19   29235288 xdistilbert_customer13.tar.gz\n",
      "2023-01-20 01:14:22   29235288 xdistilbert_customer130.tar.gz\n",
      "2023-01-20 01:14:23   29235288 xdistilbert_customer131.tar.gz\n",
      "2023-01-20 01:14:24   29235288 xdistilbert_customer132.tar.gz\n",
      "2023-01-20 01:14:25   29235288 xdistilbert_customer133.tar.gz\n",
      "2023-01-20 01:14:26   29235288 xdistilbert_customer134.tar.gz\n",
      "2023-01-20 01:14:27   29235288 xdistilbert_customer135.tar.gz\n",
      "2023-01-20 01:14:28   29235288 xdistilbert_customer136.tar.gz\n",
      "2023-01-20 01:14:29   29235288 xdistilbert_customer137.tar.gz\n",
      "2023-01-20 01:14:30   29235288 xdistilbert_customer138.tar.gz\n",
      "2023-01-20 01:14:31   29235288 xdistilbert_customer139.tar.gz\n",
      "2023-01-20 01:12:20   29235288 xdistilbert_customer14.tar.gz\n",
      "2023-01-20 01:14:32   29235288 xdistilbert_customer140.tar.gz\n",
      "2023-01-20 01:14:33   29235288 xdistilbert_customer141.tar.gz\n",
      "2023-01-20 01:14:34   29235288 xdistilbert_customer142.tar.gz\n",
      "2023-01-20 01:14:35   29235288 xdistilbert_customer143.tar.gz\n",
      "2023-01-20 01:14:36   29235288 xdistilbert_customer144.tar.gz\n",
      "2023-01-20 01:14:37   29235288 xdistilbert_customer145.tar.gz\n",
      "2023-01-20 01:14:38   29235288 xdistilbert_customer146.tar.gz\n",
      "2023-01-20 01:14:39   29235288 xdistilbert_customer147.tar.gz\n",
      "2023-01-20 01:14:40   29235288 xdistilbert_customer148.tar.gz\n",
      "2023-01-20 01:14:41   29235288 xdistilbert_customer149.tar.gz\n",
      "2023-01-20 01:12:21   29235288 xdistilbert_customer15.tar.gz\n",
      "2023-01-20 01:14:42   29235288 xdistilbert_customer150.tar.gz\n",
      "2023-01-20 01:14:43   29235288 xdistilbert_customer151.tar.gz\n",
      "2023-01-20 01:14:44   29235288 xdistilbert_customer152.tar.gz\n",
      "2023-01-20 01:14:45   29235288 xdistilbert_customer153.tar.gz\n",
      "2023-01-20 01:14:46   29235288 xdistilbert_customer154.tar.gz\n",
      "2023-01-20 01:14:47   29235288 xdistilbert_customer155.tar.gz\n",
      "2023-01-20 01:14:48   29235288 xdistilbert_customer156.tar.gz\n",
      "2023-01-20 01:14:49   29235288 xdistilbert_customer157.tar.gz\n",
      "2023-01-20 01:14:50   29235288 xdistilbert_customer158.tar.gz\n",
      "2023-01-20 01:14:51   29235288 xdistilbert_customer159.tar.gz\n",
      "2023-01-20 01:12:22   29235288 xdistilbert_customer16.tar.gz\n",
      "2023-01-20 01:14:52   29235288 xdistilbert_customer160.tar.gz\n",
      "2023-01-20 01:14:53   29235288 xdistilbert_customer161.tar.gz\n",
      "2023-01-20 01:14:54   29235288 xdistilbert_customer162.tar.gz\n",
      "2023-01-20 01:14:55   29235288 xdistilbert_customer163.tar.gz\n",
      "2023-01-20 01:14:56   29235288 xdistilbert_customer164.tar.gz\n",
      "2023-01-20 01:14:57   29235288 xdistilbert_customer165.tar.gz\n",
      "2023-01-20 01:14:58   29235288 xdistilbert_customer166.tar.gz\n",
      "2023-01-20 01:14:59   29235288 xdistilbert_customer167.tar.gz\n",
      "2023-01-20 01:15:00   29235288 xdistilbert_customer168.tar.gz\n",
      "2023-01-20 01:15:01   29235288 xdistilbert_customer169.tar.gz\n",
      "2023-01-20 01:12:23   29235288 xdistilbert_customer17.tar.gz\n",
      "2023-01-20 01:15:02   29235288 xdistilbert_customer170.tar.gz\n",
      "2023-01-20 01:15:04   29235288 xdistilbert_customer171.tar.gz\n",
      "2023-01-20 01:15:05   29235288 xdistilbert_customer172.tar.gz\n",
      "2023-01-20 01:15:07   29235288 xdistilbert_customer173.tar.gz\n",
      "2023-01-20 01:15:08   29235288 xdistilbert_customer174.tar.gz\n",
      "2023-01-20 01:15:09   29235288 xdistilbert_customer175.tar.gz\n",
      "2023-01-20 01:15:10   29235288 xdistilbert_customer176.tar.gz\n",
      "2023-01-20 01:15:11   29235288 xdistilbert_customer177.tar.gz\n",
      "2023-01-20 01:15:12   29235288 xdistilbert_customer178.tar.gz\n",
      "2023-01-20 01:15:13   29235288 xdistilbert_customer179.tar.gz\n",
      "2023-01-20 01:12:24   29235288 xdistilbert_customer18.tar.gz\n",
      "2023-01-20 01:15:14   29235288 xdistilbert_customer180.tar.gz\n",
      "2023-01-20 01:15:15   29235288 xdistilbert_customer181.tar.gz\n",
      "2023-01-20 01:15:16   29235288 xdistilbert_customer182.tar.gz\n",
      "2023-01-20 01:15:17   29235288 xdistilbert_customer183.tar.gz\n",
      "2023-01-20 01:15:18   29235288 xdistilbert_customer184.tar.gz\n",
      "2023-01-20 01:15:19   29235288 xdistilbert_customer185.tar.gz\n",
      "2023-01-20 01:15:20   29235288 xdistilbert_customer186.tar.gz\n",
      "2023-01-20 01:15:21   29235288 xdistilbert_customer187.tar.gz\n",
      "2023-01-20 01:15:22   29235288 xdistilbert_customer188.tar.gz\n",
      "2023-01-20 01:15:23   29235288 xdistilbert_customer189.tar.gz\n",
      "2023-01-20 01:12:25   29235288 xdistilbert_customer19.tar.gz\n",
      "2023-01-20 01:15:24   29235288 xdistilbert_customer190.tar.gz\n",
      "2023-01-20 01:15:25   29235288 xdistilbert_customer191.tar.gz\n",
      "2023-01-20 01:15:26   29235288 xdistilbert_customer192.tar.gz\n",
      "2023-01-20 01:15:28   29235288 xdistilbert_customer193.tar.gz\n",
      "2023-01-20 01:15:29   29235288 xdistilbert_customer194.tar.gz\n",
      "2023-01-20 01:15:30   29235288 xdistilbert_customer195.tar.gz\n",
      "2023-01-20 01:15:31   29235288 xdistilbert_customer196.tar.gz\n",
      "2023-01-20 01:15:32   29235288 xdistilbert_customer197.tar.gz\n",
      "2023-01-20 01:15:33   29235288 xdistilbert_customer198.tar.gz\n",
      "2023-01-20 01:15:34   29235288 xdistilbert_customer199.tar.gz\n",
      "2023-01-20 01:12:08   29235288 xdistilbert_customer2.tar.gz\n",
      "2023-01-20 01:12:26   29235288 xdistilbert_customer20.tar.gz\n",
      "2023-01-20 01:15:35   29235288 xdistilbert_customer200.tar.gz\n",
      "2023-01-20 01:15:36   29235288 xdistilbert_customer201.tar.gz\n",
      "2023-01-20 01:15:37   29235288 xdistilbert_customer202.tar.gz\n",
      "2023-01-20 01:15:38   29235288 xdistilbert_customer203.tar.gz\n",
      "2023-01-20 01:15:39   29235288 xdistilbert_customer204.tar.gz\n",
      "2023-01-20 01:15:40   29235288 xdistilbert_customer205.tar.gz\n",
      "2023-01-20 01:15:41   29235288 xdistilbert_customer206.tar.gz\n",
      "2023-01-20 01:15:42   29235288 xdistilbert_customer207.tar.gz\n",
      "2023-01-20 01:15:43   29235288 xdistilbert_customer208.tar.gz\n",
      "2023-01-20 01:15:44   29235288 xdistilbert_customer209.tar.gz\n",
      "2023-01-20 01:12:27   29235288 xdistilbert_customer21.tar.gz\n",
      "2023-01-20 01:15:45   29235288 xdistilbert_customer210.tar.gz\n",
      "2023-01-20 01:15:46   29235288 xdistilbert_customer211.tar.gz\n",
      "2023-01-20 01:15:47   29235288 xdistilbert_customer212.tar.gz\n",
      "2023-01-20 01:15:48   29235288 xdistilbert_customer213.tar.gz\n",
      "2023-01-20 01:15:49   29235288 xdistilbert_customer214.tar.gz\n",
      "2023-01-20 01:15:50   29235288 xdistilbert_customer215.tar.gz\n",
      "2023-01-20 01:15:51   29235288 xdistilbert_customer216.tar.gz\n",
      "2023-01-20 01:15:52   29235288 xdistilbert_customer217.tar.gz\n",
      "2023-01-20 01:15:53   29235288 xdistilbert_customer218.tar.gz\n",
      "2023-01-20 01:15:54   29235288 xdistilbert_customer219.tar.gz\n",
      "2023-01-20 01:12:28   29235288 xdistilbert_customer22.tar.gz\n",
      "2023-01-20 01:15:57   29235288 xdistilbert_customer220.tar.gz\n",
      "2023-01-20 01:15:58   29235288 xdistilbert_customer221.tar.gz\n",
      "2023-01-20 01:15:59   29235288 xdistilbert_customer222.tar.gz\n",
      "2023-01-20 01:16:00   29235288 xdistilbert_customer223.tar.gz\n",
      "2023-01-20 01:16:01   29235288 xdistilbert_customer224.tar.gz\n",
      "2023-01-20 01:16:02   29235288 xdistilbert_customer225.tar.gz\n",
      "2023-01-20 01:16:03   29235288 xdistilbert_customer226.tar.gz\n",
      "2023-01-20 01:16:04   29235288 xdistilbert_customer227.tar.gz\n",
      "2023-01-20 01:16:05   29235288 xdistilbert_customer228.tar.gz\n",
      "2023-01-20 01:16:06   29235288 xdistilbert_customer229.tar.gz\n",
      "2023-01-20 01:12:29   29235288 xdistilbert_customer23.tar.gz\n",
      "2023-01-20 01:16:07   29235288 xdistilbert_customer230.tar.gz\n",
      "2023-01-20 01:16:08   29235288 xdistilbert_customer231.tar.gz\n",
      "2023-01-20 01:16:09   29235288 xdistilbert_customer232.tar.gz\n",
      "2023-01-20 01:16:10   29235288 xdistilbert_customer233.tar.gz\n",
      "2023-01-20 01:16:11   29235288 xdistilbert_customer234.tar.gz\n",
      "2023-01-20 01:16:15   29235288 xdistilbert_customer235.tar.gz\n",
      "2023-01-20 01:16:16   29235288 xdistilbert_customer236.tar.gz\n",
      "2023-01-20 01:16:17   29235288 xdistilbert_customer237.tar.gz\n",
      "2023-01-20 01:16:18   29235288 xdistilbert_customer238.tar.gz\n",
      "2023-01-20 01:16:19   29235288 xdistilbert_customer239.tar.gz\n",
      "2023-01-20 01:12:30   29235288 xdistilbert_customer24.tar.gz\n",
      "2023-01-20 01:16:20   29235288 xdistilbert_customer240.tar.gz\n",
      "2023-01-20 01:16:21   29235288 xdistilbert_customer241.tar.gz\n",
      "2023-01-20 01:16:22   29235288 xdistilbert_customer242.tar.gz\n",
      "2023-01-20 01:16:23   29235288 xdistilbert_customer243.tar.gz\n",
      "2023-01-20 01:16:24   29235288 xdistilbert_customer244.tar.gz\n",
      "2023-01-20 01:16:25   29235288 xdistilbert_customer245.tar.gz\n",
      "2023-01-20 01:16:26   29235288 xdistilbert_customer246.tar.gz\n",
      "2023-01-20 01:16:28   29235288 xdistilbert_customer247.tar.gz\n",
      "2023-01-20 01:16:29   29235288 xdistilbert_customer248.tar.gz\n",
      "2023-01-20 01:16:30   29235288 xdistilbert_customer249.tar.gz\n",
      "2023-01-20 01:12:31   29235288 xdistilbert_customer25.tar.gz\n",
      "2023-01-20 01:16:31   29235288 xdistilbert_customer250.tar.gz\n",
      "2023-01-20 01:16:32   29235288 xdistilbert_customer251.tar.gz\n",
      "2023-01-20 01:16:33   29235288 xdistilbert_customer252.tar.gz\n",
      "2023-01-20 01:16:34   29235288 xdistilbert_customer253.tar.gz\n",
      "2023-01-20 01:16:35   29235288 xdistilbert_customer254.tar.gz\n",
      "2023-01-20 01:16:36   29235288 xdistilbert_customer255.tar.gz\n",
      "2023-01-20 01:16:37   29235288 xdistilbert_customer256.tar.gz\n",
      "2023-01-20 01:16:38   29235288 xdistilbert_customer257.tar.gz\n",
      "2023-01-20 01:16:39   29235288 xdistilbert_customer258.tar.gz\n",
      "2023-01-20 01:16:40   29235288 xdistilbert_customer259.tar.gz\n",
      "2023-01-20 01:12:32   29235288 xdistilbert_customer26.tar.gz\n",
      "2023-01-20 01:16:41   29235288 xdistilbert_customer260.tar.gz\n",
      "2023-01-20 01:16:42   29235288 xdistilbert_customer261.tar.gz\n",
      "2023-01-20 01:16:43   29235288 xdistilbert_customer262.tar.gz\n",
      "2023-01-20 01:16:44   29235288 xdistilbert_customer263.tar.gz\n",
      "2023-01-20 01:16:45   29235288 xdistilbert_customer264.tar.gz\n",
      "2023-01-20 01:16:46   29235288 xdistilbert_customer265.tar.gz\n",
      "2023-01-20 01:16:47   29235288 xdistilbert_customer266.tar.gz\n",
      "2023-01-20 01:16:48   29235288 xdistilbert_customer267.tar.gz\n",
      "2023-01-20 01:16:49   29235288 xdistilbert_customer268.tar.gz\n",
      "2023-01-20 01:16:50   29235288 xdistilbert_customer269.tar.gz\n",
      "2023-01-20 01:12:33   29235288 xdistilbert_customer27.tar.gz\n",
      "2023-01-20 01:16:51   29235288 xdistilbert_customer270.tar.gz\n",
      "2023-01-20 01:16:52   29235288 xdistilbert_customer271.tar.gz\n",
      "2023-01-20 01:16:53   29235288 xdistilbert_customer272.tar.gz\n",
      "2023-01-20 01:16:54   29235288 xdistilbert_customer273.tar.gz\n",
      "2023-01-20 01:16:55   29235288 xdistilbert_customer274.tar.gz\n",
      "2023-01-20 01:16:56   29235288 xdistilbert_customer275.tar.gz\n",
      "2023-01-20 01:16:57   29235288 xdistilbert_customer276.tar.gz\n",
      "2023-01-20 01:16:58   29235288 xdistilbert_customer277.tar.gz\n",
      "2023-01-20 01:16:59   29235288 xdistilbert_customer278.tar.gz\n",
      "2023-01-20 01:17:00   29235288 xdistilbert_customer279.tar.gz\n",
      "2023-01-20 01:12:34   29235288 xdistilbert_customer28.tar.gz\n",
      "2023-01-20 01:17:01   29235288 xdistilbert_customer280.tar.gz\n",
      "2023-01-20 01:17:02   29235288 xdistilbert_customer281.tar.gz\n",
      "2023-01-20 01:17:03   29235288 xdistilbert_customer282.tar.gz\n",
      "2023-01-20 01:17:04   29235288 xdistilbert_customer283.tar.gz\n",
      "2023-01-20 01:17:05   29235288 xdistilbert_customer284.tar.gz\n",
      "2023-01-20 01:17:06   29235288 xdistilbert_customer285.tar.gz\n",
      "2023-01-20 01:17:07   29235288 xdistilbert_customer286.tar.gz\n",
      "2023-01-20 01:17:08   29235288 xdistilbert_customer287.tar.gz\n",
      "2023-01-20 01:17:09   29235288 xdistilbert_customer288.tar.gz\n",
      "2023-01-20 01:17:10   29235288 xdistilbert_customer289.tar.gz\n",
      "2023-01-20 01:12:35   29235288 xdistilbert_customer29.tar.gz\n",
      "2023-01-20 01:17:11   29235288 xdistilbert_customer290.tar.gz\n",
      "2023-01-20 01:17:12   29235288 xdistilbert_customer291.tar.gz\n",
      "2023-01-20 01:17:13   29235288 xdistilbert_customer292.tar.gz\n",
      "2023-01-20 01:17:14   29235288 xdistilbert_customer293.tar.gz\n",
      "2023-01-20 01:17:15   29235288 xdistilbert_customer294.tar.gz\n",
      "2023-01-20 01:17:16   29235288 xdistilbert_customer295.tar.gz\n",
      "2023-01-20 01:17:17   29235288 xdistilbert_customer296.tar.gz\n",
      "2023-01-20 01:17:18   29235288 xdistilbert_customer297.tar.gz\n",
      "2023-01-20 01:17:19   29235288 xdistilbert_customer298.tar.gz\n",
      "2023-01-20 01:17:20   29235288 xdistilbert_customer299.tar.gz\n",
      "2023-01-20 01:12:09   29235288 xdistilbert_customer3.tar.gz\n",
      "2023-01-20 01:12:36   29235288 xdistilbert_customer30.tar.gz\n",
      "2023-01-20 01:17:21   29235288 xdistilbert_customer300.tar.gz\n",
      "2023-01-20 01:17:22   29235288 xdistilbert_customer301.tar.gz\n",
      "2023-01-20 01:17:23   29235288 xdistilbert_customer302.tar.gz\n",
      "2023-01-20 01:17:24   29235288 xdistilbert_customer303.tar.gz\n",
      "2023-01-20 01:17:25   29235288 xdistilbert_customer304.tar.gz\n",
      "2023-01-20 01:17:26   29235288 xdistilbert_customer305.tar.gz\n",
      "2023-01-20 01:17:27   29235288 xdistilbert_customer306.tar.gz\n",
      "2023-01-20 01:17:28   29235288 xdistilbert_customer307.tar.gz\n",
      "2023-01-20 01:17:29   29235288 xdistilbert_customer308.tar.gz\n",
      "2023-01-20 01:17:30   29235288 xdistilbert_customer309.tar.gz\n",
      "2023-01-20 01:12:37   29235288 xdistilbert_customer31.tar.gz\n",
      "2023-01-20 01:17:31   29235288 xdistilbert_customer310.tar.gz\n",
      "2023-01-20 01:17:32   29235288 xdistilbert_customer311.tar.gz\n",
      "2023-01-20 01:17:33   29235288 xdistilbert_customer312.tar.gz\n",
      "2023-01-20 01:17:34   29235288 xdistilbert_customer313.tar.gz\n",
      "2023-01-20 01:17:35   29235288 xdistilbert_customer314.tar.gz\n",
      "2023-01-20 01:17:36   29235288 xdistilbert_customer315.tar.gz\n",
      "2023-01-20 01:17:37   29235288 xdistilbert_customer316.tar.gz\n",
      "2023-01-20 01:17:38   29235288 xdistilbert_customer317.tar.gz\n",
      "2023-01-20 01:17:39   29235288 xdistilbert_customer318.tar.gz\n",
      "2023-01-20 01:17:40   29235288 xdistilbert_customer319.tar.gz\n",
      "2023-01-20 01:12:38   29235288 xdistilbert_customer32.tar.gz\n",
      "2023-01-20 01:17:41   29235288 xdistilbert_customer320.tar.gz\n",
      "2023-01-20 01:17:42   29235288 xdistilbert_customer321.tar.gz\n",
      "2023-01-20 01:17:43   29235288 xdistilbert_customer322.tar.gz\n",
      "2023-01-20 01:17:44   29235288 xdistilbert_customer323.tar.gz\n",
      "2023-01-20 01:17:45   29235288 xdistilbert_customer324.tar.gz\n",
      "2023-01-20 01:17:46   29235288 xdistilbert_customer325.tar.gz\n",
      "2023-01-20 01:17:47   29235288 xdistilbert_customer326.tar.gz\n",
      "2023-01-20 01:17:48   29235288 xdistilbert_customer327.tar.gz\n",
      "2023-01-20 01:17:49   29235288 xdistilbert_customer328.tar.gz\n",
      "2023-01-20 01:17:50   29235288 xdistilbert_customer329.tar.gz\n",
      "2023-01-20 01:12:39   29235288 xdistilbert_customer33.tar.gz\n",
      "2023-01-20 01:17:51   29235288 xdistilbert_customer330.tar.gz\n",
      "2023-01-20 01:17:52   29235288 xdistilbert_customer331.tar.gz\n",
      "2023-01-20 01:17:53   29235288 xdistilbert_customer332.tar.gz\n",
      "2023-01-20 01:17:53   29235288 xdistilbert_customer333.tar.gz\n",
      "2023-01-20 01:17:54   29235288 xdistilbert_customer334.tar.gz\n",
      "2023-01-20 01:17:56   29235288 xdistilbert_customer335.tar.gz\n",
      "2023-01-20 01:17:57   29235288 xdistilbert_customer336.tar.gz\n",
      "2023-01-20 01:17:58   29235288 xdistilbert_customer337.tar.gz\n",
      "2023-01-20 01:17:59   29235288 xdistilbert_customer338.tar.gz\n",
      "2023-01-20 01:18:00   29235288 xdistilbert_customer339.tar.gz\n",
      "2023-01-20 01:12:40   29235288 xdistilbert_customer34.tar.gz\n",
      "2023-01-20 01:18:04   29235288 xdistilbert_customer340.tar.gz\n",
      "2023-01-20 01:18:05   29235288 xdistilbert_customer341.tar.gz\n",
      "2023-01-20 01:18:06   29235288 xdistilbert_customer342.tar.gz\n",
      "2023-01-20 01:18:07   29235288 xdistilbert_customer343.tar.gz\n",
      "2023-01-20 01:18:09   29235288 xdistilbert_customer344.tar.gz\n",
      "2023-01-20 01:18:10   29235288 xdistilbert_customer345.tar.gz\n",
      "2023-01-20 01:18:10   29235288 xdistilbert_customer346.tar.gz\n",
      "2023-01-20 01:18:11   29235288 xdistilbert_customer347.tar.gz\n",
      "2023-01-20 01:18:12   29235288 xdistilbert_customer348.tar.gz\n",
      "2023-01-20 01:18:13   29235288 xdistilbert_customer349.tar.gz\n",
      "2023-01-20 01:12:41   29235288 xdistilbert_customer35.tar.gz\n",
      "2023-01-20 01:18:14   29235288 xdistilbert_customer350.tar.gz\n",
      "2023-01-20 01:18:15   29235288 xdistilbert_customer351.tar.gz\n",
      "2023-01-20 01:18:16   29235288 xdistilbert_customer352.tar.gz\n",
      "2023-01-20 01:18:20   29235288 xdistilbert_customer353.tar.gz\n",
      "2023-01-20 01:18:21   29235288 xdistilbert_customer354.tar.gz\n",
      "2023-01-20 01:18:22   29235288 xdistilbert_customer355.tar.gz\n",
      "2023-01-20 01:18:23   29235288 xdistilbert_customer356.tar.gz\n",
      "2023-01-20 01:18:24   29235288 xdistilbert_customer357.tar.gz\n",
      "2023-01-20 01:18:25   29235288 xdistilbert_customer358.tar.gz\n",
      "2023-01-20 01:18:26   29235288 xdistilbert_customer359.tar.gz\n",
      "2023-01-20 01:12:42   29235288 xdistilbert_customer36.tar.gz\n",
      "2023-01-20 01:18:27   29235288 xdistilbert_customer360.tar.gz\n",
      "2023-01-20 01:18:28   29235288 xdistilbert_customer361.tar.gz\n",
      "2023-01-20 01:18:29   29235288 xdistilbert_customer362.tar.gz\n",
      "2023-01-20 01:18:30   29235288 xdistilbert_customer363.tar.gz\n",
      "2023-01-20 01:18:31   29235288 xdistilbert_customer364.tar.gz\n",
      "2023-01-20 01:18:32   29235288 xdistilbert_customer365.tar.gz\n",
      "2023-01-20 01:18:33   29235288 xdistilbert_customer366.tar.gz\n",
      "2023-01-20 01:18:34   29235288 xdistilbert_customer367.tar.gz\n",
      "2023-01-20 01:18:35   29235288 xdistilbert_customer368.tar.gz\n",
      "2023-01-20 01:18:36   29235288 xdistilbert_customer369.tar.gz\n",
      "2023-01-20 01:12:43   29235288 xdistilbert_customer37.tar.gz\n",
      "2023-01-20 01:18:37   29235288 xdistilbert_customer370.tar.gz\n",
      "2023-01-20 01:18:38   29235288 xdistilbert_customer371.tar.gz\n",
      "2023-01-20 01:18:39   29235288 xdistilbert_customer372.tar.gz\n",
      "2023-01-20 01:18:40   29235288 xdistilbert_customer373.tar.gz\n",
      "2023-01-20 01:18:41   29235288 xdistilbert_customer374.tar.gz\n",
      "2023-01-20 01:18:42   29235288 xdistilbert_customer375.tar.gz\n",
      "2023-01-20 01:18:43   29235288 xdistilbert_customer376.tar.gz\n",
      "2023-01-20 01:18:44   29235288 xdistilbert_customer377.tar.gz\n",
      "2023-01-20 01:18:45   29235288 xdistilbert_customer378.tar.gz\n",
      "2023-01-20 01:18:46   29235288 xdistilbert_customer379.tar.gz\n",
      "2023-01-20 01:12:44   29235288 xdistilbert_customer38.tar.gz\n",
      "2023-01-20 01:18:47   29235288 xdistilbert_customer380.tar.gz\n",
      "2023-01-20 01:18:48   29235288 xdistilbert_customer381.tar.gz\n",
      "2023-01-20 01:18:49   29235288 xdistilbert_customer382.tar.gz\n",
      "2023-01-20 01:18:50   29235288 xdistilbert_customer383.tar.gz\n",
      "2023-01-20 01:18:51   29235288 xdistilbert_customer384.tar.gz\n",
      "2023-01-20 01:18:52   29235288 xdistilbert_customer385.tar.gz\n",
      "2023-01-20 01:18:53   29235288 xdistilbert_customer386.tar.gz\n",
      "2023-01-20 01:18:54   29235288 xdistilbert_customer387.tar.gz\n",
      "2023-01-20 01:18:55   29235288 xdistilbert_customer388.tar.gz\n",
      "2023-01-20 01:18:56   29235288 xdistilbert_customer389.tar.gz\n",
      "2023-01-20 01:12:45   29235288 xdistilbert_customer39.tar.gz\n",
      "2023-01-20 01:18:57   29235288 xdistilbert_customer390.tar.gz\n",
      "2023-01-20 01:18:58   29235288 xdistilbert_customer391.tar.gz\n",
      "2023-01-20 01:18:59   29235288 xdistilbert_customer392.tar.gz\n",
      "2023-01-20 01:19:00   29235288 xdistilbert_customer393.tar.gz\n",
      "2023-01-20 01:19:01   29235288 xdistilbert_customer394.tar.gz\n",
      "2023-01-20 01:19:02   29235288 xdistilbert_customer395.tar.gz\n",
      "2023-01-20 01:19:03   29235288 xdistilbert_customer396.tar.gz\n",
      "2023-01-20 01:19:04   29235288 xdistilbert_customer397.tar.gz\n",
      "2023-01-20 01:19:06   29235288 xdistilbert_customer398.tar.gz\n",
      "2023-01-20 01:19:07   29235288 xdistilbert_customer399.tar.gz\n",
      "2023-01-20 01:12:10   29235288 xdistilbert_customer4.tar.gz\n",
      "2023-01-20 01:12:46   29235288 xdistilbert_customer40.tar.gz\n",
      "2023-01-20 01:19:08   29235288 xdistilbert_customer400.tar.gz\n",
      "2023-01-20 01:19:09   29235288 xdistilbert_customer401.tar.gz\n",
      "2023-01-20 01:19:10   29235288 xdistilbert_customer402.tar.gz\n",
      "2023-01-20 01:19:11   29235288 xdistilbert_customer403.tar.gz\n",
      "2023-01-20 01:19:12   29235288 xdistilbert_customer404.tar.gz\n",
      "2023-01-20 01:19:13   29235288 xdistilbert_customer405.tar.gz\n",
      "2023-01-20 01:19:14   29235288 xdistilbert_customer406.tar.gz\n",
      "2023-01-20 01:19:15   29235288 xdistilbert_customer407.tar.gz\n",
      "2023-01-20 01:19:16   29235288 xdistilbert_customer408.tar.gz\n",
      "2023-01-20 01:19:17   29235288 xdistilbert_customer409.tar.gz\n",
      "2023-01-20 01:12:47   29235288 xdistilbert_customer41.tar.gz\n",
      "2023-01-20 01:19:18   29235288 xdistilbert_customer410.tar.gz\n",
      "2023-01-20 01:19:19   29235288 xdistilbert_customer411.tar.gz\n",
      "2023-01-20 01:19:20   29235288 xdistilbert_customer412.tar.gz\n",
      "2023-01-20 01:19:21   29235288 xdistilbert_customer413.tar.gz\n",
      "2023-01-20 01:19:22   29235288 xdistilbert_customer414.tar.gz\n",
      "2023-01-20 01:19:23   29235288 xdistilbert_customer415.tar.gz\n",
      "2023-01-20 01:19:24   29235288 xdistilbert_customer416.tar.gz\n",
      "2023-01-20 01:19:25   29235288 xdistilbert_customer417.tar.gz\n",
      "2023-01-20 01:19:26   29235288 xdistilbert_customer418.tar.gz\n",
      "2023-01-20 01:19:27   29235288 xdistilbert_customer419.tar.gz\n",
      "2023-01-20 01:12:48   29235288 xdistilbert_customer42.tar.gz\n",
      "2023-01-20 01:19:28   29235288 xdistilbert_customer420.tar.gz\n",
      "2023-01-20 01:19:29   29235288 xdistilbert_customer421.tar.gz\n",
      "2023-01-20 01:19:30   29235288 xdistilbert_customer422.tar.gz\n",
      "2023-01-20 01:19:31   29235288 xdistilbert_customer423.tar.gz\n",
      "2023-01-20 01:19:32   29235288 xdistilbert_customer424.tar.gz\n",
      "2023-01-20 01:19:33   29235288 xdistilbert_customer425.tar.gz\n",
      "2023-01-20 01:19:34   29235288 xdistilbert_customer426.tar.gz\n",
      "2023-01-20 01:19:35   29235288 xdistilbert_customer427.tar.gz\n",
      "2023-01-20 01:19:36   29235288 xdistilbert_customer428.tar.gz\n",
      "2023-01-20 01:19:37   29235288 xdistilbert_customer429.tar.gz\n",
      "2023-01-20 01:12:49   29235288 xdistilbert_customer43.tar.gz\n",
      "2023-01-20 01:19:38   29235288 xdistilbert_customer430.tar.gz\n",
      "2023-01-20 01:19:38   29235288 xdistilbert_customer431.tar.gz\n",
      "2023-01-20 01:19:39   29235288 xdistilbert_customer432.tar.gz\n",
      "2023-01-20 01:19:40   29235288 xdistilbert_customer433.tar.gz\n",
      "2023-01-20 01:19:41   29235288 xdistilbert_customer434.tar.gz\n",
      "2023-01-20 01:19:42   29235288 xdistilbert_customer435.tar.gz\n",
      "2023-01-20 01:19:43   29235288 xdistilbert_customer436.tar.gz\n",
      "2023-01-20 01:19:44   29235288 xdistilbert_customer437.tar.gz\n",
      "2023-01-20 01:19:45   29235288 xdistilbert_customer438.tar.gz\n",
      "2023-01-20 01:19:46   29235288 xdistilbert_customer439.tar.gz\n",
      "2023-01-20 01:12:50   29235288 xdistilbert_customer44.tar.gz\n",
      "2023-01-20 01:19:47   29235288 xdistilbert_customer440.tar.gz\n",
      "2023-01-20 01:19:48   29235288 xdistilbert_customer441.tar.gz\n",
      "2023-01-20 01:19:49   29235288 xdistilbert_customer442.tar.gz\n",
      "2023-01-20 01:19:50   29235288 xdistilbert_customer443.tar.gz\n",
      "2023-01-20 01:19:51   29235288 xdistilbert_customer444.tar.gz\n",
      "2023-01-20 01:19:52   29235288 xdistilbert_customer445.tar.gz\n",
      "2023-01-20 01:19:53   29235288 xdistilbert_customer446.tar.gz\n",
      "2023-01-20 01:19:54   29235288 xdistilbert_customer447.tar.gz\n",
      "2023-01-20 01:19:55   29235288 xdistilbert_customer448.tar.gz\n",
      "2023-01-20 01:19:56   29235288 xdistilbert_customer449.tar.gz\n",
      "2023-01-20 01:12:51   29235288 xdistilbert_customer45.tar.gz\n",
      "2023-01-20 01:19:57   29235288 xdistilbert_customer450.tar.gz\n",
      "2023-01-20 01:19:58   29235288 xdistilbert_customer451.tar.gz\n",
      "2023-01-20 01:19:59   29235288 xdistilbert_customer452.tar.gz\n",
      "2023-01-20 01:20:01   29235288 xdistilbert_customer453.tar.gz\n",
      "2023-01-20 01:20:02   29235288 xdistilbert_customer454.tar.gz\n",
      "2023-01-20 01:20:03   29235288 xdistilbert_customer455.tar.gz\n",
      "2023-01-20 01:20:04   29235288 xdistilbert_customer456.tar.gz\n",
      "2023-01-20 01:20:06   29235288 xdistilbert_customer457.tar.gz\n",
      "2023-01-20 01:20:07   29235288 xdistilbert_customer458.tar.gz\n",
      "2023-01-20 01:20:08   29235288 xdistilbert_customer459.tar.gz\n",
      "2023-01-20 01:12:52   29235288 xdistilbert_customer46.tar.gz\n",
      "2023-01-20 01:20:09   29235288 xdistilbert_customer460.tar.gz\n",
      "2023-01-20 01:20:10   29235288 xdistilbert_customer461.tar.gz\n",
      "2023-01-20 01:20:11   29235288 xdistilbert_customer462.tar.gz\n",
      "2023-01-20 01:20:12   29235288 xdistilbert_customer463.tar.gz\n",
      "2023-01-20 01:20:13   29235288 xdistilbert_customer464.tar.gz\n",
      "2023-01-20 01:20:14   29235288 xdistilbert_customer465.tar.gz\n",
      "2023-01-20 01:20:15   29235288 xdistilbert_customer466.tar.gz\n",
      "2023-01-20 01:20:16   29235288 xdistilbert_customer467.tar.gz\n",
      "2023-01-20 01:20:17   29235288 xdistilbert_customer468.tar.gz\n",
      "2023-01-20 01:20:18   29235288 xdistilbert_customer469.tar.gz\n",
      "2023-01-20 01:12:53   29235288 xdistilbert_customer47.tar.gz\n",
      "2023-01-20 01:20:19   29235288 xdistilbert_customer470.tar.gz\n",
      "2023-01-20 01:20:20   29235288 xdistilbert_customer471.tar.gz\n",
      "2023-01-20 01:20:21   29235288 xdistilbert_customer472.tar.gz\n",
      "2023-01-20 01:20:22   29235288 xdistilbert_customer473.tar.gz\n",
      "2023-01-20 01:20:24   29235288 xdistilbert_customer474.tar.gz\n",
      "2023-01-20 01:20:25   29235288 xdistilbert_customer475.tar.gz\n",
      "2023-01-20 01:20:26   29235288 xdistilbert_customer476.tar.gz\n",
      "2023-01-20 01:20:27   29235288 xdistilbert_customer477.tar.gz\n",
      "2023-01-20 01:20:28   29235288 xdistilbert_customer478.tar.gz\n",
      "2023-01-20 01:20:29   29235288 xdistilbert_customer479.tar.gz\n",
      "2023-01-20 01:12:54   29235288 xdistilbert_customer48.tar.gz\n",
      "2023-01-20 01:20:30   29235288 xdistilbert_customer480.tar.gz\n",
      "2023-01-20 01:20:31   29235288 xdistilbert_customer481.tar.gz\n",
      "2023-01-20 01:20:32   29235288 xdistilbert_customer482.tar.gz\n",
      "2023-01-20 01:20:33   29235288 xdistilbert_customer483.tar.gz\n",
      "2023-01-20 01:20:34   29235288 xdistilbert_customer484.tar.gz\n",
      "2023-01-20 01:20:36   29235288 xdistilbert_customer485.tar.gz\n",
      "2023-01-20 01:20:37   29235288 xdistilbert_customer486.tar.gz\n",
      "2023-01-20 01:20:38   29235288 xdistilbert_customer487.tar.gz\n",
      "2023-01-20 01:20:38   29235288 xdistilbert_customer488.tar.gz\n",
      "2023-01-20 01:20:39   29235288 xdistilbert_customer489.tar.gz\n",
      "2023-01-20 01:12:55   29235288 xdistilbert_customer49.tar.gz\n",
      "2023-01-20 01:20:40   29235288 xdistilbert_customer490.tar.gz\n",
      "2023-01-20 01:20:42   29235288 xdistilbert_customer491.tar.gz\n",
      "2023-01-20 01:20:43   29235288 xdistilbert_customer492.tar.gz\n",
      "2023-01-20 01:20:44   29235288 xdistilbert_customer493.tar.gz\n",
      "2023-01-20 01:20:45   29235288 xdistilbert_customer494.tar.gz\n",
      "2023-01-20 01:20:46   29235288 xdistilbert_customer495.tar.gz\n",
      "2023-01-20 01:20:47   29235288 xdistilbert_customer496.tar.gz\n",
      "2023-01-20 01:20:48   29235288 xdistilbert_customer497.tar.gz\n",
      "2023-01-20 01:20:49   29235288 xdistilbert_customer498.tar.gz\n",
      "2023-01-20 01:20:49   29235288 xdistilbert_customer499.tar.gz\n",
      "2023-01-20 01:12:11   29235288 xdistilbert_customer5.tar.gz\n",
      "2023-01-20 01:12:56   29235288 xdistilbert_customer50.tar.gz\n",
      "2023-01-20 01:20:50   29235288 xdistilbert_customer500.tar.gz\n",
      "2023-01-20 01:20:51   29235288 xdistilbert_customer501.tar.gz\n",
      "2023-01-20 01:20:52   29235288 xdistilbert_customer502.tar.gz\n",
      "2023-01-20 01:20:53   29235288 xdistilbert_customer503.tar.gz\n",
      "2023-01-20 01:20:54   29235288 xdistilbert_customer504.tar.gz\n",
      "2023-01-20 01:20:55   29235288 xdistilbert_customer505.tar.gz\n",
      "2023-01-20 01:20:56   29235288 xdistilbert_customer506.tar.gz\n",
      "2023-01-20 01:20:57   29235288 xdistilbert_customer507.tar.gz\n",
      "2023-01-20 01:20:58   29235288 xdistilbert_customer508.tar.gz\n",
      "2023-01-20 01:20:59   29235288 xdistilbert_customer509.tar.gz\n",
      "2023-01-20 01:12:57   29235288 xdistilbert_customer51.tar.gz\n",
      "2023-01-20 01:21:00   29235288 xdistilbert_customer510.tar.gz\n",
      "2023-01-20 01:21:01   29235288 xdistilbert_customer511.tar.gz\n",
      "2023-01-20 01:21:02   29235288 xdistilbert_customer512.tar.gz\n",
      "2023-01-20 01:21:03   29235288 xdistilbert_customer513.tar.gz\n",
      "2023-01-20 01:21:04   29235288 xdistilbert_customer514.tar.gz\n",
      "2023-01-20 01:21:05   29235288 xdistilbert_customer515.tar.gz\n",
      "2023-01-20 01:21:06   29235288 xdistilbert_customer516.tar.gz\n",
      "2023-01-20 01:21:07   29235288 xdistilbert_customer517.tar.gz\n",
      "2023-01-20 01:21:08   29235288 xdistilbert_customer518.tar.gz\n",
      "2023-01-20 01:21:09   29235288 xdistilbert_customer519.tar.gz\n",
      "2023-01-20 01:12:58   29235288 xdistilbert_customer52.tar.gz\n",
      "2023-01-20 01:21:10   29235288 xdistilbert_customer520.tar.gz\n",
      "2023-01-20 01:21:11   29235288 xdistilbert_customer521.tar.gz\n",
      "2023-01-20 01:21:12   29235288 xdistilbert_customer522.tar.gz\n",
      "2023-01-20 01:21:13   29235288 xdistilbert_customer523.tar.gz\n",
      "2023-01-20 01:21:14   29235288 xdistilbert_customer524.tar.gz\n",
      "2023-01-20 01:21:15   29235288 xdistilbert_customer525.tar.gz\n",
      "2023-01-20 01:21:16   29235288 xdistilbert_customer526.tar.gz\n",
      "2023-01-20 01:21:17   29235288 xdistilbert_customer527.tar.gz\n",
      "2023-01-20 01:21:18   29235288 xdistilbert_customer528.tar.gz\n",
      "2023-01-20 01:21:19   29235288 xdistilbert_customer529.tar.gz\n",
      "2023-01-20 01:12:59   29235288 xdistilbert_customer53.tar.gz\n",
      "2023-01-20 01:21:20   29235288 xdistilbert_customer530.tar.gz\n",
      "2023-01-20 01:21:21   29235288 xdistilbert_customer531.tar.gz\n",
      "2023-01-20 01:21:22   29235288 xdistilbert_customer532.tar.gz\n",
      "2023-01-20 01:21:23   29235288 xdistilbert_customer533.tar.gz\n",
      "2023-01-20 01:21:24   29235288 xdistilbert_customer534.tar.gz\n",
      "2023-01-20 01:21:25   29235288 xdistilbert_customer535.tar.gz\n",
      "2023-01-20 01:21:26   29235288 xdistilbert_customer536.tar.gz\n",
      "2023-01-20 01:21:27   29235288 xdistilbert_customer537.tar.gz\n",
      "2023-01-20 01:21:28   29235288 xdistilbert_customer538.tar.gz\n",
      "2023-01-20 01:21:29   29235288 xdistilbert_customer539.tar.gz\n",
      "2023-01-20 01:13:00   29235288 xdistilbert_customer54.tar.gz\n",
      "2023-01-20 01:21:30   29235288 xdistilbert_customer540.tar.gz\n",
      "2023-01-20 01:21:30   29235288 xdistilbert_customer541.tar.gz\n",
      "2023-01-20 01:21:32   29235288 xdistilbert_customer542.tar.gz\n",
      "2023-01-20 01:21:32   29235288 xdistilbert_customer543.tar.gz\n",
      "2023-01-20 01:21:33   29235288 xdistilbert_customer544.tar.gz\n",
      "2023-01-20 01:21:34   29235288 xdistilbert_customer545.tar.gz\n",
      "2023-01-20 01:21:35   29235288 xdistilbert_customer546.tar.gz\n",
      "2023-01-20 01:21:37   29235288 xdistilbert_customer547.tar.gz\n",
      "2023-01-20 01:21:38   29235288 xdistilbert_customer548.tar.gz\n",
      "2023-01-20 01:21:39   29235288 xdistilbert_customer549.tar.gz\n",
      "2023-01-20 01:13:01   29235288 xdistilbert_customer55.tar.gz\n",
      "2023-01-20 01:21:40   29235288 xdistilbert_customer550.tar.gz\n",
      "2023-01-20 01:21:41   29235288 xdistilbert_customer551.tar.gz\n",
      "2023-01-20 01:21:41   29235288 xdistilbert_customer552.tar.gz\n",
      "2023-01-20 01:21:42   29235288 xdistilbert_customer553.tar.gz\n",
      "2023-01-20 01:21:43   29235288 xdistilbert_customer554.tar.gz\n",
      "2023-01-20 01:21:44   29235288 xdistilbert_customer555.tar.gz\n",
      "2023-01-20 01:21:45   29235288 xdistilbert_customer556.tar.gz\n",
      "2023-01-20 01:21:46   29235288 xdistilbert_customer557.tar.gz\n",
      "2023-01-20 01:21:47   29235288 xdistilbert_customer558.tar.gz\n",
      "2023-01-20 01:21:48   29235288 xdistilbert_customer559.tar.gz\n",
      "2023-01-20 01:13:02   29235288 xdistilbert_customer56.tar.gz\n",
      "2023-01-20 01:21:49   29235288 xdistilbert_customer560.tar.gz\n",
      "2023-01-20 01:21:50   29235288 xdistilbert_customer561.tar.gz\n",
      "2023-01-20 01:21:51   29235288 xdistilbert_customer562.tar.gz\n",
      "2023-01-20 01:21:52   29235288 xdistilbert_customer563.tar.gz\n",
      "2023-01-20 01:21:53   29235288 xdistilbert_customer564.tar.gz\n",
      "2023-01-20 01:21:55   29235288 xdistilbert_customer565.tar.gz\n",
      "2023-01-20 01:21:56   29235288 xdistilbert_customer566.tar.gz\n",
      "2023-01-20 01:21:57   29235288 xdistilbert_customer567.tar.gz\n",
      "2023-01-20 01:21:58   29235288 xdistilbert_customer568.tar.gz\n",
      "2023-01-20 01:21:59   29235288 xdistilbert_customer569.tar.gz\n",
      "2023-01-20 01:13:03   29235288 xdistilbert_customer57.tar.gz\n",
      "2023-01-20 01:22:00   29235288 xdistilbert_customer570.tar.gz\n",
      "2023-01-20 01:22:01   29235288 xdistilbert_customer571.tar.gz\n",
      "2023-01-20 01:22:02   29235288 xdistilbert_customer572.tar.gz\n",
      "2023-01-20 01:22:03   29235288 xdistilbert_customer573.tar.gz\n",
      "2023-01-20 01:22:04   29235288 xdistilbert_customer574.tar.gz\n",
      "2023-01-20 01:22:05   29235288 xdistilbert_customer575.tar.gz\n",
      "2023-01-20 01:22:06   29235288 xdistilbert_customer576.tar.gz\n",
      "2023-01-20 01:22:07   29235288 xdistilbert_customer577.tar.gz\n",
      "2023-01-20 01:22:08   29235288 xdistilbert_customer578.tar.gz\n",
      "2023-01-20 01:22:09   29235288 xdistilbert_customer579.tar.gz\n",
      "2023-01-20 01:13:04   29235288 xdistilbert_customer58.tar.gz\n",
      "2023-01-20 01:22:10   29235288 xdistilbert_customer580.tar.gz\n",
      "2023-01-20 01:22:11   29235288 xdistilbert_customer581.tar.gz\n",
      "2023-01-20 01:22:13   29235288 xdistilbert_customer582.tar.gz\n",
      "2023-01-20 01:22:14   29235288 xdistilbert_customer583.tar.gz\n",
      "2023-01-20 01:22:15   29235288 xdistilbert_customer584.tar.gz\n",
      "2023-01-20 01:22:16   29235288 xdistilbert_customer585.tar.gz\n",
      "2023-01-20 01:22:17   29235288 xdistilbert_customer586.tar.gz\n",
      "2023-01-20 01:22:18   29235288 xdistilbert_customer587.tar.gz\n",
      "2023-01-20 01:22:19   29235288 xdistilbert_customer588.tar.gz\n",
      "2023-01-20 01:22:20   29235288 xdistilbert_customer589.tar.gz\n",
      "2023-01-20 01:13:05   29235288 xdistilbert_customer59.tar.gz\n",
      "2023-01-20 01:22:21   29235288 xdistilbert_customer590.tar.gz\n",
      "2023-01-20 01:22:21   29235288 xdistilbert_customer591.tar.gz\n",
      "2023-01-20 01:22:22   29235288 xdistilbert_customer592.tar.gz\n",
      "2023-01-20 01:22:23   29235288 xdistilbert_customer593.tar.gz\n",
      "2023-01-20 01:22:24   29235288 xdistilbert_customer594.tar.gz\n",
      "2023-01-20 01:22:25   29235288 xdistilbert_customer595.tar.gz\n",
      "2023-01-20 01:22:26   29235288 xdistilbert_customer596.tar.gz\n",
      "2023-01-20 01:22:27   29235288 xdistilbert_customer597.tar.gz\n",
      "2023-01-20 01:22:28   29235288 xdistilbert_customer598.tar.gz\n",
      "2023-01-20 01:22:29   29235288 xdistilbert_customer599.tar.gz\n",
      "2023-01-20 01:12:12   29235288 xdistilbert_customer6.tar.gz\n",
      "2023-01-20 01:13:08   29235288 xdistilbert_customer60.tar.gz\n",
      "2023-01-20 01:22:30   29235288 xdistilbert_customer600.tar.gz\n",
      "2023-01-20 01:22:31   29235288 xdistilbert_customer601.tar.gz\n",
      "2023-01-20 01:22:32   29235288 xdistilbert_customer602.tar.gz\n",
      "2023-01-20 01:22:33   29235288 xdistilbert_customer603.tar.gz\n",
      "2023-01-20 01:22:35   29235288 xdistilbert_customer604.tar.gz\n",
      "2023-01-20 01:22:35   29235288 xdistilbert_customer605.tar.gz\n",
      "2023-01-20 01:22:37   29235288 xdistilbert_customer606.tar.gz\n",
      "2023-01-20 01:22:38   29235288 xdistilbert_customer607.tar.gz\n",
      "2023-01-20 01:22:39   29235288 xdistilbert_customer608.tar.gz\n",
      "2023-01-20 01:22:40   29235288 xdistilbert_customer609.tar.gz\n",
      "2023-01-20 01:13:09   29235288 xdistilbert_customer61.tar.gz\n",
      "2023-01-20 01:22:41   29235288 xdistilbert_customer610.tar.gz\n",
      "2023-01-20 01:22:42   29235288 xdistilbert_customer611.tar.gz\n",
      "2023-01-20 01:22:43   29235288 xdistilbert_customer612.tar.gz\n",
      "2023-01-20 01:22:44   29235288 xdistilbert_customer613.tar.gz\n",
      "2023-01-20 01:22:45   29235288 xdistilbert_customer614.tar.gz\n",
      "2023-01-20 01:22:46   29235288 xdistilbert_customer615.tar.gz\n",
      "2023-01-20 01:22:47   29235288 xdistilbert_customer616.tar.gz\n",
      "2023-01-20 01:22:48   29235288 xdistilbert_customer617.tar.gz\n",
      "2023-01-20 01:22:49   29235288 xdistilbert_customer618.tar.gz\n",
      "2023-01-20 01:22:50   29235288 xdistilbert_customer619.tar.gz\n",
      "2023-01-20 01:13:10   29235288 xdistilbert_customer62.tar.gz\n",
      "2023-01-20 01:22:51   29235288 xdistilbert_customer620.tar.gz\n",
      "2023-01-20 01:22:52   29235288 xdistilbert_customer621.tar.gz\n",
      "2023-01-20 01:22:53   29235288 xdistilbert_customer622.tar.gz\n",
      "2023-01-20 01:22:54   29235288 xdistilbert_customer623.tar.gz\n",
      "2023-01-20 01:22:55   29235288 xdistilbert_customer624.tar.gz\n",
      "2023-01-20 01:22:56   29235288 xdistilbert_customer625.tar.gz\n",
      "2023-01-20 01:22:57   29235288 xdistilbert_customer626.tar.gz\n",
      "2023-01-20 01:22:58   29235288 xdistilbert_customer627.tar.gz\n",
      "2023-01-20 01:22:59   29235288 xdistilbert_customer628.tar.gz\n",
      "2023-01-20 01:23:03   29235288 xdistilbert_customer629.tar.gz\n",
      "2023-01-20 01:13:11   29235288 xdistilbert_customer63.tar.gz\n",
      "2023-01-20 01:23:04   29235288 xdistilbert_customer630.tar.gz\n",
      "2023-01-20 01:23:05   29235288 xdistilbert_customer631.tar.gz\n",
      "2023-01-20 01:23:06   29235288 xdistilbert_customer632.tar.gz\n",
      "2023-01-20 01:23:07   29235288 xdistilbert_customer633.tar.gz\n",
      "2023-01-20 01:23:08   29235288 xdistilbert_customer634.tar.gz\n",
      "2023-01-20 01:23:09   29235288 xdistilbert_customer635.tar.gz\n",
      "2023-01-20 01:23:10   29235288 xdistilbert_customer636.tar.gz\n",
      "2023-01-20 01:23:10   29235288 xdistilbert_customer637.tar.gz\n",
      "2023-01-20 01:23:12   29235288 xdistilbert_customer638.tar.gz\n",
      "2023-01-20 01:23:12   29235288 xdistilbert_customer639.tar.gz\n",
      "2023-01-20 01:13:12   29235288 xdistilbert_customer64.tar.gz\n",
      "2023-01-20 01:23:13   29235288 xdistilbert_customer640.tar.gz\n",
      "2023-01-20 01:23:14   29235288 xdistilbert_customer641.tar.gz\n",
      "2023-01-20 01:23:15   29235288 xdistilbert_customer642.tar.gz\n",
      "2023-01-20 01:23:17   29235288 xdistilbert_customer643.tar.gz\n",
      "2023-01-20 01:23:18   29235288 xdistilbert_customer644.tar.gz\n",
      "2023-01-20 01:23:19   29235288 xdistilbert_customer645.tar.gz\n",
      "2023-01-20 01:23:20   29235288 xdistilbert_customer646.tar.gz\n",
      "2023-01-20 01:23:21   29235288 xdistilbert_customer647.tar.gz\n",
      "2023-01-20 01:23:22   29235288 xdistilbert_customer648.tar.gz\n",
      "2023-01-20 01:23:23   29235288 xdistilbert_customer649.tar.gz\n",
      "2023-01-20 01:13:13   29235288 xdistilbert_customer65.tar.gz\n",
      "2023-01-20 01:23:24   29235288 xdistilbert_customer650.tar.gz\n",
      "2023-01-20 01:23:25   29235288 xdistilbert_customer651.tar.gz\n",
      "2023-01-20 01:23:26   29235288 xdistilbert_customer652.tar.gz\n",
      "2023-01-20 01:23:27   29235288 xdistilbert_customer653.tar.gz\n",
      "2023-01-20 01:23:28   29235288 xdistilbert_customer654.tar.gz\n",
      "2023-01-20 01:23:29   29235288 xdistilbert_customer655.tar.gz\n",
      "2023-01-20 01:23:30   29235288 xdistilbert_customer656.tar.gz\n",
      "2023-01-20 01:23:31   29235288 xdistilbert_customer657.tar.gz\n",
      "2023-01-20 01:23:32   29235288 xdistilbert_customer658.tar.gz\n",
      "2023-01-20 01:23:33   29235288 xdistilbert_customer659.tar.gz\n",
      "2023-01-20 01:13:14   29235288 xdistilbert_customer66.tar.gz\n",
      "2023-01-20 01:23:34   29235288 xdistilbert_customer660.tar.gz\n",
      "2023-01-20 01:23:35   29235288 xdistilbert_customer661.tar.gz\n",
      "2023-01-20 01:23:36   29235288 xdistilbert_customer662.tar.gz\n",
      "2023-01-20 01:23:37   29235288 xdistilbert_customer663.tar.gz\n",
      "2023-01-20 01:23:38   29235288 xdistilbert_customer664.tar.gz\n",
      "2023-01-20 01:23:39   29235288 xdistilbert_customer665.tar.gz\n",
      "2023-01-20 01:23:40   29235288 xdistilbert_customer666.tar.gz\n",
      "2023-01-20 01:23:41   29235288 xdistilbert_customer667.tar.gz\n",
      "2023-01-20 01:23:42   29235288 xdistilbert_customer668.tar.gz\n",
      "2023-01-20 01:23:43   29235288 xdistilbert_customer669.tar.gz\n",
      "2023-01-20 01:13:15   29235288 xdistilbert_customer67.tar.gz\n",
      "2023-01-20 01:23:44   29235288 xdistilbert_customer670.tar.gz\n",
      "2023-01-20 01:23:45   29235288 xdistilbert_customer671.tar.gz\n",
      "2023-01-20 01:23:46   29235288 xdistilbert_customer672.tar.gz\n",
      "2023-01-20 01:23:48   29235288 xdistilbert_customer673.tar.gz\n",
      "2023-01-20 01:23:48   29235288 xdistilbert_customer674.tar.gz\n",
      "2023-01-20 01:23:49   29235288 xdistilbert_customer675.tar.gz\n",
      "2023-01-20 01:23:51   29235288 xdistilbert_customer676.tar.gz\n",
      "2023-01-20 01:23:51   29235288 xdistilbert_customer677.tar.gz\n",
      "2023-01-20 01:23:52   29235288 xdistilbert_customer678.tar.gz\n",
      "2023-01-20 01:23:54   29235288 xdistilbert_customer679.tar.gz\n",
      "2023-01-20 01:13:16   29235288 xdistilbert_customer68.tar.gz\n",
      "2023-01-20 01:23:54   29235288 xdistilbert_customer680.tar.gz\n",
      "2023-01-20 01:23:55   29235288 xdistilbert_customer681.tar.gz\n",
      "2023-01-20 01:23:56   29235288 xdistilbert_customer682.tar.gz\n",
      "2023-01-20 01:23:57   29235288 xdistilbert_customer683.tar.gz\n",
      "2023-01-20 01:23:58   29235288 xdistilbert_customer684.tar.gz\n",
      "2023-01-20 01:23:59   29235288 xdistilbert_customer685.tar.gz\n",
      "2023-01-20 01:24:00   29235288 xdistilbert_customer686.tar.gz\n",
      "2023-01-20 01:24:01   29235288 xdistilbert_customer687.tar.gz\n",
      "2023-01-20 01:24:03   29235288 xdistilbert_customer688.tar.gz\n",
      "2023-01-20 01:24:03   29235288 xdistilbert_customer689.tar.gz\n",
      "2023-01-20 01:13:17   29235288 xdistilbert_customer69.tar.gz\n",
      "2023-01-20 01:24:04   29235288 xdistilbert_customer690.tar.gz\n",
      "2023-01-20 01:24:06   29235288 xdistilbert_customer691.tar.gz\n",
      "2023-01-20 01:24:07   29235288 xdistilbert_customer692.tar.gz\n",
      "2023-01-20 01:24:08   29235288 xdistilbert_customer693.tar.gz\n",
      "2023-01-20 01:24:09   29235288 xdistilbert_customer694.tar.gz\n",
      "2023-01-20 01:24:10   29235288 xdistilbert_customer695.tar.gz\n",
      "2023-01-20 01:24:11   29235288 xdistilbert_customer696.tar.gz\n",
      "2023-01-20 01:24:12   29235288 xdistilbert_customer697.tar.gz\n",
      "2023-01-20 01:24:13   29235288 xdistilbert_customer698.tar.gz\n",
      "2023-01-20 01:24:14   29235288 xdistilbert_customer699.tar.gz\n",
      "2023-01-20 01:12:13   29235288 xdistilbert_customer7.tar.gz\n",
      "2023-01-20 01:13:18   29235288 xdistilbert_customer70.tar.gz\n",
      "2023-01-20 01:24:15   29235288 xdistilbert_customer700.tar.gz\n",
      "2023-01-20 01:24:16   29235288 xdistilbert_customer701.tar.gz\n",
      "2023-01-20 01:24:17   29235288 xdistilbert_customer702.tar.gz\n",
      "2023-01-20 01:24:18   29235288 xdistilbert_customer703.tar.gz\n",
      "2023-01-20 01:24:19   29235288 xdistilbert_customer704.tar.gz\n",
      "2023-01-20 01:24:20   29235288 xdistilbert_customer705.tar.gz\n",
      "2023-01-20 01:24:21   29235288 xdistilbert_customer706.tar.gz\n",
      "2023-01-20 01:24:22   29235288 xdistilbert_customer707.tar.gz\n",
      "2023-01-20 01:24:23   29235288 xdistilbert_customer708.tar.gz\n",
      "2023-01-20 01:24:24   29235288 xdistilbert_customer709.tar.gz\n",
      "2023-01-20 01:13:19   29235288 xdistilbert_customer71.tar.gz\n",
      "2023-01-20 01:24:25   29235288 xdistilbert_customer710.tar.gz\n",
      "2023-01-20 01:24:26   29235288 xdistilbert_customer711.tar.gz\n",
      "2023-01-20 01:24:27   29235288 xdistilbert_customer712.tar.gz\n",
      "2023-01-20 01:24:28   29235288 xdistilbert_customer713.tar.gz\n",
      "2023-01-20 01:24:32   29235288 xdistilbert_customer714.tar.gz\n",
      "2023-01-20 01:24:33   29235288 xdistilbert_customer715.tar.gz\n",
      "2023-01-20 01:24:34   29235288 xdistilbert_customer716.tar.gz\n",
      "2023-01-20 01:24:34   29235288 xdistilbert_customer717.tar.gz\n",
      "2023-01-20 01:24:36   29235288 xdistilbert_customer718.tar.gz\n",
      "2023-01-20 01:24:37   29235288 xdistilbert_customer719.tar.gz\n",
      "2023-01-20 01:13:20   29235288 xdistilbert_customer72.tar.gz\n",
      "2023-01-20 01:24:38   29235288 xdistilbert_customer720.tar.gz\n",
      "2023-01-20 01:24:39   29235288 xdistilbert_customer721.tar.gz\n",
      "2023-01-20 01:24:40   29235288 xdistilbert_customer722.tar.gz\n",
      "2023-01-20 01:24:41   29235288 xdistilbert_customer723.tar.gz\n",
      "2023-01-20 01:24:42   29235288 xdistilbert_customer724.tar.gz\n",
      "2023-01-20 01:24:43   29235288 xdistilbert_customer725.tar.gz\n",
      "2023-01-20 01:24:44   29235288 xdistilbert_customer726.tar.gz\n",
      "2023-01-20 01:24:45   29235288 xdistilbert_customer727.tar.gz\n",
      "2023-01-20 01:24:46   29235288 xdistilbert_customer728.tar.gz\n",
      "2023-01-20 01:24:47   29235288 xdistilbert_customer729.tar.gz\n",
      "2023-01-20 01:13:21   29235288 xdistilbert_customer73.tar.gz\n",
      "2023-01-20 01:24:48   29235288 xdistilbert_customer730.tar.gz\n",
      "2023-01-20 01:24:49   29235288 xdistilbert_customer731.tar.gz\n",
      "2023-01-20 01:24:50   29235288 xdistilbert_customer732.tar.gz\n",
      "2023-01-20 01:24:51   29235288 xdistilbert_customer733.tar.gz\n",
      "2023-01-20 01:24:52   29235288 xdistilbert_customer734.tar.gz\n",
      "2023-01-20 01:24:53   29235288 xdistilbert_customer735.tar.gz\n",
      "2023-01-20 01:24:54   29235288 xdistilbert_customer736.tar.gz\n",
      "2023-01-20 01:24:55   29235288 xdistilbert_customer737.tar.gz\n",
      "2023-01-20 01:24:56   29235288 xdistilbert_customer738.tar.gz\n",
      "2023-01-20 01:24:57   29235288 xdistilbert_customer739.tar.gz\n",
      "2023-01-20 01:13:22   29235288 xdistilbert_customer74.tar.gz\n",
      "2023-01-20 01:24:58   29235288 xdistilbert_customer740.tar.gz\n",
      "2023-01-20 01:24:59   29235288 xdistilbert_customer741.tar.gz\n",
      "2023-01-20 01:25:00   29235288 xdistilbert_customer742.tar.gz\n",
      "2023-01-20 01:25:01   29235288 xdistilbert_customer743.tar.gz\n",
      "2023-01-20 01:25:02   29235288 xdistilbert_customer744.tar.gz\n",
      "2023-01-20 01:25:03   29235288 xdistilbert_customer745.tar.gz\n",
      "2023-01-20 01:25:04   29235288 xdistilbert_customer746.tar.gz\n",
      "2023-01-20 01:25:06   29235288 xdistilbert_customer747.tar.gz\n",
      "2023-01-20 01:25:07   29235288 xdistilbert_customer748.tar.gz\n",
      "2023-01-20 01:25:08   29235288 xdistilbert_customer749.tar.gz\n",
      "2023-01-20 01:13:23   29235288 xdistilbert_customer75.tar.gz\n",
      "2023-01-20 01:25:09   29235288 xdistilbert_customer750.tar.gz\n",
      "2023-01-20 01:25:10   29235288 xdistilbert_customer751.tar.gz\n",
      "2023-01-20 01:25:11   29235288 xdistilbert_customer752.tar.gz\n",
      "2023-01-20 01:25:12   29235288 xdistilbert_customer753.tar.gz\n",
      "2023-01-20 01:25:13   29235288 xdistilbert_customer754.tar.gz\n",
      "2023-01-20 01:25:14   29235288 xdistilbert_customer755.tar.gz\n",
      "2023-01-20 01:25:15   29235288 xdistilbert_customer756.tar.gz\n",
      "2023-01-20 01:25:16   29235288 xdistilbert_customer757.tar.gz\n",
      "2023-01-20 01:25:17   29235288 xdistilbert_customer758.tar.gz\n",
      "2023-01-20 01:25:18   29235288 xdistilbert_customer759.tar.gz\n",
      "2023-01-20 01:13:24   29235288 xdistilbert_customer76.tar.gz\n",
      "2023-01-20 01:25:21   29235288 xdistilbert_customer760.tar.gz\n",
      "2023-01-20 01:25:23   29235288 xdistilbert_customer761.tar.gz\n",
      "2023-01-20 01:25:23   29235288 xdistilbert_customer762.tar.gz\n",
      "2023-01-20 01:25:24   29235288 xdistilbert_customer763.tar.gz\n",
      "2023-01-20 01:25:25   29235288 xdistilbert_customer764.tar.gz\n",
      "2023-01-20 01:25:26   29235288 xdistilbert_customer765.tar.gz\n",
      "2023-01-20 01:25:27   29235288 xdistilbert_customer766.tar.gz\n",
      "2023-01-20 01:25:28   29235288 xdistilbert_customer767.tar.gz\n",
      "2023-01-20 01:25:29   29235288 xdistilbert_customer768.tar.gz\n",
      "2023-01-20 01:25:30   29235288 xdistilbert_customer769.tar.gz\n",
      "2023-01-20 01:13:25   29235288 xdistilbert_customer77.tar.gz\n",
      "2023-01-20 01:25:31   29235288 xdistilbert_customer770.tar.gz\n",
      "2023-01-20 01:25:32   29235288 xdistilbert_customer771.tar.gz\n",
      "2023-01-20 01:25:33   29235288 xdistilbert_customer772.tar.gz\n",
      "2023-01-20 01:25:34   29235288 xdistilbert_customer773.tar.gz\n",
      "2023-01-20 01:25:35   29235288 xdistilbert_customer774.tar.gz\n",
      "2023-01-20 01:25:36   29235288 xdistilbert_customer775.tar.gz\n",
      "2023-01-20 01:25:38   29235288 xdistilbert_customer776.tar.gz\n",
      "2023-01-20 01:25:39   29235288 xdistilbert_customer777.tar.gz\n",
      "2023-01-20 01:25:40   29235288 xdistilbert_customer778.tar.gz\n",
      "2023-01-20 01:25:41   29235288 xdistilbert_customer779.tar.gz\n",
      "2023-01-20 01:13:26   29235288 xdistilbert_customer78.tar.gz\n",
      "2023-01-20 01:25:42   29235288 xdistilbert_customer780.tar.gz\n",
      "2023-01-20 01:25:43   29235288 xdistilbert_customer781.tar.gz\n",
      "2023-01-20 01:25:44   29235288 xdistilbert_customer782.tar.gz\n",
      "2023-01-20 01:25:45   29235288 xdistilbert_customer783.tar.gz\n",
      "2023-01-20 01:25:46   29235288 xdistilbert_customer784.tar.gz\n",
      "2023-01-20 01:25:47   29235288 xdistilbert_customer785.tar.gz\n",
      "2023-01-20 01:25:48   29235288 xdistilbert_customer786.tar.gz\n",
      "2023-01-20 01:25:49   29235288 xdistilbert_customer787.tar.gz\n",
      "2023-01-20 01:25:50   29235288 xdistilbert_customer788.tar.gz\n",
      "2023-01-20 01:25:51   29235288 xdistilbert_customer789.tar.gz\n",
      "2023-01-20 01:13:27   29235288 xdistilbert_customer79.tar.gz\n",
      "2023-01-20 01:25:52   29235288 xdistilbert_customer790.tar.gz\n",
      "2023-01-20 01:25:53   29235288 xdistilbert_customer791.tar.gz\n",
      "2023-01-20 01:25:54   29235288 xdistilbert_customer792.tar.gz\n",
      "2023-01-20 01:25:55   29235288 xdistilbert_customer793.tar.gz\n",
      "2023-01-20 01:25:56   29235288 xdistilbert_customer794.tar.gz\n",
      "2023-01-20 01:25:57   29235288 xdistilbert_customer795.tar.gz\n",
      "2023-01-20 01:25:58   29235288 xdistilbert_customer796.tar.gz\n",
      "2023-01-20 01:25:58   29235288 xdistilbert_customer797.tar.gz\n",
      "2023-01-20 01:25:59   29235288 xdistilbert_customer798.tar.gz\n",
      "2023-01-20 01:26:00   29235288 xdistilbert_customer799.tar.gz\n",
      "2023-01-20 01:12:14   29235288 xdistilbert_customer8.tar.gz\n",
      "2023-01-20 01:13:28   29235288 xdistilbert_customer80.tar.gz\n",
      "2023-01-20 01:26:01   29235288 xdistilbert_customer800.tar.gz\n",
      "2023-01-20 01:26:03   29235288 xdistilbert_customer801.tar.gz\n",
      "2023-01-20 01:26:03   29235288 xdistilbert_customer802.tar.gz\n",
      "2023-01-20 01:26:04   29235288 xdistilbert_customer803.tar.gz\n",
      "2023-01-20 01:26:05   29235288 xdistilbert_customer804.tar.gz\n",
      "2023-01-20 01:26:07   29235288 xdistilbert_customer805.tar.gz\n",
      "2023-01-20 01:26:08   29235288 xdistilbert_customer806.tar.gz\n",
      "2023-01-20 01:26:09   29235288 xdistilbert_customer807.tar.gz\n",
      "2023-01-20 01:26:11   29235288 xdistilbert_customer808.tar.gz\n",
      "2023-01-20 01:26:12   29235288 xdistilbert_customer809.tar.gz\n",
      "2023-01-20 01:13:29   29235288 xdistilbert_customer81.tar.gz\n",
      "2023-01-20 01:26:13   29235288 xdistilbert_customer810.tar.gz\n",
      "2023-01-20 01:26:14   29235288 xdistilbert_customer811.tar.gz\n",
      "2023-01-20 01:26:15   29235288 xdistilbert_customer812.tar.gz\n",
      "2023-01-20 01:26:16   29235288 xdistilbert_customer813.tar.gz\n",
      "2023-01-20 01:26:17   29235288 xdistilbert_customer814.tar.gz\n",
      "2023-01-20 01:26:18   29235288 xdistilbert_customer815.tar.gz\n",
      "2023-01-20 01:26:19   29235288 xdistilbert_customer816.tar.gz\n",
      "2023-01-20 01:26:20   29235288 xdistilbert_customer817.tar.gz\n",
      "2023-01-20 01:26:21   29235288 xdistilbert_customer818.tar.gz\n",
      "2023-01-20 01:26:22   29235288 xdistilbert_customer819.tar.gz\n",
      "2023-01-20 01:13:30   29235288 xdistilbert_customer82.tar.gz\n",
      "2023-01-20 01:26:23   29235288 xdistilbert_customer820.tar.gz\n",
      "2023-01-20 01:26:24   29235288 xdistilbert_customer821.tar.gz\n",
      "2023-01-20 01:26:25   29235288 xdistilbert_customer822.tar.gz\n",
      "2023-01-20 01:26:26   29235288 xdistilbert_customer823.tar.gz\n",
      "2023-01-20 01:26:27   29235288 xdistilbert_customer824.tar.gz\n",
      "2023-01-20 01:26:28   29235288 xdistilbert_customer825.tar.gz\n",
      "2023-01-20 01:26:29   29235288 xdistilbert_customer826.tar.gz\n",
      "2023-01-20 01:26:30   29235288 xdistilbert_customer827.tar.gz\n",
      "2023-01-20 01:26:31   29235288 xdistilbert_customer828.tar.gz\n",
      "2023-01-20 01:26:32   29235288 xdistilbert_customer829.tar.gz\n",
      "2023-01-20 01:13:31   29235288 xdistilbert_customer83.tar.gz\n",
      "2023-01-20 01:26:33   29235288 xdistilbert_customer830.tar.gz\n",
      "2023-01-20 01:26:34   29235288 xdistilbert_customer831.tar.gz\n",
      "2023-01-20 01:26:35   29235288 xdistilbert_customer832.tar.gz\n",
      "2023-01-20 01:26:36   29235288 xdistilbert_customer833.tar.gz\n",
      "2023-01-20 01:26:37   29235288 xdistilbert_customer834.tar.gz\n",
      "2023-01-20 01:26:38   29235288 xdistilbert_customer835.tar.gz\n",
      "2023-01-20 01:26:39   29235288 xdistilbert_customer836.tar.gz\n",
      "2023-01-20 01:26:40   29235288 xdistilbert_customer837.tar.gz\n",
      "2023-01-20 01:26:41   29235288 xdistilbert_customer838.tar.gz\n",
      "2023-01-20 01:26:42   29235288 xdistilbert_customer839.tar.gz\n",
      "2023-01-20 01:13:32   29235288 xdistilbert_customer84.tar.gz\n",
      "2023-01-20 01:26:43   29235288 xdistilbert_customer840.tar.gz\n",
      "2023-01-20 01:26:44   29235288 xdistilbert_customer841.tar.gz\n",
      "2023-01-20 01:26:45   29235288 xdistilbert_customer842.tar.gz\n",
      "2023-01-20 01:26:46   29235288 xdistilbert_customer843.tar.gz\n",
      "2023-01-20 01:26:47   29235288 xdistilbert_customer844.tar.gz\n",
      "2023-01-20 01:26:48   29235288 xdistilbert_customer845.tar.gz\n",
      "2023-01-20 01:26:49   29235288 xdistilbert_customer846.tar.gz\n",
      "2023-01-20 01:26:50   29235288 xdistilbert_customer847.tar.gz\n",
      "2023-01-20 01:26:51   29235288 xdistilbert_customer848.tar.gz\n",
      "2023-01-20 01:26:52   29235288 xdistilbert_customer849.tar.gz\n",
      "2023-01-20 01:13:33   29235288 xdistilbert_customer85.tar.gz\n",
      "2023-01-20 01:26:53   29235288 xdistilbert_customer850.tar.gz\n",
      "2023-01-20 01:26:54   29235288 xdistilbert_customer851.tar.gz\n",
      "2023-01-20 01:26:55   29235288 xdistilbert_customer852.tar.gz\n",
      "2023-01-20 01:26:56   29235288 xdistilbert_customer853.tar.gz\n",
      "2023-01-20 01:26:57   29235288 xdistilbert_customer854.tar.gz\n",
      "2023-01-20 01:26:58   29235288 xdistilbert_customer855.tar.gz\n",
      "2023-01-20 01:26:59   29235288 xdistilbert_customer856.tar.gz\n",
      "2023-01-20 01:27:00   29235288 xdistilbert_customer857.tar.gz\n",
      "2023-01-20 01:27:01   29235288 xdistilbert_customer858.tar.gz\n",
      "2023-01-20 01:27:02   29235288 xdistilbert_customer859.tar.gz\n",
      "2023-01-20 01:13:34   29235288 xdistilbert_customer86.tar.gz\n",
      "2023-01-20 01:27:03   29235288 xdistilbert_customer860.tar.gz\n",
      "2023-01-20 01:27:04   29235288 xdistilbert_customer861.tar.gz\n",
      "2023-01-20 01:27:05   29235288 xdistilbert_customer862.tar.gz\n",
      "2023-01-20 01:27:07   29235288 xdistilbert_customer863.tar.gz\n",
      "2023-01-20 01:27:08   29235288 xdistilbert_customer864.tar.gz\n",
      "2023-01-20 01:27:08   29235288 xdistilbert_customer865.tar.gz\n",
      "2023-01-20 01:27:09   29235288 xdistilbert_customer866.tar.gz\n",
      "2023-01-20 01:27:10   29235288 xdistilbert_customer867.tar.gz\n",
      "2023-01-20 01:27:11   29235288 xdistilbert_customer868.tar.gz\n",
      "2023-01-20 01:27:13   29235288 xdistilbert_customer869.tar.gz\n",
      "2023-01-20 01:13:35   29235288 xdistilbert_customer87.tar.gz\n",
      "2023-01-20 01:27:14   29235288 xdistilbert_customer870.tar.gz\n",
      "2023-01-20 01:27:15   29235288 xdistilbert_customer871.tar.gz\n",
      "2023-01-20 01:27:16   29235288 xdistilbert_customer872.tar.gz\n",
      "2023-01-20 01:27:17   29235288 xdistilbert_customer873.tar.gz\n",
      "2023-01-20 01:27:18   29235288 xdistilbert_customer874.tar.gz\n",
      "2023-01-20 01:27:19   29235288 xdistilbert_customer875.tar.gz\n",
      "2023-01-20 01:27:20   29235288 xdistilbert_customer876.tar.gz\n",
      "2023-01-20 01:27:21   29235288 xdistilbert_customer877.tar.gz\n",
      "2023-01-20 01:27:22   29235288 xdistilbert_customer878.tar.gz\n",
      "2023-01-20 01:27:23   29235288 xdistilbert_customer879.tar.gz\n",
      "2023-01-20 01:13:36   29235288 xdistilbert_customer88.tar.gz\n",
      "2023-01-20 01:27:24   29235288 xdistilbert_customer880.tar.gz\n",
      "2023-01-20 01:27:25   29235288 xdistilbert_customer881.tar.gz\n",
      "2023-01-20 01:27:26   29235288 xdistilbert_customer882.tar.gz\n",
      "2023-01-20 01:27:27   29235288 xdistilbert_customer883.tar.gz\n",
      "2023-01-20 01:27:28   29235288 xdistilbert_customer884.tar.gz\n",
      "2023-01-20 01:27:29   29235288 xdistilbert_customer885.tar.gz\n",
      "2023-01-20 01:27:30   29235288 xdistilbert_customer886.tar.gz\n",
      "2023-01-20 01:27:31   29235288 xdistilbert_customer887.tar.gz\n",
      "2023-01-20 01:27:32   29235288 xdistilbert_customer888.tar.gz\n",
      "2023-01-20 01:27:33   29235288 xdistilbert_customer889.tar.gz\n",
      "2023-01-20 01:13:37   29235288 xdistilbert_customer89.tar.gz\n",
      "2023-01-20 01:27:34   29235288 xdistilbert_customer890.tar.gz\n",
      "2023-01-20 01:27:35   29235288 xdistilbert_customer891.tar.gz\n",
      "2023-01-20 01:27:37   29235288 xdistilbert_customer892.tar.gz\n",
      "2023-01-20 01:27:38   29235288 xdistilbert_customer893.tar.gz\n",
      "2023-01-20 01:27:39   29235288 xdistilbert_customer894.tar.gz\n",
      "2023-01-20 01:27:40   29235288 xdistilbert_customer895.tar.gz\n",
      "2023-01-20 01:27:41   29235288 xdistilbert_customer896.tar.gz\n",
      "2023-01-20 01:27:41   29235288 xdistilbert_customer897.tar.gz\n",
      "2023-01-20 01:27:42   29235288 xdistilbert_customer898.tar.gz\n",
      "2023-01-20 01:27:43   29235288 xdistilbert_customer899.tar.gz\n",
      "2023-01-20 01:12:15   29235288 xdistilbert_customer9.tar.gz\n",
      "2023-01-20 01:13:38   29235288 xdistilbert_customer90.tar.gz\n",
      "2023-01-20 01:27:44   29235288 xdistilbert_customer900.tar.gz\n",
      "2023-01-20 01:27:45   29235288 xdistilbert_customer901.tar.gz\n",
      "2023-01-20 01:27:46   29235288 xdistilbert_customer902.tar.gz\n",
      "2023-01-20 01:27:47   29235288 xdistilbert_customer903.tar.gz\n",
      "2023-01-20 01:27:48   29235288 xdistilbert_customer904.tar.gz\n",
      "2023-01-20 01:27:49   29235288 xdistilbert_customer905.tar.gz\n",
      "2023-01-20 01:27:50   29235288 xdistilbert_customer906.tar.gz\n",
      "2023-01-20 01:27:51   29235288 xdistilbert_customer907.tar.gz\n",
      "2023-01-20 01:27:52   29235288 xdistilbert_customer908.tar.gz\n",
      "2023-01-20 01:27:53   29235288 xdistilbert_customer909.tar.gz\n",
      "2023-01-20 01:13:39   29235288 xdistilbert_customer91.tar.gz\n",
      "2023-01-20 01:27:54   29235288 xdistilbert_customer910.tar.gz\n",
      "2023-01-20 01:27:55   29235288 xdistilbert_customer911.tar.gz\n",
      "2023-01-20 01:27:56   29235288 xdistilbert_customer912.tar.gz\n",
      "2023-01-20 01:27:57   29235288 xdistilbert_customer913.tar.gz\n",
      "2023-01-20 01:27:58   29235288 xdistilbert_customer914.tar.gz\n",
      "2023-01-20 01:27:59   29235288 xdistilbert_customer915.tar.gz\n",
      "2023-01-20 01:28:00   29235288 xdistilbert_customer916.tar.gz\n",
      "2023-01-20 01:28:01   29235288 xdistilbert_customer917.tar.gz\n",
      "2023-01-20 01:28:02   29235288 xdistilbert_customer918.tar.gz\n",
      "2023-01-20 01:28:03   29235288 xdistilbert_customer919.tar.gz\n",
      "2023-01-20 01:13:40   29235288 xdistilbert_customer92.tar.gz\n",
      "2023-01-20 01:28:04   29235288 xdistilbert_customer920.tar.gz\n",
      "2023-01-20 01:28:05   29235288 xdistilbert_customer921.tar.gz\n",
      "2023-01-20 01:28:06   29235288 xdistilbert_customer922.tar.gz\n",
      "2023-01-20 01:28:07   29235288 xdistilbert_customer923.tar.gz\n",
      "2023-01-20 01:28:08   29235288 xdistilbert_customer924.tar.gz\n",
      "2023-01-20 01:28:09   29235288 xdistilbert_customer925.tar.gz\n",
      "2023-01-20 01:28:10   29235288 xdistilbert_customer926.tar.gz\n",
      "2023-01-20 01:28:11   29235288 xdistilbert_customer927.tar.gz\n",
      "2023-01-20 01:28:12   29235288 xdistilbert_customer928.tar.gz\n",
      "2023-01-20 01:28:13   29235288 xdistilbert_customer929.tar.gz\n",
      "2023-01-20 01:13:41   29235288 xdistilbert_customer93.tar.gz\n",
      "2023-01-20 01:28:14   29235288 xdistilbert_customer930.tar.gz\n",
      "2023-01-20 01:28:15   29235288 xdistilbert_customer931.tar.gz\n",
      "2023-01-20 01:28:16   29235288 xdistilbert_customer932.tar.gz\n",
      "2023-01-20 01:28:17   29235288 xdistilbert_customer933.tar.gz\n",
      "2023-01-20 01:28:18   29235288 xdistilbert_customer934.tar.gz\n",
      "2023-01-20 01:28:19   29235288 xdistilbert_customer935.tar.gz\n",
      "2023-01-20 01:28:20   29235288 xdistilbert_customer936.tar.gz\n",
      "2023-01-20 01:28:21   29235288 xdistilbert_customer937.tar.gz\n",
      "2023-01-20 01:28:22   29235288 xdistilbert_customer938.tar.gz\n",
      "2023-01-20 01:28:23   29235288 xdistilbert_customer939.tar.gz\n",
      "2023-01-20 01:13:43   29235288 xdistilbert_customer94.tar.gz\n",
      "2023-01-20 01:28:24   29235288 xdistilbert_customer940.tar.gz\n",
      "2023-01-20 01:28:25   29235288 xdistilbert_customer941.tar.gz\n",
      "2023-01-20 01:28:26   29235288 xdistilbert_customer942.tar.gz\n",
      "2023-01-20 01:28:27   29235288 xdistilbert_customer943.tar.gz\n",
      "2023-01-20 01:28:28   29235288 xdistilbert_customer944.tar.gz\n",
      "2023-01-20 01:28:29   29235288 xdistilbert_customer945.tar.gz\n",
      "2023-01-20 01:28:30   29235288 xdistilbert_customer946.tar.gz\n",
      "2023-01-20 01:28:31   29235288 xdistilbert_customer947.tar.gz\n",
      "2023-01-20 01:28:32   29235288 xdistilbert_customer948.tar.gz\n",
      "2023-01-20 01:28:33   29235288 xdistilbert_customer949.tar.gz\n",
      "2023-01-20 01:13:44   29235288 xdistilbert_customer95.tar.gz\n",
      "2023-01-20 01:28:34   29235288 xdistilbert_customer950.tar.gz\n",
      "2023-01-20 01:28:35   29235288 xdistilbert_customer951.tar.gz\n",
      "2023-01-20 01:28:36   29235288 xdistilbert_customer952.tar.gz\n",
      "2023-01-20 01:28:37   29235288 xdistilbert_customer953.tar.gz\n",
      "2023-01-20 01:28:38   29235288 xdistilbert_customer954.tar.gz\n",
      "2023-01-20 01:28:39   29235288 xdistilbert_customer955.tar.gz\n",
      "2023-01-20 01:28:40   29235288 xdistilbert_customer956.tar.gz\n",
      "2023-01-20 01:28:41   29235288 xdistilbert_customer957.tar.gz\n",
      "2023-01-20 01:28:42   29235288 xdistilbert_customer958.tar.gz\n",
      "2023-01-20 01:28:43   29235288 xdistilbert_customer959.tar.gz\n",
      "2023-01-20 01:13:45   29235288 xdistilbert_customer96.tar.gz\n",
      "2023-01-20 01:28:44   29235288 xdistilbert_customer960.tar.gz\n",
      "2023-01-20 01:28:45   29235288 xdistilbert_customer961.tar.gz\n",
      "2023-01-20 01:28:46   29235288 xdistilbert_customer962.tar.gz\n",
      "2023-01-20 01:28:47   29235288 xdistilbert_customer963.tar.gz\n",
      "2023-01-20 01:28:48   29235288 xdistilbert_customer964.tar.gz\n",
      "2023-01-20 01:28:49   29235288 xdistilbert_customer965.tar.gz\n",
      "2023-01-20 01:28:50   29235288 xdistilbert_customer966.tar.gz\n",
      "2023-01-20 01:28:51   29235288 xdistilbert_customer967.tar.gz\n",
      "2023-01-20 01:28:52   29235288 xdistilbert_customer968.tar.gz\n",
      "2023-01-20 01:28:53   29235288 xdistilbert_customer969.tar.gz\n",
      "2023-01-20 01:13:46   29235288 xdistilbert_customer97.tar.gz\n",
      "2023-01-20 01:28:54   29235288 xdistilbert_customer970.tar.gz\n",
      "2023-01-20 01:28:55   29235288 xdistilbert_customer971.tar.gz\n",
      "2023-01-20 01:28:56   29235288 xdistilbert_customer972.tar.gz\n",
      "2023-01-20 01:28:57   29235288 xdistilbert_customer973.tar.gz\n",
      "2023-01-20 01:28:58   29235288 xdistilbert_customer974.tar.gz\n",
      "2023-01-20 01:28:59   29235288 xdistilbert_customer975.tar.gz\n",
      "2023-01-20 01:29:00   29235288 xdistilbert_customer976.tar.gz\n",
      "2023-01-20 01:29:01   29235288 xdistilbert_customer977.tar.gz\n",
      "2023-01-20 01:29:02   29235288 xdistilbert_customer978.tar.gz\n",
      "2023-01-20 01:29:03   29235288 xdistilbert_customer979.tar.gz\n",
      "2023-01-20 01:13:47   29235288 xdistilbert_customer98.tar.gz\n",
      "2023-01-20 01:29:04   29235288 xdistilbert_customer980.tar.gz\n",
      "2023-01-20 01:29:05   29235288 xdistilbert_customer981.tar.gz\n",
      "2023-01-20 01:29:06   29235288 xdistilbert_customer982.tar.gz\n",
      "2023-01-20 01:29:07   29235288 xdistilbert_customer983.tar.gz\n",
      "2023-01-20 01:29:09   29235288 xdistilbert_customer984.tar.gz\n",
      "2023-01-20 01:29:10   29235288 xdistilbert_customer985.tar.gz\n",
      "2023-01-20 01:29:11   29235288 xdistilbert_customer986.tar.gz\n",
      "2023-01-20 01:29:12   29235288 xdistilbert_customer987.tar.gz\n",
      "2023-01-20 01:29:12   29235288 xdistilbert_customer988.tar.gz\n",
      "2023-01-20 01:29:13   29235288 xdistilbert_customer989.tar.gz\n",
      "2023-01-20 01:13:48   29235288 xdistilbert_customer99.tar.gz\n",
      "2023-01-20 01:29:15   29235288 xdistilbert_customer990.tar.gz\n",
      "2023-01-20 01:29:16   29235288 xdistilbert_customer991.tar.gz\n",
      "2023-01-20 01:29:17   29235288 xdistilbert_customer992.tar.gz\n",
      "2023-01-20 01:29:17   29235288 xdistilbert_customer993.tar.gz\n",
      "2023-01-20 01:29:18   29235288 xdistilbert_customer994.tar.gz\n",
      "2023-01-20 01:29:19   29235288 xdistilbert_customer995.tar.gz\n",
      "2023-01-20 01:29:20   29235288 xdistilbert_customer996.tar.gz\n",
      "2023-01-20 01:29:21   29235288 xdistilbert_customer997.tar.gz\n",
      "2023-01-20 01:29:22   29235288 xdistilbert_customer998.tar.gz\n",
      "2023-01-20 01:29:23   29235288 xdistilbert_customer999.tar.gz\n",
      "2023-01-20 00:55:01   46620193 xdistilbert_pt.tar.gz\n",
      "2023-01-20 00:55:04   29235288 xdistilbert_trt.tar.gz\n"
     ]
    }
   ],
   "source": [
    "!aws s3 ls $model_data_url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f091ec-f438-41c0-b00a-71f50111b546",
   "metadata": {},
   "source": [
    "## Set up MME AutoScaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2f2eb482-42ee-43f0-a7d9-2bb7328a5dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_scaling_client = boto3.client('application-autoscaling')\n",
    "\n",
    "resource_id='endpoint/' + endpoint_name + '/variant/' + 'AllTraffic' \n",
    "response = auto_scaling_client.register_scalable_target(\n",
    "    ServiceNamespace='sagemaker',\n",
    "    ResourceId=resource_id,\n",
    "    ScalableDimension='sagemaker:variant:DesiredInstanceCount',\n",
    "    MinCapacity = 1,\n",
    "    MaxCapacity = 13\n",
    ")\n",
    "\n",
    "response = auto_scaling_client.put_scaling_policy(\n",
    "    PolicyName='GPUMemUtil-ScalingPolicy',\n",
    "    ServiceNamespace='sagemaker',\n",
    "    ResourceId=resource_id,\n",
    "    ScalableDimension='sagemaker:variant:DesiredInstanceCount', \n",
    "    PolicyType='TargetTrackingScaling',\n",
    "    TargetTrackingScalingPolicyConfiguration={\n",
    "        'TargetValue': 70.0, \n",
    "        'CustomizedMetricSpecification':\n",
    "        {\n",
    "            'MetricName': 'GPUMemoryUtilization',\n",
    "            'Namespace': '/aws/sagemaker/Endpoints',\n",
    "            'Dimensions': [\n",
    "                {'Name': 'EndpointName', 'Value': endpoint_name},\n",
    "                {'Name': 'VariantName','Value': 'AllTraffic'}\n",
    "            ],\n",
    "            'Statistic': 'Average',\n",
    "            'Unit': 'Percent'\n",
    "        },\n",
    "        'ScaleInCooldown': 600,\n",
    "        'ScaleOutCooldown': 1 \n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd09ee3a-7b8e-4bf0-b491-1aa2f16156cd",
   "metadata": {},
   "source": [
    "## Put Load on MME Endpoint to see it scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d3976ac2-0c78-4224-a1ff-a40d90e5c9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict_model(text, model_name):\n",
    "    print(f\"Using model {model_name} to predict\")\n",
    "    \n",
    "    request_body, header_length = get_sample_tokenized_text_binary_trt(text)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    response = runtime_sm_client.invoke_endpoint(EndpointName=endpoint_name,\n",
    "                                  ContentType='application/vnd.sagemaker-triton.binary+json;json-header-size={}'.format(header_length),\n",
    "                                  Body=request_body,\n",
    "                                  TargetModel=model_name)\n",
    "    \n",
    "    duration = time.time() - start_time\n",
    "    \n",
    "    # Parse json header size length from the response\n",
    "    header_length_prefix = \"application/vnd.sagemaker-triton.binary+json;json-header-size=\"\n",
    "    header_length_str = response['ContentType'][len(header_length_prefix):]\n",
    "    output_name = \"logits\"\n",
    "    # Read response body\n",
    "    result = httpclient.InferenceServerClient.parse_response_body(\n",
    "        response['Body'].read(), header_length=int(header_length_str))\n",
    "    logits = result.as_numpy(output_name)\n",
    "    predictions = get_predictions(logits)\n",
    "    \n",
    "    print(f\"prediction: {predictions}, took {int(duration * 1000)} ms\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dada5960-1f28-49c6-9d56-8e5e6064f0be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model xdistilbert_trt.tar.gz to predict\n",
      "prediction: ['JOY'], took 10 ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict_model(sample_text, \"xdistilbert_trt.tar.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "287b1cf7-7aea-4018-868e-7d14ecf25cdc",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model xdistilbert_customer799.tar.gz to predict\n",
      "prediction: ['JOY'], took 3074 ms\n",
      "\n",
      "Using model xdistilbert_customer118.tar.gz to predict\n",
      "prediction: ['JOY'], took 1288 ms\n",
      "\n",
      "Using model xdistilbert_customer195.tar.gz to predict\n",
      "prediction: ['JOY'], took 1274 ms\n",
      "\n",
      "Using model xdistilbert_customer376.tar.gz to predict\n",
      "prediction: ['JOY'], took 1274 ms\n",
      "\n",
      "Using model xdistilbert_customer507.tar.gz to predict\n",
      "prediction: ['JOY'], took 1223 ms\n",
      "\n",
      "Using model xdistilbert_customer550.tar.gz to predict\n",
      "prediction: ['JOY'], took 1299 ms\n",
      "\n",
      "Using model xdistilbert_customer244.tar.gz to predict\n",
      "prediction: ['JOY'], took 1649 ms\n",
      "\n",
      "Using model xdistilbert_customer195.tar.gz to predict\n",
      "prediction: ['JOY'], took 11 ms\n",
      "\n",
      "Using model xdistilbert_customer149.tar.gz to predict\n",
      "prediction: ['JOY'], took 1236 ms\n",
      "\n",
      "Using model xdistilbert_customer696.tar.gz to predict\n",
      "prediction: ['JOY'], took 1399 ms\n",
      "\n",
      "Using model xdistilbert_customer848.tar.gz to predict\n",
      "prediction: ['JOY'], took 1273 ms\n",
      "\n",
      "Using model xdistilbert_customer495.tar.gz to predict\n",
      "prediction: ['JOY'], took 1250 ms\n",
      "\n",
      "Using model xdistilbert_customer999.tar.gz to predict\n",
      "prediction: ['JOY'], took 1249 ms\n",
      "\n",
      "Using model xdistilbert_customer20.tar.gz to predict\n",
      "prediction: ['JOY'], took 1223 ms\n",
      "\n",
      "Using model xdistilbert_customer286.tar.gz to predict\n",
      "prediction: ['JOY'], took 1374 ms\n",
      "\n",
      "Using model xdistilbert_customer892.tar.gz to predict\n",
      "prediction: ['JOY'], took 1201 ms\n",
      "\n",
      "Using model xdistilbert_customer624.tar.gz to predict\n",
      "prediction: ['JOY'], took 1272 ms\n",
      "\n",
      "Using model xdistilbert_customer259.tar.gz to predict\n",
      "prediction: ['JOY'], took 1299 ms\n",
      "\n",
      "Using model xdistilbert_customer808.tar.gz to predict\n",
      "prediction: ['JOY'], took 1299 ms\n",
      "\n",
      "Using model xdistilbert_customer40.tar.gz to predict\n",
      "prediction: ['JOY'], took 1324 ms\n",
      "\n",
      "Using model xdistilbert_customer841.tar.gz to predict\n",
      "prediction: ['JOY'], took 1273 ms\n",
      "\n",
      "Using model xdistilbert_customer150.tar.gz to predict\n",
      "prediction: ['JOY'], took 1299 ms\n",
      "\n",
      "Using model xdistilbert_customer260.tar.gz to predict\n",
      "prediction: ['JOY'], took 1299 ms\n",
      "\n",
      "Using model xdistilbert_customer922.tar.gz to predict\n",
      "prediction: ['JOY'], took 1249 ms\n",
      "\n",
      "Using model xdistilbert_customer803.tar.gz to predict\n",
      "prediction: ['JOY'], took 1223 ms\n",
      "\n",
      "Using model xdistilbert_customer684.tar.gz to predict\n",
      "prediction: ['JOY'], took 1273 ms\n",
      "\n",
      "Using model xdistilbert_customer796.tar.gz to predict\n",
      "prediction: ['JOY'], took 1250 ms\n",
      "\n",
      "Using model xdistilbert_customer642.tar.gz to predict\n",
      "prediction: ['JOY'], took 1197 ms\n",
      "\n",
      "Using model xdistilbert_customer841.tar.gz to predict\n",
      "prediction: ['JOY'], took 8 ms\n",
      "\n",
      "Using model xdistilbert_customer885.tar.gz to predict\n",
      "prediction: ['JOY'], took 1441 ms\n",
      "\n",
      "Using model xdistilbert_customer287.tar.gz to predict\n",
      "prediction: ['JOY'], took 1324 ms\n",
      "\n",
      "Using model xdistilbert_customer876.tar.gz to predict\n",
      "prediction: ['JOY'], took 1298 ms\n",
      "\n",
      "Using model xdistilbert_customer643.tar.gz to predict\n",
      "prediction: ['JOY'], took 1273 ms\n",
      "\n",
      "Using model xdistilbert_customer902.tar.gz to predict\n",
      "prediction: ['JOY'], took 1249 ms\n",
      "\n",
      "Using model xdistilbert_customer106.tar.gz to predict\n",
      "prediction: ['JOY'], took 1274 ms\n",
      "\n",
      "Using model xdistilbert_customer491.tar.gz to predict\n",
      "prediction: ['JOY'], took 1274 ms\n",
      "\n",
      "Using model xdistilbert_customer328.tar.gz to predict\n",
      "prediction: ['JOY'], took 1224 ms\n",
      "\n",
      "Using model xdistilbert_customer829.tar.gz to predict\n",
      "prediction: ['JOY'], took 1273 ms\n",
      "\n",
      "Using model xdistilbert_customer223.tar.gz to predict\n",
      "prediction: ['JOY'], took 1324 ms\n",
      "\n",
      "Using model xdistilbert_customer790.tar.gz to predict\n",
      "prediction: ['JOY'], took 1300 ms\n",
      "\n",
      "Using model xdistilbert_customer754.tar.gz to predict\n",
      "prediction: ['JOY'], took 1298 ms\n",
      "\n",
      "Using model xdistilbert_customer400.tar.gz to predict\n",
      "prediction: ['JOY'], took 1248 ms\n",
      "\n",
      "Using model xdistilbert_customer948.tar.gz to predict\n",
      "prediction: ['JOY'], took 1374 ms\n",
      "\n",
      "Using model xdistilbert_customer577.tar.gz to predict\n",
      "prediction: ['JOY'], took 1323 ms\n",
      "\n",
      "Using model xdistilbert_customer530.tar.gz to predict\n",
      "prediction: ['JOY'], took 1249 ms\n",
      "\n",
      "Using model xdistilbert_customer136.tar.gz to predict\n",
      "prediction: ['JOY'], took 1299 ms\n",
      "\n",
      "Using model xdistilbert_customer522.tar.gz to predict\n",
      "prediction: ['JOY'], took 1273 ms\n",
      "\n",
      "Using model xdistilbert_customer788.tar.gz to predict\n",
      "prediction: ['JOY'], took 1299 ms\n",
      "\n",
      "Using model xdistilbert_customer974.tar.gz to predict\n",
      "prediction: ['JOY'], took 1224 ms\n",
      "\n",
      "Using model xdistilbert_customer749.tar.gz to predict\n",
      "prediction: ['JOY'], took 1273 ms\n",
      "\n",
      "Using model xdistilbert_customer606.tar.gz to predict\n",
      "prediction: ['JOY'], took 1224 ms\n",
      "\n",
      "Using model xdistilbert_customer533.tar.gz to predict\n",
      "prediction: ['JOY'], took 1199 ms\n",
      "\n",
      "Using model xdistilbert_customer710.tar.gz to predict\n",
      "prediction: ['JOY'], took 1249 ms\n",
      "\n",
      "Using model xdistilbert_customer74.tar.gz to predict\n",
      "prediction: ['JOY'], took 1274 ms\n",
      "\n",
      "Using model xdistilbert_customer594.tar.gz to predict\n",
      "prediction: ['JOY'], took 1373 ms\n",
      "\n",
      "Using model xdistilbert_customer552.tar.gz to predict\n",
      "prediction: ['JOY'], took 1248 ms\n",
      "\n",
      "Using model xdistilbert_customer367.tar.gz to predict\n",
      "prediction: ['JOY'], took 1224 ms\n",
      "\n",
      "Using model xdistilbert_customer799.tar.gz to predict\n",
      "prediction: ['JOY'], took 9 ms\n",
      "\n",
      "Using model xdistilbert_customer39.tar.gz to predict\n",
      "prediction: ['JOY'], took 1314 ms\n",
      "\n",
      "Using model xdistilbert_customer787.tar.gz to predict\n",
      "prediction: ['JOY'], took 1274 ms\n",
      "\n",
      "Using model xdistilbert_customer863.tar.gz to predict\n",
      "prediction: ['JOY'], took 1223 ms\n",
      "\n",
      "Using model xdistilbert_customer306.tar.gz to predict\n",
      "prediction: ['JOY'], took 1324 ms\n",
      "\n",
      "Using model xdistilbert_customer281.tar.gz to predict\n",
      "prediction: ['JOY'], took 1274 ms\n",
      "\n",
      "Using model xdistilbert_customer896.tar.gz to predict\n",
      "prediction: ['JOY'], took 1448 ms\n",
      "\n",
      "Using model xdistilbert_customer441.tar.gz to predict\n",
      "prediction: ['JOY'], took 1250 ms\n",
      "\n",
      "Using model xdistilbert_customer196.tar.gz to predict\n",
      "prediction: ['JOY'], took 1248 ms\n",
      "\n",
      "Using model xdistilbert_customer544.tar.gz to predict\n",
      "prediction: ['JOY'], took 1299 ms\n",
      "\n",
      "Using model xdistilbert_customer927.tar.gz to predict\n",
      "prediction: ['JOY'], took 1273 ms\n",
      "\n",
      "Using model xdistilbert_customer634.tar.gz to predict\n",
      "prediction: ['JOY'], took 1199 ms\n",
      "\n",
      "Using model xdistilbert_customer938.tar.gz to predict\n",
      "prediction: ['JOY'], took 1275 ms\n",
      "\n",
      "Using model xdistilbert_customer327.tar.gz to predict\n",
      "prediction: ['JOY'], took 1272 ms\n",
      "\n",
      "Using model xdistilbert_customer607.tar.gz to predict\n",
      "prediction: ['JOY'], took 1299 ms\n",
      "\n",
      "Using model xdistilbert_customer791.tar.gz to predict\n",
      "prediction: ['JOY'], took 1249 ms\n",
      "\n",
      "Using model xdistilbert_customer179.tar.gz to predict\n",
      "prediction: ['JOY'], took 1349 ms\n",
      "\n",
      "Using model xdistilbert_customer816.tar.gz to predict\n",
      "prediction: ['JOY'], took 1349 ms\n",
      "\n",
      "Using model xdistilbert_customer271.tar.gz to predict\n",
      "prediction: ['JOY'], took 1298 ms\n",
      "\n",
      "Using model xdistilbert_customer303.tar.gz to predict\n",
      "prediction: ['JOY'], took 1274 ms\n",
      "\n",
      "Using model xdistilbert_customer285.tar.gz to predict\n",
      "prediction: ['JOY'], took 1249 ms\n",
      "\n",
      "Using model xdistilbert_customer25.tar.gz to predict\n",
      "prediction: ['JOY'], took 1300 ms\n",
      "\n",
      "Using model xdistilbert_customer942.tar.gz to predict\n",
      "prediction: ['JOY'], took 1274 ms\n",
      "\n",
      "Using model xdistilbert_customer871.tar.gz to predict\n",
      "prediction: ['JOY'], took 1249 ms\n",
      "\n",
      "Using model xdistilbert_customer61.tar.gz to predict\n",
      "prediction: ['JOY'], took 1248 ms\n",
      "\n",
      "Using model xdistilbert_customer754.tar.gz to predict\n",
      "prediction: ['JOY'], took 8 ms\n",
      "\n",
      "Using model xdistilbert_customer879.tar.gz to predict\n",
      "prediction: ['JOY'], took 1316 ms\n",
      "\n",
      "Using model xdistilbert_customer175.tar.gz to predict\n",
      "prediction: ['JOY'], took 1299 ms\n",
      "\n",
      "Using model xdistilbert_customer804.tar.gz to predict\n",
      "prediction: ['JOY'], took 1274 ms\n",
      "\n",
      "Using model xdistilbert_customer550.tar.gz to predict\n",
      "prediction: ['JOY'], took 7 ms\n",
      "\n",
      "Using model xdistilbert_customer146.tar.gz to predict\n",
      "prediction: ['JOY'], took 1241 ms\n",
      "\n",
      "Using model xdistilbert_customer608.tar.gz to predict\n",
      "prediction: ['JOY'], took 1198 ms\n",
      "\n",
      "Using model xdistilbert_customer874.tar.gz to predict\n",
      "prediction: ['JOY'], took 1349 ms\n",
      "\n",
      "Using model xdistilbert_customer445.tar.gz to predict\n",
      "prediction: ['JOY'], took 1224 ms\n",
      "\n",
      "Using model xdistilbert_customer442.tar.gz to predict\n",
      "prediction: ['JOY'], took 1324 ms\n",
      "\n",
      "Using model xdistilbert_customer163.tar.gz to predict\n",
      "prediction: ['JOY'], took 1249 ms\n",
      "\n",
      "Using model xdistilbert_customer184.tar.gz to predict\n",
      "prediction: ['JOY'], took 1223 ms\n",
      "\n",
      "Using model xdistilbert_customer750.tar.gz to predict\n",
      "prediction: ['JOY'], took 1299 ms\n",
      "\n",
      "Using model xdistilbert_customer425.tar.gz to predict\n",
      "prediction: ['JOY'], took 1324 ms\n",
      "\n",
      "Using model xdistilbert_customer768.tar.gz to predict\n",
      "prediction: ['JOY'], took 1249 ms\n",
      "\n",
      "Using model xdistilbert_customer417.tar.gz to predict\n",
      "prediction: ['JOY'], took 1349 ms\n",
      "\n",
      "Using model xdistilbert_customer874.tar.gz to predict\n",
      "prediction: ['JOY'], took 29 ms\n",
      "\n",
      "Using model xdistilbert_customer712.tar.gz to predict\n",
      "prediction: ['JOY'], took 1268 ms\n",
      "\n",
      "Using model xdistilbert_customer409.tar.gz to predict\n",
      "prediction: ['JOY'], took 1249 ms\n",
      "\n",
      "Using model xdistilbert_customer276.tar.gz to predict\n",
      "prediction: ['JOY'], took 1274 ms\n",
      "\n",
      "Using model xdistilbert_customer755.tar.gz to predict\n",
      "prediction: ['JOY'], took 1348 ms\n",
      "\n",
      "Using model xdistilbert_customer429.tar.gz to predict\n",
      "prediction: ['JOY'], took 1224 ms\n",
      "\n",
      "Using model xdistilbert_customer430.tar.gz to predict\n"
     ]
    },
    {
     "ename": "ModelError",
     "evalue": "An error occurred (ModelError) when calling the InvokeEndpoint operation: Received client error (400) from primary with message \"{\"error\":\"load failed for model '9e1557a22aabdec50dee32213a37b2f0': version 1 is at UNAVAILABLE state: Internal: unable to load plan file to auto complete config: /opt/ml/models/9e1557a22aabdec50dee32213a37b2f0/model/xdistilbert_trt/1/model.plan;\\n\"}\". See https://us-west-2.console.aws.amazon.com/cloudwatch/home?region=us-west-2#logEventViewer:group=/aws/sagemaker/Endpoints/mme-gpu-ep-2023-01-20-02-09-04 in account 354625738399 for more information.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModelError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_7879/2121613491.py\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNUM_MODELS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mcustomer_model_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"xdistilbert_customer{i}.tar.gz\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mpredict_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustomer_model_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_7879/354592797.py\u001b[0m in \u001b[0;36mpredict_model\u001b[0;34m(text, model_name)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     response = runtime_sm_client.invoke_endpoint(EndpointName=endpoint_name,\n\u001b[0m\u001b[1;32m      9\u001b[0m                                   \u001b[0mContentType\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'application/vnd.sagemaker-triton.binary+json;json-header-size={}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheader_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                                   \u001b[0mBody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest_body\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    528\u001b[0m                 )\n\u001b[1;32m    529\u001b[0m             \u001b[0;31m# The \"self\" in this scope is referring to the BaseClient.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_api_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0m_api_call\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_operation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    958\u001b[0m             \u001b[0merror_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Code\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m             \u001b[0merror_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 960\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    961\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModelError\u001b[0m: An error occurred (ModelError) when calling the InvokeEndpoint operation: Received client error (400) from primary with message \"{\"error\":\"load failed for model '9e1557a22aabdec50dee32213a37b2f0': version 1 is at UNAVAILABLE state: Internal: unable to load plan file to auto complete config: /opt/ml/models/9e1557a22aabdec50dee32213a37b2f0/model/xdistilbert_trt/1/model.plan;\\n\"}\". See https://us-west-2.console.aws.amazon.com/cloudwatch/home?region=us-west-2#logEventViewer:group=/aws/sagemaker/Endpoints/mme-gpu-ep-2023-01-20-02-09-04 in account 354625738399 for more information."
     ]
    }
   ],
   "source": [
    "import random\n",
    "NUM_MODELS = 1000\n",
    "for _ in range(100000):\n",
    "    i = random.randint(1, NUM_MODELS)\n",
    "    customer_model_name = f\"xdistilbert_customer{i}.tar.gz\"\n",
    "    predict_model(sample_text, customer_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d81c8398-cd11-4763-8a5c-8b7c98b55e0d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: InService\n"
     ]
    }
   ],
   "source": [
    "response = sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "status = response['EndpointStatus']\n",
    "print(\"Status: \" + status)\n",
    "\n",
    "while status=='Updating':\n",
    "    time.sleep(60)\n",
    "    response = sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "    status = response['EndpointStatus']\n",
    "    instance_count = response['ProductionVariants'][0]['CurrentInstanceCount']\n",
    "    print(f\"Status: {status}\")\n",
    "    print(f\"Current Instance count: {instance_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8f8a5e18-dd70-44a2-b42e-e10d54a54262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: InService\n",
      "Current Instance count: 1\n"
     ]
    }
   ],
   "source": [
    "response = sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "status = response['EndpointStatus']\n",
    "instance_count = response['ProductionVariants'][0]['CurrentInstanceCount']\n",
    "print(f\"Status: {status}\")\n",
    "print(f\"Current Instance count: {instance_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc554e11-61c0-484c-893e-cdd973c7201f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c73e4a-a309-4730-8ff0-04c59d506b4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0984d714-aff5-447e-9436-d1a534309263",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "12b8d083-c9ae-4629-bf94-7c024af46628",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27272ff9-28a7-43e6-9e05-2ab52e5f03cb",
   "metadata": {},
   "source": [
    "```\n",
    "xdistilbert_english\n",
    ".\n",
    ".\n",
    ".\n",
    "xdistilbert_chinese \n",
    "xdistilbert_APAC\n",
    ".\n",
    ".\n",
    ".\n",
    "xdistilbert_NALA\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbec88f-cbdb-4567-9048-50c0d9746fae",
   "metadata": {},
   "source": [
    "# Clean Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1081fd3f-48c1-4de1-bbfc-4368ae8e8742",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '80c487ef-48ec-4849-8f84-499ebd07274c',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '80c487ef-48ec-4849-8f84-499ebd07274c',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '0',\n",
       "   'date': 'Fri, 20 Jan 2023 04:14:38 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm_client.delete_endpoint(EndpointName=endpoint_name)\n",
    "sm_client.delete_endpoint_config(EndpointConfigName=endpoint_config_name)\n",
    "sm_client.delete_model(ModelName=sm_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31407206-2d9e-4cc8-83a7-8d9e8e4748c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
