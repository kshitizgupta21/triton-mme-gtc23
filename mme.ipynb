{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7210102-aba1-42f4-a5f7-90bac19ac6b3",
   "metadata": {},
   "source": [
    "## Deploying Multiple Frameworks Models on GPU "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66483eb5-f1ee-43ac-8f8b-3bc2a02a1fc3",
   "metadata": {},
   "source": [
    "## Installs <a class=\"anchor\" id=\"installs-and-set-up\"></a>\n",
    "\n",
    "Install required packages using pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9e2956ae-e471-401e-9eb7-87a69df9c4b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))': /simple/pip/\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))': /packages/90/5b/02becd3e137fdacdc30c6442d04094d0b92e500f978df00b1a197b68fd2b/transformers-4.25.1-py3-none-any.whl\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -qU pip boto3 sagemaker awscli tritonclient[http] transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b537a3-72b8-40d9-aed4-415efd008d09",
   "metadata": {},
   "source": [
    "#### Imports and variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92279c0c-cd98-4928-8425-3530697fb9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "import time\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "#variables\n",
    "prefix = \"mme-gpu\"\n",
    "model_name = \"xdistilbert\"\n",
    "pytorch_model_file_name = f\"{model_name}_pt.tar.gz\"\n",
    "tensorrt_model_file_name = f\"{model_name}_trt.tar.gz\"\n",
    "s3_client = boto3.client(\"s3\")\n",
    "ts = time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.gmtime())\n",
    "\n",
    "# sagemaker variables\n",
    "role = get_execution_role()\n",
    "sm_client = boto3.client(service_name=\"sagemaker\")\n",
    "runtime_sm_client = boto3.client(\"sagemaker-runtime\")\n",
    "sagemaker_session = sagemaker.Session(boto_session=boto3.Session())\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "\n",
    "# endpoint variables\n",
    "sm_model_name = f\"{prefix}-mdl-{ts}\"\n",
    "endpoint_config_name = f\"{prefix}-epc-{ts}\"\n",
    "endpoint_name = f\"{prefix}-ep-{ts}\"\n",
    "model_data_url = f\"s3://{bucket}/{prefix}/\"\n",
    "instance_type = \"ml.g5.xlarge\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308dede4-e603-4e48-adb8-2d5a55b8f0d0",
   "metadata": {},
   "source": [
    "## Creating Model Artifacts <a class=\"anchor\" id=\"pytorch-efficientnet-model\"></a>\n",
    "\n",
    "\n",
    "\n",
    "<div class=\"alert alert-info\"><strong> Note </strong>\n",
    "We are demonstrating deployment with\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eeb7345-7bee-4ade-9213-1bd7082ca900",
   "metadata": {},
   "source": [
    "### Prepare PyTorch Model  <a class=\"anchor\" id=\"create-pytorch-model\"></a>\n",
    "\n",
    "Run the cell below and check out the [pt_exporter.py](./workspace/pt_exporter.py) file for more details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0dae16a-1bde-422b-9635-5b6e005e59c2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to find image 'nvcr.io/nvidia/pytorch:22.12-py3' locally\n",
      "22.12-py3: Pulling from nvidia/pytorch\n",
      "\n",
      "\u001b[1B0b181fff: Pulling fs layer \n",
      "\u001b[1Bf751e984: Pulling fs layer \n",
      "\u001b[1Bb807c637: Pulling fs layer \n",
      "\u001b[1B2991e393: Pulling fs layer \n",
      "\u001b[1B71274096: Pulling fs layer \n",
      "\u001b[1B91138ef8: Pulling fs layer \n",
      "\u001b[1Bed3c7117: Pulling fs layer \n",
      "\u001b[1B46181ee6: Pulling fs layer \n",
      "\u001b[1Ba7918caa: Pulling fs layer \n",
      "\u001b[1B2fbe7c33: Pulling fs layer \n",
      "\u001b[1B8dd49356: Pulling fs layer \n",
      "\u001b[1B8fc97997: Pulling fs layer \n",
      "\u001b[1Ba4765a47: Pulling fs layer \n",
      "\u001b[1Bb700ef54: Pulling fs layer \n",
      "\u001b[1B6993c2a6: Pulling fs layer \n",
      "\u001b[1Bdfdccd09: Pulling fs layer \n",
      "\u001b[1B104c2b1e: Pulling fs layer \n",
      "\u001b[1Ba5e6a375: Pulling fs layer \n",
      "\u001b[1Be985500c: Pulling fs layer \n",
      "\u001b[1Bb7199f2c: Pulling fs layer \n",
      "\u001b[1Bdc6e60f7: Pulling fs layer \n",
      "\u001b[1Bfe94dbe9: Pulling fs layer \n",
      "\u001b[1Bdb54f010: Pulling fs layer \n",
      "\u001b[1B4e90123e: Pulling fs layer \n",
      "\u001b[1B49f11018: Pulling fs layer \n",
      "\u001b[1B91f2bc74: Pulling fs layer \n",
      "\u001b[1Ba7d4c536: Pulling fs layer \n",
      "\u001b[1B766c07ef: Pulling fs layer \n",
      "\u001b[1B2db3297f: Pulling fs layer \n",
      "\u001b[1Bbd0521b8: Pulling fs layer \n",
      "\u001b[1B30010aab: Pulling fs layer \n",
      "\u001b[1B7d58d41b: Pulling fs layer \n",
      "\u001b[1Bc2240c04: Pulling fs layer \n",
      "\u001b[1Bc6aa1ac1: Pulling fs layer \n",
      "\u001b[1B6c358afc: Pulling fs layer \n",
      "\u001b[1B583747a2: Pulling fs layer \n",
      "\u001b[1B6fedcb8d: Pulling fs layer \n",
      "\u001b[1B1e887990: Pulling fs layer \n",
      "\u001b[1B9ebf13c6: Pulling fs layer \n",
      "\u001b[1B4e0e4c1a: Pulling fs layer \n",
      "\u001b[37B1274096: Waiting fs layer \n",
      "\u001b[1B3a280b31: Pulling fs layer \n",
      "\u001b[38B1138ef8: Waiting fs layer \n",
      "\u001b[38Bd3c7117: Waiting fs layer \n",
      "\u001b[1Bc579ff7d: Pulling fs layer \n",
      "\u001b[1B5ec0bb13: Pull complete  512B/512B1kBB\u001b[44A\u001b[2K\u001b[46A\u001b[2K\u001b[44A\u001b[2K\u001b[46A\u001b[2K\u001b[45A\u001b[2K\u001b[44A\u001b[2K\u001b[45A\u001b[2K\u001b[44A\u001b[2K\u001b[45A\u001b[2K\u001b[44A\u001b[2K\u001b[45A\u001b[2K\u001b[45A\u001b[2K\u001b[45A\u001b[2K\u001b[45A\u001b[2K\u001b[45A\u001b[2K\u001b[42A\u001b[2K\u001b[40A\u001b[2K\u001b[42A\u001b[2K\u001b[44A\u001b[2K\u001b[42A\u001b[2K\u001b[44A\u001b[2K\u001b[42A\u001b[2K\u001b[44A\u001b[2K\u001b[46A\u001b[2K\u001b[46A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[45A\u001b[2K\u001b[42A\u001b[2K\u001b[44A\u001b[2K\u001b[42A\u001b[2K\u001b[44A\u001b[2K\u001b[42A\u001b[2K\u001b[44A\u001b[2K\u001b[42A\u001b[2K\u001b[44A\u001b[2K\u001b[42A\u001b[2K\u001b[36A\u001b[2K\u001b[42A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[45A\u001b[2K\u001b[42A\u001b[2K\u001b[34A\u001b[2K\u001b[42A\u001b[2K\u001b[34A\u001b[2K\u001b[42A\u001b[2K\u001b[34A\u001b[2K\u001b[42A\u001b[2K\u001b[34A\u001b[2K\u001b[45A\u001b[2K\u001b[34A\u001b[2K\u001b[45A\u001b[2K\u001b[34A\u001b[2K\u001b[45A\u001b[2K\u001b[34A\u001b[2K\u001b[45A\u001b[2K\u001b[34A\u001b[2K\u001b[45A\u001b[2K\u001b[44A\u001b[2K\u001b[42A\u001b[2K\u001b[34A\u001b[2K\u001b[42A\u001b[2K\u001b[45A\u001b[2K\u001b[44A\u001b[2K\u001b[45A\u001b[2K\u001b[42A\u001b[2K\u001b[34A\u001b[2K\u001b[42A\u001b[2K\u001b[44A\u001b[2K\u001b[42A\u001b[2K\u001b[34A\u001b[2K\u001b[45A\u001b[2K\u001b[34A\u001b[2K\u001b[45A\u001b[2K\u001b[34A\u001b[2K\u001b[42A\u001b[2K\u001b[34A\u001b[2K\u001b[42A\u001b[2K\u001b[44A\u001b[2K\u001b[42A\u001b[2K\u001b[44A\u001b[2K\u001b[42A\u001b[2K\u001b[34A\u001b[2K\u001b[42A\u001b[2K\u001b[34A\u001b[2K\u001b[45A\u001b[2K\u001b[34A\u001b[2K\u001b[44A\u001b[2K\u001b[34A\u001b[2K\u001b[42A\u001b[2K\u001b[34A\u001b[2K\u001b[45A\u001b[2K\u001b[44A\u001b[2K\u001b[45A\u001b[2K\u001b[42A\u001b[2K\u001b[45A\u001b[2K\u001b[42A\u001b[2K\u001b[45A\u001b[2K\u001b[44A\u001b[2K\u001b[45A\u001b[2K\u001b[34A\u001b[2K\u001b[45A\u001b[2K\u001b[44A\u001b[2K\u001b[42A\u001b[2K\u001b[32A\u001b[2K\u001b[44A\u001b[2K\u001b[32A\u001b[2K\u001b[44A\u001b[2K\u001b[32A\u001b[2K\u001b[44A\u001b[2K\u001b[42A\u001b[2K\u001b[44A\u001b[2K\u001b[42A\u001b[2K\u001b[44A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[44A\u001b[2K\u001b[29A\u001b[2K\u001b[42A\u001b[2K\u001b[44A\u001b[2K\u001b[44A\u001b[2K\u001b[42A\u001b[2K\u001b[44A\u001b[2K\u001b[42A\u001b[2K\u001b[28A\u001b[2K\u001b[44A\u001b[2K\u001b[28A\u001b[2K\u001b[44A\u001b[2K\u001b[44A\u001b[2K\u001b[27A\u001b[2K\u001b[44A\u001b[2K\u001b[27A\u001b[2K\u001b[28A\u001b[2K\u001b[27A\u001b[2K\u001b[28A\u001b[2K\u001b[44A\u001b[2K\u001b[42A\u001b[2K\u001b[44A\u001b[2K\u001b[42A\u001b[2K\u001b[27A\u001b[2K\u001b[28A\u001b[2K\u001b[27A\u001b[2K\u001b[28A\u001b[2K\u001b[27A\u001b[2K\u001b[44A\u001b[2K\u001b[42A\u001b[2K\u001b[44A\u001b[2K\u001b[27A\u001b[2K\u001b[44A\u001b[2K\u001b[27A\u001b[2K\u001b[44A\u001b[2K\u001b[27A\u001b[2K\u001b[44A\u001b[2K\u001b[27A\u001b[2K\u001b[28A\u001b[2K\u001b[27A\u001b[2K\u001b[42A\u001b[2K\u001b[44A\u001b[2K\u001b[26A\u001b[2K\u001b[27A\u001b[2K\u001b[26A\u001b[2K\u001b[27A\u001b[2K\u001b[44A\u001b[2K\u001b[27A\u001b[2K\u001b[44A\u001b[2K\u001b[27A\u001b[2K\u001b[44A\u001b[2K\u001b[27A\u001b[2K\u001b[42A\u001b[2K\u001b[27A\u001b[2K\u001b[42A\u001b[2K\u001b[27A\u001b[2K\u001b[24A\u001b[2K\u001b[27A\u001b[2K\u001b[24A\u001b[2K\u001b[27A\u001b[2K\u001b[24A\u001b[2K\u001b[27A\u001b[2K\u001b[23A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[44A\u001b[2K\u001b[27A\u001b[2K\u001b[44A\u001b[2K\u001b[27A\u001b[2K\u001b[42A\u001b[2K\u001b[44A\u001b[2K\u001b[42A\u001b[2K\u001b[27A\u001b[2K\u001b[44A\u001b[2K\u001b[27A\u001b[2K\u001b[44A\u001b[2K\u001b[27A\u001b[2K\u001b[42A\u001b[2K\u001b[21A\u001b[2K\u001b[42A\u001b[2K\u001b[21A\u001b[2K\u001b[42A\u001b[2K\u001b[21A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[21A\u001b[2K\u001b[27A\u001b[2K\u001b[42A\u001b[2K\u001b[27A\u001b[2K\u001b[44A\u001b[2K\u001b[21A\u001b[2K\u001b[42A\u001b[2K\u001b[21A\u001b[2K\u001b[27A\u001b[2K\u001b[42A\u001b[2K\u001b[27A\u001b[2K\u001b[21A\u001b[2K\u001b[27A\u001b[2K\u001b[42A\u001b[2K\u001b[21A\u001b[2K\u001b[44A\u001b[2K\u001b[42A\u001b[2K\u001b[44A\u001b[2K\u001b[42A\u001b[2K\u001b[44A\u001b[2K\u001b[20A\u001b[2K\u001b[44A\u001b[2K\u001b[20A\u001b[2K\u001b[42A\u001b[2K\u001b[20A\u001b[2K\u001b[27A\u001b[2K\u001b[20A\u001b[2K\u001b[27A\u001b[2K\u001b[20A\u001b[2K\u001b[44A\u001b[2K\u001b[20A\u001b[2K\u001b[27A\u001b[2K\u001b[44A\u001b[2K\u001b[27A\u001b[2K\u001b[20A\u001b[2K\u001b[27A\u001b[2K\u001b[44A\u001b[2K\u001b[42A\u001b[2K\u001b[20A\u001b[2K\u001b[44A\u001b[2K\u001b[20A\u001b[2K\u001b[42A\u001b[2K\u001b[44A\u001b[2K\u001b[20A\u001b[2K\u001b[27A\u001b[2K\u001b[44A\u001b[2K\u001b[42A\u001b[2K\u001b[27A\u001b[2K\u001b[44A\u001b[2K\u001b[27A\u001b[2K\u001b[42A\u001b[2K\u001b[27A\u001b[2K\u001b[20A\u001b[2K\u001b[27A\u001b[2K\u001b[20A\u001b[2K\u001b[42A\u001b[2K\u001b[20A\u001b[2K\u001b[42A\u001b[2K\u001b[27A\u001b[2K\u001b[42A\u001b[2K\u001b[27A\u001b[2K\u001b[44A\u001b[2K\u001b[27A\u001b[2K\u001b[20A\u001b[2K\u001b[44A\u001b[2K\u001b[27A\u001b[2K\u001b[42A\u001b[2K\u001b[44A\u001b[2K\u001b[20A\u001b[2K\u001b[44A\u001b[2K\u001b[20A\u001b[2K\u001b[44A\u001b[2K\u001b[20A\u001b[2K\u001b[44A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[20A\u001b[2K\u001b[42A\u001b[2K\u001b[44A\u001b[2K\u001b[20A\u001b[2K\u001b[44A\u001b[2K\u001b[42A\u001b[2K\u001b[44A\u001b[2K\u001b[42A\u001b[2K\u001b[20A\u001b[2K\u001b[44A\u001b[2K\u001b[20A\u001b[2K\u001b[42A\u001b[2K\u001b[20A\u001b[2K\u001b[42A\u001b[2K\u001b[44A\u001b[2K\u001b[42A\u001b[2K\u001b[19A\u001b[2K\u001b[42A\u001b[2K\u001b[19A\u001b[2K\u001b[44A\u001b[2K\u001b[20A\u001b[2K\u001b[44A\u001b[2K\u001b[19A\u001b[2K\u001b[42A\u001b[2K\u001b[19A\u001b[2K\u001b[42A\u001b[2K\u001b[19A\u001b[2K\u001b[20A\u001b[2K\u001b[19A\u001b[2K\u001b[20A\u001b[2K\u001b[44A\u001b[2K\u001b[20A\u001b[2K\u001b[42A\u001b[2K\u001b[20A\u001b[2K\u001b[42A\u001b[2K\u001b[20A\u001b[2K\u001b[43A\u001b[2K\u001b[20A\u001b[2K\u001b[42A\u001b[2K\u001b[20A\u001b[2K\u001b[42A\u001b[2K\u001b[20A\u001b[2K\u001b[42A\u001b[2K\u001b[20A\u001b[2K\u001b[19A\u001b[2K\u001b[20A\u001b[2K\u001b[42A\u001b[2K\u001b[20A\u001b[2K\u001b[42A\u001b[2K\u001b[20A\u001b[2K\u001b[42A\u001b[2K\u001b[20A\u001b[2K\u001b[19A\u001b[2K\u001b[20A\u001b[2K\u001b[19A\u001b[2K\u001b[42A\u001b[2K\u001b[19A\u001b[2K\u001b[20A\u001b[2K\u001b[19A\u001b[2K\u001b[20A\u001b[2K\u001b[19A\u001b[2K\u001b[20A\u001b[2K\u001b[19A\u001b[2K\u001b[20A\u001b[2K\u001b[19A\u001b[2K\u001b[20A\u001b[2K\u001b[42A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[19A\u001b[2K\u001b[20A\u001b[2K\u001b[42A\u001b[2K\u001b[20A\u001b[2K\u001b[42A\u001b[2K\u001b[20A\u001b[2K\u001b[19A\u001b[2K\u001b[20A\u001b[2K\u001b[19A\u001b[2K\u001b[42A\u001b[2K\u001b[20A\u001b[2K\u001b[19A\u001b[2K\u001b[20A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[20A\u001b[2K\u001b[19A\u001b[2K\u001b[42A\u001b[2K\u001b[19A\u001b[2K\u001b[42A\u001b[2K\u001b[19A\u001b[2K\u001b[42A\u001b[2K\u001b[19A\u001b[2K\u001b[20A\u001b[2K\u001b[19A\u001b[2K\u001b[42A\u001b[2K\u001b[19A\u001b[2K\u001b[42A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[19A\u001b[2K\u001b[20A\u001b[2K\u001b[19A\u001b[2K\u001b[20A\u001b[2K\u001b[19A\u001b[2K\u001b[42A\u001b[2K\u001b[19A\u001b[2K\u001b[42A\u001b[2K\u001b[19A\u001b[2K\u001b[20A\u001b[2K\u001b[19A\u001b[2K\u001b[20A\u001b[2K\u001b[19A\u001b[2K\u001b[20A\u001b[2K\u001b[42A\u001b[2K\u001b[20A\u001b[2K\u001b[42A\u001b[2K\u001b[20A\u001b[2K\u001b[42A\u001b[2K\u001b[19A\u001b[2K\u001b[20A\u001b[2K\u001b[19A\u001b[2K\u001b[20A\u001b[2K\u001b[19A\u001b[2K\u001b[20A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[20A\u001b[2K\u001b[19A\u001b[2K\u001b[42A\u001b[2K\u001b[19A\u001b[2K\u001b[20A\u001b[2K\u001b[19A\u001b[2K\u001b[42A\u001b[2K\u001b[19A\u001b[2K\u001b[20A\u001b[2K\u001b[19A\u001b[2K\u001b[42A\u001b[2K\u001b[19A\u001b[2K\u001b[42A\u001b[2K\u001b[19A\u001b[2K\u001b[42A\u001b[2K\u001b[19A\u001b[2K\u001b[20A\u001b[2K\u001b[42A\u001b[2K\u001b[19A\u001b[2K\u001b[42A\u001b[2K\u001b[19A\u001b[2K\u001b[20A\u001b[2K\u001b[19A\u001b[2K\u001b[42A\u001b[2K\u001b[19A\u001b[2K\u001b[42A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[20A\u001b[2K\u001b[42A\u001b[2K\u001b[19A\u001b[2K\u001b[42A\u001b[2K\u001b[19A\u001b[2K\u001b[42A\u001b[2K\u001b[19A\u001b[2K\u001b[42A\u001b[2K\u001b[20A\u001b[2K\u001b[19A\u001b[2K\u001b[42A\u001b[2K\u001b[19A\u001b[2K\u001b[42A\u001b[2K\u001b[19A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[19A\u001b[2K\u001b[20A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[20A\u001b[2K\u001b[42A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[18A\u001b[2K\u001b[17A\u001b[2K\u001b[42A\u001b[2K\u001b[16A\u001b[2K\u001b[18A\u001b[2K\u001b[42A\u001b[2K\u001b[14A\u001b[2K\u001b[16A\u001b[2K\u001b[13A\u001b[2K\u001b[42A\u001b[2K\u001b[13A\u001b[2K\u001b[42A\u001b[2K\u001b[13A\u001b[2K\u001b[42A\u001b[2K\u001b[13A\u001b[2K\u001b[16A\u001b[2K\u001b[42A\u001b[2K\u001b[16A\u001b[2K\u001b[42A\u001b[2K\u001b[16A\u001b[2K\u001b[42A\u001b[2K\u001b[13A\u001b[2K\u001b[42A\u001b[2K\u001b[13A\u001b[2K\u001b[16A\u001b[2K\u001b[13A\u001b[2K\u001b[16A\u001b[2K\u001b[42A\u001b[2K\u001b[13A\u001b[2K\u001b[42A\u001b[2K\u001b[13A\u001b[2K\u001b[42A\u001b[2K\u001b[13A\u001b[2K\u001b[42A\u001b[2K\u001b[10A\u001b[2K\u001b[13A\u001b[2K\u001b[10A\u001b[2K\u001b[13A\u001b[2K\u001b[42A\u001b[2K\u001b[9A\u001b[2K\u001b[42A\u001b[2K\u001b[13A\u001b[2K\u001b[42A\u001b[2K\u001b[13A\u001b[2K\u001b[42A\u001b[2K\u001b[13A\u001b[2K\u001b[42A\u001b[2K\u001b[13A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[13A\u001b[2K\u001b[42A\u001b[2K\u001b[13A\u001b[2K\u001b[42A\u001b[2K\u001b[8A\u001b[2K\u001b[42A\u001b[2K\u001b[13A\u001b[2K\u001b[42A\u001b[2K\u001b[13A\u001b[2K\u001b[42A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[13A\u001b[2K\u001b[42A\u001b[2K\u001b[6A\u001b[2K\u001b[13A\u001b[2K\u001b[42A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[5A\u001b[2K\u001b[13A\u001b[2K\u001b[5A\u001b[2K\u001b[42A\u001b[2K\u001b[5A\u001b[2K\u001b[13A\u001b[2K\u001b[5A\u001b[2K\u001b[13A\u001b[2K\u001b[42A\u001b[2K\u001b[4A\u001b[2K\u001b[42A\u001b[2K\u001b[4A\u001b[2K\u001b[42A\u001b[2K\u001b[4A\u001b[2K\u001b[42A\u001b[2K\u001b[13A\u001b[2K\u001b[42A\u001b[2K\u001b[13A\u001b[2K\u001b[42A\u001b[2K\u001b[13A\u001b[2K\u001b[42A\u001b[2K\u001b[13A\u001b[2K\u001b[42A\u001b[2K\u001b[3A\u001b[2K\u001b[42A\u001b[2K\u001b[3A\u001b[2K\u001b[42A\u001b[2K\u001b[3A\u001b[2K\u001b[42A\u001b[2K\u001b[3A\u001b[2K\u001b[42A\u001b[2K\u001b[3A\u001b[2K\u001b[13A\u001b[2K\u001b[3A\u001b[2K\u001b[13A\u001b[2K\u001b[42A\u001b[2K\u001b[2A\u001b[2K\u001b[42A\u001b[2K\u001b[13A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[1A\u001b[2K\u001b[42A\u001b[2K\u001b[13A\u001b[2K\u001b[42A\u001b[2K\u001b[13A\u001b[2K\u001b[42A\u001b[2K\u001b[13A\u001b[2K\u001b[42A\u001b[2K\u001b[13A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[42A\u001b[2K\u001b[13A\u001b[2K\u001b[42A\u001b[2K\u001b[13A\u001b[2K\u001b[42A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[42A\u001b[2K\u001b[13A\u001b[2K\u001b[42A\u001b[2K\u001b[13A\u001b[2K\u001b[42A\u001b[2K\u001b[13A\u001b[2K\u001b[42A\u001b[2K\u001b[13A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[42A\u001b[2K\u001b[13A\u001b[2K\u001b[42A\u001b[2K\u001b[13A\u001b[2K\u001b[42A\u001b[2K\u001b[13A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[13A\u001b[2K\u001b[42A\u001b[2K\u001b[13A\u001b[2K\u001b[42A\u001b[2K\u001b[13A\u001b[2K\u001b[42A\u001b[2K\u001b[13A\u001b[2K\u001b[42A\u001b[2K\u001b[13A\u001b[2K\u001b[42A\u001b[2K\u001b[13A\u001b[2K\u001b[42A\u001b[2K\u001b[13A\u001b[2K\u001b[42A\u001b[2K\u001b[13A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[42A\u001b[2K\u001b[13A\u001b[2K\u001b[42A\u001b[2K\u001b[13A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[13A\u001b[2K\u001b[42A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[42A\u001b[2K\u001b[13A\u001b[2K\u001b[42A\u001b[2K\u001b[13A\u001b[2K\u001b[42A\u001b[2K\u001b[13A\u001b[2K\u001b[42A\u001b[2K\u001b[13A\u001b[2K\u001b[42A\u001b[2K\u001b[13A\u001b[2K\u001b[42A\u001b[2K\u001b[13A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[13A\u001b[2K\u001b[42A\u001b[2K\u001b[13A\u001b[2K\u001b[42A\u001b[2K\u001b[13A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[13A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[42A\u001b[2K\u001b[13A\u001b[2K\u001b[42A\u001b[2K\u001b[13A\u001b[2K\u001b[42A\u001b[2K\u001b[13A\u001b[2K\u001b[42A\u001b[2K\u001b[13A\u001b[2K\u001b[42A\u001b[2K\u001b[13A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[13A\u001b[2K\u001b[42A\u001b[2K\u001b[13A\u001b[2K\u001b[42A\u001b[2K\u001b[13A\u001b[2K\u001b[42A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[42A\u001b[2K\u001b[13A\u001b[2K\u001b[42A\u001b[2K\u001b[13A\u001b[2K\u001b[42A\u001b[2K\u001b[13A\u001b[2K\u001b[42A\u001b[2K\u001b[13A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[13A\u001b[2K\u001b[42A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[42A\u001b[2K\u001b[13A\u001b[2K\u001b[42A\u001b[2K\u001b[13A\u001b[2K\u001b[42A\u001b[2K\u001b[13A\u001b[2K\u001b[42A\u001b[2K\u001b[13A\u001b[2K\u001b[42A\u001b[2K\u001b[13A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[13A\u001b[2K\u001b[42A\u001b[2K\u001b[13A\u001b[2K\u001b[42A\u001b[2K\u001b[13A\u001b[2K\u001b[42A\u001b[2K\u001b[13A\u001b[2K\u001b[42A\u001b[2K\u001b[13A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[13A\u001b[2K\u001b[42A\u001b[2K\u001b[13A\u001b[2K\u001b[42A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[42A\u001b[2K\u001b[13A\u001b[2K\u001b[42A\u001b[2K\u001b[13A\u001b[2K\u001b[42A\u001b[2K\u001b[13A\u001b[2K\u001b[42A\u001b[2K\u001b[13A\u001b[2K\u001b[42A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[42A\u001b[2K\u001b[13A\u001b[2K\u001b[42A\u001b[2K\u001b[13A\u001b[2K\u001b[42A\u001b[2K\u001b[13A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[13A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[42A\u001b[2K\u001b[13A\u001b[2K\u001b[42A\u001b[2K\u001b[13A\u001b[2K\u001b[42A\u001b[2K\u001b[13A\u001b[2K\u001b[42A\u001b[2K\u001b[13A\u001b[2K\u001b[42A\u001b[2K\u001b[13A\u001b[2K\u001b[42A\u001b[2K\u001b[13A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[42A\u001b[2K\u001b[41A\u001b[2K\u001b[41A\u001b[2K\u001b[40A\u001b[2K\u001b[40A\u001b[2K\u001b[39A\u001b[2K\u001b[38A\u001b[2K\u001b[37A\u001b[2K\u001b[37A\u001b[2K\u001b[37A\u001b[2K\u001b[37A\u001b[2K\u001b[37A\u001b[2K\u001b[37A\u001b[2K\u001b[37A\u001b[2K\u001b[37A\u001b[2K\u001b[37A\u001b[2K\u001b[37A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[32A\u001b[2K\u001b[32A\u001b[2K\u001b[32A\u001b[2K\u001b[32A\u001b[2K\u001b[32A\u001b[2K\u001b[32A\u001b[2K\u001b[32A\u001b[2K\u001b[32A\u001b[2K\u001b[32A\u001b[2K\u001b[32A\u001b[2K\u001b[32A\u001b[2K\u001b[32A\u001b[2K\u001b[32A\u001b[2K\u001b[32A\u001b[2K\u001b[32A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[29A\u001b[2K\u001b[29A\u001b[2K\u001b[29A\u001b[2K\u001b[29A\u001b[2K\u001b[29A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2KExtracting  811.1MB/917.2MB\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[26A\u001b[2K\u001b[26A\u001b[2K\u001b[26A\u001b[2K\u001b[26A\u001b[2K\u001b[26A\u001b[2K\u001b[26A\u001b[2K\u001b[26A\u001b[2K\u001b[26A\u001b[2K\u001b[26A\u001b[2K\u001b[26A\u001b[2K\u001b[26A\u001b[2K\u001b[26A\u001b[2K\u001b[26A\u001b[2K\u001b[26A\u001b[2K\u001b[26A\u001b[2K\u001b[26A\u001b[2K\u001b[26A\u001b[2K\u001b[25A\u001b[2K\u001b[24A\u001b[2K\u001b[24A\u001b[2K\u001b[24A\u001b[2K\u001b[24A\u001b[2K\u001b[24A\u001b[2K\u001b[24A\u001b[2K\u001b[24A\u001b[2K\u001b[24A\u001b[2K\u001b[24A\u001b[2K\u001b[24A\u001b[2K\u001b[24A\u001b[2K\u001b[24A\u001b[2K\u001b[24A\u001b[2K\u001b[24A\u001b[2K\u001b[24A\u001b[2K\u001b[24A\u001b[2K\u001b[24A\u001b[2K\u001b[24A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[22A\u001b[2K\u001b[22A\u001b[2K\u001b[22A\u001b[2K\u001b[22A\u001b[2K\u001b[22A\u001b[2K\u001b[22A\u001b[2K\u001b[22A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2KExtracting  380.5MB/449.5MB\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[18A\u001b[2K\u001b[18A\u001b[2K\u001b[18A\u001b[2K\u001b[18A\u001b[2K\u001b[18A\u001b[2K\u001b[18A\u001b[2K\u001b[18A\u001b[2K\u001b[18A\u001b[2K\u001b[18A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[16A\u001b[2K\u001b[16A\u001b[2K\u001b[16A\u001b[2K\u001b[16A\u001b[2K\u001b[16A\u001b[2K\u001b[16A\u001b[2K\u001b[16A\u001b[2K\u001b[16A\u001b[2K\u001b[16A\u001b[2K\u001b[16A\u001b[2K\u001b[16A\u001b[2K\u001b[16A\u001b[2K\u001b[16A\u001b[2K\u001b[16A\u001b[2K\u001b[16A\u001b[2K\u001b[16A\u001b[2K\u001b[16A\u001b[2K\u001b[16A\u001b[2K\u001b[16A\u001b[2K\u001b[16A\u001b[2K\u001b[16A\u001b[2K\u001b[16A\u001b[2K\u001b[16A\u001b[2K\u001b[16A\u001b[2K\u001b[16A\u001b[2K\u001b[16A\u001b[2K\u001b[16A\u001b[2K\u001b[16A\u001b[2K\u001b[16A\u001b[2K\u001b[16A\u001b[2K\u001b[16A\u001b[2K\u001b[15A\u001b[2K\u001b[14A\u001b[2K\u001b[14A\u001b[2K\u001b[14A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[12A\u001b[2K\u001b[12A\u001b[2K\u001b[11A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[2A\u001b[2K\u001b[1A\u001b[2KDigest: sha256:09a80f272dd173c9d8f28c23a1985aebe2bd3edd41a184ee9634f6e3f8a1f63d\n",
      "Status: Downloaded newer image for nvcr.io/nvidia/pytorch:22.12-py3\n",
      "\n",
      "=============\n",
      "== PyTorch ==\n",
      "=============\n",
      "\n",
      "NVIDIA Release 22.12 (build 49968248)\n",
      "PyTorch Version 1.14.0a0+410ce96\n",
      "\n",
      "Container image Copyright (c) 2022, NVIDIA CORPORATION & AFFILIATES. All rights reserved.\n",
      "\n",
      "Copyright (c) 2014-2022 Facebook Inc.\n",
      "Copyright (c) 2011-2014 Idiap Research Institute (Ronan Collobert)\n",
      "Copyright (c) 2012-2014 Deepmind Technologies    (Koray Kavukcuoglu)\n",
      "Copyright (c) 2011-2012 NEC Laboratories America (Koray Kavukcuoglu)\n",
      "Copyright (c) 2011-2013 NYU                      (Clement Farabet)\n",
      "Copyright (c) 2006-2010 NEC Laboratories America (Ronan Collobert, Leon Bottou, Iain Melvin, Jason Weston)\n",
      "Copyright (c) 2006      Idiap Research Institute (Samy Bengio)\n",
      "Copyright (c) 2001-2004 Idiap Research Institute (Ronan Collobert, Samy Bengio, Johnny Mariethoz)\n",
      "Copyright (c) 2015      Google Inc.\n",
      "Copyright (c) 2015      Yangqing Jia\n",
      "Copyright (c) 2013-2016 The Caffe contributors\n",
      "All rights reserved.\n",
      "\n",
      "Various files include modifications (c) NVIDIA CORPORATION & AFFILIATES.  All rights reserved.\n",
      "\n",
      "This container image and its contents are governed by the NVIDIA Deep Learning Container License.\n",
      "By pulling and using the container, you accept the terms and conditions of this license:\n",
      "https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license\n",
      "\n",
      "NOTE: CUDA Forward Compatibility mode ENABLED.\n",
      "  Using CUDA 11.8 driver version 520.61.05 with kernel driver version 510.47.03.\n",
      "  See https://docs.nvidia.com/deploy/cuda-compatibility/ for details.\n",
      "\n",
      "Installing Transformers...\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Downloading xdistillbert model from HuggingFace...\n",
      "Exporting model to Torchscript...\n",
      "Downloading: 100%|| 991/991 [00:00<00:00, 1.23MB/s]\n",
      "Downloading: 100%|| 51.1M/51.1M [00:00<00:00, 92.4MB/s]\n"
     ]
    }
   ],
   "source": [
    "!docker run --gpus=all --rm -it --ipc=host --ulimit memlock=-1 --ulimit stack=67108864 \\\n",
    "            -v `pwd`/workspace:/workspace -w /workspace nvcr.io/nvidia/pytorch:22.12-py3 \\\n",
    "            /bin/bash generate_model_pytorch.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9a21ac8-012c-4e6c-8d17-27838295f507",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p model_repository/xdistilbert_pt/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b45c395e-c52a-4a28-a18b-7baa746fc1b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing model_repository/xdistilbert_pt/config.pbtxt\n"
     ]
    }
   ],
   "source": [
    "%%writefile model_repository/xdistilbert_pt/config.pbtxt\n",
    "backend: \"pytorch\"\n",
    "max_batch_size: 224\n",
    "input [\n",
    "  {\n",
    "    name: \"INPUT__0\"\n",
    "    data_type: TYPE_INT32\n",
    "    dims: [128]\n",
    "  },\n",
    "  {\n",
    "    name: \"INPUT__1\"\n",
    "    data_type: TYPE_INT32\n",
    "    dims: [128]\n",
    "  },\n",
    "    {\n",
    "    name: \"INPUT__2\"\n",
    "    data_type: TYPE_INT32\n",
    "    dims: [128]\n",
    "  }\n",
    "]\n",
    "output [\n",
    "  {\n",
    "    name: \"OUTPUT__0\"\n",
    "    data_type: TYPE_FP32\n",
    "    dims: [6]\n",
    "  }\n",
    "]\n",
    "instance_group {\n",
    "  count: 1\n",
    "  kind: KIND_GPU\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87036cb6-f830-495a-b2cc-9651ec93fe06",
   "metadata": {},
   "source": [
    "### Prepare TensorRT Model <a class=\"anchor\" id=\"create-tensorrt-model\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca98ddb-d90b-4095-b310-825d09774954",
   "metadata": {},
   "source": [
    "- We load pre-trained xdistilbert from torch\n",
    "- Convert to onnx representation using torch onnx exporter.\n",
    "- Use TensorRT trtexec command to create the model plan to be hosted with Triton. \n",
    "- The script for exporting this model can be found [here](./workspace/generate_model_trt.sh). \n",
    "\n",
    "Execute the below cell and check out the file for more details\n",
    "\n",
    "<div class=\"alert alert-info\"><strong> Note </strong>\n",
    "This step takes around 8 minutes to complete. While the step is running, please take a look at the logs in the below cell to understand TensorRT optimizations\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "daefd65d-f654-44b6-9569-0a1d5597a7f2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=============\n",
      "== PyTorch ==\n",
      "=============\n",
      "\n",
      "NVIDIA Release 22.12 (build 49968248)\n",
      "PyTorch Version 1.14.0a0+410ce96\n",
      "\n",
      "Container image Copyright (c) 2022, NVIDIA CORPORATION & AFFILIATES. All rights reserved.\n",
      "\n",
      "Copyright (c) 2014-2022 Facebook Inc.\n",
      "Copyright (c) 2011-2014 Idiap Research Institute (Ronan Collobert)\n",
      "Copyright (c) 2012-2014 Deepmind Technologies    (Koray Kavukcuoglu)\n",
      "Copyright (c) 2011-2012 NEC Laboratories America (Koray Kavukcuoglu)\n",
      "Copyright (c) 2011-2013 NYU                      (Clement Farabet)\n",
      "Copyright (c) 2006-2010 NEC Laboratories America (Ronan Collobert, Leon Bottou, Iain Melvin, Jason Weston)\n",
      "Copyright (c) 2006      Idiap Research Institute (Samy Bengio)\n",
      "Copyright (c) 2001-2004 Idiap Research Institute (Ronan Collobert, Samy Bengio, Johnny Mariethoz)\n",
      "Copyright (c) 2015      Google Inc.\n",
      "Copyright (c) 2015      Yangqing Jia\n",
      "Copyright (c) 2013-2016 The Caffe contributors\n",
      "All rights reserved.\n",
      "\n",
      "Various files include modifications (c) NVIDIA CORPORATION & AFFILIATES.  All rights reserved.\n",
      "\n",
      "This container image and its contents are governed by the NVIDIA Deep Learning Container License.\n",
      "By pulling and using the container, you accept the terms and conditions of this license:\n",
      "https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license\n",
      "\n",
      "NOTE: CUDA Forward Compatibility mode ENABLED.\n",
      "  Using CUDA 11.8 driver version 520.61.05 with kernel driver version 510.47.03.\n",
      "  See https://docs.nvidia.com/deploy/cuda-compatibility/ for details.\n",
      "\n",
      "Installing Transformers...\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Exporting model to ONNX...\n",
      "Framework not requested. Using torch to export to ONNX.\n",
      "Downloading: 100%|| 991/991 [00:00<00:00, 1.24MB/s]\n",
      "Downloading: 100%|| 51.1M/51.1M [00:00<00:00, 94.3MB/s]\n",
      "Downloading: 100%|| 365/365 [00:00<00:00, 444kB/s]\n",
      "Downloading: 100%|| 232k/232k [00:00<00:00, 910kB/s]\n",
      "Downloading: 100%|| 466k/466k [00:00<00:00, 1.54MB/s]\n",
      "Downloading: 100%|| 112/112 [00:00<00:00, 131kB/s]\n",
      "Using framework PyTorch: 1.14.0a0+410ce96\n",
      "Overriding 1 configuration item(s)\n",
      "\t- use_cache -> False\n",
      "Validating ONNX model...\n",
      "\t-[] ONNX model output names match reference model ({'logits'})\n",
      "\t- Validating ONNX Model output \"logits\":\n",
      "\t\t-[] (3, 6) matches (3, 6)\n",
      "\t\t-[] all values close (atol: 1e-05)\n",
      "All good, model saved at: /workspace/onnx/model.onnx\n",
      "Converting ONNX Model to TensorRT FP16 Plan...\n",
      "&&&& RUNNING TensorRT.trtexec [TensorRT v8501] # trtexec --onnx=/workspace/onnx/model.onnx --saveEngine=/workspace/model.plan --minShapes=input_ids:1x128,attention_mask:1x128,token_type_ids:1x128 --optShapes=input_ids:16x128,attention_mask:16x128,token_type_ids:16x128 --maxShapes=input_ids:224x128,attention_mask:224x128,token_type_ids:224x128 --fp16 --verbose --workspace=23000\n",
      "[01/18/2023-20:38:43] [W] --workspace flag has been deprecated by --memPoolSize flag.\n",
      "[01/18/2023-20:38:43] [I] === Model Options ===\n",
      "[01/18/2023-20:38:43] [I] Format: ONNX\n",
      "[01/18/2023-20:38:43] [I] Model: /workspace/onnx/model.onnx\n",
      "[01/18/2023-20:38:43] [I] Output:\n",
      "[01/18/2023-20:38:43] [I] === Build Options ===\n",
      "[01/18/2023-20:38:43] [I] Max batch: explicit batch\n",
      "[01/18/2023-20:38:43] [I] Memory Pools: workspace: 23000 MiB, dlaSRAM: default, dlaLocalDRAM: default, dlaGlobalDRAM: default\n",
      "[01/18/2023-20:38:43] [I] minTiming: 1\n",
      "[01/18/2023-20:38:43] [I] avgTiming: 8\n",
      "[01/18/2023-20:38:43] [I] Precision: FP32+FP16\n",
      "[01/18/2023-20:38:43] [I] LayerPrecisions: \n",
      "[01/18/2023-20:38:43] [I] Calibration: \n",
      "[01/18/2023-20:38:43] [I] Refit: Disabled\n",
      "[01/18/2023-20:38:43] [I] Sparsity: Disabled\n",
      "[01/18/2023-20:38:43] [I] Safe mode: Disabled\n",
      "[01/18/2023-20:38:43] [I] DirectIO mode: Disabled\n",
      "[01/18/2023-20:38:43] [I] Restricted mode: Disabled\n",
      "[01/18/2023-20:38:43] [I] Build only: Disabled\n",
      "[01/18/2023-20:38:43] [I] Save engine: /workspace/model.plan\n",
      "[01/18/2023-20:38:43] [I] Load engine: \n",
      "[01/18/2023-20:38:43] [I] Profiling verbosity: 0\n",
      "[01/18/2023-20:38:43] [I] Tactic sources: Using default tactic sources\n",
      "[01/18/2023-20:38:43] [I] timingCacheMode: local\n",
      "[01/18/2023-20:38:43] [I] timingCacheFile: \n",
      "[01/18/2023-20:38:43] [I] Heuristic: Disabled\n",
      "[01/18/2023-20:38:43] [I] Preview Features: Use default preview flags.\n",
      "[01/18/2023-20:38:43] [I] Input(s)s format: fp32:CHW\n",
      "[01/18/2023-20:38:43] [I] Output(s)s format: fp32:CHW\n",
      "[01/18/2023-20:38:43] [I] Input build shape: input_ids=1x128+16x128+224x128\n",
      "[01/18/2023-20:38:43] [I] Input build shape: attention_mask=1x128+16x128+224x128\n",
      "[01/18/2023-20:38:43] [I] Input build shape: token_type_ids=1x128+16x128+224x128\n",
      "[01/18/2023-20:38:43] [I] Input calibration shapes: model\n",
      "[01/18/2023-20:38:43] [I] === System Options ===\n",
      "[01/18/2023-20:38:43] [I] Device: 0\n",
      "[01/18/2023-20:38:43] [I] DLACore: \n",
      "[01/18/2023-20:38:43] [I] Plugins:\n",
      "[01/18/2023-20:38:43] [I] === Inference Options ===\n",
      "[01/18/2023-20:38:43] [I] Batch: Explicit\n",
      "[01/18/2023-20:38:43] [I] Input inference shape: token_type_ids=16x128\n",
      "[01/18/2023-20:38:43] [I] Input inference shape: attention_mask=16x128\n",
      "[01/18/2023-20:38:43] [I] Input inference shape: input_ids=16x128\n",
      "[01/18/2023-20:38:43] [I] Iterations: 10\n",
      "[01/18/2023-20:38:43] [I] Duration: 3s (+ 200ms warm up)\n",
      "[01/18/2023-20:38:43] [I] Sleep time: 0ms\n",
      "[01/18/2023-20:38:43] [I] Idle time: 0ms\n",
      "[01/18/2023-20:38:43] [I] Streams: 1\n",
      "[01/18/2023-20:38:43] [I] ExposeDMA: Disabled\n",
      "[01/18/2023-20:38:43] [I] Data transfers: Enabled\n",
      "[01/18/2023-20:38:43] [I] Spin-wait: Disabled\n",
      "[01/18/2023-20:38:43] [I] Multithreading: Disabled\n",
      "[01/18/2023-20:38:43] [I] CUDA Graph: Disabled\n",
      "[01/18/2023-20:38:43] [I] Separate profiling: Disabled\n",
      "[01/18/2023-20:38:43] [I] Time Deserialize: Disabled\n",
      "[01/18/2023-20:38:43] [I] Time Refit: Disabled\n",
      "[01/18/2023-20:38:43] [I] NVTX verbosity: 0\n",
      "[01/18/2023-20:38:43] [I] Persistent Cache Ratio: 0\n",
      "[01/18/2023-20:38:43] [I] Inputs:\n",
      "[01/18/2023-20:38:43] [I] === Reporting Options ===\n",
      "[01/18/2023-20:38:43] [I] Verbose: Enabled\n",
      "[01/18/2023-20:38:43] [I] Averages: 10 inferences\n",
      "[01/18/2023-20:38:43] [I] Percentiles: 90,95,99\n",
      "[01/18/2023-20:38:43] [I] Dump refittable layers:Disabled\n",
      "[01/18/2023-20:38:43] [I] Dump output: Disabled\n",
      "[01/18/2023-20:38:43] [I] Profile: Disabled\n",
      "[01/18/2023-20:38:43] [I] Export timing to JSON file: \n",
      "[01/18/2023-20:38:43] [I] Export output to JSON file: \n",
      "[01/18/2023-20:38:43] [I] Export profile to JSON file: \n",
      "[01/18/2023-20:38:43] [I] \n",
      "[01/18/2023-20:38:43] [I] === Device Information ===\n",
      "[01/18/2023-20:38:43] [I] Selected Device: NVIDIA A10G\n",
      "[01/18/2023-20:38:43] [I] Compute Capability: 8.6\n",
      "[01/18/2023-20:38:43] [I] SMs: 80\n",
      "[01/18/2023-20:38:43] [I] Compute Clock Rate: 1.71 GHz\n",
      "[01/18/2023-20:38:43] [I] Device Global Memory: 22731 MiB\n",
      "[01/18/2023-20:38:43] [I] Shared Memory per SM: 100 KiB\n",
      "[01/18/2023-20:38:43] [I] Memory Bus Width: 384 bits (ECC enabled)\n",
      "[01/18/2023-20:38:43] [I] Memory Clock Rate: 6.251 GHz\n",
      "[01/18/2023-20:38:43] [I] \n",
      "[01/18/2023-20:38:43] [I] TensorRT version: 8.5.1\n",
      "[01/18/2023-20:38:43] [V] [TRT] Registered plugin creator - ::BatchTilePlugin_TRT version 1\n",
      "[01/18/2023-20:38:43] [V] [TRT] Registered plugin creator - ::BatchedNMS_TRT version 1\n",
      "[01/18/2023-20:38:43] [V] [TRT] Registered plugin creator - ::BatchedNMSDynamic_TRT version 1\n",
      "[01/18/2023-20:38:43] [V] [TRT] Registered plugin creator - ::Clip_TRT version 1\n",
      "[01/18/2023-20:38:43] [V] [TRT] Registered plugin creator - ::CoordConvAC version 1\n",
      "[01/18/2023-20:38:43] [V] [TRT] Registered plugin creator - ::CropAndResize version 1\n",
      "[01/18/2023-20:38:43] [V] [TRT] Registered plugin creator - ::CropAndResizeDynamic version 1\n",
      "[01/18/2023-20:38:43] [V] [TRT] Registered plugin creator - ::DecodeBbox3DPlugin version 1\n",
      "[01/18/2023-20:38:43] [V] [TRT] Registered plugin creator - ::DetectionLayer_TRT version 1\n",
      "[01/18/2023-20:38:43] [V] [TRT] Registered plugin creator - ::EfficientNMS_TRT version 1\n",
      "[01/18/2023-20:38:43] [V] [TRT] Registered plugin creator - ::EfficientNMS_ONNX_TRT version 1\n",
      "[01/18/2023-20:38:43] [V] [TRT] Registered plugin creator - ::EfficientNMS_Explicit_TF_TRT version 1\n",
      "[01/18/2023-20:38:43] [V] [TRT] Registered plugin creator - ::EfficientNMS_Implicit_TF_TRT version 1\n",
      "[01/18/2023-20:38:43] [V] [TRT] Registered plugin creator - ::FlattenConcat_TRT version 1\n",
      "[01/18/2023-20:38:43] [V] [TRT] Registered plugin creator - ::GenerateDetection_TRT version 1\n",
      "[01/18/2023-20:38:43] [V] [TRT] Registered plugin creator - ::GridAnchor_TRT version 1\n",
      "[01/18/2023-20:38:43] [V] [TRT] Registered plugin creator - ::GridAnchorRect_TRT version 1\n",
      "[01/18/2023-20:38:43] [V] [TRT] Registered plugin creator - ::GroupNorm version 1\n",
      "[01/18/2023-20:38:43] [V] [TRT] Registered plugin creator - ::InstanceNormalization_TRT version 1\n",
      "[01/18/2023-20:38:43] [V] [TRT] Registered plugin creator - ::LayerNorm version 1\n",
      "[01/18/2023-20:38:43] [V] [TRT] Registered plugin creator - ::LReLU_TRT version 1\n",
      "[01/18/2023-20:38:43] [V] [TRT] Registered plugin creator - ::MultilevelCropAndResize_TRT version 1\n",
      "[01/18/2023-20:38:43] [V] [TRT] Registered plugin creator - ::MultilevelProposeROI_TRT version 1\n",
      "[01/18/2023-20:38:43] [V] [TRT] Registered plugin creator - ::MultiscaleDeformableAttnPlugin_TRT version 1\n",
      "[01/18/2023-20:38:43] [V] [TRT] Registered plugin creator - ::NMS_TRT version 1\n",
      "[01/18/2023-20:38:43] [V] [TRT] Registered plugin creator - ::NMSDynamic_TRT version 1\n",
      "[01/18/2023-20:38:43] [V] [TRT] Registered plugin creator - ::Normalize_TRT version 1\n",
      "[01/18/2023-20:38:43] [V] [TRT] Registered plugin creator - ::PillarScatterPlugin version 1\n",
      "[01/18/2023-20:38:43] [V] [TRT] Registered plugin creator - ::PriorBox_TRT version 1\n",
      "[01/18/2023-20:38:43] [V] [TRT] Registered plugin creator - ::ProposalLayer_TRT version 1\n",
      "[01/18/2023-20:38:43] [V] [TRT] Registered plugin creator - ::Proposal version 1\n",
      "[01/18/2023-20:38:43] [V] [TRT] Registered plugin creator - ::ProposalDynamic version 1\n",
      "[01/18/2023-20:38:43] [V] [TRT] Registered plugin creator - ::PyramidROIAlign_TRT version 1\n",
      "[01/18/2023-20:38:43] [V] [TRT] Registered plugin creator - ::Region_TRT version 1\n",
      "[01/18/2023-20:38:43] [V] [TRT] Registered plugin creator - ::Reorg_TRT version 1\n",
      "[01/18/2023-20:38:43] [V] [TRT] Registered plugin creator - ::ResizeNearest_TRT version 1\n",
      "[01/18/2023-20:38:43] [V] [TRT] Registered plugin creator - ::RPROI_TRT version 1\n",
      "[01/18/2023-20:38:43] [V] [TRT] Registered plugin creator - ::ROIAlign_TRT version 1\n",
      "[01/18/2023-20:38:43] [V] [TRT] Registered plugin creator - ::ScatterND version 1\n",
      "[01/18/2023-20:38:43] [V] [TRT] Registered plugin creator - ::SeqLen2Spatial version 1\n",
      "[01/18/2023-20:38:43] [V] [TRT] Registered plugin creator - ::SpecialSlice_TRT version 1\n",
      "[01/18/2023-20:38:43] [V] [TRT] Registered plugin creator - ::SplitGeLU version 1\n",
      "[01/18/2023-20:38:43] [V] [TRT] Registered plugin creator - ::Split version 1\n",
      "[01/18/2023-20:38:43] [V] [TRT] Registered plugin creator - ::VoxelGeneratorPlugin version 1\n",
      "[01/18/2023-20:38:43] [I] [TRT] [MemUsageChange] Init CUDA: CPU +10, GPU +0, now: CPU 23, GPU 248 (MiB)\n",
      "[01/18/2023-20:38:43] [V] [TRT] Trying to load shared library libnvinfer_builder_resource.so.8.5.1\n",
      "[01/18/2023-20:38:43] [V] [TRT] Loaded shared library libnvinfer_builder_resource.so.8.5.1\n",
      "[01/18/2023-20:38:46] [I] [TRT] [MemUsageChange] Init builder kernel library: CPU +444, GPU +120, now: CPU 522, GPU 368 (MiB)\n",
      "[01/18/2023-20:38:46] [V] [TRT] CUDA lazy loading is enabled.\n",
      "[01/18/2023-20:38:46] [I] Start parsing network model\n",
      "[01/18/2023-20:38:46] [I] [TRT] ----------------------------------------------------------------\n",
      "[01/18/2023-20:38:46] [I] [TRT] Input filename:   /workspace/onnx/model.onnx\n",
      "[01/18/2023-20:38:46] [I] [TRT] ONNX IR version:  0.0.6\n",
      "[01/18/2023-20:38:46] [I] [TRT] Opset version:    11\n",
      "[01/18/2023-20:38:46] [I] [TRT] Producer name:    pytorch\n",
      "[01/18/2023-20:38:46] [I] [TRT] Producer version: 1.14.0\n",
      "[01/18/2023-20:38:46] [I] [TRT] Domain:           \n",
      "[01/18/2023-20:38:46] [I] [TRT] Model version:    0\n",
      "[01/18/2023-20:38:46] [I] [TRT] Doc string:       \n",
      "[01/18/2023-20:38:46] [I] [TRT] ----------------------------------------------------------------\n",
      "[01/18/2023-20:38:46] [V] [TRT] Plugin creator already registered - ::BatchTilePlugin_TRT version 1\n",
      "[01/18/2023-20:38:46] [V] [TRT] Plugin creator already registered - ::BatchedNMS_TRT version 1\n",
      "[01/18/2023-20:38:46] [V] [TRT] Plugin creator already registered - ::BatchedNMSDynamic_TRT version 1\n",
      "[01/18/2023-20:38:46] [V] [TRT] Plugin creator already registered - ::Clip_TRT version 1\n",
      "[01/18/2023-20:38:46] [V] [TRT] Plugin creator already registered - ::CoordConvAC version 1\n",
      "[01/18/2023-20:38:46] [V] [TRT] Plugin creator already registered - ::CropAndResize version 1\n",
      "[01/18/2023-20:38:46] [V] [TRT] Plugin creator already registered - ::CropAndResizeDynamic version 1\n",
      "[01/18/2023-20:38:46] [V] [TRT] Plugin creator already registered - ::DecodeBbox3DPlugin version 1\n",
      "[01/18/2023-20:38:46] [V] [TRT] Plugin creator already registered - ::DetectionLayer_TRT version 1\n",
      "[01/18/2023-20:38:46] [V] [TRT] Plugin creator already registered - ::EfficientNMS_TRT version 1\n",
      "[01/18/2023-20:38:46] [V] [TRT] Plugin creator already registered - ::EfficientNMS_ONNX_TRT version 1\n",
      "[01/18/2023-20:38:46] [V] [TRT] Plugin creator already registered - ::EfficientNMS_Explicit_TF_TRT version 1\n",
      "[01/18/2023-20:38:46] [V] [TRT] Plugin creator already registered - ::EfficientNMS_Implicit_TF_TRT version 1\n",
      "[01/18/2023-20:38:46] [V] [TRT] Plugin creator already registered - ::FlattenConcat_TRT version 1\n",
      "[01/18/2023-20:38:46] [V] [TRT] Plugin creator already registered - ::GenerateDetection_TRT version 1\n",
      "[01/18/2023-20:38:46] [V] [TRT] Plugin creator already registered - ::GridAnchor_TRT version 1\n",
      "[01/18/2023-20:38:46] [V] [TRT] Plugin creator already registered - ::GridAnchorRect_TRT version 1\n",
      "[01/18/2023-20:38:46] [V] [TRT] Plugin creator already registered - ::GroupNorm version 1\n",
      "[01/18/2023-20:38:46] [V] [TRT] Plugin creator already registered - ::InstanceNormalization_TRT version 1\n",
      "[01/18/2023-20:38:46] [V] [TRT] Plugin creator already registered - ::LayerNorm version 1\n",
      "[01/18/2023-20:38:46] [V] [TRT] Plugin creator already registered - ::LReLU_TRT version 1\n",
      "[01/18/2023-20:38:46] [V] [TRT] Plugin creator already registered - ::MultilevelCropAndResize_TRT version 1\n",
      "[01/18/2023-20:38:46] [V] [TRT] Plugin creator already registered - ::MultilevelProposeROI_TRT version 1\n",
      "[01/18/2023-20:38:46] [V] [TRT] Plugin creator already registered - ::MultiscaleDeformableAttnPlugin_TRT version 1\n",
      "[01/18/2023-20:38:46] [V] [TRT] Plugin creator already registered - ::NMS_TRT version 1\n",
      "[01/18/2023-20:38:46] [V] [TRT] Plugin creator already registered - ::NMSDynamic_TRT version 1\n",
      "[01/18/2023-20:38:46] [V] [TRT] Plugin creator already registered - ::Normalize_TRT version 1\n",
      "[01/18/2023-20:38:46] [V] [TRT] Plugin creator already registered - ::PillarScatterPlugin version 1\n",
      "[01/18/2023-20:38:46] [V] [TRT] Plugin creator already registered - ::PriorBox_TRT version 1\n",
      "[01/18/2023-20:38:46] [V] [TRT] Plugin creator already registered - ::ProposalLayer_TRT version 1\n",
      "[01/18/2023-20:38:46] [V] [TRT] Plugin creator already registered - ::Proposal version 1\n",
      "[01/18/2023-20:38:46] [V] [TRT] Plugin creator already registered - ::ProposalDynamic version 1\n",
      "[01/18/2023-20:38:46] [V] [TRT] Plugin creator already registered - ::PyramidROIAlign_TRT version 1\n",
      "[01/18/2023-20:38:46] [V] [TRT] Plugin creator already registered - ::Region_TRT version 1\n",
      "[01/18/2023-20:38:46] [V] [TRT] Plugin creator already registered - ::Reorg_TRT version 1\n",
      "[01/18/2023-20:38:46] [V] [TRT] Plugin creator already registered - ::ResizeNearest_TRT version 1\n",
      "[01/18/2023-20:38:46] [V] [TRT] Plugin creator already registered - ::RPROI_TRT version 1\n",
      "[01/18/2023-20:38:46] [V] [TRT] Plugin creator already registered - ::ROIAlign_TRT version 1\n",
      "[01/18/2023-20:38:46] [V] [TRT] Plugin creator already registered - ::ScatterND version 1\n",
      "[01/18/2023-20:38:46] [V] [TRT] Plugin creator already registered - ::SeqLen2Spatial version 1\n",
      "[01/18/2023-20:38:46] [V] [TRT] Plugin creator already registered - ::SpecialSlice_TRT version 1\n",
      "[01/18/2023-20:38:46] [V] [TRT] Plugin creator already registered - ::SplitGeLU version 1\n",
      "[01/18/2023-20:38:46] [V] [TRT] Plugin creator already registered - ::Split version 1\n",
      "[01/18/2023-20:38:46] [V] [TRT] Plugin creator already registered - ::VoxelGeneratorPlugin version 1\n",
      "[01/18/2023-20:38:46] [V] [TRT] Adding network input: input_ids with dtype: int32, dimensions: (-1, -1)\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: input_ids for ONNX tensor: input_ids\n",
      "[01/18/2023-20:38:46] [V] [TRT] Adding network input: attention_mask with dtype: int32, dimensions: (-1, -1)\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: attention_mask for ONNX tensor: attention_mask\n",
      "[01/18/2023-20:38:46] [V] [TRT] Adding network input: token_type_ids with dtype: int32, dimensions: (-1, -1)\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: token_type_ids for ONNX tensor: token_type_ids\n",
      "[01/18/[01/18/2023-20:38:46] [V] [TRT] Importing initializer: bert.embeddings.position_ids\n",
      "2023-20:38:46] [W] [TRT] parsers/onnx/onnx2trt_utils.cpp:375: Your ONNX model has been generated with INT64 weights, while TensorRT does not natively support INT64. Attempting to cast down to INT32.\n",
      "[01/18/2023-20:38:46] [V] [TRT] Importing initializer: bert.embeddings.word_embeddings.weight\n",
      "[01/18/2023-20:38:46] [V] [TRT] Importing initializer: bert.embeddings.position_embeddings.weight\n",
      "[01/18/2023-20:38:46] [V] [TRT] Importing initializer: bert.embeddings.token_type_embeddings.weight\n",
      "[01/18/2023-20:38:46] [V] [TRT] Importing initializer: bert.embeddings.LayerNorm.weight\n",
      "[01/18/2023-20:38:46] [V] [TRT] Importing initializer: bert.embeddings.LayerNorm.bias\n",
      "[01/18/2023-20:38:46] [V] [TRT] Importing initializer: bert.encoder.layer.0.attention.self.query.bias\n",
      "[01/18/2023-20:38:46] [V] [TRT] Importing initializer: bert.encoder.layer.0.attention.self.key.bias\n",
      "[01/18/2023-20:38:46] [V] [TRT] Importing initializer: bert.encoder.layer.0.attention.self.value.bias\n",
      "[01/18/2023-20:38:46] [V] [TRT] Importing initializer: bert.encoder.layer.0.attention.output.dense.bias\n",
      "[01/18/2023-20:38:46] [V] [TRT] Importing initializer: bert.encoder.layer.0.attention.output.LayerNorm.weight\n",
      "[01/18/2023-20:38:46] [V] [TRT] Importing initializer: bert.encoder.layer.0.attention.output.LayerNorm.bias\n",
      "[01/18/2023-20:38:46] [V] [TRT] Importing initializer: bert.encoder.layer.0.intermediate.dense.bias\n",
      "[01/18/2023-20:38:46] [V] [TRT] Importing initializer: bert.encoder.layer.0.output.dense.bias\n",
      "[01/18/2023-20:38:46] [V] [TRT] Importing initializer: bert.encoder.layer.0.output.LayerNorm.weight\n",
      "[01/18/2023-20:38:46] [V] [TRT] Importing initializer: bert.encoder.layer.0.output.LayerNorm.bias\n",
      "[01/18/2023-20:38:46] [V] [TRT] Importing initializer: bert.encoder.layer.1.attention.self.query.bias\n",
      "[01/18/2023-20:38:46] [V] [TRT] Importing initializer: bert.encoder.layer.1.attention.self.key.bias\n",
      "[01/18/2023-20:38:46] [V] [TRT] Importing initializer: bert.encoder.layer.1.attention.self.value.bias\n",
      "[01/18/2023-20:38:46] [V] [TRT] Importing initializer: bert.encoder.layer.1.attention.output.dense.bias\n",
      "[01/18/2023-20:38:46] [V] [TRT] Importing initializer: bert.encoder.layer.1.attention.output.LayerNorm.weight\n",
      "[01/18/2023-20:38:46] [V] [TRT] Importing initializer: bert.encoder.layer.1.attention.output.LayerNorm.bias\n",
      "[01/18/2023-20:38:46] [V] [TRT] Importing initializer: bert.encoder.layer.1.intermediate.dense.bias\n",
      "[01/18/2023-20:38:46] [V] [TRT] Importing initializer: bert.encoder.layer.1.output.dense.bias\n",
      "[01/18/2023-20:38:46] [V] [TRT] Importing initializer: bert.encoder.layer.1.output.LayerNorm.weight\n",
      "[01/18/2023-20:38:46] [V] [TRT] Importing initializer: bert.encoder.layer.1.output.LayerNorm.bias\n",
      "[01/18/2023-20:38:46] [V] [TRT] Importing initializer: bert.encoder.layer.2.attention.self.query.bias\n",
      "[01/18/2023-20:38:46] [V] [TRT] Importing initializer: bert.encoder.layer.2.attention.self.key.bias\n",
      "[01/18/2023-20:38:46] [V] [TRT] Importing initializer: bert.encoder.layer.2.attention.self.value.bias\n",
      "[01/18/2023-20:38:46] [V] [TRT] Importing initializer: bert.encoder.layer.2.attention.output.dense.bias\n",
      "[01/18/2023-20:38:46] [V] [TRT] Importing initializer: bert.encoder.layer.2.attention.output.LayerNorm.weight\n",
      "[01/18/2023-20:38:46] [V] [TRT] Importing initializer: bert.encoder.layer.2.attention.output.LayerNorm.bias\n",
      "[01/18/2023-20:38:46] [V] [TRT] Importing initializer: bert.encoder.layer.2.intermediate.dense.bias\n",
      "[01/18/2023-20:38:46] [V] [TRT] Importing initializer: bert.encoder.layer.2.output.dense.bias\n",
      "[01/18/2023-20:38:46] [V] [TRT] Importing initializer: bert.encoder.layer.2.output.LayerNorm.weight\n",
      "[01/18/2023-20:38:46] [V] [TRT] Importing initializer: bert.encoder.layer.2.output.LayerNorm.bias\n",
      "[01/18/2023-20:38:46] [V] [TRT] Importing initializer: bert.encoder.layer.3.attention.self.query.bias\n",
      "[01/18/2023-20:38:46] [V] [TRT] Importing initializer: bert.encoder.layer.3.attention.self.key.bias\n",
      "[01/18/2023-20:38:46] [V] [TRT] Importing initializer: bert.encoder.layer.3.attention.self.value.bias\n",
      "[01/18/2023-20:38:46] [V] [TRT] Importing initializer: bert.encoder.layer.3.attention.output.dense.bias\n",
      "[01/18/2023-20:38:46] [V] [TRT] Importing initializer: bert.encoder.layer.3.attention.output.LayerNorm.weight\n",
      "[01/18/2023-20:38:46] [V] [TRT] Importing initializer: bert.encoder.layer.3.attention.output.LayerNorm.bias\n",
      "[01/18/2023-20:38:46] [V] [TRT] Importing initializer: bert.encoder.layer.3.intermediate.dense.bias\n",
      "[01/18/2023-20:38:46] [V] [TRT] Importing initializer: bert.encoder.layer.3.output.dense.bias\n",
      "[01/18/2023-20:38:46] [V] [TRT] Importing initializer: bert.encoder.layer.3.output.LayerNorm.weight\n",
      "[01/18/2023-20:38:46] [V] [TRT] Importing initializer: bert.encoder.layer.3.output.LayerNorm.bias\n",
      "[01/18/2023-20:38:46] [V] [TRT] Importing initializer: bert.encoder.layer.4.attention.self.query.bias\n",
      "[01/18/2023-20:38:46] [V] [TRT] Importing initializer: bert.encoder.layer.4.attention.self.key.bias\n",
      "[01/18/2023-20:38:46] [V] [TRT] Importing initializer: bert.encoder.layer.4.attention.self.value.bias\n",
      "[01/18/2023-20:38:46] [V] [TRT] Importing initializer: bert.encoder.layer.4.attention.output.dense.bias\n",
      "[01/18/2023-20:38:46] [V] [TRT] Importing initializer: bert.encoder.layer.4.attention.output.LayerNorm.weight\n",
      "[01/18/2023-20:38:46] [V] [TRT] Importing initializer: bert.encoder.layer.4.attention.output.LayerNorm.bias\n",
      "[01/18/2023-20:38:46] [V] [TRT] Importing initializer: bert.encoder.layer.4.intermediate.dense.bias\n",
      "[01/18/2023-20:38:46] [V] [TRT] Importing initializer: bert.encoder.layer.4.output.dense.bias\n",
      "[01/18/2023-20:38:46] [V] [TRT] Importing initializer: bert.encoder.layer.4.output.LayerNorm.weight\n",
      "[01/18/2023-20:38:46] [V] [TRT] Importing initializer: bert.encoder.layer.4.output.LayerNorm.bias\n",
      "[01/18/2023-20:38:46] [V] [TRT] Importing initializer: bert.encoder.layer.5.attention.self.query.bias\n",
      "[01/18/2023-20:38:46] [V] [TRT] Importing initializer: bert.encoder.layer.5.attention.self.key.bias\n",
      "[01/18/2023-20:38:46] [V] [TRT] Importing initializer: bert.encoder.layer.5.attention.self.value.bias\n",
      "[01/18/2023-20:38:46] [V] [TRT] Importing initializer: bert.encoder.layer.5.attention.output.dense.bias\n",
      "[01/18/2023-20:38:46] [V] [TRT] Importing initializer: bert.encoder.layer.5.attention.output.LayerNorm.weight\n",
      "[01/18/2023-20:38:46] [V] [TRT] Importing initializer: bert.encoder.layer.5.attention.output.LayerNorm.bias\n",
      "[01/18/2023-20:38:46] [V] [TRT] Importing initializer: bert.encoder.layer.5.intermediate.dense.bias\n",
      "[01/18/2023-20:38:46] [V] [TRT] Importing initializer: bert.encoder.layer.5.output.dense.bias\n",
      "[01/18/2023-20:38:46] [V] [TRT] Importing initializer: bert.encoder.layer.5.output.LayerNorm.weight\n",
      "[01/18/2023-20:38:46] [V] [TRT] Importing initializer: bert.encoder.layer.5.output.LayerNorm.bias\n",
      "[01/18/2023-20:38:46] [V] [TRT] Importing initializer: bert.pooler.dense.weight\n",
      "[01/18/2023-20:38:46] [V] [TRT] Importing initializer: bert.pooler.dense.bias\n",
      "[01/18/2023-20:38:46] [V] [TRT] Importing initializer: classifier.weight\n",
      "[01/18/2023-20:38:46] [V] [TRT] Importing initializer: classifier.bias\n",
      "[01/18/2023-20:38:46] [V] [TRT] Importing initializer: onnx::MatMul_793\n",
      "[01/18/2023-20:38:46] [V] [TRT] Importing initializer: onnx::MatMul_794\n",
      "[01/18/2023-20:38:46] [V] [TRT] Importing initializer: onnx::MatMul_797\n",
      "[01/18/2023-20:38:46] [V] [TRT] Importing initializer: onnx::MatMul_803\n",
      "[01/18/2023-20:38:46] [V] [TRT] Importing initializer: onnx::MatMul_804\n",
      "[01/18/2023-20:38:46] [V] [TRT] Importing initializer: onnx::MatMul_805\n",
      "[01/18/2023-20:38:46] [V] [TRT] Importing initializer: onnx::MatMul_806\n",
      "[01/18/2023-20:38:46] [V] [TRT] Importing initializer: onnx::MatMul_807\n",
      "[01/18/2023-20:38:46] [V] [TRT] Importing initializer: onnx::MatMul_810\n",
      "[01/18/2023-20:38:46] [V] [TRT] Importing initializer: onnx::MatMul_816\n",
      "[01/18/2023-20:38:46] [V] [TRT] Importing initializer: onnx::MatMul_817\n",
      "[01/18/2023-20:38:46] [V] [TRT] Importing initializer: onnx::MatMul_818\n",
      "[01/18/2023-20:38:46] [V] [TRT] Importing initializer: onnx::MatMul_819\n",
      "[01/18/2023-20:38:46] [V] [TRT] Importing initializer: onnx::MatMul_820\n",
      "[01/18/2023-20:38:46] [V] [TRT] Importing initializer: onnx::MatMul_823\n",
      "[01/18/2023-20:38:46] [V] [TRT] Importing initializer: onnx::MatMul_829\n",
      "[01/18/2023-20:38:46] [V] [TRT] Importing initializer: onnx::MatMul_830\n",
      "[01/18/2023-20:38:46] [V] [TRT] Importing initializer: onnx::MatMul_831\n",
      "[01/18/2023-20:38:46] [V] [TRT] Importing initializer: onnx::MatMul_832\n",
      "[01/18/2023-20:38:46] [V] [TRT] Importing initializer: onnx::MatMul_833\n",
      "[01/18/2023-20:38:46] [V] [TRT] Importing initializer: onnx::MatMul_836\n",
      "[01/18/2023-20:38:46] [V] [TRT] Importing initializer: onnx::MatMul_842\n",
      "[01/18/2023-20:38:46] [V] [TRT] Importing initializer: onnx::MatMul_843\n",
      "[01/18/2023-20:38:46] [V] [TRT] Importing initializer: onnx::MatMul_844\n",
      "[01/18/2023-20:38:46] [V] [TRT] Importing initializer: onnx::MatMul_845\n",
      "[01/18/2023-20:38:46] [V] [TRT] Importing initializer: onnx::MatMul_846\n",
      "[01/18/2023-20:38:46] [V] [TRT] Importing initializer: onnx::MatMul_849\n",
      "[01/18/2023-20:38:46] [V] [TRT] Importing initializer: onnx::MatMul_855\n",
      "[01/18/2023-20:38:46] [V] [TRT] Importing initializer: onnx::MatMul_856\n",
      "[01/18/2023-20:38:46] [V] [TRT] Importing initializer: onnx::MatMul_857\n",
      "[01/18/2023-20:38:46] [V] [TRT] Importing initializer: onnx::MatMul_858\n",
      "[01/18/2023-20:38:46] [V] [TRT] Importing initializer: onnx::MatMul_859\n",
      "[01/18/2023-20:38:46] [V] [TRT] Importing initializer: onnx::MatMul_862\n",
      "[01/18/2023-20:38:46] [V] [TRT] Importing initializer: onnx::MatMul_868\n",
      "[01/18/2023-20:38:46] [V] [TRT] Importing initializer: onnx::MatMul_869\n",
      "[01/18/2023-20:38:46] [V] [TRT] Importing initializer: onnx::MatMul_870\n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/Constant [Constant]\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/Constant [Constant] inputs: \n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/Constant [Constant] outputs: [/bert/Constant_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/Unsqueeze [Unsqueeze]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: attention_mask\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/Unsqueeze [Unsqueeze] inputs: [attention_mask -> (-1, -1)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Original shape: (_, _), unsqueezing to: (_, _, _)\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/Unsqueeze for ONNX node: /bert/Unsqueeze\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/Unsqueeze_output_0 for ONNX tensor: /bert/Unsqueeze_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/Unsqueeze [Unsqueeze] outputs: [/bert/Unsqueeze_output_0 -> (-1, 1, -1)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/Unsqueeze_1 [Unsqueeze]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/Unsqueeze_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/Unsqueeze_1 [Unsqueeze] inputs: [/bert/Unsqueeze_output_0 -> (-1, 1, -1)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Original shape: (_, 1, _), unsqueezing to: (_, _, _, _)\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/Unsqueeze_1 for ONNX node: /bert/Unsqueeze_1\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/Unsqueeze_1_output_0 for ONNX tensor: /bert/Unsqueeze_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/Unsqueeze_1 [Unsqueeze] outputs: [/bert/Unsqueeze_1_output_0 -> (-1, 1, 1, -1)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/Cast [Cast]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/Unsqueeze_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/Cast [Cast] inputs: [/bert/Unsqueeze_1_output_0 -> (-1, 1, 1, -1)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Casting to type: float32\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/Cast for ONNX node: /bert/Cast\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/Cast_output_0 for ONNX tensor: /bert/Cast_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/Cast [Cast] outputs: [/bert/Cast_output_0 -> (-1, 1, 1, -1)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/Constant_1 [Constant]\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/Constant_1 [Constant] inputs: \n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/Constant_1 [Constant] outputs: [/bert/Constant_1_output_0 -> ()[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/Sub [Sub]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/Constant_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/Cast_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/Sub [Sub] inputs: [/bert/Constant_1_output_0 -> ()[FLOAT]], [/bert/Cast_output_0 -> (-1, 1, 1, -1)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/Constant_1_output_0 for ONNX node: /bert/Constant_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/Sub for ONNX node: /bert/Sub\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/Sub_output_0 for ONNX tensor: /bert/Sub_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/Sub [Sub] outputs: [/bert/Sub_output_0 -> (-1, 1, 1, -1)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/Constant_2 [Constant]\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/Constant_2 [Constant] inputs: \n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/Constant_2 [Constant] outputs: [/bert/Constant_2_output_0 -> ()[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/Mul [Mul]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/Sub_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/Constant_2_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/Mul [Mul] inputs: [/bert/Sub_output_0 -> (-1, 1, 1, -1)[FLOAT]], [/bert/Constant_2_output_0 -> ()[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/Constant_2_output_0 for ONNX node: /bert/Constant_2_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/Mul for ONNX node: /bert/Mul\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/Mul_output_0 for ONNX tensor: /bert/Mul_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/Mul [Mul] outputs: [/bert/Mul_output_0 -> (-1, 1, 1, -1)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/embeddings/Shape [Shape]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: input_ids\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/embeddings/Shape [Shape] inputs: [input_ids -> (-1, -1)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/embeddings/Shape for ONNX node: /bert/embeddings/Shape\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/embeddings/Shape_output_0 for ONNX tensor: /bert/embeddings/Shape_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/embeddings/Shape [Shape] outputs: [/bert/embeddings/Shape_output_0 -> (2)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/embeddings/Constant [Constant]\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/embeddings/Constant [Constant] inputs: \n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/embeddings/Constant [Constant] outputs: [/bert/embeddings/Constant_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/embeddings/Gather [Gather]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/embeddings/Shape_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/embeddings/Constant_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/embeddings/Gather [Gather] inputs: [/bert/embeddings/Shape_output_0 -> (2)[INT32]], [/bert/embeddings/Constant_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/embeddings/Constant_output_0 for ONNX node: /bert/embeddings/Constant_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Using Gather axis: 0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/embeddings/Gather for ONNX node: /bert/embeddings/Gather\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/embeddings/Gather_output_0 for ONNX tensor: /bert/embeddings/Gather_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/embeddings/Gather [Gather] outputs: [/bert/embeddings/Gather_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/embeddings/Constant_1 [Constant]\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/embeddings/Constant_1 [Constant] inputs: \n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/embeddings/Constant_1 [Constant] outputs: [/bert/embeddings/Constant_1_output_0 -> (1)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/embeddings/Unsqueeze [Unsqueeze]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/embeddings/Gather_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/embeddings/Unsqueeze [Unsqueeze] inputs: [/bert/embeddings/Gather_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/embeddings/Unsqueeze for ONNX node: /bert/embeddings/Unsqueeze\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/embeddings/Unsqueeze_output_0 for ONNX tensor: /bert/embeddings/Unsqueeze_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/embeddings/Unsqueeze [Unsqueeze] outputs: [/bert/embeddings/Unsqueeze_output_0 -> (1)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/embeddings/Constant_2 [Constant]\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/embeddings/Constant_2 [Constant] inputs: \n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/embeddings/Constant_2 [Constant] outputs: [/bert/embeddings/Constant_2_output_0 -> (1)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/embeddings/Constant_3 [Constant]\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/embeddings/Constant_3 [Constant] inputs: \n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/embeddings/Constant_3 [Constant] outputs: [/bert/embeddings/Constant_3_output_0 -> (1)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/embeddings/Slice [Slice]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: bert.embeddings.position_ids\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/embeddings/Constant_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/embeddings/Unsqueeze_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/embeddings/Constant_2_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/embeddings/Constant_3_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/embeddings/Slice [Slice] inputs: [bert.embeddings.position_ids -> (1, 512)[INT32]], [/bert/embeddings/Constant_1_output_0 -> (1)[INT32]], [/bert/embeddings/Unsqueeze_output_0 -> (1)[INT32]], [/bert/embeddings/Constant_2_output_0 -> (1)[INT32]], [/bert/embeddings/Constant_3_output_0 -> (1)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: bert.embeddings.position_ids for ONNX node: bert.embeddings.position_ids\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/embeddings/Slice for ONNX node: /bert/embeddings/Slice\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/embeddings/Slice_output_0 for ONNX tensor: /bert/embeddings/Slice_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/embeddings/Slice [Slice] outputs: [/bert/embeddings/Slice_output_0 -> (1, -1)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/embeddings/word_embeddings/Gather [Gather]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: bert.embeddings.word_embeddings.weight\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: input_ids\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/embeddings/word_embeddings/Gather [Gather] inputs: [bert.embeddings.word_embeddings.weight -> (30522, 256)[FLOAT]], [input_ids -> (-1, -1)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: bert.embeddings.word_embeddings.weight for ONNX node: bert.embeddings.word_embeddings.weight\n",
      "[01/18/2023-20:38:46] [V] [TRT] Using Gather axis: 0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/embeddings/word_embeddings/Gather for ONNX node: /bert/embeddings/word_embeddings/Gather\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/embeddings/word_embeddings/Gather_output_0 for ONNX tensor: /bert/embeddings/word_embeddings/Gather_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/embeddings/word_embeddings/Gather [Gather] outputs: [/bert/embeddings/word_embeddings/Gather_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/embeddings/token_type_embeddings/Gather [Gather]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: bert.embeddings.token_type_embeddings.weight\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: token_type_ids\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/embeddings/token_type_embeddings/Gather [Gather] inputs: [bert.embeddings.token_type_embeddings.weight -> (2, 256)[FLOAT]], [token_type_ids -> (-1, -1)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: bert.embeddings.token_type_embeddings.weight for ONNX node: bert.embeddings.token_type_embeddings.weight\n",
      "[01/18/2023-20:38:46] [V] [TRT] Using Gather axis: 0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/embeddings/token_type_embeddings/Gather for ONNX node: /bert/embeddings/token_type_embeddings/Gather\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/embeddings/token_type_embeddings/Gather_output_0 for ONNX tensor: /bert/embeddings/token_type_embeddings/Gather_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/embeddings/token_type_embeddings/Gather [Gather] outputs: [/bert/embeddings/token_type_embeddings/Gather_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/embeddings/Add [Add]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/embeddings/word_embeddings/Gather_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/embeddings/token_type_embeddings/Gather_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/embeddings/Add [Add] inputs: [/bert/embeddings/word_embeddings/Gather_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/embeddings/token_type_embeddings/Gather_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/embeddings/Add for ONNX node: /bert/embeddings/Add\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/embeddings/Add_output_0 for ONNX tensor: /bert/embeddings/Add_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/embeddings/Add [Add] outputs: [/bert/embeddings/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/embeddings/position_embeddings/Gather [Gather]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: bert.embeddings.position_embeddings.weight\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/embeddings/Slice_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/embeddings/position_embeddings/Gather [Gather] inputs: [bert.embeddings.position_embeddings.weight -> (512, 256)[FLOAT]], [/bert/embeddings/Slice_output_0 -> (1, -1)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: bert.embeddings.position_embeddings.weight for ONNX node: bert.embeddings.position_embeddings.weight\n",
      "[01/18/2023-20:38:46] [V] [TRT] Using Gather axis: 0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/embeddings/position_embeddings/Gather for ONNX node: /bert/embeddings/position_embeddings/Gather\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/embeddings/position_embeddings/Gather_output_0 for ONNX tensor: /bert/embeddings/position_embeddings/Gather_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/embeddings/position_embeddings/Gather [Gather] outputs: [/bert/embeddings/position_embeddings/Gather_output_0 -> (1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/embeddings/Add_1 [Add]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/embeddings/Add_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/embeddings/position_embeddings/Gather_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/embeddings/Add_1 [Add] inputs: [/bert/embeddings/Add_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/embeddings/position_embeddings/Gather_output_0 -> (1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/embeddings/Add_1 for ONNX node: /bert/embeddings/Add_1\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/embeddings/Add_1_output_0 for ONNX tensor: /bert/embeddings/Add_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/embeddings/Add_1 [Add] outputs: [/bert/embeddings/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/embeddings/LayerNorm/ReduceMean [ReduceMean]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/embeddings/Add_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/embeddings/LayerNorm/ReduceMean [ReduceMean] inputs: [/bert/embeddings/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/embeddings/LayerNorm/ReduceMean for ONNX node: /bert/embeddings/LayerNorm/ReduceMean\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/embeddings/LayerNorm/ReduceMean_output_0 for ONNX tensor: /bert/embeddings/LayerNorm/ReduceMean_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/embeddings/LayerNorm/ReduceMean [ReduceMean] outputs: [/bert/embeddings/LayerNorm/ReduceMean_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/embeddings/LayerNorm/Sub [Sub]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/embeddings/Add_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/embeddings/LayerNorm/ReduceMean_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/embeddings/LayerNorm/Sub [Sub] inputs: [/bert/embeddings/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/embeddings/LayerNorm/ReduceMean_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/embeddings/LayerNorm/Sub for ONNX node: /bert/embeddings/LayerNorm/Sub\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/embeddings/LayerNorm/Sub_output_0 for ONNX tensor: /bert/embeddings/LayerNorm/Sub_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/embeddings/LayerNorm/Sub [Sub] outputs: [/bert/embeddings/LayerNorm/Sub_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/embeddings/LayerNorm/Constant [Constant]\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/embeddings/LayerNorm/Constant [Constant] inputs: \n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/embeddings/LayerNorm/Constant [Constant] outputs: [/bert/embeddings/LayerNorm/Constant_output_0 -> ()[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/embeddings/LayerNorm/Pow [Pow]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/embeddings/LayerNorm/Sub_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/embeddings/LayerNorm/Constant_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/embeddings/LayerNorm/Pow [Pow] inputs: [/bert/embeddings/LayerNorm/Sub_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/embeddings/LayerNorm/Constant_output_0 -> ()[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/embeddings/LayerNorm/Constant_output_0 for ONNX node: /bert/embeddings/LayerNorm/Constant_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/embeddings/LayerNorm/Pow for ONNX node: /bert/embeddings/LayerNorm/Pow\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/embeddings/LayerNorm/Pow_output_0 for ONNX tensor: /bert/embeddings/LayerNorm/Pow_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/embeddings/LayerNorm/Pow [Pow] outputs: [/bert/embeddings/LayerNorm/Pow_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/embeddings/LayerNorm/ReduceMean_1 [ReduceMean]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/embeddings/LayerNorm/Pow_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/embeddings/LayerNorm/ReduceMean_1 [ReduceMean] inputs: [/bert/embeddings/LayerNorm/Pow_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/embeddings/LayerNorm/ReduceMean_1 for ONNX node: /bert/embeddings/LayerNorm/ReduceMean_1\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/embeddings/LayerNorm/ReduceMean_1_output_0 for ONNX tensor: /bert/embeddings/LayerNorm/ReduceMean_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/embeddings/LayerNorm/ReduceMean_1 [ReduceMean] outputs: [/bert/embeddings/LayerNorm/ReduceMean_1_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/embeddings/LayerNorm/Constant_1 [Constant]\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/embeddings/LayerNorm/Constant_1 [Constant] inputs: \n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/embeddings/LayerNorm/Constant_1 [Constant] outputs: [/bert/embeddings/LayerNorm/Constant_1_output_0 -> ()[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/embeddings/LayerNorm/Add [Add]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/embeddings/LayerNorm/ReduceMean_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/embeddings/LayerNorm/Constant_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/embeddings/LayerNorm/Add [Add] inputs: [/bert/embeddings/LayerNorm/ReduceMean_1_output_0 -> (-1, -1, 1)[FLOAT]], [/bert/embeddings/LayerNorm/Constant_1_output_0 -> ()[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/embeddings/LayerNorm/Constant_1_output_0 for ONNX node: /bert/embeddings/LayerNorm/Constant_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/embeddings/LayerNorm/Add for ONNX node: /bert/embeddings/LayerNorm/Add\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/embeddings/LayerNorm/Add_output_0 for ONNX tensor: /bert/embeddings/LayerNorm/Add_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/embeddings/LayerNorm/Add [Add] outputs: [/bert/embeddings/LayerNorm/Add_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/embeddings/LayerNorm/Sqrt [Sqrt]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/embeddings/LayerNorm/Add_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/embeddings/LayerNorm/Sqrt [Sqrt] inputs: [/bert/embeddings/LayerNorm/Add_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/embeddings/LayerNorm/Sqrt for ONNX node: /bert/embeddings/LayerNorm/Sqrt\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/embeddings/LayerNorm/Sqrt_output_0 for ONNX tensor: /bert/embeddings/LayerNorm/Sqrt_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/embeddings/LayerNorm/Sqrt [Sqrt] outputs: [/bert/embeddings/LayerNorm/Sqrt_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/embeddings/LayerNorm/Div [Div]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/embeddings/LayerNorm/Sub_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/embeddings/LayerNorm/Sqrt_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/embeddings/LayerNorm/Div [Div] inputs: [/bert/embeddings/LayerNorm/Sub_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/embeddings/LayerNorm/Sqrt_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/embeddings/LayerNorm/Div for ONNX node: /bert/embeddings/LayerNorm/Div\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/embeddings/LayerNorm/Div_output_0 for ONNX tensor: /bert/embeddings/LayerNorm/Div_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/embeddings/LayerNorm/Div [Div] outputs: [/bert/embeddings/LayerNorm/Div_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/embeddings/LayerNorm/Mul [Mul]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/embeddings/LayerNorm/Div_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: bert.embeddings.LayerNorm.weight\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/embeddings/LayerNorm/Mul [Mul] inputs: [/bert/embeddings/LayerNorm/Div_output_0 -> (-1, -1, 256)[FLOAT]], [bert.embeddings.LayerNorm.weight -> (256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: bert.embeddings.LayerNorm.weight for ONNX node: bert.embeddings.LayerNorm.weight\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/embeddings/LayerNorm/Mul for ONNX node: /bert/embeddings/LayerNorm/Mul\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/embeddings/LayerNorm/Mul_output_0 for ONNX tensor: /bert/embeddings/LayerNorm/Mul_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/embeddings/LayerNorm/Mul [Mul] outputs: [/bert/embeddings/LayerNorm/Mul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/embeddings/LayerNorm/Add_1 [Add]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/embeddings/LayerNorm/Mul_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: bert.embeddings.LayerNorm.bias\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/embeddings/LayerNorm/Add_1 [Add] inputs: [/bert/embeddings/LayerNorm/Mul_output_0 -> (-1, -1, 256)[FLOAT]], [bert.embeddings.LayerNorm.bias -> (256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: bert.embeddings.LayerNorm.bias for ONNX node: bert.embeddings.LayerNorm.bias\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/embeddings/LayerNorm/Add_1 for ONNX node: /bert/embeddings/LayerNorm/Add_1\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/embeddings/LayerNorm/Add_1_output_0 for ONNX tensor: /bert/embeddings/LayerNorm/Add_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/embeddings/LayerNorm/Add_1 [Add] outputs: [/bert/embeddings/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/query/MatMul [MatMul]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/embeddings/LayerNorm/Add_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: onnx::MatMul_793\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/self/query/MatMul [MatMul] inputs: [/bert/embeddings/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], [onnx::MatMul_793 -> (256, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: onnx::MatMul_793 for ONNX node: onnx::MatMul_793\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/query/MatMul for ONNX node: /bert/encoder/layer.0/attention/self/query/MatMul\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/query/MatMul_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/query/MatMul_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/self/query/MatMul [MatMul] outputs: [/bert/encoder/layer.0/attention/self/query/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/query/Add [Add]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: bert.encoder.layer.0.attention.self.query.bias\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/query/MatMul_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/self/query/Add [Add] inputs: [bert.encoder.layer.0.attention.self.query.bias -> (256)[FLOAT]], [/bert/encoder/layer.0/attention/self/query/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: bert.encoder.layer.0.attention.self.query.bias for ONNX node: bert.encoder.layer.0.attention.self.query.bias\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/query/Add for ONNX node: /bert/encoder/layer.0/attention/self/query/Add\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/query/Add_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/query/Add_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/self/query/Add [Add] outputs: [/bert/encoder/layer.0/attention/self/query/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/key/MatMul [MatMul]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/embeddings/LayerNorm/Add_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: onnx::MatMul_794\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/self/key/MatMul [MatMul] inputs: [/bert/embeddings/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], [onnx::MatMul_794 -> (256, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: onnx::MatMul_794 for ONNX node: onnx::MatMul_794\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/key/MatMul for ONNX node: /bert/encoder/layer.0/attention/self/key/MatMul\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/key/MatMul_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/key/MatMul_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/self/key/MatMul [MatMul] outputs: [/bert/encoder/layer.0/attention/self/key/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/key/Add [Add]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: bert.encoder.layer.0.attention.self.key.bias\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/key/MatMul_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/self/key/Add [Add] inputs: [bert.encoder.layer.0.attention.self.key.bias -> (256)[FLOAT]], [/bert/encoder/layer.0/attention/self/key/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: bert.encoder.layer.0.attention.self.key.bias for ONNX node: bert.encoder.layer.0.attention.self.key.bias\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/key/Add for ONNX node: /bert/encoder/layer.0/attention/self/key/Add\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/key/Add_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/key/Add_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/self/key/Add [Add] outputs: [/bert/encoder/layer.0/attention/self/key/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Shape [Shape]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/key/Add_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/self/Shape [Shape] inputs: [/bert/encoder/layer.0/attention/self/key/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Shape for ONNX node: /bert/encoder/layer.0/attention/self/Shape\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/Shape_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/Shape_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/self/Shape [Shape] outputs: [/bert/encoder/layer.0/attention/self/Shape_output_0 -> (3)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Constant [Constant]\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/self/Constant [Constant] inputs: \n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/self/Constant [Constant] outputs: [/bert/encoder/layer.0/attention/self/Constant_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Gather [Gather]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Shape_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Constant_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/self/Gather [Gather] inputs: [/bert/encoder/layer.0/attention/self/Shape_output_0 -> (3)[INT32]], [/bert/encoder/layer.0/attention/self/Constant_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Constant_output_0 for ONNX node: /bert/encoder/layer.0/attention/self/Constant_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Using Gather axis: 0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Gather for ONNX node: /bert/encoder/layer.0/attention/self/Gather\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/Gather_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/Gather_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/self/Gather [Gather] outputs: [/bert/encoder/layer.0/attention/self/Gather_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Shape_1 [Shape]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/key/Add_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/self/Shape_1 [Shape] inputs: [/bert/encoder/layer.0/attention/self/key/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Shape_1 for ONNX node: /bert/encoder/layer.0/attention/self/Shape_1\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/Shape_1_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/Shape_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/self/Shape_1 [Shape] outputs: [/bert/encoder/layer.0/attention/self/Shape_1_output_0 -> (3)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Constant_1 [Constant]\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/self/Constant_1 [Constant] inputs: \n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/self/Constant_1 [Constant] outputs: [/bert/encoder/layer.0/attention/self/Constant_1_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Gather_1 [Gather]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Shape_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Constant_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/self/Gather_1 [Gather] inputs: [/bert/encoder/layer.0/attention/self/Shape_1_output_0 -> (3)[INT32]], [/bert/encoder/layer.0/attention/self/Constant_1_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Constant_1_output_0 for ONNX node: /bert/encoder/layer.0/attention/self/Constant_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Using Gather axis: 0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Gather_1 for ONNX node: /bert/encoder/layer.0/attention/self/Gather_1\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/Gather_1_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/Gather_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/self/Gather_1 [Gather] outputs: [/bert/encoder/layer.0/attention/self/Gather_1_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Unsqueeze [Unsqueeze]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Gather_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/self/Unsqueeze [Unsqueeze] inputs: [/bert/encoder/layer.0/attention/self/Gather_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Unsqueeze for ONNX node: /bert/encoder/layer.0/attention/self/Unsqueeze\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/Unsqueeze_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/Unsqueeze_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/self/Unsqueeze [Unsqueeze] outputs: [/bert/encoder/layer.0/attention/self/Unsqueeze_output_0 -> (1)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Unsqueeze_1 [Unsqueeze]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Gather_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/self/Unsqueeze_1 [Unsqueeze] inputs: [/bert/encoder/layer.0/attention/self/Gather_1_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Unsqueeze_1 for ONNX node: /bert/encoder/layer.0/attention/self/Unsqueeze_1\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/Unsqueeze_1_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/Unsqueeze_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/self/Unsqueeze_1 [Unsqueeze] outputs: [/bert/encoder/layer.0/attention/self/Unsqueeze_1_output_0 -> (1)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Constant_2 [Constant]\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/self/Constant_2 [Constant] inputs: \n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/self/Constant_2 [Constant] outputs: [/bert/encoder/layer.0/attention/self/Constant_2_output_0 -> (1)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Constant_3 [Constant]\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/self/Constant_3 [Constant] inputs: \n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/self/Constant_3 [Constant] outputs: [/bert/encoder/layer.0/attention/self/Constant_3_output_0 -> (1)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Concat [Concat]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Unsqueeze_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Unsqueeze_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Constant_2_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Constant_3_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/self/Concat [Concat] inputs: [/bert/encoder/layer.0/attention/self/Unsqueeze_output_0 -> (1)[INT32]], [/bert/encoder/layer.0/attention/self/Unsqueeze_1_output_0 -> (1)[INT32]], [/bert/encoder/layer.0/attention/self/Constant_2_output_0 -> (1)[INT32]], [/bert/encoder/layer.0/attention/self/Constant_3_output_0 -> (1)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Constant_2_output_0 for ONNX node: /bert/encoder/layer.0/attention/self/Constant_2_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Constant_3_output_0 for ONNX node: /bert/encoder/layer.0/attention/self/Constant_3_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Concat for ONNX node: /bert/encoder/layer.0/attention/self/Concat\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/Concat_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/Concat_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/self/Concat [Concat] outputs: [/bert/encoder/layer.0/attention/self/Concat_output_0 -> (4)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Reshape [Reshape]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/key/Add_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Concat_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/self/Reshape [Reshape] inputs: [/bert/encoder/layer.0/attention/self/key/Add_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.0/attention/self/Concat_output_0 -> (4)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Reshape for ONNX node: /bert/encoder/layer.0/attention/self/Reshape\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/Reshape_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/Reshape_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/self/Reshape [Reshape] outputs: [/bert/encoder/layer.0/attention/self/Reshape_output_0 -> (-1, -1, 8, 32)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/value/MatMul [MatMul]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/embeddings/LayerNorm/Add_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: onnx::MatMul_797\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/self/value/MatMul [MatMul] inputs: [/bert/embeddings/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], [onnx::MatMul_797 -> (256, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: onnx::MatMul_797 for ONNX node: onnx::MatMul_797\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/value/MatMul for ONNX node: /bert/encoder/layer.0/attention/self/value/MatMul\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/value/MatMul_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/value/MatMul_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/self/value/MatMul [MatMul] outputs: [/bert/encoder/layer.0/attention/self/value/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/value/Add [Add]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: bert.encoder.layer.0.attention.self.value.bias\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/value/MatMul_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/self/value/Add [Add] inputs: [bert.encoder.layer.0.attention.self.value.bias -> (256)[FLOAT]], [/bert/encoder/layer.0/attention/self/value/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: bert.encoder.layer.0.attention.self.value.bias for ONNX node: bert.encoder.layer.0.attention.self.value.bias\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/value/Add for ONNX node: /bert/encoder/layer.0/attention/self/value/Add\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/value/Add_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/value/Add_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/self/value/Add [Add] outputs: [/bert/encoder/layer.0/attention/self/value/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Shape_2 [Shape]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/value/Add_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/self/Shape_2 [Shape] inputs: [/bert/encoder/layer.0/attention/self/value/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Shape_2 for ONNX node: /bert/encoder/layer.0/attention/self/Shape_2\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/Shape_2_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/Shape_2_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/self/Shape_2 [Shape] outputs: [/bert/encoder/layer.0/attention/self/Shape_2_output_0 -> (3)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Constant_4 [Constant]\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/self/Constant_4 [Constant] inputs: \n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/self/Constant_4 [Constant] outputs: [/bert/encoder/layer.0/attention/self/Constant_4_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Gather_2 [Gather]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Shape_2_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Constant_4_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/self/Gather_2 [Gather] inputs: [/bert/encoder/layer.0/attention/self/Shape_2_output_0 -> (3)[INT32]], [/bert/encoder/layer.0/attention/self/Constant_4_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Constant_4_output_0 for ONNX node: /bert/encoder/layer.0/attention/self/Constant_4_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Using Gather axis: 0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Gather_2 for ONNX node: /bert/encoder/layer.0/attention/self/Gather_2\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/Gather_2_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/Gather_2_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/self/Gather_2 [Gather] outputs: [/bert/encoder/layer.0/attention/self/Gather_2_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Shape_3 [Shape]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/value/Add_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/self/Shape_3 [Shape] inputs: [/bert/encoder/layer.0/attention/self/value/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Shape_3 for ONNX node: /bert/encoder/layer.0/attention/self/Shape_3\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/Shape_3_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/Shape_3_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/self/Shape_3 [Shape] outputs: [/bert/encoder/layer.0/attention/self/Shape_3_output_0 -> (3)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Constant_5 [Constant]\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/self/Constant_5 [Constant] inputs: \n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/self/Constant_5 [Constant] outputs: [/bert/encoder/layer.0/attention/self/Constant_5_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Gather_3 [Gather]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Shape_3_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Constant_5_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/self/Gather_3 [Gather] inputs: [/bert/encoder/layer.0/attention/self/Shape_3_output_0 -> (3)[INT32]], [/bert/encoder/layer.0/attention/self/Constant_5_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Constant_5_output_0 for ONNX node: /bert/encoder/layer.0/attention/self/Constant_5_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Using Gather axis: 0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Gather_3 for ONNX node: /bert/encoder/layer.0/attention/self/Gather_3\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/Gather_3_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/Gather_3_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/self/Gather_3 [Gather] outputs: [/bert/encoder/layer.0/attention/self/Gather_3_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Unsqueeze_2 [Unsqueeze]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Gather_2_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/self/Unsqueeze_2 [Unsqueeze] inputs: [/bert/encoder/layer.0/attention/self/Gather_2_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Unsqueeze_2 for ONNX node: /bert/encoder/layer.0/attention/self/Unsqueeze_2\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/Unsqueeze_2_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/Unsqueeze_2_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/self/Unsqueeze_2 [Unsqueeze] outputs: [/bert/encoder/layer.0/attention/self/Unsqueeze_2_output_0 -> (1)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Unsqueeze_3 [Unsqueeze]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Gather_3_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/self/Unsqueeze_3 [Unsqueeze] inputs: [/bert/encoder/layer.0/attention/self/Gather_3_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Unsqueeze_3 for ONNX node: /bert/encoder/layer.0/attention/self/Unsqueeze_3\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/Unsqueeze_3_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/Unsqueeze_3_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/self/Unsqueeze_3 [Unsqueeze] outputs: [/bert/encoder/layer.0/attention/self/Unsqueeze_3_output_0 -> (1)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Constant_6 [Constant]\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/self/Constant_6 [Constant] inputs: \n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/self/Constant_6 [Constant] outputs: [/bert/encoder/layer.0/attention/self/Constant_6_output_0 -> (1)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Constant_7 [Constant]\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/self/Constant_7 [Constant] inputs: \n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/self/Constant_7 [Constant] outputs: [/bert/encoder/layer.0/attention/self/Constant_7_output_0 -> (1)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Concat_1 [Concat]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Unsqueeze_2_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Unsqueeze_3_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Constant_6_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Constant_7_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/self/Concat_1 [Concat] inputs: [/bert/encoder/layer.0/attention/self/Unsqueeze_2_output_0 -> (1)[INT32]], [/bert/encoder/layer.0/attention/self/Unsqueeze_3_output_0 -> (1)[INT32]], [/bert/encoder/layer.0/attention/self/Constant_6_output_0 -> (1)[INT32]], [/bert/encoder/layer.0/attention/self/Constant_7_output_0 -> (1)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Constant_6_output_0 for ONNX node: /bert/encoder/layer.0/attention/self/Constant_6_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Constant_7_output_0 for ONNX node: /bert/encoder/layer.0/attention/self/Constant_7_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Concat_1 for ONNX node: /bert/encoder/layer.0/attention/self/Concat_1\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/Concat_1_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/Concat_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/self/Concat_1 [Concat] outputs: [/bert/encoder/layer.0/attention/self/Concat_1_output_0 -> (4)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Reshape_1 [Reshape]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/value/Add_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Concat_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/self/Reshape_1 [Reshape] inputs: [/bert/encoder/layer.0/attention/self/value/Add_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.0/attention/self/Concat_1_output_0 -> (4)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Reshape_1 for ONNX node: /bert/encoder/layer.0/attention/self/Reshape_1\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/Reshape_1_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/Reshape_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/self/Reshape_1 [Reshape] outputs: [/bert/encoder/layer.0/attention/self/Reshape_1_output_0 -> (-1, -1, 8, 32)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Transpose [Transpose]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Reshape_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/self/Transpose [Transpose] inputs: [/bert/encoder/layer.0/attention/self/Reshape_1_output_0 -> (-1, -1, 8, 32)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Transpose for ONNX node: /bert/encoder/layer.0/attention/self/Transpose\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/Transpose_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/Transpose_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/self/Transpose [Transpose] outputs: [/bert/encoder/layer.0/attention/self/Transpose_output_0 -> (-1, 8, -1, 32)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Shape_4 [Shape]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/query/Add_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/self/Shape_4 [Shape] inputs: [/bert/encoder/layer.0/attention/self/query/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Shape_4 for ONNX node: /bert/encoder/layer.0/attention/self/Shape_4\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/Shape_4_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/Shape_4_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/self/Shape_4 [Shape] outputs: [/bert/encoder/layer.0/attention/self/Shape_4_output_0 -> (3)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Constant_8 [Constant]\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/self/Constant_8 [Constant] inputs: \n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/self/Constant_8 [Constant] outputs: [/bert/encoder/layer.0/attention/self/Constant_8_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Gather_4 [Gather]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Shape_4_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Constant_8_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/self/Gather_4 [Gather] inputs: [/bert/encoder/layer.0/attention/self/Shape_4_output_0 -> (3)[INT32]], [/bert/encoder/layer.0/attention/self/Constant_8_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Constant_8_output_0 for ONNX node: /bert/encoder/layer.0/attention/self/Constant_8_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Using Gather axis: 0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Gather_4 for ONNX node: /bert/encoder/layer.0/attention/self/Gather_4\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/Gather_4_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/Gather_4_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/self/Gather_4 [Gather] outputs: [/bert/encoder/layer.0/attention/self/Gather_4_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Shape_5 [Shape]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/query/Add_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/self/Shape_5 [Shape] inputs: [/bert/encoder/layer.0/attention/self/query/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Shape_5 for ONNX node: /bert/encoder/layer.0/attention/self/Shape_5\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/Shape_5_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/Shape_5_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/self/Shape_5 [Shape] outputs: [/bert/encoder/layer.0/attention/self/Shape_5_output_0 -> (3)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Constant_9 [Constant]\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/self/Constant_9 [Constant] inputs: \n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/self/Constant_9 [Constant] outputs: [/bert/encoder/layer.0/attention/self/Constant_9_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Gather_5 [Gather]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Shape_5_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Constant_9_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/self/Gather_5 [Gather] inputs: [/bert/encoder/layer.0/attention/self/Shape_5_output_0 -> (3)[INT32]], [/bert/encoder/layer.0/attention/self/Constant_9_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Constant_9_output_0 for ONNX node: /bert/encoder/layer.0/attention/self/Constant_9_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Using Gather axis: 0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Gather_5 for ONNX node: /bert/encoder/layer.0/attention/self/Gather_5\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/Gather_5_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/Gather_5_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/self/Gather_5 [Gather] outputs: [/bert/encoder/layer.0/attention/self/Gather_5_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Unsqueeze_4 [Unsqueeze]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Gather_4_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/self/Unsqueeze_4 [Unsqueeze] inputs: [/bert/encoder/layer.0/attention/self/Gather_4_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Unsqueeze_4 for ONNX node: /bert/encoder/layer.0/attention/self/Unsqueeze_4\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/Unsqueeze_4_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/Unsqueeze_4_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/self/Unsqueeze_4 [Unsqueeze] outputs: [/bert/encoder/layer.0/attention/self/Unsqueeze_4_output_0 -> (1)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Unsqueeze_5 [Unsqueeze]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Gather_5_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/self/Unsqueeze_5 [Unsqueeze] inputs: [/bert/encoder/layer.0/attention/self/Gather_5_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Unsqueeze_5 for ONNX node: /bert/encoder/layer.0/attention/self/Unsqueeze_5\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/Unsqueeze_5_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/Unsqueeze_5_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/self/Unsqueeze_5 [Unsqueeze] outputs: [/bert/encoder/layer.0/attention/self/Unsqueeze_5_output_0 -> (1)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Constant_10 [Constant]\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/self/Constant_10 [Constant] inputs: \n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/self/Constant_10 [Constant] outputs: [/bert/encoder/layer.0/attention/self/Constant_10_output_0 -> (1)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Constant_11 [Constant]\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/self/Constant_11 [Constant] inputs: \n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/self/Constant_11 [Constant] outputs: [/bert/encoder/layer.0/attention/self/Constant_11_output_0 -> (1)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Concat_2 [Concat]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Unsqueeze_4_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Unsqueeze_5_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Constant_10_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Constant_11_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/self/Concat_2 [Concat] inputs: [/bert/encoder/layer.0/attention/self/Unsqueeze_4_output_0 -> (1)[INT32]], [/bert/encoder/layer.0/attention/self/Unsqueeze_5_output_0 -> (1)[INT32]], [/bert/encoder/layer.0/attention/self/Constant_10_output_0 -> (1)[INT32]], [/bert/encoder/layer.0/attention/self/Constant_11_output_0 -> (1)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Constant_10_output_0 for ONNX node: /bert/encoder/layer.0/attention/self/Constant_10_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Constant_11_output_0 for ONNX node: /bert/encoder/layer.0/attention/self/Constant_11_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Concat_2 for ONNX node: /bert/encoder/layer.0/attention/self/Concat_2\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/Concat_2_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/Concat_2_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/self/Concat_2 [Concat] outputs: [/bert/encoder/layer.0/attention/self/Concat_2_output_0 -> (4)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Reshape_2 [Reshape]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/query/Add_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Concat_2_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/self/Reshape_2 [Reshape] inputs: [/bert/encoder/layer.0/attention/self/query/Add_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.0/attention/self/Concat_2_output_0 -> (4)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Reshape_2 for ONNX node: /bert/encoder/layer.0/attention/self/Reshape_2\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/Reshape_2_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/Reshape_2_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/self/Reshape_2 [Reshape] outputs: [/bert/encoder/layer.0/attention/self/Reshape_2_output_0 -> (-1, -1, 8, 32)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Transpose_1 [Transpose]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Reshape_2_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/self/Transpose_1 [Transpose] inputs: [/bert/encoder/layer.0/attention/self/Reshape_2_output_0 -> (-1, -1, 8, 32)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Transpose_1 for ONNX node: /bert/encoder/layer.0/attention/self/Transpose_1\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/Transpose_1_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/Transpose_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/self/Transpose_1 [Transpose] outputs: [/bert/encoder/layer.0/attention/self/Transpose_1_output_0 -> (-1, 8, -1, 32)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Transpose_2 [Transpose]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Reshape_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/self/Transpose_2 [Transpose] inputs: [/bert/encoder/layer.0/attention/self/Reshape_output_0 -> (-1, -1, 8, 32)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Transpose_2 for ONNX node: /bert/encoder/layer.0/attention/self/Transpose_2\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/Transpose_2_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/Transpose_2_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/self/Transpose_2 [Transpose] outputs: [/bert/encoder/layer.0/attention/self/Transpose_2_output_0 -> (-1, 8, 32, -1)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/MatMul [MatMul]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Transpose_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Transpose_2_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/self/MatMul [MatMul] inputs: [/bert/encoder/layer.0/attention/self/Transpose_1_output_0 -> (-1, 8, -1, 32)[FLOAT]], [/bert/encoder/layer.0/attention/self/Transpose_2_output_0 -> (-1, 8, 32, -1)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/MatMul for ONNX node: /bert/encoder/layer.0/attention/self/MatMul\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/MatMul_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/MatMul_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/self/MatMul [MatMul] outputs: [/bert/encoder/layer.0/attention/self/MatMul_output_0 -> (-1, 8, -1, -1)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Constant_12 [Constant]\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/self/Constant_12 [Constant] inputs: \n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/self/Constant_12 [Constant] outputs: [/bert/encoder/layer.0/attention/self/Constant_12_output_0 -> ()[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Div [Div]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/MatMul_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Constant_12_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/self/Div [Div] inputs: [/bert/encoder/layer.0/attention/self/MatMul_output_0 -> (-1, 8, -1, -1)[FLOAT]], [/bert/encoder/layer.0/attention/self/Constant_12_output_0 -> ()[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Constant_12_output_0 for ONNX node: /bert/encoder/layer.0/attention/self/Constant_12_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Div for ONNX node: /bert/encoder/layer.0/attention/self/Div\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/Div_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/Div_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/self/Div [Div] outputs: [/bert/encoder/layer.0/attention/self/Div_output_0 -> (-1, 8, -1, -1)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Add [Add]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Div_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/Mul_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/self/Add [Add] inputs: [/bert/encoder/layer.0/attention/self/Div_output_0 -> (-1, 8, -1, -1)[FLOAT]], [/bert/Mul_output_0 -> (-1, 1, 1, -1)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Add for ONNX node: /bert/encoder/layer.0/attention/self/Add\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/Add_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/Add_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/self/Add [Add] outputs: [/bert/encoder/layer.0/attention/self/Add_output_0 -> (-1, 8, -1, -1)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Softmax [Softmax]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Add_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/self/Softmax [Softmax] inputs: [/bert/encoder/layer.0/attention/self/Add_output_0 -> (-1, 8, -1, -1)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Softmax for ONNX node: /bert/encoder/layer.0/attention/self/Softmax\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/Softmax_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/Softmax_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/self/Softmax [Softmax] outputs: [/bert/encoder/layer.0/attention/self/Softmax_output_0 -> (-1, 8, -1, -1)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/MatMul_1 [MatMul]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Softmax_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Transpose_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/self/MatMul_1 [MatMul] inputs: [/bert/encoder/layer.0/attention/self/Softmax_output_0 -> (-1, 8, -1, -1)[FLOAT]], [/bert/encoder/layer.0/attention/self/Transpose_output_0 -> (-1, 8, -1, 32)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/MatMul_1 for ONNX node: /bert/encoder/layer.0/attention/self/MatMul_1\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/MatMul_1_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/MatMul_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/self/MatMul_1 [MatMul] outputs: [/bert/encoder/layer.0/attention/self/MatMul_1_output_0 -> (-1, 8, -1, 32)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Transpose_3 [Transpose]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/MatMul_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/self/Transpose_3 [Transpose] inputs: [/bert/encoder/layer.0/attention/self/MatMul_1_output_0 -> (-1, 8, -1, 32)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Transpose_3 for ONNX node: /bert/encoder/layer.0/attention/self/Transpose_3\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/Transpose_3_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/Transpose_3_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/self/Transpose_3 [Transpose] outputs: [/bert/encoder/layer.0/attention/self/Transpose_3_output_0 -> (-1, -1, 8, 32)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Shape_6 [Shape]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Transpose_3_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/self/Shape_6 [Shape] inputs: [/bert/encoder/layer.0/attention/self/Transpose_3_output_0 -> (-1, -1, 8, 32)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Shape_6 for ONNX node: /bert/encoder/layer.0/attention/self/Shape_6\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/Shape_6_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/Shape_6_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/self/Shape_6 [Shape] outputs: [/bert/encoder/layer.0/attention/self/Shape_6_output_0 -> (4)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Constant_13 [Constant]\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/self/Constant_13 [Constant] inputs: \n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/self/Constant_13 [Constant] outputs: [/bert/encoder/layer.0/attention/self/Constant_13_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Gather_6 [Gather]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Shape_6_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Constant_13_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/self/Gather_6 [Gather] inputs: [/bert/encoder/layer.0/attention/self/Shape_6_output_0 -> (4)[INT32]], [/bert/encoder/layer.0/attention/self/Constant_13_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Constant_13_output_0 for ONNX node: /bert/encoder/layer.0/attention/self/Constant_13_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Using Gather axis: 0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Gather_6 for ONNX node: /bert/encoder/layer.0/attention/self/Gather_6\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/Gather_6_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/Gather_6_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/self/Gather_6 [Gather] outputs: [/bert/encoder/layer.0/attention/self/Gather_6_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Shape_7 [Shape]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Transpose_3_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/self/Shape_7 [Shape] inputs: [/bert/encoder/layer.0/attention/self/Transpose_3_output_0 -> (-1, -1, 8, 32)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Shape_7 for ONNX node: /bert/encoder/layer.0/attention/self/Shape_7\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/Shape_7_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/Shape_7_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/self/Shape_7 [Shape] outputs: [/bert/encoder/layer.0/attention/self/Shape_7_output_0 -> (4)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Constant_14 [Constant]\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/self/Constant_14 [Constant] inputs: \n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/self/Constant_14 [Constant] outputs: [/bert/encoder/layer.0/attention/self/Constant_14_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Gather_7 [Gather]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Shape_7_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Constant_14_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/self/Gather_7 [Gather] inputs: [/bert/encoder/layer.0/attention/self/Shape_7_output_0 -> (4)[INT32]], [/bert/encoder/layer.0/attention/self/Constant_14_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Constant_14_output_0 for ONNX node: /bert/encoder/layer.0/attention/self/Constant_14_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Using Gather axis: 0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Gather_7 for ONNX node: /bert/encoder/layer.0/attention/self/Gather_7\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/Gather_7_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/Gather_7_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/self/Gather_7 [Gather] outputs: [/bert/encoder/layer.0/attention/self/Gather_7_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Unsqueeze_6 [Unsqueeze]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Gather_6_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/self/Unsqueeze_6 [Unsqueeze] inputs: [/bert/encoder/layer.0/attention/self/Gather_6_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Unsqueeze_6 for ONNX node: /bert/encoder/layer.0/attention/self/Unsqueeze_6\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/Unsqueeze_6_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/Unsqueeze_6_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/self/Unsqueeze_6 [Unsqueeze] outputs: [/bert/encoder/layer.0/attention/self/Unsqueeze_6_output_0 -> (1)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Unsqueeze_7 [Unsqueeze]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Gather_7_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/self/Unsqueeze_7 [Unsqueeze] inputs: [/bert/encoder/layer.0/attention/self/Gather_7_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Unsqueeze_7 for ONNX node: /bert/encoder/layer.0/attention/self/Unsqueeze_7\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/Unsqueeze_7_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/Unsqueeze_7_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/self/Unsqueeze_7 [Unsqueeze] outputs: [/bert/encoder/layer.0/attention/self/Unsqueeze_7_output_0 -> (1)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Constant_15 [Constant]\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/self/Constant_15 [Constant] inputs: \n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/self/Constant_15 [Constant] outputs: [/bert/encoder/layer.0/attention/self/Constant_15_output_0 -> (1)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Concat_3 [Concat]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Unsqueeze_6_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Unsqueeze_7_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Constant_15_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/self/Concat_3 [Concat] inputs: [/bert/encoder/layer.0/attention/self/Unsqueeze_6_output_0 -> (1)[INT32]], [/bert/encoder/layer.0/attention/self/Unsqueeze_7_output_0 -> (1)[INT32]], [/bert/encoder/layer.0/attention/self/Constant_15_output_0 -> (1)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Constant_15_output_0 for ONNX node: /bert/encoder/layer.0/attention/self/Constant_15_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Concat_3 for ONNX node: /bert/encoder/layer.0/attention/self/Concat_3\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/Concat_3_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/Concat_3_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/self/Concat_3 [Concat] outputs: [/bert/encoder/layer.0/attention/self/Concat_3_output_0 -> (3)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/self/Reshape_3 [Reshape]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Transpose_3_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Concat_3_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/self/Reshape_3 [Reshape] inputs: [/bert/encoder/layer.0/attention/self/Transpose_3_output_0 -> (-1, -1, 8, 32)[FLOAT]], [/bert/encoder/layer.0/attention/self/Concat_3_output_0 -> (3)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/self/Reshape_3 for ONNX node: /bert/encoder/layer.0/attention/self/Reshape_3\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/self/Reshape_3_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/self/Reshape_3_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/self/Reshape_3 [Reshape] outputs: [/bert/encoder/layer.0/attention/self/Reshape_3_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/output/dense/MatMul [MatMul]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/self/Reshape_3_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: onnx::MatMul_803\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/output/dense/MatMul [MatMul] inputs: [/bert/encoder/layer.0/attention/self/Reshape_3_output_0 -> (-1, -1, 256)[FLOAT]], [onnx::MatMul_803 -> (256, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: onnx::MatMul_803 for ONNX node: onnx::MatMul_803\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/output/dense/MatMul for ONNX node: /bert/encoder/layer.0/attention/output/dense/MatMul\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/output/dense/MatMul_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/output/dense/MatMul_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/output/dense/MatMul [MatMul] outputs: [/bert/encoder/layer.0/attention/output/dense/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/output/dense/Add [Add]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: bert.encoder.layer.0.attention.output.dense.bias\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/output/dense/MatMul_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/output/dense/Add [Add] inputs: [bert.encoder.layer.0.attention.output.dense.bias -> (256)[FLOAT]], [/bert/encoder/layer.0/attention/output/dense/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: bert.encoder.layer.0.attention.output.dense.bias for ONNX node: bert.encoder.layer.0.attention.output.dense.bias\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/output/dense/Add for ONNX node: /bert/encoder/layer.0/attention/output/dense/Add\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/output/dense/Add_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/output/dense/Add_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/output/dense/Add [Add] outputs: [/bert/encoder/layer.0/attention/output/dense/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/output/Add [Add]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/output/dense/Add_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/embeddings/LayerNorm/Add_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/output/Add [Add] inputs: [/bert/encoder/layer.0/attention/output/dense/Add_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/embeddings/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/output/Add for ONNX node: /bert/encoder/layer.0/attention/output/Add\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/output/Add_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/output/Add_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/output/Add [Add] outputs: [/bert/encoder/layer.0/attention/output/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/output/LayerNorm/ReduceMean [ReduceMean]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/output/Add_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/output/LayerNorm/ReduceMean [ReduceMean] inputs: [/bert/encoder/layer.0/attention/output/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/output/LayerNorm/ReduceMean for ONNX node: /bert/encoder/layer.0/attention/output/LayerNorm/ReduceMean\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/output/LayerNorm/ReduceMean_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/output/LayerNorm/ReduceMean_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/output/LayerNorm/ReduceMean [ReduceMean] outputs: [/bert/encoder/layer.0/attention/output/LayerNorm/ReduceMean_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/output/LayerNorm/Sub [Sub]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/output/Add_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/output/LayerNorm/ReduceMean_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/output/LayerNorm/Sub [Sub] inputs: [/bert/encoder/layer.0/attention/output/Add_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.0/attention/output/LayerNorm/ReduceMean_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/output/LayerNorm/Sub for ONNX node: /bert/encoder/layer.0/attention/output/LayerNorm/Sub\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/output/LayerNorm/Sub_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/output/LayerNorm/Sub_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/output/LayerNorm/Sub [Sub] outputs: [/bert/encoder/layer.0/attention/output/LayerNorm/Sub_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/output/LayerNorm/Constant [Constant]\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/output/LayerNorm/Constant [Constant] inputs: \n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/output/LayerNorm/Constant [Constant] outputs: [/bert/encoder/layer.0/attention/output/LayerNorm/Constant_output_0 -> ()[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/output/LayerNorm/Pow [Pow]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/output/LayerNorm/Sub_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/output/LayerNorm/Constant_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/output/LayerNorm/Pow [Pow] inputs: [/bert/encoder/layer.0/attention/output/LayerNorm/Sub_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.0/attention/output/LayerNorm/Constant_output_0 -> ()[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/output/LayerNorm/Constant_output_0 for ONNX node: /bert/encoder/layer.0/attention/output/LayerNorm/Constant_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/output/LayerNorm/Pow for ONNX node: /bert/encoder/layer.0/attention/output/LayerNorm/Pow\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/output/LayerNorm/Pow_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/output/LayerNorm/Pow_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/output/LayerNorm/Pow [Pow] outputs: [/bert/encoder/layer.0/attention/output/LayerNorm/Pow_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/output/LayerNorm/ReduceMean_1 [ReduceMean]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/output/LayerNorm/Pow_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/output/LayerNorm/ReduceMean_1 [ReduceMean] inputs: [/bert/encoder/layer.0/attention/output/LayerNorm/Pow_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/output/LayerNorm/ReduceMean_1 for ONNX node: /bert/encoder/layer.0/attention/output/LayerNorm/ReduceMean_1\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/output/LayerNorm/ReduceMean_1_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/output/LayerNorm/ReduceMean_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/output/LayerNorm/ReduceMean_1 [ReduceMean] outputs: [/bert/encoder/layer.0/attention/output/LayerNorm/ReduceMean_1_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/output/LayerNorm/Constant_1 [Constant]\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/output/LayerNorm/Constant_1 [Constant] inputs: \n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/output/LayerNorm/Constant_1 [Constant] outputs: [/bert/encoder/layer.0/attention/output/LayerNorm/Constant_1_output_0 -> ()[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/output/LayerNorm/Add [Add]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/output/LayerNorm/ReduceMean_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/output/LayerNorm/Constant_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/output/LayerNorm/Add [Add] inputs: [/bert/encoder/layer.0/attention/output/LayerNorm/ReduceMean_1_output_0 -> (-1, -1, 1)[FLOAT]], [/bert/encoder/layer.0/attention/output/LayerNorm/Constant_1_output_0 -> ()[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/output/LayerNorm/Constant_1_output_0 for ONNX node: /bert/encoder/layer.0/attention/output/LayerNorm/Constant_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/output/LayerNorm/Add for ONNX node: /bert/encoder/layer.0/attention/output/LayerNorm/Add\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/output/LayerNorm/Add_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/output/LayerNorm/Add_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/output/LayerNorm/Add [Add] outputs: [/bert/encoder/layer.0/attention/output/LayerNorm/Add_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/output/LayerNorm/Sqrt [Sqrt]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/output/LayerNorm/Add_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/output/LayerNorm/Sqrt [Sqrt] inputs: [/bert/encoder/layer.0/attention/output/LayerNorm/Add_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/output/LayerNorm/Sqrt for ONNX node: /bert/encoder/layer.0/attention/output/LayerNorm/Sqrt\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/output/LayerNorm/Sqrt_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/output/LayerNorm/Sqrt_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/output/LayerNorm/Sqrt [Sqrt] outputs: [/bert/encoder/layer.0/attention/output/LayerNorm/Sqrt_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/output/LayerNorm/Div [Div]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/output/LayerNorm/Sub_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/output/LayerNorm/Sqrt_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/output/LayerNorm/Div [Div] inputs: [/bert/encoder/layer.0/attention/output/LayerNorm/Sub_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.0/attention/output/LayerNorm/Sqrt_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/output/LayerNorm/Div for ONNX node: /bert/encoder/layer.0/attention/output/LayerNorm/Div\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/output/LayerNorm/Div_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/output/LayerNorm/Div_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/output/LayerNorm/Div [Div] outputs: [/bert/encoder/layer.0/attention/output/LayerNorm/Div_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/output/LayerNorm/Mul [Mul]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/output/LayerNorm/Div_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: bert.encoder.layer.0.attention.output.LayerNorm.weight\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/output/LayerNorm/Mul [Mul] inputs: [/bert/encoder/layer.0/attention/output/LayerNorm/Div_output_0 -> (-1, -1, 256)[FLOAT]], [bert.encoder.layer.0.attention.output.LayerNorm.weight -> (256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: bert.encoder.layer.0.attention.output.LayerNorm.weight for ONNX node: bert.encoder.layer.0.attention.output.LayerNorm.weight\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/output/LayerNorm/Mul for ONNX node: /bert/encoder/layer.0/attention/output/LayerNorm/Mul\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/output/LayerNorm/Mul_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/output/LayerNorm/Mul_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/output/LayerNorm/Mul [Mul] outputs: [/bert/encoder/layer.0/attention/output/LayerNorm/Mul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.0/attention/output/LayerNorm/Add_1 [Add]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/output/LayerNorm/Mul_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: bert.encoder.layer.0.attention.output.LayerNorm.bias\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/output/LayerNorm/Add_1 [Add] inputs: [/bert/encoder/layer.0/attention/output/LayerNorm/Mul_output_0 -> (-1, -1, 256)[FLOAT]], [bert.encoder.layer.0.attention.output.LayerNorm.bias -> (256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: bert.encoder.layer.0.attention.output.LayerNorm.bias for ONNX node: bert.encoder.layer.0.attention.output.LayerNorm.bias\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.0/attention/output/LayerNorm/Add_1 for ONNX node: /bert/encoder/layer.0/attention/output/LayerNorm/Add_1\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.0/attention/output/LayerNorm/Add_1_output_0 for ONNX tensor: /bert/encoder/layer.0/attention/output/LayerNorm/Add_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/attention/output/LayerNorm/Add_1 [Add] outputs: [/bert/encoder/layer.0/attention/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.0/intermediate/dense/MatMul [MatMul]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/output/LayerNorm/Add_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: onnx::MatMul_804\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/intermediate/dense/MatMul [MatMul] inputs: [/bert/encoder/layer.0/attention/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], [onnx::MatMul_804 -> (256, 1024)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: onnx::MatMul_804 for ONNX node: onnx::MatMul_804\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.0/intermediate/dense/MatMul for ONNX node: /bert/encoder/layer.0/intermediate/dense/MatMul\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.0/intermediate/dense/MatMul_output_0 for ONNX tensor: /bert/encoder/layer.0/intermediate/dense/MatMul_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/intermediate/dense/MatMul [MatMul] outputs: [/bert/encoder/layer.0/intermediate/dense/MatMul_output_0 -> (-1, -1, 1024)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.0/intermediate/dense/Add [Add]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: bert.encoder.layer.0.intermediate.dense.bias\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.0/intermediate/dense/MatMul_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/intermediate/dense/Add [Add] inputs: [bert.encoder.layer.0.intermediate.dense.bias -> (1024)[FLOAT]], [/bert/encoder/layer.0/intermediate/dense/MatMul_output_0 -> (-1, -1, 1024)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: bert.encoder.layer.0.intermediate.dense.bias for ONNX node: bert.encoder.layer.0.intermediate.dense.bias\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.0/intermediate/dense/Add for ONNX node: /bert/encoder/layer.0/intermediate/dense/Add\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.0/intermediate/dense/Add_output_0 for ONNX tensor: /bert/encoder/layer.0/intermediate/dense/Add_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/intermediate/dense/Add [Add] outputs: [/bert/encoder/layer.0/intermediate/dense/Add_output_0 -> (-1, -1, 1024)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.0/intermediate/intermediate_act_fn/Constant [Constant]\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/intermediate/intermediate_act_fn/Constant [Constant] inputs: \n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/intermediate/intermediate_act_fn/Constant [Constant] outputs: [/bert/encoder/layer.0/intermediate/intermediate_act_fn/Constant_output_0 -> ()[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.0/intermediate/intermediate_act_fn/Div [Div]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.0/intermediate/dense/Add_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.0/intermediate/intermediate_act_fn/Constant_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/intermediate/intermediate_act_fn/Div [Div] inputs: [/bert/encoder/layer.0/intermediate/dense/Add_output_0 -> (-1, -1, 1024)[FLOAT]], [/bert/encoder/layer.0/intermediate/intermediate_act_fn/Constant_output_0 -> ()[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.0/intermediate/intermediate_act_fn/Constant_output_0 for ONNX node: /bert/encoder/layer.0/intermediate/intermediate_act_fn/Constant_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.0/intermediate/intermediate_act_fn/Div for ONNX node: /bert/encoder/layer.0/intermediate/intermediate_act_fn/Div\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.0/intermediate/intermediate_act_fn/Div_output_0 for ONNX tensor: /bert/encoder/layer.0/intermediate/intermediate_act_fn/Div_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/intermediate/intermediate_act_fn/Div [Div] outputs: [/bert/encoder/layer.0/intermediate/intermediate_act_fn/Div_output_0 -> (-1, -1, 1024)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.0/intermediate/intermediate_act_fn/Erf [Erf]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.0/intermediate/intermediate_act_fn/Div_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/intermediate/intermediate_act_fn/Erf [Erf] inputs: [/bert/encoder/layer.0/intermediate/intermediate_act_fn/Div_output_0 -> (-1, -1, 1024)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.0/intermediate/intermediate_act_fn/Erf for ONNX node: /bert/encoder/layer.0/intermediate/intermediate_act_fn/Erf\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.0/intermediate/intermediate_act_fn/Erf_output_0 for ONNX tensor: /bert/encoder/layer.0/intermediate/intermediate_act_fn/Erf_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/intermediate/intermediate_act_fn/Erf [Erf] outputs: [/bert/encoder/layer.0/intermediate/intermediate_act_fn/Erf_output_0 -> (-1, -1, 1024)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.0/intermediate/intermediate_act_fn/Constant_1 [Constant]\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/intermediate/intermediate_act_fn/Constant_1 [Constant] inputs: \n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/intermediate/intermediate_act_fn/Constant_1 [Constant] outputs: [/bert/encoder/layer.0/intermediate/intermediate_act_fn/Constant_1_output_0 -> ()[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.0/intermediate/intermediate_act_fn/Add [Add]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.0/intermediate/intermediate_act_fn/Erf_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.0/intermediate/intermediate_act_fn/Constant_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/intermediate/intermediate_act_fn/Add [Add] inputs: [/bert/encoder/layer.0/intermediate/intermediate_act_fn/Erf_output_0 -> (-1, -1, 1024)[FLOAT]], [/bert/encoder/layer.0/intermediate/intermediate_act_fn/Constant_1_output_0 -> ()[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.0/intermediate/intermediate_act_fn/Constant_1_output_0 for ONNX node: /bert/encoder/layer.0/intermediate/intermediate_act_fn/Constant_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.0/intermediate/intermediate_act_fn/Add for ONNX node: /bert/encoder/layer.0/intermediate/intermediate_act_fn/Add\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.0/intermediate/intermediate_act_fn/Add_output_0 for ONNX tensor: /bert/encoder/layer.0/intermediate/intermediate_act_fn/Add_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/intermediate/intermediate_act_fn/Add [Add] outputs: [/bert/encoder/layer.0/intermediate/intermediate_act_fn/Add_output_0 -> (-1, -1, 1024)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.0/intermediate/intermediate_act_fn/Mul [Mul]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.0/intermediate/dense/Add_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.0/intermediate/intermediate_act_fn/Add_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/intermediate/intermediate_act_fn/Mul [Mul] inputs: [/bert/encoder/layer.0/intermediate/dense/Add_output_0 -> (-1, -1, 1024)[FLOAT]], [/bert/encoder/layer.0/intermediate/intermediate_act_fn/Add_output_0 -> (-1, -1, 1024)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.0/intermediate/intermediate_act_fn/Mul for ONNX node: /bert/encoder/layer.0/intermediate/intermediate_act_fn/Mul\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.0/intermediate/intermediate_act_fn/Mul_output_0 for ONNX tensor: /bert/encoder/layer.0/intermediate/intermediate_act_fn/Mul_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/intermediate/intermediate_act_fn/Mul [Mul] outputs: [/bert/encoder/layer.0/intermediate/intermediate_act_fn/Mul_output_0 -> (-1, -1, 1024)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.0/intermediate/intermediate_act_fn/Constant_2 [Constant]\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/intermediate/intermediate_act_fn/Constant_2 [Constant] inputs: \n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/intermediate/intermediate_act_fn/Constant_2 [Constant] outputs: [/bert/encoder/layer.0/intermediate/intermediate_act_fn/Constant_2_output_0 -> ()[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.0/intermediate/intermediate_act_fn/Mul_1 [Mul]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.0/intermediate/intermediate_act_fn/Mul_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.0/intermediate/intermediate_act_fn/Constant_2_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/intermediate/intermediate_act_fn/Mul_1 [Mul] inputs: [/bert/encoder/layer.0/intermediate/intermediate_act_fn/Mul_output_0 -> (-1, -1, 1024)[FLOAT]], [/bert/encoder/layer.0/intermediate/intermediate_act_fn/Constant_2_output_0 -> ()[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.0/intermediate/intermediate_act_fn/Constant_2_output_0 for ONNX node: /bert/encoder/layer.0/intermediate/intermediate_act_fn/Constant_2_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.0/intermediate/intermediate_act_fn/Mul_1 for ONNX node: /bert/encoder/layer.0/intermediate/intermediate_act_fn/Mul_1\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.0/intermediate/intermediate_act_fn/Mul_1_output_0 for ONNX tensor: /bert/encoder/layer.0/intermediate/intermediate_act_fn/Mul_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/intermediate/intermediate_act_fn/Mul_1 [Mul] outputs: [/bert/encoder/layer.0/intermediate/intermediate_act_fn/Mul_1_output_0 -> (-1, -1, 1024)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.0/output/dense/MatMul [MatMul]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.0/intermediate/intermediate_act_fn/Mul_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: onnx::MatMul_805\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/output/dense/MatMul [MatMul] inputs: [/bert/encoder/layer.0/intermediate/intermediate_act_fn/Mul_1_output_0 -> (-1, -1, 1024)[FLOAT]], [onnx::MatMul_805 -> (1024, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: onnx::MatMul_805 for ONNX node: onnx::MatMul_805\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.0/output/dense/MatMul for ONNX node: /bert/encoder/layer.0/output/dense/MatMul\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.0/output/dense/MatMul_output_0 for ONNX tensor: /bert/encoder/layer.0/output/dense/MatMul_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/output/dense/MatMul [MatMul] outputs: [/bert/encoder/layer.0/output/dense/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.0/output/dense/Add [Add]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: bert.encoder.layer.0.output.dense.bias\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.0/output/dense/MatMul_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/output/dense/Add [Add] inputs: [bert.encoder.layer.0.output.dense.bias -> (256)[FLOAT]], [/bert/encoder/layer.0/output/dense/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: bert.encoder.layer.0.output.dense.bias for ONNX node: bert.encoder.layer.0.output.dense.bias\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.0/output/dense/Add for ONNX node: /bert/encoder/layer.0/output/dense/Add\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.0/output/dense/Add_output_0 for ONNX tensor: /bert/encoder/layer.0/output/dense/Add_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/output/dense/Add [Add] outputs: [/bert/encoder/layer.0/output/dense/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.0/output/Add [Add]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.0/output/dense/Add_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.0/attention/output/LayerNorm/Add_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/output/Add [Add] inputs: [/bert/encoder/layer.0/output/dense/Add_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.0/attention/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.0/output/Add for ONNX node: /bert/encoder/layer.0/output/Add\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.0/output/Add_output_0 for ONNX tensor: /bert/encoder/layer.0/output/Add_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/output/Add [Add] outputs: [/bert/encoder/layer.0/output/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.0/output/LayerNorm/ReduceMean [ReduceMean]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.0/output/Add_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/output/LayerNorm/ReduceMean [ReduceMean] inputs: [/bert/encoder/layer.0/output/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.0/output/LayerNorm/ReduceMean for ONNX node: /bert/encoder/layer.0/output/LayerNorm/ReduceMean\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.0/output/LayerNorm/ReduceMean_output_0 for ONNX tensor: /bert/encoder/layer.0/output/LayerNorm/ReduceMean_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/output/LayerNorm/ReduceMean [ReduceMean] outputs: [/bert/encoder/layer.0/output/LayerNorm/ReduceMean_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.0/output/LayerNorm/Sub [Sub]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.0/output/Add_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.0/output/LayerNorm/ReduceMean_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/output/LayerNorm/Sub [Sub] inputs: [/bert/encoder/layer.0/output/Add_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.0/output/LayerNorm/ReduceMean_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.0/output/LayerNorm/Sub for ONNX node: /bert/encoder/layer.0/output/LayerNorm/Sub\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.0/output/LayerNorm/Sub_output_0 for ONNX tensor: /bert/encoder/layer.0/output/LayerNorm/Sub_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/output/LayerNorm/Sub [Sub] outputs: [/bert/encoder/layer.0/output/LayerNorm/Sub_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.0/output/LayerNorm/Constant [Constant]\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/output/LayerNorm/Constant [Constant] inputs: \n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/output/LayerNorm/Constant [Constant] outputs: [/bert/encoder/layer.0/output/LayerNorm/Constant_output_0 -> ()[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.0/output/LayerNorm/Pow [Pow]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.0/output/LayerNorm/Sub_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.0/output/LayerNorm/Constant_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/output/LayerNorm/Pow [Pow] inputs: [/bert/encoder/layer.0/output/LayerNorm/Sub_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.0/output/LayerNorm/Constant_output_0 -> ()[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.0/output/LayerNorm/Constant_output_0 for ONNX node: /bert/encoder/layer.0/output/LayerNorm/Constant_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.0/output/LayerNorm/Pow for ONNX node: /bert/encoder/layer.0/output/LayerNorm/Pow\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.0/output/LayerNorm/Pow_output_0 for ONNX tensor: /bert/encoder/layer.0/output/LayerNorm/Pow_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/output/LayerNorm/Pow [Pow] outputs: [/bert/encoder/layer.0/output/LayerNorm/Pow_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.0/output/LayerNorm/ReduceMean_1 [ReduceMean]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.0/output/LayerNorm/Pow_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/output/LayerNorm/ReduceMean_1 [ReduceMean] inputs: [/bert/encoder/layer.0/output/LayerNorm/Pow_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.0/output/LayerNorm/ReduceMean_1 for ONNX node: /bert/encoder/layer.0/output/LayerNorm/ReduceMean_1\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.0/output/LayerNorm/ReduceMean_1_output_0 for ONNX tensor: /bert/encoder/layer.0/output/LayerNorm/ReduceMean_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/output/LayerNorm/ReduceMean_1 [ReduceMean] outputs: [/bert/encoder/layer.0/output/LayerNorm/ReduceMean_1_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.0/output/LayerNorm/Constant_1 [Constant]\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/output/LayerNorm/Constant_1 [Constant] inputs: \n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/output/LayerNorm/Constant_1 [Constant] outputs: [/bert/encoder/layer.0/output/LayerNorm/Constant_1_output_0 -> ()[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.0/output/LayerNorm/Add [Add]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.0/output/LayerNorm/ReduceMean_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.0/output/LayerNorm/Constant_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/output/LayerNorm/Add [Add] inputs: [/bert/encoder/layer.0/output/LayerNorm/ReduceMean_1_output_0 -> (-1, -1, 1)[FLOAT]], [/bert/encoder/layer.0/output/LayerNorm/Constant_1_output_0 -> ()[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.0/output/LayerNorm/Constant_1_output_0 for ONNX node: /bert/encoder/layer.0/output/LayerNorm/Constant_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.0/output/LayerNorm/Add for ONNX node: /bert/encoder/layer.0/output/LayerNorm/Add\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.0/output/LayerNorm/Add_output_0 for ONNX tensor: /bert/encoder/layer.0/output/LayerNorm/Add_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/output/LayerNorm/Add [Add] outputs: [/bert/encoder/layer.0/output/LayerNorm/Add_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.0/output/LayerNorm/Sqrt [Sqrt]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.0/output/LayerNorm/Add_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/output/LayerNorm/Sqrt [Sqrt] inputs: [/bert/encoder/layer.0/output/LayerNorm/Add_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.0/output/LayerNorm/Sqrt for ONNX node: /bert/encoder/layer.0/output/LayerNorm/Sqrt\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.0/output/LayerNorm/Sqrt_output_0 for ONNX tensor: /bert/encoder/layer.0/output/LayerNorm/Sqrt_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/output/LayerNorm/Sqrt [Sqrt] outputs: [/bert/encoder/layer.0/output/LayerNorm/Sqrt_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.0/output/LayerNorm/Div [Div]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.0/output/LayerNorm/Sub_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.0/output/LayerNorm/Sqrt_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/output/LayerNorm/Div [Div] inputs: [/bert/encoder/layer.0/output/LayerNorm/Sub_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.0/output/LayerNorm/Sqrt_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.0/output/LayerNorm/Div for ONNX node: /bert/encoder/layer.0/output/LayerNorm/Div\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.0/output/LayerNorm/Div_output_0 for ONNX tensor: /bert/encoder/layer.0/output/LayerNorm/Div_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/output/LayerNorm/Div [Div] outputs: [/bert/encoder/layer.0/output/LayerNorm/Div_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.0/output/LayerNorm/Mul [Mul]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.0/output/LayerNorm/Div_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: bert.encoder.layer.0.output.LayerNorm.weight\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/output/LayerNorm/Mul [Mul] inputs: [/bert/encoder/layer.0/output/LayerNorm/Div_output_0 -> (-1, -1, 256)[FLOAT]], [bert.encoder.layer.0.output.LayerNorm.weight -> (256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: bert.encoder.layer.0.output.LayerNorm.weight for ONNX node: bert.encoder.layer.0.output.LayerNorm.weight\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.0/output/LayerNorm/Mul for ONNX node: /bert/encoder/layer.0/output/LayerNorm/Mul\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.0/output/LayerNorm/Mul_output_0 for ONNX tensor: /bert/encoder/layer.0/output/LayerNorm/Mul_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/output/LayerNorm/Mul [Mul] outputs: [/bert/encoder/layer.0/output/LayerNorm/Mul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.0/output/LayerNorm/Add_1 [Add]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.0/output/LayerNorm/Mul_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: bert.encoder.layer.0.output.LayerNorm.bias\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/output/LayerNorm/Add_1 [Add] inputs: [/bert/encoder/layer.0/output/LayerNorm/Mul_output_0 -> (-1, -1, 256)[FLOAT]], [bert.encoder.layer.0.output.LayerNorm.bias -> (256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: bert.encoder.layer.0.output.LayerNorm.bias for ONNX node: bert.encoder.layer.0.output.LayerNorm.bias\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.0/output/LayerNorm/Add_1 for ONNX node: /bert/encoder/layer.0/output/LayerNorm/Add_1\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.0/output/LayerNorm/Add_1_output_0 for ONNX tensor: /bert/encoder/layer.0/output/LayerNorm/Add_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.0/output/LayerNorm/Add_1 [Add] outputs: [/bert/encoder/layer.0/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/query/MatMul [MatMul]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.0/output/LayerNorm/Add_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: onnx::MatMul_806\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/self/query/MatMul [MatMul] inputs: [/bert/encoder/layer.0/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], [onnx::MatMul_806 -> (256, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: onnx::MatMul_806 for ONNX node: onnx::MatMul_806\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/query/MatMul for ONNX node: /bert/encoder/layer.1/attention/self/query/MatMul\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/query/MatMul_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/query/MatMul_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/self/query/MatMul [MatMul] outputs: [/bert/encoder/layer.1/attention/self/query/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/query/Add [Add]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: bert.encoder.layer.1.attention.self.query.bias\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/query/MatMul_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/self/query/Add [Add] inputs: [bert.encoder.layer.1.attention.self.query.bias -> (256)[FLOAT]], [/bert/encoder/layer.1/attention/self/query/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: bert.encoder.layer.1.attention.self.query.bias for ONNX node: bert.encoder.layer.1.attention.self.query.bias\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/query/Add for ONNX node: /bert/encoder/layer.1/attention/self/query/Add\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/query/Add_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/query/Add_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/self/query/Add [Add] outputs: [/bert/encoder/layer.1/attention/self/query/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/key/MatMul [MatMul]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.0/output/LayerNorm/Add_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: onnx::MatMul_807\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/self/key/MatMul [MatMul] inputs: [/bert/encoder/layer.0/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], [onnx::MatMul_807 -> (256, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: onnx::MatMul_807 for ONNX node: onnx::MatMul_807\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/key/MatMul for ONNX node: /bert/encoder/layer.1/attention/self/key/MatMul\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/key/MatMul_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/key/MatMul_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/self/key/MatMul [MatMul] outputs: [/bert/encoder/layer.1/attention/self/key/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/key/Add [Add]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: bert.encoder.layer.1.attention.self.key.bias\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/key/MatMul_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/self/key/Add [Add] inputs: [bert.encoder.layer.1.attention.self.key.bias -> (256)[FLOAT]], [/bert/encoder/layer.1/attention/self/key/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: bert.encoder.layer.1.attention.self.key.bias for ONNX node: bert.encoder.layer.1.attention.self.key.bias\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/key/Add for ONNX node: /bert/encoder/layer.1/attention/self/key/Add\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/key/Add_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/key/Add_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/self/key/Add [Add] outputs: [/bert/encoder/layer.1/attention/self/key/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Shape [Shape]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/key/Add_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/self/Shape [Shape] inputs: [/bert/encoder/layer.1/attention/self/key/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Shape for ONNX node: /bert/encoder/layer.1/attention/self/Shape\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/Shape_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/Shape_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/self/Shape [Shape] outputs: [/bert/encoder/layer.1/attention/self/Shape_output_0 -> (3)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Constant [Constant]\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/self/Constant [Constant] inputs: \n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/self/Constant [Constant] outputs: [/bert/encoder/layer.1/attention/self/Constant_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Gather [Gather]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Shape_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Constant_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/self/Gather [Gather] inputs: [/bert/encoder/layer.1/attention/self/Shape_output_0 -> (3)[INT32]], [/bert/encoder/layer.1/attention/self/Constant_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Constant_output_0 for ONNX node: /bert/encoder/layer.1/attention/self/Constant_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Using Gather axis: 0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Gather for ONNX node: /bert/encoder/layer.1/attention/self/Gather\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/Gather_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/Gather_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/self/Gather [Gather] outputs: [/bert/encoder/layer.1/attention/self/Gather_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Shape_1 [Shape]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/key/Add_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/self/Shape_1 [Shape] inputs: [/bert/encoder/layer.1/attention/self/key/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Shape_1 for ONNX node: /bert/encoder/layer.1/attention/self/Shape_1\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/Shape_1_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/Shape_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/self/Shape_1 [Shape] outputs: [/bert/encoder/layer.1/attention/self/Shape_1_output_0 -> (3)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Constant_1 [Constant]\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/self/Constant_1 [Constant] inputs: \n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/self/Constant_1 [Constant] outputs: [/bert/encoder/layer.1/attention/self/Constant_1_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Gather_1 [Gather]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Shape_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Constant_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/self/Gather_1 [Gather] inputs: [/bert/encoder/layer.1/attention/self/Shape_1_output_0 -> (3)[INT32]], [/bert/encoder/layer.1/attention/self/Constant_1_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Constant_1_output_0 for ONNX node: /bert/encoder/layer.1/attention/self/Constant_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Using Gather axis: 0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Gather_1 for ONNX node: /bert/encoder/layer.1/attention/self/Gather_1\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/Gather_1_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/Gather_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/self/Gather_1 [Gather] outputs: [/bert/encoder/layer.1/attention/self/Gather_1_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Unsqueeze [Unsqueeze]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Gather_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/self/Unsqueeze [Unsqueeze] inputs: [/bert/encoder/layer.1/attention/self/Gather_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Unsqueeze for ONNX node: /bert/encoder/layer.1/attention/self/Unsqueeze\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/Unsqueeze_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/Unsqueeze_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/self/Unsqueeze [Unsqueeze] outputs: [/bert/encoder/layer.1/attention/self/Unsqueeze_output_0 -> (1)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Unsqueeze_1 [Unsqueeze]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Gather_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/self/Unsqueeze_1 [Unsqueeze] inputs: [/bert/encoder/layer.1/attention/self/Gather_1_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Unsqueeze_1 for ONNX node: /bert/encoder/layer.1/attention/self/Unsqueeze_1\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/Unsqueeze_1_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/Unsqueeze_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/self/Unsqueeze_1 [Unsqueeze] outputs: [/bert/encoder/layer.1/attention/self/Unsqueeze_1_output_0 -> (1)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Constant_2 [Constant]\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/self/Constant_2 [Constant] inputs: \n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/self/Constant_2 [Constant] outputs: [/bert/encoder/layer.1/attention/self/Constant_2_output_0 -> (1)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Constant_3 [Constant]\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/self/Constant_3 [Constant] inputs: \n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/self/Constant_3 [Constant] outputs: [/bert/encoder/layer.1/attention/self/Constant_3_output_0 -> (1)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Concat [Concat]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Unsqueeze_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Unsqueeze_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Constant_2_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Constant_3_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/self/Concat [Concat] inputs: [/bert/encoder/layer.1/attention/self/Unsqueeze_output_0 -> (1)[INT32]], [/bert/encoder/layer.1/attention/self/Unsqueeze_1_output_0 -> (1)[INT32]], [/bert/encoder/layer.1/attention/self/Constant_2_output_0 -> (1)[INT32]], [/bert/encoder/layer.1/attention/self/Constant_3_output_0 -> (1)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Constant_2_output_0 for ONNX node: /bert/encoder/layer.1/attention/self/Constant_2_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Constant_3_output_0 for ONNX node: /bert/encoder/layer.1/attention/self/Constant_3_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Concat for ONNX node: /bert/encoder/layer.1/attention/self/Concat\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/Concat_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/Concat_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/self/Concat [Concat] outputs: [/bert/encoder/layer.1/attention/self/Concat_output_0 -> (4)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Reshape [Reshape]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/key/Add_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Concat_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/self/Reshape [Reshape] inputs: [/bert/encoder/layer.1/attention/self/key/Add_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.1/attention/self/Concat_output_0 -> (4)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Reshape for ONNX node: /bert/encoder/layer.1/attention/self/Reshape\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/Reshape_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/Reshape_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/self/Reshape [Reshape] outputs: [/bert/encoder/layer.1/attention/self/Reshape_output_0 -> (-1, -1, 8, 32)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/value/MatMul [MatMul]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.0/output/LayerNorm/Add_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: onnx::MatMul_810\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/self/value/MatMul [MatMul] inputs: [/bert/encoder/layer.0/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], [onnx::MatMul_810 -> (256, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: onnx::MatMul_810 for ONNX node: onnx::MatMul_810\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/value/MatMul for ONNX node: /bert/encoder/layer.1/attention/self/value/MatMul\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/value/MatMul_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/value/MatMul_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/self/value/MatMul [MatMul] outputs: [/bert/encoder/layer.1/attention/self/value/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/value/Add [Add]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: bert.encoder.layer.1.attention.self.value.bias\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/value/MatMul_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/self/value/Add [Add] inputs: [bert.encoder.layer.1.attention.self.value.bias -> (256)[FLOAT]], [/bert/encoder/layer.1/attention/self/value/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: bert.encoder.layer.1.attention.self.value.bias for ONNX node: bert.encoder.layer.1.attention.self.value.bias\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/value/Add for ONNX node: /bert/encoder/layer.1/attention/self/value/Add\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/value/Add_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/value/Add_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/self/value/Add [Add] outputs: [/bert/encoder/layer.1/attention/self/value/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Shape_2 [Shape]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/value/Add_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/self/Shape_2 [Shape] inputs: [/bert/encoder/layer.1/attention/self/value/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Shape_2 for ONNX node: /bert/encoder/layer.1/attention/self/Shape_2\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/Shape_2_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/Shape_2_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/self/Shape_2 [Shape] outputs: [/bert/encoder/layer.1/attention/self/Shape_2_output_0 -> (3)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Constant_4 [Constant]\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/self/Constant_4 [Constant] inputs: \n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/self/Constant_4 [Constant] outputs: [/bert/encoder/layer.1/attention/self/Constant_4_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Gather_2 [Gather]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Shape_2_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Constant_4_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/self/Gather_2 [Gather] inputs: [/bert/encoder/layer.1/attention/self/Shape_2_output_0 -> (3)[INT32]], [/bert/encoder/layer.1/attention/self/Constant_4_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Constant_4_output_0 for ONNX node: /bert/encoder/layer.1/attention/self/Constant_4_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Using Gather axis: 0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Gather_2 for ONNX node: /bert/encoder/layer.1/attention/self/Gather_2\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/Gather_2_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/Gather_2_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/self/Gather_2 [Gather] outputs: [/bert/encoder/layer.1/attention/self/Gather_2_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Shape_3 [Shape]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/value/Add_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/self/Shape_3 [Shape] inputs: [/bert/encoder/layer.1/attention/self/value/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Shape_3 for ONNX node: /bert/encoder/layer.1/attention/self/Shape_3\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/Shape_3_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/Shape_3_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/self/Shape_3 [Shape] outputs: [/bert/encoder/layer.1/attention/self/Shape_3_output_0 -> (3)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Constant_5 [Constant]\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/self/Constant_5 [Constant] inputs: \n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/self/Constant_5 [Constant] outputs: [/bert/encoder/layer.1/attention/self/Constant_5_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Gather_3 [Gather]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Shape_3_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Constant_5_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/self/Gather_3 [Gather] inputs: [/bert/encoder/layer.1/attention/self/Shape_3_output_0 -> (3)[INT32]], [/bert/encoder/layer.1/attention/self/Constant_5_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Constant_5_output_0 for ONNX node: /bert/encoder/layer.1/attention/self/Constant_5_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Using Gather axis: 0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Gather_3 for ONNX node: /bert/encoder/layer.1/attention/self/Gather_3\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/Gather_3_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/Gather_3_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/self/Gather_3 [Gather] outputs: [/bert/encoder/layer.1/attention/self/Gather_3_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Unsqueeze_2 [Unsqueeze]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Gather_2_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/self/Unsqueeze_2 [Unsqueeze] inputs: [/bert/encoder/layer.1/attention/self/Gather_2_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Unsqueeze_2 for ONNX node: /bert/encoder/layer.1/attention/self/Unsqueeze_2\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/Unsqueeze_2_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/Unsqueeze_2_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/self/Unsqueeze_2 [Unsqueeze] outputs: [/bert/encoder/layer.1/attention/self/Unsqueeze_2_output_0 -> (1)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Unsqueeze_3 [Unsqueeze]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Gather_3_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/self/Unsqueeze_3 [Unsqueeze] inputs: [/bert/encoder/layer.1/attention/self/Gather_3_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Unsqueeze_3 for ONNX node: /bert/encoder/layer.1/attention/self/Unsqueeze_3\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/Unsqueeze_3_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/Unsqueeze_3_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/self/Unsqueeze_3 [Unsqueeze] outputs: [/bert/encoder/layer.1/attention/self/Unsqueeze_3_output_0 -> (1)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Constant_6 [Constant]\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/self/Constant_6 [Constant] inputs: \n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/self/Constant_6 [Constant] outputs: [/bert/encoder/layer.1/attention/self/Constant_6_output_0 -> (1)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Constant_7 [Constant]\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/self/Constant_7 [Constant] inputs: \n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/self/Constant_7 [Constant] outputs: [/bert/encoder/layer.1/attention/self/Constant_7_output_0 -> (1)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Concat_1 [Concat]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Unsqueeze_2_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Unsqueeze_3_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Constant_6_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Constant_7_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/self/Concat_1 [Concat] inputs: [/bert/encoder/layer.1/attention/self/Unsqueeze_2_output_0 -> (1)[INT32]], [/bert/encoder/layer.1/attention/self/Unsqueeze_3_output_0 -> (1)[INT32]], [/bert/encoder/layer.1/attention/self/Constant_6_output_0 -> (1)[INT32]], [/bert/encoder/layer.1/attention/self/Constant_7_output_0 -> (1)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Constant_6_output_0 for ONNX node: /bert/encoder/layer.1/attention/self/Constant_6_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Constant_7_output_0 for ONNX node: /bert/encoder/layer.1/attention/self/Constant_7_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Concat_1 for ONNX node: /bert/encoder/layer.1/attention/self/Concat_1\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/Concat_1_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/Concat_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/self/Concat_1 [Concat] outputs: [/bert/encoder/layer.1/attention/self/Concat_1_output_0 -> (4)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Reshape_1 [Reshape]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/value/Add_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Concat_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/self/Reshape_1 [Reshape] inputs: [/bert/encoder/layer.1/attention/self/value/Add_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.1/attention/self/Concat_1_output_0 -> (4)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Reshape_1 for ONNX node: /bert/encoder/layer.1/attention/self/Reshape_1\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/Reshape_1_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/Reshape_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/self/Reshape_1 [Reshape] outputs: [/bert/encoder/layer.1/attention/self/Reshape_1_output_0 -> (-1, -1, 8, 32)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Transpose [Transpose]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Reshape_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/self/Transpose [Transpose] inputs: [/bert/encoder/layer.1/attention/self/Reshape_1_output_0 -> (-1, -1, 8, 32)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Transpose for ONNX node: /bert/encoder/layer.1/attention/self/Transpose\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/Transpose_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/Transpose_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/self/Transpose [Transpose] outputs: [/bert/encoder/layer.1/attention/self/Transpose_output_0 -> (-1, 8, -1, 32)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Shape_4 [Shape]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/query/Add_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/self/Shape_4 [Shape] inputs: [/bert/encoder/layer.1/attention/self/query/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Shape_4 for ONNX node: /bert/encoder/layer.1/attention/self/Shape_4\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/Shape_4_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/Shape_4_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/self/Shape_4 [Shape] outputs: [/bert/encoder/layer.1/attention/self/Shape_4_output_0 -> (3)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Constant_8 [Constant]\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/self/Constant_8 [Constant] inputs: \n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/self/Constant_8 [Constant] outputs: [/bert/encoder/layer.1/attention/self/Constant_8_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Gather_4 [Gather]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Shape_4_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Constant_8_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/self/Gather_4 [Gather] inputs: [/bert/encoder/layer.1/attention/self/Shape_4_output_0 -> (3)[INT32]], [/bert/encoder/layer.1/attention/self/Constant_8_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Constant_8_output_0 for ONNX node: /bert/encoder/layer.1/attention/self/Constant_8_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Using Gather axis: 0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Gather_4 for ONNX node: /bert/encoder/layer.1/attention/self/Gather_4\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/Gather_4_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/Gather_4_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/self/Gather_4 [Gather] outputs: [/bert/encoder/layer.1/attention/self/Gather_4_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Shape_5 [Shape]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/query/Add_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/self/Shape_5 [Shape] inputs: [/bert/encoder/layer.1/attention/self/query/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Shape_5 for ONNX node: /bert/encoder/layer.1/attention/self/Shape_5\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/Shape_5_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/Shape_5_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/self/Shape_5 [Shape] outputs: [/bert/encoder/layer.1/attention/self/Shape_5_output_0 -> (3)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Constant_9 [Constant]\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/self/Constant_9 [Constant] inputs: \n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/self/Constant_9 [Constant] outputs: [/bert/encoder/layer.1/attention/self/Constant_9_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Gather_5 [Gather]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Shape_5_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Constant_9_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/self/Gather_5 [Gather] inputs: [/bert/encoder/layer.1/attention/self/Shape_5_output_0 -> (3)[INT32]], [/bert/encoder/layer.1/attention/self/Constant_9_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Constant_9_output_0 for ONNX node: /bert/encoder/layer.1/attention/self/Constant_9_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Using Gather axis: 0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Gather_5 for ONNX node: /bert/encoder/layer.1/attention/self/Gather_5\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/Gather_5_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/Gather_5_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/self/Gather_5 [Gather] outputs: [/bert/encoder/layer.1/attention/self/Gather_5_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Unsqueeze_4 [Unsqueeze]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Gather_4_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/self/Unsqueeze_4 [Unsqueeze] inputs: [/bert/encoder/layer.1/attention/self/Gather_4_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Unsqueeze_4 for ONNX node: /bert/encoder/layer.1/attention/self/Unsqueeze_4\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/Unsqueeze_4_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/Unsqueeze_4_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/self/Unsqueeze_4 [Unsqueeze] outputs: [/bert/encoder/layer.1/attention/self/Unsqueeze_4_output_0 -> (1)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Unsqueeze_5 [Unsqueeze]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Gather_5_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/self/Unsqueeze_5 [Unsqueeze] inputs: [/bert/encoder/layer.1/attention/self/Gather_5_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Unsqueeze_5 for ONNX node: /bert/encoder/layer.1/attention/self/Unsqueeze_5\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/Unsqueeze_5_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/Unsqueeze_5_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/self/Unsqueeze_5 [Unsqueeze] outputs: [/bert/encoder/layer.1/attention/self/Unsqueeze_5_output_0 -> (1)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Constant_10 [Constant]\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/self/Constant_10 [Constant] inputs: \n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/self/Constant_10 [Constant] outputs: [/bert/encoder/layer.1/attention/self/Constant_10_output_0 -> (1)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Constant_11 [Constant]\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/self/Constant_11 [Constant] inputs: \n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/self/Constant_11 [Constant] outputs: [/bert/encoder/layer.1/attention/self/Constant_11_output_0 -> (1)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Concat_2 [Concat]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Unsqueeze_4_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Unsqueeze_5_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Constant_10_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Constant_11_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/self/Concat_2 [Concat] inputs: [/bert/encoder/layer.1/attention/self/Unsqueeze_4_output_0 -> (1)[INT32]], [/bert/encoder/layer.1/attention/self/Unsqueeze_5_output_0 -> (1)[INT32]], [/bert/encoder/layer.1/attention/self/Constant_10_output_0 -> (1)[INT32]], [/bert/encoder/layer.1/attention/self/Constant_11_output_0 -> (1)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Constant_10_output_0 for ONNX node: /bert/encoder/layer.1/attention/self/Constant_10_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Constant_11_output_0 for ONNX node: /bert/encoder/layer.1/attention/self/Constant_11_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Concat_2 for ONNX node: /bert/encoder/layer.1/attention/self/Concat_2\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/Concat_2_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/Concat_2_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/self/Concat_2 [Concat] outputs: [/bert/encoder/layer.1/attention/self/Concat_2_output_0 -> (4)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Reshape_2 [Reshape]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/query/Add_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Concat_2_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/self/Reshape_2 [Reshape] inputs: [/bert/encoder/layer.1/attention/self/query/Add_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.1/attention/self/Concat_2_output_0 -> (4)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Reshape_2 for ONNX node: /bert/encoder/layer.1/attention/self/Reshape_2\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/Reshape_2_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/Reshape_2_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/self/Reshape_2 [Reshape] outputs: [/bert/encoder/layer.1/attention/self/Reshape_2_output_0 -> (-1, -1, 8, 32)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Transpose_1 [Transpose]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Reshape_2_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/self/Transpose_1 [Transpose] inputs: [/bert/encoder/layer.1/attention/self/Reshape_2_output_0 -> (-1, -1, 8, 32)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Transpose_1 for ONNX node: /bert/encoder/layer.1/attention/self/Transpose_1\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/Transpose_1_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/Transpose_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/self/Transpose_1 [Transpose] outputs: [/bert/encoder/layer.1/attention/self/Transpose_1_output_0 -> (-1, 8, -1, 32)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Transpose_2 [Transpose]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Reshape_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/self/Transpose_2 [Transpose] inputs: [/bert/encoder/layer.1/attention/self/Reshape_output_0 -> (-1, -1, 8, 32)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Transpose_2 for ONNX node: /bert/encoder/layer.1/attention/self/Transpose_2\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/Transpose_2_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/Transpose_2_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/self/Transpose_2 [Transpose] outputs: [/bert/encoder/layer.1/attention/self/Transpose_2_output_0 -> (-1, 8, 32, -1)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/MatMul [MatMul]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Transpose_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Transpose_2_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/self/MatMul [MatMul] inputs: [/bert/encoder/layer.1/attention/self/Transpose_1_output_0 -> (-1, 8, -1, 32)[FLOAT]], [/bert/encoder/layer.1/attention/self/Transpose_2_output_0 -> (-1, 8, 32, -1)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/MatMul for ONNX node: /bert/encoder/layer.1/attention/self/MatMul\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/MatMul_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/MatMul_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/self/MatMul [MatMul] outputs: [/bert/encoder/layer.1/attention/self/MatMul_output_0 -> (-1, 8, -1, -1)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Constant_12 [Constant]\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/self/Constant_12 [Constant] inputs: \n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/self/Constant_12 [Constant] outputs: [/bert/encoder/layer.1/attention/self/Constant_12_output_0 -> ()[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Div [Div]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/MatMul_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Constant_12_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/self/Div [Div] inputs: [/bert/encoder/layer.1/attention/self/MatMul_output_0 -> (-1, 8, -1, -1)[FLOAT]], [/bert/encoder/layer.1/attention/self/Constant_12_output_0 -> ()[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Constant_12_output_0 for ONNX node: /bert/encoder/layer.1/attention/self/Constant_12_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Div for ONNX node: /bert/encoder/layer.1/attention/self/Div\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/Div_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/Div_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/self/Div [Div] outputs: [/bert/encoder/layer.1/attention/self/Div_output_0 -> (-1, 8, -1, -1)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Add [Add]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Div_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/Mul_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/self/Add [Add] inputs: [/bert/encoder/layer.1/attention/self/Div_output_0 -> (-1, 8, -1, -1)[FLOAT]], [/bert/Mul_output_0 -> (-1, 1, 1, -1)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Add for ONNX node: /bert/encoder/layer.1/attention/self/Add\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/Add_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/Add_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/self/Add [Add] outputs: [/bert/encoder/layer.1/attention/self/Add_output_0 -> (-1, 8, -1, -1)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Softmax [Softmax]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Add_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/self/Softmax [Softmax] inputs: [/bert/encoder/layer.1/attention/self/Add_output_0 -> (-1, 8, -1, -1)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Softmax for ONNX node: /bert/encoder/layer.1/attention/self/Softmax\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/Softmax_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/Softmax_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/self/Softmax [Softmax] outputs: [/bert/encoder/layer.1/attention/self/Softmax_output_0 -> (-1, 8, -1, -1)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/MatMul_1 [MatMul]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Softmax_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Transpose_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/self/MatMul_1 [MatMul] inputs: [/bert/encoder/layer.1/attention/self/Softmax_output_0 -> (-1, 8, -1, -1)[FLOAT]], [/bert/encoder/layer.1/attention/self/Transpose_output_0 -> (-1, 8, -1, 32)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/MatMul_1 for ONNX node: /bert/encoder/layer.1/attention/self/MatMul_1\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/MatMul_1_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/MatMul_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/self/MatMul_1 [MatMul] outputs: [/bert/encoder/layer.1/attention/self/MatMul_1_output_0 -> (-1, 8, -1, 32)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Transpose_3 [Transpose]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/MatMul_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/self/Transpose_3 [Transpose] inputs: [/bert/encoder/layer.1/attention/self/MatMul_1_output_0 -> (-1, 8, -1, 32)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Transpose_3 for ONNX node: /bert/encoder/layer.1/attention/self/Transpose_3\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/Transpose_3_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/Transpose_3_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/self/Transpose_3 [Transpose] outputs: [/bert/encoder/layer.1/attention/self/Transpose_3_output_0 -> (-1, -1, 8, 32)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Shape_6 [Shape]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Transpose_3_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/self/Shape_6 [Shape] inputs: [/bert/encoder/layer.1/attention/self/Transpose_3_output_0 -> (-1, -1, 8, 32)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Shape_6 for ONNX node: /bert/encoder/layer.1/attention/self/Shape_6\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/Shape_6_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/Shape_6_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/self/Shape_6 [Shape] outputs: [/bert/encoder/layer.1/attention/self/Shape_6_output_0 -> (4)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Constant_13 [Constant]\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/self/Constant_13 [Constant] inputs: \n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/self/Constant_13 [Constant] outputs: [/bert/encoder/layer.1/attention/self/Constant_13_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Gather_6 [Gather]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Shape_6_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Constant_13_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/self/Gather_6 [Gather] inputs: [/bert/encoder/layer.1/attention/self/Shape_6_output_0 -> (4)[INT32]], [/bert/encoder/layer.1/attention/self/Constant_13_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Constant_13_output_0 for ONNX node: /bert/encoder/layer.1/attention/self/Constant_13_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Using Gather axis: 0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Gather_6 for ONNX node: /bert/encoder/layer.1/attention/self/Gather_6\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/Gather_6_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/Gather_6_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/self/Gather_6 [Gather] outputs: [/bert/encoder/layer.1/attention/self/Gather_6_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Shape_7 [Shape]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Transpose_3_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/self/Shape_7 [Shape] inputs: [/bert/encoder/layer.1/attention/self/Transpose_3_output_0 -> (-1, -1, 8, 32)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Shape_7 for ONNX node: /bert/encoder/layer.1/attention/self/Shape_7\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/Shape_7_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/Shape_7_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/self/Shape_7 [Shape] outputs: [/bert/encoder/layer.1/attention/self/Shape_7_output_0 -> (4)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Constant_14 [Constant]\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/self/Constant_14 [Constant] inputs: \n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/self/Constant_14 [Constant] outputs: [/bert/encoder/layer.1/attention/self/Constant_14_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Gather_7 [Gather]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Shape_7_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Constant_14_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/self/Gather_7 [Gather] inputs: [/bert/encoder/layer.1/attention/self/Shape_7_output_0 -> (4)[INT32]], [/bert/encoder/layer.1/attention/self/Constant_14_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Constant_14_output_0 for ONNX node: /bert/encoder/layer.1/attention/self/Constant_14_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Using Gather axis: 0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Gather_7 for ONNX node: /bert/encoder/layer.1/attention/self/Gather_7\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/Gather_7_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/Gather_7_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/self/Gather_7 [Gather] outputs: [/bert/encoder/layer.1/attention/self/Gather_7_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Unsqueeze_6 [Unsqueeze]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Gather_6_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/self/Unsqueeze_6 [Unsqueeze] inputs: [/bert/encoder/layer.1/attention/self/Gather_6_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Unsqueeze_6 for ONNX node: /bert/encoder/layer.1/attention/self/Unsqueeze_6\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/Unsqueeze_6_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/Unsqueeze_6_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/self/Unsqueeze_6 [Unsqueeze] outputs: [/bert/encoder/layer.1/attention/self/Unsqueeze_6_output_0 -> (1)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Unsqueeze_7 [Unsqueeze]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Gather_7_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/self/Unsqueeze_7 [Unsqueeze] inputs: [/bert/encoder/layer.1/attention/self/Gather_7_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Unsqueeze_7 for ONNX node: /bert/encoder/layer.1/attention/self/Unsqueeze_7\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/Unsqueeze_7_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/Unsqueeze_7_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/self/Unsqueeze_7 [Unsqueeze] outputs: [/bert/encoder/layer.1/attention/self/Unsqueeze_7_output_0 -> (1)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Constant_15 [Constant]\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/self/Constant_15 [Constant] inputs: \n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/self/Constant_15 [Constant] outputs: [/bert/encoder/layer.1/attention/self/Constant_15_output_0 -> (1)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Concat_3 [Concat]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Unsqueeze_6_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Unsqueeze_7_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Constant_15_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/self/Concat_3 [Concat] inputs: [/bert/encoder/layer.1/attention/self/Unsqueeze_6_output_0 -> (1)[INT32]], [/bert/encoder/layer.1/attention/self/Unsqueeze_7_output_0 -> (1)[INT32]], [/bert/encoder/layer.1/attention/self/Constant_15_output_0 -> (1)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Constant_15_output_0 for ONNX node: /bert/encoder/layer.1/attention/self/Constant_15_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Concat_3 for ONNX node: /bert/encoder/layer.1/attention/self/Concat_3\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/Concat_3_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/Concat_3_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/self/Concat_3 [Concat] outputs: [/bert/encoder/layer.1/attention/self/Concat_3_output_0 -> (3)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/self/Reshape_3 [Reshape]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Transpose_3_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Concat_3_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/self/Reshape_3 [Reshape] inputs: [/bert/encoder/layer.1/attention/self/Transpose_3_output_0 -> (-1, -1, 8, 32)[FLOAT]], [/bert/encoder/layer.1/attention/self/Concat_3_output_0 -> (3)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/self/Reshape_3 for ONNX node: /bert/encoder/layer.1/attention/self/Reshape_3\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/self/Reshape_3_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/self/Reshape_3_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/self/Reshape_3 [Reshape] outputs: [/bert/encoder/layer.1/attention/self/Reshape_3_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/output/dense/MatMul [MatMul]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/self/Reshape_3_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: onnx::MatMul_816\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/output/dense/MatMul [MatMul] inputs: [/bert/encoder/layer.1/attention/self/Reshape_3_output_0 -> (-1, -1, 256)[FLOAT]], [onnx::MatMul_816 -> (256, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: onnx::MatMul_816 for ONNX node: onnx::MatMul_816\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/output/dense/MatMul for ONNX node: /bert/encoder/layer.1/attention/output/dense/MatMul\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/output/dense/MatMul_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/output/dense/MatMul_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/output/dense/MatMul [MatMul] outputs: [/bert/encoder/layer.1/attention/output/dense/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/output/dense/Add [Add]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: bert.encoder.layer.1.attention.output.dense.bias\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/output/dense/MatMul_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/output/dense/Add [Add] inputs: [bert.encoder.layer.1.attention.output.dense.bias -> (256)[FLOAT]], [/bert/encoder/layer.1/attention/output/dense/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: bert.encoder.layer.1.attention.output.dense.bias for ONNX node: bert.encoder.layer.1.attention.output.dense.bias\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/output/dense/Add for ONNX node: /bert/encoder/layer.1/attention/output/dense/Add\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/output/dense/Add_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/output/dense/Add_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/output/dense/Add [Add] outputs: [/bert/encoder/layer.1/attention/output/dense/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/output/Add [Add]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/output/dense/Add_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.0/output/LayerNorm/Add_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/output/Add [Add] inputs: [/bert/encoder/layer.1/attention/output/dense/Add_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.0/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/output/Add for ONNX node: /bert/encoder/layer.1/attention/output/Add\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/output/Add_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/output/Add_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/output/Add [Add] outputs: [/bert/encoder/layer.1/attention/output/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/output/LayerNorm/ReduceMean [ReduceMean]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/output/Add_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/output/LayerNorm/ReduceMean [ReduceMean] inputs: [/bert/encoder/layer.1/attention/output/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/output/LayerNorm/ReduceMean for ONNX node: /bert/encoder/layer.1/attention/output/LayerNorm/ReduceMean\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/output/LayerNorm/ReduceMean_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/output/LayerNorm/ReduceMean_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/output/LayerNorm/ReduceMean [ReduceMean] outputs: [/bert/encoder/layer.1/attention/output/LayerNorm/ReduceMean_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/output/LayerNorm/Sub [Sub]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/output/Add_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/output/LayerNorm/ReduceMean_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/output/LayerNorm/Sub [Sub] inputs: [/bert/encoder/layer.1/attention/output/Add_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.1/attention/output/LayerNorm/ReduceMean_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/output/LayerNorm/Sub for ONNX node: /bert/encoder/layer.1/attention/output/LayerNorm/Sub\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/output/LayerNorm/Sub_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/output/LayerNorm/Sub_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/output/LayerNorm/Sub [Sub] outputs: [/bert/encoder/layer.1/attention/output/LayerNorm/Sub_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/output/LayerNorm/Constant [Constant]\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/output/LayerNorm/Constant [Constant] inputs: \n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/output/LayerNorm/Constant [Constant] outputs: [/bert/encoder/layer.1/attention/output/LayerNorm/Constant_output_0 -> ()[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/output/LayerNorm/Pow [Pow]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/output/LayerNorm/Sub_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/output/LayerNorm/Constant_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/output/LayerNorm/Pow [Pow] inputs: [/bert/encoder/layer.1/attention/output/LayerNorm/Sub_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.1/attention/output/LayerNorm/Constant_output_0 -> ()[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/output/LayerNorm/Constant_output_0 for ONNX node: /bert/encoder/layer.1/attention/output/LayerNorm/Constant_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/output/LayerNorm/Pow for ONNX node: /bert/encoder/layer.1/attention/output/LayerNorm/Pow\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/output/LayerNorm/Pow_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/output/LayerNorm/Pow_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/output/LayerNorm/Pow [Pow] outputs: [/bert/encoder/layer.1/attention/output/LayerNorm/Pow_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/output/LayerNorm/ReduceMean_1 [ReduceMean]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/output/LayerNorm/Pow_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/output/LayerNorm/ReduceMean_1 [ReduceMean] inputs: [/bert/encoder/layer.1/attention/output/LayerNorm/Pow_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/output/LayerNorm/ReduceMean_1 for ONNX node: /bert/encoder/layer.1/attention/output/LayerNorm/ReduceMean_1\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/output/LayerNorm/ReduceMean_1_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/output/LayerNorm/ReduceMean_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/output/LayerNorm/ReduceMean_1 [ReduceMean] outputs: [/bert/encoder/layer.1/attention/output/LayerNorm/ReduceMean_1_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/output/LayerNorm/Constant_1 [Constant]\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/output/LayerNorm/Constant_1 [Constant] inputs: \n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/output/LayerNorm/Constant_1 [Constant] outputs: [/bert/encoder/layer.1/attention/output/LayerNorm/Constant_1_output_0 -> ()[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/output/LayerNorm/Add [Add]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/output/LayerNorm/ReduceMean_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/output/LayerNorm/Constant_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/output/LayerNorm/Add [Add] inputs: [/bert/encoder/layer.1/attention/output/LayerNorm/ReduceMean_1_output_0 -> (-1, -1, 1)[FLOAT]], [/bert/encoder/layer.1/attention/output/LayerNorm/Constant_1_output_0 -> ()[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/output/LayerNorm/Constant_1_output_0 for ONNX node: /bert/encoder/layer.1/attention/output/LayerNorm/Constant_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/output/LayerNorm/Add for ONNX node: /bert/encoder/layer.1/attention/output/LayerNorm/Add\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/output/LayerNorm/Add_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/output/LayerNorm/Add_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/output/LayerNorm/Add [Add] outputs: [/bert/encoder/layer.1/attention/output/LayerNorm/Add_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/output/LayerNorm/Sqrt [Sqrt]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/output/LayerNorm/Add_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/output/LayerNorm/Sqrt [Sqrt] inputs: [/bert/encoder/layer.1/attention/output/LayerNorm/Add_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/output/LayerNorm/Sqrt for ONNX node: /bert/encoder/layer.1/attention/output/LayerNorm/Sqrt\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/output/LayerNorm/Sqrt_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/output/LayerNorm/Sqrt_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/output/LayerNorm/Sqrt [Sqrt] outputs: [/bert/encoder/layer.1/attention/output/LayerNorm/Sqrt_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/output/LayerNorm/Div [Div]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/output/LayerNorm/Sub_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/output/LayerNorm/Sqrt_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/output/LayerNorm/Div [Div] inputs: [/bert/encoder/layer.1/attention/output/LayerNorm/Sub_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.1/attention/output/LayerNorm/Sqrt_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/output/LayerNorm/Div for ONNX node: /bert/encoder/layer.1/attention/output/LayerNorm/Div\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/output/LayerNorm/Div_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/output/LayerNorm/Div_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/output/LayerNorm/Div [Div] outputs: [/bert/encoder/layer.1/attention/output/LayerNorm/Div_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/output/LayerNorm/Mul [Mul]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/output/LayerNorm/Div_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: bert.encoder.layer.1.attention.output.LayerNorm.weight\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/output/LayerNorm/Mul [Mul] inputs: [/bert/encoder/layer.1/attention/output/LayerNorm/Div_output_0 -> (-1, -1, 256)[FLOAT]], [bert.encoder.layer.1.attention.output.LayerNorm.weight -> (256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: bert.encoder.layer.1.attention.output.LayerNorm.weight for ONNX node: bert.encoder.layer.1.attention.output.LayerNorm.weight\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/output/LayerNorm/Mul for ONNX node: /bert/encoder/layer.1/attention/output/LayerNorm/Mul\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/output/LayerNorm/Mul_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/output/LayerNorm/Mul_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/output/LayerNorm/Mul [Mul] outputs: [/bert/encoder/layer.1/attention/output/LayerNorm/Mul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.1/attention/output/LayerNorm/Add_1 [Add]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/output/LayerNorm/Mul_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: bert.encoder.layer.1.attention.output.LayerNorm.bias\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/output/LayerNorm/Add_1 [Add] inputs: [/bert/encoder/layer.1/attention/output/LayerNorm/Mul_output_0 -> (-1, -1, 256)[FLOAT]], [bert.encoder.layer.1.attention.output.LayerNorm.bias -> (256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: bert.encoder.layer.1.attention.output.LayerNorm.bias for ONNX node: bert.encoder.layer.1.attention.output.LayerNorm.bias\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.1/attention/output/LayerNorm/Add_1 for ONNX node: /bert/encoder/layer.1/attention/output/LayerNorm/Add_1\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.1/attention/output/LayerNorm/Add_1_output_0 for ONNX tensor: /bert/encoder/layer.1/attention/output/LayerNorm/Add_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/attention/output/LayerNorm/Add_1 [Add] outputs: [/bert/encoder/layer.1/attention/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.1/intermediate/dense/MatMul [MatMul]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/output/LayerNorm/Add_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: onnx::MatMul_817\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/intermediate/dense/MatMul [MatMul] inputs: [/bert/encoder/layer.1/attention/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], [onnx::MatMul_817 -> (256, 1024)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: onnx::MatMul_817 for ONNX node: onnx::MatMul_817\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.1/intermediate/dense/MatMul for ONNX node: /bert/encoder/layer.1/intermediate/dense/MatMul\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.1/intermediate/dense/MatMul_output_0 for ONNX tensor: /bert/encoder/layer.1/intermediate/dense/MatMul_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/intermediate/dense/MatMul [MatMul] outputs: [/bert/encoder/layer.1/intermediate/dense/MatMul_output_0 -> (-1, -1, 1024)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.1/intermediate/dense/Add [Add]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: bert.encoder.layer.1.intermediate.dense.bias\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.1/intermediate/dense/MatMul_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/intermediate/dense/Add [Add] inputs: [bert.encoder.layer.1.intermediate.dense.bias -> (1024)[FLOAT]], [/bert/encoder/layer.1/intermediate/dense/MatMul_output_0 -> (-1, -1, 1024)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: bert.encoder.layer.1.intermediate.dense.bias for ONNX node: bert.encoder.layer.1.intermediate.dense.bias\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.1/intermediate/dense/Add for ONNX node: /bert/encoder/layer.1/intermediate/dense/Add\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.1/intermediate/dense/Add_output_0 for ONNX tensor: /bert/encoder/layer.1/intermediate/dense/Add_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/intermediate/dense/Add [Add] outputs: [/bert/encoder/layer.1/intermediate/dense/Add_output_0 -> (-1, -1, 1024)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.1/intermediate/intermediate_act_fn/Constant [Constant]\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/intermediate/intermediate_act_fn/Constant [Constant] inputs: \n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/intermediate/intermediate_act_fn/Constant [Constant] outputs: [/bert/encoder/layer.1/intermediate/intermediate_act_fn/Constant_output_0 -> ()[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.1/intermediate/intermediate_act_fn/Div [Div]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.1/intermediate/dense/Add_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.1/intermediate/intermediate_act_fn/Constant_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/intermediate/intermediate_act_fn/Div [Div] inputs: [/bert/encoder/layer.1/intermediate/dense/Add_output_0 -> (-1, -1, 1024)[FLOAT]], [/bert/encoder/layer.1/intermediate/intermediate_act_fn/Constant_output_0 -> ()[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.1/intermediate/intermediate_act_fn/Constant_output_0 for ONNX node: /bert/encoder/layer.1/intermediate/intermediate_act_fn/Constant_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.1/intermediate/intermediate_act_fn/Div for ONNX node: /bert/encoder/layer.1/intermediate/intermediate_act_fn/Div\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.1/intermediate/intermediate_act_fn/Div_output_0 for ONNX tensor: /bert/encoder/layer.1/intermediate/intermediate_act_fn/Div_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/intermediate/intermediate_act_fn/Div [Div] outputs: [/bert/encoder/layer.1/intermediate/intermediate_act_fn/Div_output_0 -> (-1, -1, 1024)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.1/intermediate/intermediate_act_fn/Erf [Erf]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.1/intermediate/intermediate_act_fn/Div_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/intermediate/intermediate_act_fn/Erf [Erf] inputs: [/bert/encoder/layer.1/intermediate/intermediate_act_fn/Div_output_0 -> (-1, -1, 1024)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.1/intermediate/intermediate_act_fn/Erf for ONNX node: /bert/encoder/layer.1/intermediate/intermediate_act_fn/Erf\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.1/intermediate/intermediate_act_fn/Erf_output_0 for ONNX tensor: /bert/encoder/layer.1/intermediate/intermediate_act_fn/Erf_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/intermediate/intermediate_act_fn/Erf [Erf] outputs: [/bert/encoder/layer.1/intermediate/intermediate_act_fn/Erf_output_0 -> (-1, -1, 1024)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.1/intermediate/intermediate_act_fn/Constant_1 [Constant]\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/intermediate/intermediate_act_fn/Constant_1 [Constant] inputs: \n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/intermediate/intermediate_act_fn/Constant_1 [Constant] outputs: [/bert/encoder/layer.1/intermediate/intermediate_act_fn/Constant_1_output_0 -> ()[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.1/intermediate/intermediate_act_fn/Add [Add]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.1/intermediate/intermediate_act_fn/Erf_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.1/intermediate/intermediate_act_fn/Constant_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/intermediate/intermediate_act_fn/Add [Add] inputs: [/bert/encoder/layer.1/intermediate/intermediate_act_fn/Erf_output_0 -> (-1, -1, 1024)[FLOAT]], [/bert/encoder/layer.1/intermediate/intermediate_act_fn/Constant_1_output_0 -> ()[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.1/intermediate/intermediate_act_fn/Constant_1_output_0 for ONNX node: /bert/encoder/layer.1/intermediate/intermediate_act_fn/Constant_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.1/intermediate/intermediate_act_fn/Add for ONNX node: /bert/encoder/layer.1/intermediate/intermediate_act_fn/Add\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.1/intermediate/intermediate_act_fn/Add_output_0 for ONNX tensor: /bert/encoder/layer.1/intermediate/intermediate_act_fn/Add_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/intermediate/intermediate_act_fn/Add [Add] outputs: [/bert/encoder/layer.1/intermediate/intermediate_act_fn/Add_output_0 -> (-1, -1, 1024)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.1/intermediate/intermediate_act_fn/Mul [Mul]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.1/intermediate/dense/Add_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.1/intermediate/intermediate_act_fn/Add_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/intermediate/intermediate_act_fn/Mul [Mul] inputs: [/bert/encoder/layer.1/intermediate/dense/Add_output_0 -> (-1, -1, 1024)[FLOAT]], [/bert/encoder/layer.1/intermediate/intermediate_act_fn/Add_output_0 -> (-1, -1, 1024)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.1/intermediate/intermediate_act_fn/Mul for ONNX node: /bert/encoder/layer.1/intermediate/intermediate_act_fn/Mul\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.1/intermediate/intermediate_act_fn/Mul_output_0 for ONNX tensor: /bert/encoder/layer.1/intermediate/intermediate_act_fn/Mul_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/intermediate/intermediate_act_fn/Mul [Mul] outputs: [/bert/encoder/layer.1/intermediate/intermediate_act_fn/Mul_output_0 -> (-1, -1, 1024)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.1/intermediate/intermediate_act_fn/Constant_2 [Constant]\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/intermediate/intermediate_act_fn/Constant_2 [Constant] inputs: \n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/intermediate/intermediate_act_fn/Constant_2 [Constant] outputs: [/bert/encoder/layer.1/intermediate/intermediate_act_fn/Constant_2_output_0 -> ()[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.1/intermediate/intermediate_act_fn/Mul_1 [Mul]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.1/intermediate/intermediate_act_fn/Mul_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.1/intermediate/intermediate_act_fn/Constant_2_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/intermediate/intermediate_act_fn/Mul_1 [Mul] inputs: [/bert/encoder/layer.1/intermediate/intermediate_act_fn/Mul_output_0 -> (-1, -1, 1024)[FLOAT]], [/bert/encoder/layer.1/intermediate/intermediate_act_fn/Constant_2_output_0 -> ()[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.1/intermediate/intermediate_act_fn/Constant_2_output_0 for ONNX node: /bert/encoder/layer.1/intermediate/intermediate_act_fn/Constant_2_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.1/intermediate/intermediate_act_fn/Mul_1 for ONNX node: /bert/encoder/layer.1/intermediate/intermediate_act_fn/Mul_1\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.1/intermediate/intermediate_act_fn/Mul_1_output_0 for ONNX tensor: /bert/encoder/layer.1/intermediate/intermediate_act_fn/Mul_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/intermediate/intermediate_act_fn/Mul_1 [Mul] outputs: [/bert/encoder/layer.1/intermediate/intermediate_act_fn/Mul_1_output_0 -> (-1, -1, 1024)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.1/output/dense/MatMul [MatMul]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.1/intermediate/intermediate_act_fn/Mul_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: onnx::MatMul_818\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/output/dense/MatMul [MatMul] inputs: [/bert/encoder/layer.1/intermediate/intermediate_act_fn/Mul_1_output_0 -> (-1, -1, 1024)[FLOAT]], [onnx::MatMul_818 -> (1024, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: onnx::MatMul_818 for ONNX node: onnx::MatMul_818\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.1/output/dense/MatMul for ONNX node: /bert/encoder/layer.1/output/dense/MatMul\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.1/output/dense/MatMul_output_0 for ONNX tensor: /bert/encoder/layer.1/output/dense/MatMul_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/output/dense/MatMul [MatMul] outputs: [/bert/encoder/layer.1/output/dense/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.1/output/dense/Add [Add]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: bert.encoder.layer.1.output.dense.bias\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.1/output/dense/MatMul_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/output/dense/Add [Add] inputs: [bert.encoder.layer.1.output.dense.bias -> (256)[FLOAT]], [/bert/encoder/layer.1/output/dense/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: bert.encoder.layer.1.output.dense.bias for ONNX node: bert.encoder.layer.1.output.dense.bias\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.1/output/dense/Add for ONNX node: /bert/encoder/layer.1/output/dense/Add\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.1/output/dense/Add_output_0 for ONNX tensor: /bert/encoder/layer.1/output/dense/Add_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/output/dense/Add [Add] outputs: [/bert/encoder/layer.1/output/dense/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.1/output/Add [Add]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.1/output/dense/Add_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.1/attention/output/LayerNorm/Add_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/output/Add [Add] inputs: [/bert/encoder/layer.1/output/dense/Add_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.1/attention/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.1/output/Add for ONNX node: /bert/encoder/layer.1/output/Add\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.1/output/Add_output_0 for ONNX tensor: /bert/encoder/layer.1/output/Add_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/output/Add [Add] outputs: [/bert/encoder/layer.1/output/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.1/output/LayerNorm/ReduceMean [ReduceMean]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.1/output/Add_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/output/LayerNorm/ReduceMean [ReduceMean] inputs: [/bert/encoder/layer.1/output/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.1/output/LayerNorm/ReduceMean for ONNX node: /bert/encoder/layer.1/output/LayerNorm/ReduceMean\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.1/output/LayerNorm/ReduceMean_output_0 for ONNX tensor: /bert/encoder/layer.1/output/LayerNorm/ReduceMean_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/output/LayerNorm/ReduceMean [ReduceMean] outputs: [/bert/encoder/layer.1/output/LayerNorm/ReduceMean_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.1/output/LayerNorm/Sub [Sub]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.1/output/Add_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.1/output/LayerNorm/ReduceMean_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/output/LayerNorm/Sub [Sub] inputs: [/bert/encoder/layer.1/output/Add_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.1/output/LayerNorm/ReduceMean_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.1/output/LayerNorm/Sub for ONNX node: /bert/encoder/layer.1/output/LayerNorm/Sub\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.1/output/LayerNorm/Sub_output_0 for ONNX tensor: /bert/encoder/layer.1/output/LayerNorm/Sub_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/output/LayerNorm/Sub [Sub] outputs: [/bert/encoder/layer.1/output/LayerNorm/Sub_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.1/output/LayerNorm/Constant [Constant]\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/output/LayerNorm/Constant [Constant] inputs: \n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/output/LayerNorm/Constant [Constant] outputs: [/bert/encoder/layer.1/output/LayerNorm/Constant_output_0 -> ()[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.1/output/LayerNorm/Pow [Pow]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.1/output/LayerNorm/Sub_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.1/output/LayerNorm/Constant_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/output/LayerNorm/Pow [Pow] inputs: [/bert/encoder/layer.1/output/LayerNorm/Sub_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.1/output/LayerNorm/Constant_output_0 -> ()[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.1/output/LayerNorm/Constant_output_0 for ONNX node: /bert/encoder/layer.1/output/LayerNorm/Constant_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.1/output/LayerNorm/Pow for ONNX node: /bert/encoder/layer.1/output/LayerNorm/Pow\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.1/output/LayerNorm/Pow_output_0 for ONNX tensor: /bert/encoder/layer.1/output/LayerNorm/Pow_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/output/LayerNorm/Pow [Pow] outputs: [/bert/encoder/layer.1/output/LayerNorm/Pow_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.1/output/LayerNorm/ReduceMean_1 [ReduceMean]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.1/output/LayerNorm/Pow_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/output/LayerNorm/ReduceMean_1 [ReduceMean] inputs: [/bert/encoder/layer.1/output/LayerNorm/Pow_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.1/output/LayerNorm/ReduceMean_1 for ONNX node: /bert/encoder/layer.1/output/LayerNorm/ReduceMean_1\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.1/output/LayerNorm/ReduceMean_1_output_0 for ONNX tensor: /bert/encoder/layer.1/output/LayerNorm/ReduceMean_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/output/LayerNorm/ReduceMean_1 [ReduceMean] outputs: [/bert/encoder/layer.1/output/LayerNorm/ReduceMean_1_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.1/output/LayerNorm/Constant_1 [Constant]\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/output/LayerNorm/Constant_1 [Constant] inputs: \n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/output/LayerNorm/Constant_1 [Constant] outputs: [/bert/encoder/layer.1/output/LayerNorm/Constant_1_output_0 -> ()[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.1/output/LayerNorm/Add [Add]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.1/output/LayerNorm/ReduceMean_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.1/output/LayerNorm/Constant_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/output/LayerNorm/Add [Add] inputs: [/bert/encoder/layer.1/output/LayerNorm/ReduceMean_1_output_0 -> (-1, -1, 1)[FLOAT]], [/bert/encoder/layer.1/output/LayerNorm/Constant_1_output_0 -> ()[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.1/output/LayerNorm/Constant_1_output_0 for ONNX node: /bert/encoder/layer.1/output/LayerNorm/Constant_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.1/output/LayerNorm/Add for ONNX node: /bert/encoder/layer.1/output/LayerNorm/Add\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.1/output/LayerNorm/Add_output_0 for ONNX tensor: /bert/encoder/layer.1/output/LayerNorm/Add_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/output/LayerNorm/Add [Add] outputs: [/bert/encoder/layer.1/output/LayerNorm/Add_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.1/output/LayerNorm/Sqrt [Sqrt]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.1/output/LayerNorm/Add_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/output/LayerNorm/Sqrt [Sqrt] inputs: [/bert/encoder/layer.1/output/LayerNorm/Add_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.1/output/LayerNorm/Sqrt for ONNX node: /bert/encoder/layer.1/output/LayerNorm/Sqrt\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.1/output/LayerNorm/Sqrt_output_0 for ONNX tensor: /bert/encoder/layer.1/output/LayerNorm/Sqrt_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/output/LayerNorm/Sqrt [Sqrt] outputs: [/bert/encoder/layer.1/output/LayerNorm/Sqrt_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.1/output/LayerNorm/Div [Div]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.1/output/LayerNorm/Sub_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.1/output/LayerNorm/Sqrt_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/output/LayerNorm/Div [Div] inputs: [/bert/encoder/layer.1/output/LayerNorm/Sub_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.1/output/LayerNorm/Sqrt_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.1/output/LayerNorm/Div for ONNX node: /bert/encoder/layer.1/output/LayerNorm/Div\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.1/output/LayerNorm/Div_output_0 for ONNX tensor: /bert/encoder/layer.1/output/LayerNorm/Div_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/output/LayerNorm/Div [Div] outputs: [/bert/encoder/layer.1/output/LayerNorm/Div_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.1/output/LayerNorm/Mul [Mul]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.1/output/LayerNorm/Div_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: bert.encoder.layer.1.output.LayerNorm.weight\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/output/LayerNorm/Mul [Mul] inputs: [/bert/encoder/layer.1/output/LayerNorm/Div_output_0 -> (-1, -1, 256)[FLOAT]], [bert.encoder.layer.1.output.LayerNorm.weight -> (256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: bert.encoder.layer.1.output.LayerNorm.weight for ONNX node: bert.encoder.layer.1.output.LayerNorm.weight\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.1/output/LayerNorm/Mul for ONNX node: /bert/encoder/layer.1/output/LayerNorm/Mul\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.1/output/LayerNorm/Mul_output_0 for ONNX tensor: /bert/encoder/layer.1/output/LayerNorm/Mul_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/output/LayerNorm/Mul [Mul] outputs: [/bert/encoder/layer.1/output/LayerNorm/Mul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.1/output/LayerNorm/Add_1 [Add]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.1/output/LayerNorm/Mul_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: bert.encoder.layer.1.output.LayerNorm.bias\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/output/LayerNorm/Add_1 [Add] inputs: [/bert/encoder/layer.1/output/LayerNorm/Mul_output_0 -> (-1, -1, 256)[FLOAT]], [bert.encoder.layer.1.output.LayerNorm.bias -> (256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: bert.encoder.layer.1.output.LayerNorm.bias for ONNX node: bert.encoder.layer.1.output.LayerNorm.bias\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.1/output/LayerNorm/Add_1 for ONNX node: /bert/encoder/layer.1/output/LayerNorm/Add_1\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.1/output/LayerNorm/Add_1_output_0 for ONNX tensor: /bert/encoder/layer.1/output/LayerNorm/Add_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.1/output/LayerNorm/Add_1 [Add] outputs: [/bert/encoder/layer.1/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/query/MatMul [MatMul]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.1/output/LayerNorm/Add_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: onnx::MatMul_819\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/self/query/MatMul [MatMul] inputs: [/bert/encoder/layer.1/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], [onnx::MatMul_819 -> (256, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: onnx::MatMul_819 for ONNX node: onnx::MatMul_819\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/query/MatMul for ONNX node: /bert/encoder/layer.2/attention/self/query/MatMul\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/query/MatMul_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/query/MatMul_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/self/query/MatMul [MatMul] outputs: [/bert/encoder/layer.2/attention/self/query/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/query/Add [Add]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: bert.encoder.layer.2.attention.self.query.bias\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/query/MatMul_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/self/query/Add [Add] inputs: [bert.encoder.layer.2.attention.self.query.bias -> (256)[FLOAT]], [/bert/encoder/layer.2/attention/self/query/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: bert.encoder.layer.2.attention.self.query.bias for ONNX node: bert.encoder.layer.2.attention.self.query.bias\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/query/Add for ONNX node: /bert/encoder/layer.2/attention/self/query/Add\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/query/Add_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/query/Add_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/self/query/Add [Add] outputs: [/bert/encoder/layer.2/attention/self/query/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/key/MatMul [MatMul]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.1/output/LayerNorm/Add_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: onnx::MatMul_820\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/self/key/MatMul [MatMul] inputs: [/bert/encoder/layer.1/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], [onnx::MatMul_820 -> (256, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: onnx::MatMul_820 for ONNX node: onnx::MatMul_820\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/key/MatMul for ONNX node: /bert/encoder/layer.2/attention/self/key/MatMul\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/key/MatMul_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/key/MatMul_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/self/key/MatMul [MatMul] outputs: [/bert/encoder/layer.2/attention/self/key/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/key/Add [Add]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: bert.encoder.layer.2.attention.self.key.bias\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/key/MatMul_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/self/key/Add [Add] inputs: [bert.encoder.layer.2.attention.self.key.bias -> (256)[FLOAT]], [/bert/encoder/layer.2/attention/self/key/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: bert.encoder.layer.2.attention.self.key.bias for ONNX node: bert.encoder.layer.2.attention.self.key.bias\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/key/Add for ONNX node: /bert/encoder/layer.2/attention/self/key/Add\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/key/Add_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/key/Add_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/self/key/Add [Add] outputs: [/bert/encoder/layer.2/attention/self/key/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Shape [Shape]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/key/Add_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/self/Shape [Shape] inputs: [/bert/encoder/layer.2/attention/self/key/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Shape for ONNX node: /bert/encoder/layer.2/attention/self/Shape\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/Shape_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/Shape_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/self/Shape [Shape] outputs: [/bert/encoder/layer.2/attention/self/Shape_output_0 -> (3)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Constant [Constant]\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/self/Constant [Constant] inputs: \n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/self/Constant [Constant] outputs: [/bert/encoder/layer.2/attention/self/Constant_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Gather [Gather]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Shape_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Constant_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/self/Gather [Gather] inputs: [/bert/encoder/layer.2/attention/self/Shape_output_0 -> (3)[INT32]], [/bert/encoder/layer.2/attention/self/Constant_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Constant_output_0 for ONNX node: /bert/encoder/layer.2/attention/self/Constant_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Using Gather axis: 0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Gather for ONNX node: /bert/encoder/layer.2/attention/self/Gather\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/Gather_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/Gather_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/self/Gather [Gather] outputs: [/bert/encoder/layer.2/attention/self/Gather_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Shape_1 [Shape]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/key/Add_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/self/Shape_1 [Shape] inputs: [/bert/encoder/layer.2/attention/self/key/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Shape_1 for ONNX node: /bert/encoder/layer.2/attention/self/Shape_1\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/Shape_1_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/Shape_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/self/Shape_1 [Shape] outputs: [/bert/encoder/layer.2/attention/self/Shape_1_output_0 -> (3)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Constant_1 [Constant]\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/self/Constant_1 [Constant] inputs: \n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/self/Constant_1 [Constant] outputs: [/bert/encoder/layer.2/attention/self/Constant_1_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Gather_1 [Gather]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Shape_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Constant_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/self/Gather_1 [Gather] inputs: [/bert/encoder/layer.2/attention/self/Shape_1_output_0 -> (3)[INT32]], [/bert/encoder/layer.2/attention/self/Constant_1_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Constant_1_output_0 for ONNX node: /bert/encoder/layer.2/attention/self/Constant_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Using Gather axis: 0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Gather_1 for ONNX node: /bert/encoder/layer.2/attention/self/Gather_1\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/Gather_1_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/Gather_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/self/Gather_1 [Gather] outputs: [/bert/encoder/layer.2/attention/self/Gather_1_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Unsqueeze [Unsqueeze]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Gather_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/self/Unsqueeze [Unsqueeze] inputs: [/bert/encoder/layer.2/attention/self/Gather_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Unsqueeze for ONNX node: /bert/encoder/layer.2/attention/self/Unsqueeze\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/Unsqueeze_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/Unsqueeze_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/self/Unsqueeze [Unsqueeze] outputs: [/bert/encoder/layer.2/attention/self/Unsqueeze_output_0 -> (1)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Unsqueeze_1 [Unsqueeze]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Gather_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/self/Unsqueeze_1 [Unsqueeze] inputs: [/bert/encoder/layer.2/attention/self/Gather_1_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Unsqueeze_1 for ONNX node: /bert/encoder/layer.2/attention/self/Unsqueeze_1\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/Unsqueeze_1_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/Unsqueeze_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/self/Unsqueeze_1 [Unsqueeze] outputs: [/bert/encoder/layer.2/attention/self/Unsqueeze_1_output_0 -> (1)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Constant_2 [Constant]\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/self/Constant_2 [Constant] inputs: \n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/self/Constant_2 [Constant] outputs: [/bert/encoder/layer.2/attention/self/Constant_2_output_0 -> (1)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Constant_3 [Constant]\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/self/Constant_3 [Constant] inputs: \n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/self/Constant_3 [Constant] outputs: [/bert/encoder/layer.2/attention/self/Constant_3_output_0 -> (1)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Concat [Concat]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Unsqueeze_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Unsqueeze_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Constant_2_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Constant_3_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/self/Concat [Concat] inputs: [/bert/encoder/layer.2/attention/self/Unsqueeze_output_0 -> (1)[INT32]], [/bert/encoder/layer.2/attention/self/Unsqueeze_1_output_0 -> (1)[INT32]], [/bert/encoder/layer.2/attention/self/Constant_2_output_0 -> (1)[INT32]], [/bert/encoder/layer.2/attention/self/Constant_3_output_0 -> (1)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Constant_2_output_0 for ONNX node: /bert/encoder/layer.2/attention/self/Constant_2_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Constant_3_output_0 for ONNX node: /bert/encoder/layer.2/attention/self/Constant_3_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Concat for ONNX node: /bert/encoder/layer.2/attention/self/Concat\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/Concat_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/Concat_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/self/Concat [Concat] outputs: [/bert/encoder/layer.2/attention/self/Concat_output_0 -> (4)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Reshape [Reshape]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/key/Add_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Concat_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/self/Reshape [Reshape] inputs: [/bert/encoder/layer.2/attention/self/key/Add_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.2/attention/self/Concat_output_0 -> (4)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Reshape for ONNX node: /bert/encoder/layer.2/attention/self/Reshape\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/Reshape_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/Reshape_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/self/Reshape [Reshape] outputs: [/bert/encoder/layer.2/attention/self/Reshape_output_0 -> (-1, -1, 8, 32)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/value/MatMul [MatMul]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.1/output/LayerNorm/Add_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: onnx::MatMul_823\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/self/value/MatMul [MatMul] inputs: [/bert/encoder/layer.1/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], [onnx::MatMul_823 -> (256, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: onnx::MatMul_823 for ONNX node: onnx::MatMul_823\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/value/MatMul for ONNX node: /bert/encoder/layer.2/attention/self/value/MatMul\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/value/MatMul_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/value/MatMul_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/self/value/MatMul [MatMul] outputs: [/bert/encoder/layer.2/attention/self/value/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/value/Add [Add]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: bert.encoder.layer.2.attention.self.value.bias\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/value/MatMul_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/self/value/Add [Add] inputs: [bert.encoder.layer.2.attention.self.value.bias -> (256)[FLOAT]], [/bert/encoder/layer.2/attention/self/value/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: bert.encoder.layer.2.attention.self.value.bias for ONNX node: bert.encoder.layer.2.attention.self.value.bias\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/value/Add for ONNX node: /bert/encoder/layer.2/attention/self/value/Add\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/value/Add_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/value/Add_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/self/value/Add [Add] outputs: [/bert/encoder/layer.2/attention/self/value/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Shape_2 [Shape]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/value/Add_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/self/Shape_2 [Shape] inputs: [/bert/encoder/layer.2/attention/self/value/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Shape_2 for ONNX node: /bert/encoder/layer.2/attention/self/Shape_2\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/Shape_2_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/Shape_2_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/self/Shape_2 [Shape] outputs: [/bert/encoder/layer.2/attention/self/Shape_2_output_0 -> (3)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Constant_4 [Constant]\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/self/Constant_4 [Constant] inputs: \n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/self/Constant_4 [Constant] outputs: [/bert/encoder/layer.2/attention/self/Constant_4_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Gather_2 [Gather]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Shape_2_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Constant_4_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/self/Gather_2 [Gather] inputs: [/bert/encoder/layer.2/attention/self/Shape_2_output_0 -> (3)[INT32]], [/bert/encoder/layer.2/attention/self/Constant_4_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Constant_4_output_0 for ONNX node: /bert/encoder/layer.2/attention/self/Constant_4_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Using Gather axis: 0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Gather_2 for ONNX node: /bert/encoder/layer.2/attention/self/Gather_2\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/Gather_2_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/Gather_2_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/self/Gather_2 [Gather] outputs: [/bert/encoder/layer.2/attention/self/Gather_2_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Shape_3 [Shape]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/value/Add_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/self/Shape_3 [Shape] inputs: [/bert/encoder/layer.2/attention/self/value/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Shape_3 for ONNX node: /bert/encoder/layer.2/attention/self/Shape_3\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/Shape_3_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/Shape_3_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/self/Shape_3 [Shape] outputs: [/bert/encoder/layer.2/attention/self/Shape_3_output_0 -> (3)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Constant_5 [Constant]\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/self/Constant_5 [Constant] inputs: \n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/self/Constant_5 [Constant] outputs: [/bert/encoder/layer.2/attention/self/Constant_5_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Gather_3 [Gather]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Shape_3_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Constant_5_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/self/Gather_3 [Gather] inputs: [/bert/encoder/layer.2/attention/self/Shape_3_output_0 -> (3)[INT32]], [/bert/encoder/layer.2/attention/self/Constant_5_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Constant_5_output_0 for ONNX node: /bert/encoder/layer.2/attention/self/Constant_5_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Using Gather axis: 0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Gather_3 for ONNX node: /bert/encoder/layer.2/attention/self/Gather_3\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/Gather_3_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/Gather_3_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/self/Gather_3 [Gather] outputs: [/bert/encoder/layer.2/attention/self/Gather_3_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Unsqueeze_2 [Unsqueeze]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Gather_2_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/self/Unsqueeze_2 [Unsqueeze] inputs: [/bert/encoder/layer.2/attention/self/Gather_2_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Unsqueeze_2 for ONNX node: /bert/encoder/layer.2/attention/self/Unsqueeze_2\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/Unsqueeze_2_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/Unsqueeze_2_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/self/Unsqueeze_2 [Unsqueeze] outputs: [/bert/encoder/layer.2/attention/self/Unsqueeze_2_output_0 -> (1)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Unsqueeze_3 [Unsqueeze]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Gather_3_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/self/Unsqueeze_3 [Unsqueeze] inputs: [/bert/encoder/layer.2/attention/self/Gather_3_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Unsqueeze_3 for ONNX node: /bert/encoder/layer.2/attention/self/Unsqueeze_3\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/Unsqueeze_3_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/Unsqueeze_3_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/self/Unsqueeze_3 [Unsqueeze] outputs: [/bert/encoder/layer.2/attention/self/Unsqueeze_3_output_0 -> (1)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Constant_6 [Constant]\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/self/Constant_6 [Constant] inputs: \n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/self/Constant_6 [Constant] outputs: [/bert/encoder/layer.2/attention/self/Constant_6_output_0 -> (1)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Constant_7 [Constant]\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/self/Constant_7 [Constant] inputs: \n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/self/Constant_7 [Constant] outputs: [/bert/encoder/layer.2/attention/self/Constant_7_output_0 -> (1)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Concat_1 [Concat]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Unsqueeze_2_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Unsqueeze_3_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Constant_6_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Constant_7_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/self/Concat_1 [Concat] inputs: [/bert/encoder/layer.2/attention/self/Unsqueeze_2_output_0 -> (1)[INT32]], [/bert/encoder/layer.2/attention/self/Unsqueeze_3_output_0 -> (1)[INT32]], [/bert/encoder/layer.2/attention/self/Constant_6_output_0 -> (1)[INT32]], [/bert/encoder/layer.2/attention/self/Constant_7_output_0 -> (1)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Constant_6_output_0 for ONNX node: /bert/encoder/layer.2/attention/self/Constant_6_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Constant_7_output_0 for ONNX node: /bert/encoder/layer.2/attention/self/Constant_7_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Concat_1 for ONNX node: /bert/encoder/layer.2/attention/self/Concat_1\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/Concat_1_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/Concat_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/self/Concat_1 [Concat] outputs: [/bert/encoder/layer.2/attention/self/Concat_1_output_0 -> (4)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Reshape_1 [Reshape]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/value/Add_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Concat_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/self/Reshape_1 [Reshape] inputs: [/bert/encoder/layer.2/attention/self/value/Add_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.2/attention/self/Concat_1_output_0 -> (4)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Reshape_1 for ONNX node: /bert/encoder/layer.2/attention/self/Reshape_1\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/Reshape_1_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/Reshape_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/self/Reshape_1 [Reshape] outputs: [/bert/encoder/layer.2/attention/self/Reshape_1_output_0 -> (-1, -1, 8, 32)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Transpose [Transpose]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Reshape_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/self/Transpose [Transpose] inputs: [/bert/encoder/layer.2/attention/self/Reshape_1_output_0 -> (-1, -1, 8, 32)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Transpose for ONNX node: /bert/encoder/layer.2/attention/self/Transpose\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/Transpose_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/Transpose_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/self/Transpose [Transpose] outputs: [/bert/encoder/layer.2/attention/self/Transpose_output_0 -> (-1, 8, -1, 32)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Shape_4 [Shape]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/query/Add_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/self/Shape_4 [Shape] inputs: [/bert/encoder/layer.2/attention/self/query/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Shape_4 for ONNX node: /bert/encoder/layer.2/attention/self/Shape_4\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/Shape_4_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/Shape_4_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/self/Shape_4 [Shape] outputs: [/bert/encoder/layer.2/attention/self/Shape_4_output_0 -> (3)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Constant_8 [Constant]\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/self/Constant_8 [Constant] inputs: \n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/self/Constant_8 [Constant] outputs: [/bert/encoder/layer.2/attention/self/Constant_8_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Gather_4 [Gather]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Shape_4_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Constant_8_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/self/Gather_4 [Gather] inputs: [/bert/encoder/layer.2/attention/self/Shape_4_output_0 -> (3)[INT32]], [/bert/encoder/layer.2/attention/self/Constant_8_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Constant_8_output_0 for ONNX node: /bert/encoder/layer.2/attention/self/Constant_8_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Using Gather axis: 0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Gather_4 for ONNX node: /bert/encoder/layer.2/attention/self/Gather_4\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/Gather_4_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/Gather_4_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/self/Gather_4 [Gather] outputs: [/bert/encoder/layer.2/attention/self/Gather_4_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Shape_5 [Shape]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/query/Add_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/self/Shape_5 [Shape] inputs: [/bert/encoder/layer.2/attention/self/query/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Shape_5 for ONNX node: /bert/encoder/layer.2/attention/self/Shape_5\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/Shape_5_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/Shape_5_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/self/Shape_5 [Shape] outputs: [/bert/encoder/layer.2/attention/self/Shape_5_output_0 -> (3)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Constant_9 [Constant]\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/self/Constant_9 [Constant] inputs: \n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/self/Constant_9 [Constant] outputs: [/bert/encoder/layer.2/attention/self/Constant_9_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Gather_5 [Gather]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Shape_5_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Constant_9_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/self/Gather_5 [Gather] inputs: [/bert/encoder/layer.2/attention/self/Shape_5_output_0 -> (3)[INT32]], [/bert/encoder/layer.2/attention/self/Constant_9_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Constant_9_output_0 for ONNX node: /bert/encoder/layer.2/attention/self/Constant_9_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Using Gather axis: 0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Gather_5 for ONNX node: /bert/encoder/layer.2/attention/self/Gather_5\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/Gather_5_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/Gather_5_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/self/Gather_5 [Gather] outputs: [/bert/encoder/layer.2/attention/self/Gather_5_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Unsqueeze_4 [Unsqueeze]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Gather_4_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/self/Unsqueeze_4 [Unsqueeze] inputs: [/bert/encoder/layer.2/attention/self/Gather_4_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Unsqueeze_4 for ONNX node: /bert/encoder/layer.2/attention/self/Unsqueeze_4\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/Unsqueeze_4_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/Unsqueeze_4_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/self/Unsqueeze_4 [Unsqueeze] outputs: [/bert/encoder/layer.2/attention/self/Unsqueeze_4_output_0 -> (1)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Unsqueeze_5 [Unsqueeze]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Gather_5_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/self/Unsqueeze_5 [Unsqueeze] inputs: [/bert/encoder/layer.2/attention/self/Gather_5_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Unsqueeze_5 for ONNX node: /bert/encoder/layer.2/attention/self/Unsqueeze_5\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/Unsqueeze_5_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/Unsqueeze_5_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/self/Unsqueeze_5 [Unsqueeze] outputs: [/bert/encoder/layer.2/attention/self/Unsqueeze_5_output_0 -> (1)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Constant_10 [Constant]\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/self/Constant_10 [Constant] inputs: \n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/self/Constant_10 [Constant] outputs: [/bert/encoder/layer.2/attention/self/Constant_10_output_0 -> (1)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Constant_11 [Constant]\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/self/Constant_11 [Constant] inputs: \n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/self/Constant_11 [Constant] outputs: [/bert/encoder/layer.2/attention/self/Constant_11_output_0 -> (1)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Concat_2 [Concat]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Unsqueeze_4_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Unsqueeze_5_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Constant_10_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Constant_11_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/self/Concat_2 [Concat] inputs: [/bert/encoder/layer.2/attention/self/Unsqueeze_4_output_0 -> (1)[INT32]], [/bert/encoder/layer.2/attention/self/Unsqueeze_5_output_0 -> (1)[INT32]], [/bert/encoder/layer.2/attention/self/Constant_10_output_0 -> (1)[INT32]], [/bert/encoder/layer.2/attention/self/Constant_11_output_0 -> (1)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Constant_10_output_0 for ONNX node: /bert/encoder/layer.2/attention/self/Constant_10_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Constant_11_output_0 for ONNX node: /bert/encoder/layer.2/attention/self/Constant_11_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Concat_2 for ONNX node: /bert/encoder/layer.2/attention/self/Concat_2\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/Concat_2_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/Concat_2_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/self/Concat_2 [Concat] outputs: [/bert/encoder/layer.2/attention/self/Concat_2_output_0 -> (4)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Reshape_2 [Reshape]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/query/Add_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Concat_2_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/self/Reshape_2 [Reshape] inputs: [/bert/encoder/layer.2/attention/self/query/Add_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.2/attention/self/Concat_2_output_0 -> (4)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Reshape_2 for ONNX node: /bert/encoder/layer.2/attention/self/Reshape_2\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/Reshape_2_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/Reshape_2_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/self/Reshape_2 [Reshape] outputs: [/bert/encoder/layer.2/attention/self/Reshape_2_output_0 -> (-1, -1, 8, 32)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Transpose_1 [Transpose]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Reshape_2_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/self/Transpose_1 [Transpose] inputs: [/bert/encoder/layer.2/attention/self/Reshape_2_output_0 -> (-1, -1, 8, 32)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Transpose_1 for ONNX node: /bert/encoder/layer.2/attention/self/Transpose_1\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/Transpose_1_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/Transpose_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/self/Transpose_1 [Transpose] outputs: [/bert/encoder/layer.2/attention/self/Transpose_1_output_0 -> (-1, 8, -1, 32)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Transpose_2 [Transpose]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Reshape_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/self/Transpose_2 [Transpose] inputs: [/bert/encoder/layer.2/attention/self/Reshape_output_0 -> (-1, -1, 8, 32)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Transpose_2 for ONNX node: /bert/encoder/layer.2/attention/self/Transpose_2\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/Transpose_2_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/Transpose_2_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/self/Transpose_2 [Transpose] outputs: [/bert/encoder/layer.2/attention/self/Transpose_2_output_0 -> (-1, 8, 32, -1)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/MatMul [MatMul]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Transpose_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Transpose_2_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/self/MatMul [MatMul] inputs: [/bert/encoder/layer.2/attention/self/Transpose_1_output_0 -> (-1, 8, -1, 32)[FLOAT]], [/bert/encoder/layer.2/attention/self/Transpose_2_output_0 -> (-1, 8, 32, -1)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/MatMul for ONNX node: /bert/encoder/layer.2/attention/self/MatMul\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/MatMul_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/MatMul_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/self/MatMul [MatMul] outputs: [/bert/encoder/layer.2/attention/self/MatMul_output_0 -> (-1, 8, -1, -1)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Constant_12 [Constant]\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/self/Constant_12 [Constant] inputs: \n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/self/Constant_12 [Constant] outputs: [/bert/encoder/layer.2/attention/self/Constant_12_output_0 -> ()[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Div [Div]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/MatMul_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Constant_12_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/self/Div [Div] inputs: [/bert/encoder/layer.2/attention/self/MatMul_output_0 -> (-1, 8, -1, -1)[FLOAT]], [/bert/encoder/layer.2/attention/self/Constant_12_output_0 -> ()[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Constant_12_output_0 for ONNX node: /bert/encoder/layer.2/attention/self/Constant_12_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Div for ONNX node: /bert/encoder/layer.2/attention/self/Div\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/Div_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/Div_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/self/Div [Div] outputs: [/bert/encoder/layer.2/attention/self/Div_output_0 -> (-1, 8, -1, -1)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Add [Add]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Div_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/Mul_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/self/Add [Add] inputs: [/bert/encoder/layer.2/attention/self/Div_output_0 -> (-1, 8, -1, -1)[FLOAT]], [/bert/Mul_output_0 -> (-1, 1, 1, -1)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Add for ONNX node: /bert/encoder/layer.2/attention/self/Add\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/Add_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/Add_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/self/Add [Add] outputs: [/bert/encoder/layer.2/attention/self/Add_output_0 -> (-1, 8, -1, -1)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Softmax [Softmax]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Add_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/self/Softmax [Softmax] inputs: [/bert/encoder/layer.2/attention/self/Add_output_0 -> (-1, 8, -1, -1)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Softmax for ONNX node: /bert/encoder/layer.2/attention/self/Softmax\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/Softmax_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/Softmax_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/self/Softmax [Softmax] outputs: [/bert/encoder/layer.2/attention/self/Softmax_output_0 -> (-1, 8, -1, -1)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/MatMul_1 [MatMul]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Softmax_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Transpose_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/self/MatMul_1 [MatMul] inputs: [/bert/encoder/layer.2/attention/self/Softmax_output_0 -> (-1, 8, -1, -1)[FLOAT]], [/bert/encoder/layer.2/attention/self/Transpose_output_0 -> (-1, 8, -1, 32)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/MatMul_1 for ONNX node: /bert/encoder/layer.2/attention/self/MatMul_1\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/MatMul_1_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/MatMul_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/self/MatMul_1 [MatMul] outputs: [/bert/encoder/layer.2/attention/self/MatMul_1_output_0 -> (-1, 8, -1, 32)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Transpose_3 [Transpose]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/MatMul_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/self/Transpose_3 [Transpose] inputs: [/bert/encoder/layer.2/attention/self/MatMul_1_output_0 -> (-1, 8, -1, 32)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Transpose_3 for ONNX node: /bert/encoder/layer.2/attention/self/Transpose_3\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/Transpose_3_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/Transpose_3_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/self/Transpose_3 [Transpose] outputs: [/bert/encoder/layer.2/attention/self/Transpose_3_output_0 -> (-1, -1, 8, 32)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Shape_6 [Shape]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Transpose_3_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/self/Shape_6 [Shape] inputs: [/bert/encoder/layer.2/attention/self/Transpose_3_output_0 -> (-1, -1, 8, 32)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Shape_6 for ONNX node: /bert/encoder/layer.2/attention/self/Shape_6\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/Shape_6_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/Shape_6_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/self/Shape_6 [Shape] outputs: [/bert/encoder/layer.2/attention/self/Shape_6_output_0 -> (4)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Constant_13 [Constant]\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/self/Constant_13 [Constant] inputs: \n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/self/Constant_13 [Constant] outputs: [/bert/encoder/layer.2/attention/self/Constant_13_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Gather_6 [Gather]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Shape_6_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Constant_13_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/self/Gather_6 [Gather] inputs: [/bert/encoder/layer.2/attention/self/Shape_6_output_0 -> (4)[INT32]], [/bert/encoder/layer.2/attention/self/Constant_13_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Constant_13_output_0 for ONNX node: /bert/encoder/layer.2/attention/self/Constant_13_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Using Gather axis: 0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Gather_6 for ONNX node: /bert/encoder/layer.2/attention/self/Gather_6\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/Gather_6_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/Gather_6_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/self/Gather_6 [Gather] outputs: [/bert/encoder/layer.2/attention/self/Gather_6_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Shape_7 [Shape]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Transpose_3_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/self/Shape_7 [Shape] inputs: [/bert/encoder/layer.2/attention/self/Transpose_3_output_0 -> (-1, -1, 8, 32)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Shape_7 for ONNX node: /bert/encoder/layer.2/attention/self/Shape_7\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/Shape_7_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/Shape_7_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/self/Shape_7 [Shape] outputs: [/bert/encoder/layer.2/attention/self/Shape_7_output_0 -> (4)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Constant_14 [Constant]\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/self/Constant_14 [Constant] inputs: \n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/self/Constant_14 [Constant] outputs: [/bert/encoder/layer.2/attention/self/Constant_14_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Gather_7 [Gather]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Shape_7_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Constant_14_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/self/Gather_7 [Gather] inputs: [/bert/encoder/layer.2/attention/self/Shape_7_output_0 -> (4)[INT32]], [/bert/encoder/layer.2/attention/self/Constant_14_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Constant_14_output_0 for ONNX node: /bert/encoder/layer.2/attention/self/Constant_14_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Using Gather axis: 0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Gather_7 for ONNX node: /bert/encoder/layer.2/attention/self/Gather_7\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/Gather_7_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/Gather_7_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/self/Gather_7 [Gather] outputs: [/bert/encoder/layer.2/attention/self/Gather_7_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Unsqueeze_6 [Unsqueeze]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Gather_6_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/self/Unsqueeze_6 [Unsqueeze] inputs: [/bert/encoder/layer.2/attention/self/Gather_6_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Unsqueeze_6 for ONNX node: /bert/encoder/layer.2/attention/self/Unsqueeze_6\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/Unsqueeze_6_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/Unsqueeze_6_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/self/Unsqueeze_6 [Unsqueeze] outputs: [/bert/encoder/layer.2/attention/self/Unsqueeze_6_output_0 -> (1)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Unsqueeze_7 [Unsqueeze]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Gather_7_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/self/Unsqueeze_7 [Unsqueeze] inputs: [/bert/encoder/layer.2/attention/self/Gather_7_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Unsqueeze_7 for ONNX node: /bert/encoder/layer.2/attention/self/Unsqueeze_7\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/Unsqueeze_7_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/Unsqueeze_7_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/self/Unsqueeze_7 [Unsqueeze] outputs: [/bert/encoder/layer.2/attention/self/Unsqueeze_7_output_0 -> (1)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Constant_15 [Constant]\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/self/Constant_15 [Constant] inputs: \n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/self/Constant_15 [Constant] outputs: [/bert/encoder/layer.2/attention/self/Constant_15_output_0 -> (1)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Concat_3 [Concat]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Unsqueeze_6_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Unsqueeze_7_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Constant_15_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/self/Concat_3 [Concat] inputs: [/bert/encoder/layer.2/attention/self/Unsqueeze_6_output_0 -> (1)[INT32]], [/bert/encoder/layer.2/attention/self/Unsqueeze_7_output_0 -> (1)[INT32]], [/bert/encoder/layer.2/attention/self/Constant_15_output_0 -> (1)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Constant_15_output_0 for ONNX node: /bert/encoder/layer.2/attention/self/Constant_15_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Concat_3 for ONNX node: /bert/encoder/layer.2/attention/self/Concat_3\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/Concat_3_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/Concat_3_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/self/Concat_3 [Concat] outputs: [/bert/encoder/layer.2/attention/self/Concat_3_output_0 -> (3)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/self/Reshape_3 [Reshape]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Transpose_3_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Concat_3_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/self/Reshape_3 [Reshape] inputs: [/bert/encoder/layer.2/attention/self/Transpose_3_output_0 -> (-1, -1, 8, 32)[FLOAT]], [/bert/encoder/layer.2/attention/self/Concat_3_output_0 -> (3)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/self/Reshape_3 for ONNX node: /bert/encoder/layer.2/attention/self/Reshape_3\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/self/Reshape_3_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/self/Reshape_3_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/self/Reshape_3 [Reshape] outputs: [/bert/encoder/layer.2/attention/self/Reshape_3_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/output/dense/MatMul [MatMul]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/self/Reshape_3_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: onnx::MatMul_829\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/output/dense/MatMul [MatMul] inputs: [/bert/encoder/layer.2/attention/self/Reshape_3_output_0 -> (-1, -1, 256)[FLOAT]], [onnx::MatMul_829 -> (256, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: onnx::MatMul_829 for ONNX node: onnx::MatMul_829\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/output/dense/MatMul for ONNX node: /bert/encoder/layer.2/attention/output/dense/MatMul\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/output/dense/MatMul_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/output/dense/MatMul_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/output/dense/MatMul [MatMul] outputs: [/bert/encoder/layer.2/attention/output/dense/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/output/dense/Add [Add]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: bert.encoder.layer.2.attention.output.dense.bias\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/output/dense/MatMul_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/output/dense/Add [Add] inputs: [bert.encoder.layer.2.attention.output.dense.bias -> (256)[FLOAT]], [/bert/encoder/layer.2/attention/output/dense/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: bert.encoder.layer.2.attention.output.dense.bias for ONNX node: bert.encoder.layer.2.attention.output.dense.bias\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/output/dense/Add for ONNX node: /bert/encoder/layer.2/attention/output/dense/Add\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/output/dense/Add_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/output/dense/Add_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/output/dense/Add [Add] outputs: [/bert/encoder/layer.2/attention/output/dense/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/output/Add [Add]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/output/dense/Add_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.1/output/LayerNorm/Add_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/output/Add [Add] inputs: [/bert/encoder/layer.2/attention/output/dense/Add_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.1/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/output/Add for ONNX node: /bert/encoder/layer.2/attention/output/Add\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/output/Add_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/output/Add_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/output/Add [Add] outputs: [/bert/encoder/layer.2/attention/output/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/output/LayerNorm/ReduceMean [ReduceMean]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/output/Add_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/output/LayerNorm/ReduceMean [ReduceMean] inputs: [/bert/encoder/layer.2/attention/output/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/output/LayerNorm/ReduceMean for ONNX node: /bert/encoder/layer.2/attention/output/LayerNorm/ReduceMean\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/output/LayerNorm/ReduceMean_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/output/LayerNorm/ReduceMean_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/output/LayerNorm/ReduceMean [ReduceMean] outputs: [/bert/encoder/layer.2/attention/output/LayerNorm/ReduceMean_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/output/LayerNorm/Sub [Sub]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/output/Add_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/output/LayerNorm/ReduceMean_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/output/LayerNorm/Sub [Sub] inputs: [/bert/encoder/layer.2/attention/output/Add_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.2/attention/output/LayerNorm/ReduceMean_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/output/LayerNorm/Sub for ONNX node: /bert/encoder/layer.2/attention/output/LayerNorm/Sub\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/output/LayerNorm/Sub_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/output/LayerNorm/Sub_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/output/LayerNorm/Sub [Sub] outputs: [/bert/encoder/layer.2/attention/output/LayerNorm/Sub_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/output/LayerNorm/Constant [Constant]\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/output/LayerNorm/Constant [Constant] inputs: \n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/output/LayerNorm/Constant [Constant] outputs: [/bert/encoder/layer.2/attention/output/LayerNorm/Constant_output_0 -> ()[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/output/LayerNorm/Pow [Pow]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/output/LayerNorm/Sub_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/output/LayerNorm/Constant_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/output/LayerNorm/Pow [Pow] inputs: [/bert/encoder/layer.2/attention/output/LayerNorm/Sub_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.2/attention/output/LayerNorm/Constant_output_0 -> ()[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/output/LayerNorm/Constant_output_0 for ONNX node: /bert/encoder/layer.2/attention/output/LayerNorm/Constant_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/output/LayerNorm/Pow for ONNX node: /bert/encoder/layer.2/attention/output/LayerNorm/Pow\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/output/LayerNorm/Pow_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/output/LayerNorm/Pow_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/output/LayerNorm/Pow [Pow] outputs: [/bert/encoder/layer.2/attention/output/LayerNorm/Pow_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/output/LayerNorm/ReduceMean_1 [ReduceMean]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/output/LayerNorm/Pow_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/output/LayerNorm/ReduceMean_1 [ReduceMean] inputs: [/bert/encoder/layer.2/attention/output/LayerNorm/Pow_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/output/LayerNorm/ReduceMean_1 for ONNX node: /bert/encoder/layer.2/attention/output/LayerNorm/ReduceMean_1\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/output/LayerNorm/ReduceMean_1_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/output/LayerNorm/ReduceMean_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/output/LayerNorm/ReduceMean_1 [ReduceMean] outputs: [/bert/encoder/layer.2/attention/output/LayerNorm/ReduceMean_1_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/output/LayerNorm/Constant_1 [Constant]\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/output/LayerNorm/Constant_1 [Constant] inputs: \n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/output/LayerNorm/Constant_1 [Constant] outputs: [/bert/encoder/layer.2/attention/output/LayerNorm/Constant_1_output_0 -> ()[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/output/LayerNorm/Add [Add]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/output/LayerNorm/ReduceMean_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/output/LayerNorm/Constant_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/output/LayerNorm/Add [Add] inputs: [/bert/encoder/layer.2/attention/output/LayerNorm/ReduceMean_1_output_0 -> (-1, -1, 1)[FLOAT]], [/bert/encoder/layer.2/attention/output/LayerNorm/Constant_1_output_0 -> ()[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/output/LayerNorm/Constant_1_output_0 for ONNX node: /bert/encoder/layer.2/attention/output/LayerNorm/Constant_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/output/LayerNorm/Add for ONNX node: /bert/encoder/layer.2/attention/output/LayerNorm/Add\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/output/LayerNorm/Add_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/output/LayerNorm/Add_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/output/LayerNorm/Add [Add] outputs: [/bert/encoder/layer.2/attention/output/LayerNorm/Add_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/output/LayerNorm/Sqrt [Sqrt]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/output/LayerNorm/Add_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/output/LayerNorm/Sqrt [Sqrt] inputs: [/bert/encoder/layer.2/attention/output/LayerNorm/Add_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/output/LayerNorm/Sqrt for ONNX node: /bert/encoder/layer.2/attention/output/LayerNorm/Sqrt\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/output/LayerNorm/Sqrt_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/output/LayerNorm/Sqrt_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/output/LayerNorm/Sqrt [Sqrt] outputs: [/bert/encoder/layer.2/attention/output/LayerNorm/Sqrt_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/output/LayerNorm/Div [Div]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/output/LayerNorm/Sub_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/output/LayerNorm/Sqrt_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/output/LayerNorm/Div [Div] inputs: [/bert/encoder/layer.2/attention/output/LayerNorm/Sub_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.2/attention/output/LayerNorm/Sqrt_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/output/LayerNorm/Div for ONNX node: /bert/encoder/layer.2/attention/output/LayerNorm/Div\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/output/LayerNorm/Div_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/output/LayerNorm/Div_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/output/LayerNorm/Div [Div] outputs: [/bert/encoder/layer.2/attention/output/LayerNorm/Div_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/output/LayerNorm/Mul [Mul]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/output/LayerNorm/Div_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: bert.encoder.layer.2.attention.output.LayerNorm.weight\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/output/LayerNorm/Mul [Mul] inputs: [/bert/encoder/layer.2/attention/output/LayerNorm/Div_output_0 -> (-1, -1, 256)[FLOAT]], [bert.encoder.layer.2.attention.output.LayerNorm.weight -> (256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: bert.encoder.layer.2.attention.output.LayerNorm.weight for ONNX node: bert.encoder.layer.2.attention.output.LayerNorm.weight\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/output/LayerNorm/Mul for ONNX node: /bert/encoder/layer.2/attention/output/LayerNorm/Mul\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/output/LayerNorm/Mul_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/output/LayerNorm/Mul_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/output/LayerNorm/Mul [Mul] outputs: [/bert/encoder/layer.2/attention/output/LayerNorm/Mul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.2/attention/output/LayerNorm/Add_1 [Add]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/output/LayerNorm/Mul_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: bert.encoder.layer.2.attention.output.LayerNorm.bias\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/output/LayerNorm/Add_1 [Add] inputs: [/bert/encoder/layer.2/attention/output/LayerNorm/Mul_output_0 -> (-1, -1, 256)[FLOAT]], [bert.encoder.layer.2.attention.output.LayerNorm.bias -> (256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: bert.encoder.layer.2.attention.output.LayerNorm.bias for ONNX node: bert.encoder.layer.2.attention.output.LayerNorm.bias\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.2/attention/output/LayerNorm/Add_1 for ONNX node: /bert/encoder/layer.2/attention/output/LayerNorm/Add_1\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.2/attention/output/LayerNorm/Add_1_output_0 for ONNX tensor: /bert/encoder/layer.2/attention/output/LayerNorm/Add_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/attention/output/LayerNorm/Add_1 [Add] outputs: [/bert/encoder/layer.2/attention/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.2/intermediate/dense/MatMul [MatMul]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/output/LayerNorm/Add_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: onnx::MatMul_830\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/intermediate/dense/MatMul [MatMul] inputs: [/bert/encoder/layer.2/attention/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], [onnx::MatMul_830 -> (256, 1024)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: onnx::MatMul_830 for ONNX node: onnx::MatMul_830\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.2/intermediate/dense/MatMul for ONNX node: /bert/encoder/layer.2/intermediate/dense/MatMul\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.2/intermediate/dense/MatMul_output_0 for ONNX tensor: /bert/encoder/layer.2/intermediate/dense/MatMul_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/intermediate/dense/MatMul [MatMul] outputs: [/bert/encoder/layer.2/intermediate/dense/MatMul_output_0 -> (-1, -1, 1024)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.2/intermediate/dense/Add [Add]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: bert.encoder.layer.2.intermediate.dense.bias\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.2/intermediate/dense/MatMul_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/intermediate/dense/Add [Add] inputs: [bert.encoder.layer.2.intermediate.dense.bias -> (1024)[FLOAT]], [/bert/encoder/layer.2/intermediate/dense/MatMul_output_0 -> (-1, -1, 1024)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: bert.encoder.layer.2.intermediate.dense.bias for ONNX node: bert.encoder.layer.2.intermediate.dense.bias\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.2/intermediate/dense/Add for ONNX node: /bert/encoder/layer.2/intermediate/dense/Add\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.2/intermediate/dense/Add_output_0 for ONNX tensor: /bert/encoder/layer.2/intermediate/dense/Add_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/intermediate/dense/Add [Add] outputs: [/bert/encoder/layer.2/intermediate/dense/Add_output_0 -> (-1, -1, 1024)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.2/intermediate/intermediate_act_fn/Constant [Constant]\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/intermediate/intermediate_act_fn/Constant [Constant] inputs: \n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/intermediate/intermediate_act_fn/Constant [Constant] outputs: [/bert/encoder/layer.2/intermediate/intermediate_act_fn/Constant_output_0 -> ()[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.2/intermediate/intermediate_act_fn/Div [Div]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.2/intermediate/dense/Add_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.2/intermediate/intermediate_act_fn/Constant_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/intermediate/intermediate_act_fn/Div [Div] inputs: [/bert/encoder/layer.2/intermediate/dense/Add_output_0 -> (-1, -1, 1024)[FLOAT]], [/bert/encoder/layer.2/intermediate/intermediate_act_fn/Constant_output_0 -> ()[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.2/intermediate/intermediate_act_fn/Constant_output_0 for ONNX node: /bert/encoder/layer.2/intermediate/intermediate_act_fn/Constant_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.2/intermediate/intermediate_act_fn/Div for ONNX node: /bert/encoder/layer.2/intermediate/intermediate_act_fn/Div\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.2/intermediate/intermediate_act_fn/Div_output_0 for ONNX tensor: /bert/encoder/layer.2/intermediate/intermediate_act_fn/Div_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/intermediate/intermediate_act_fn/Div [Div] outputs: [/bert/encoder/layer.2/intermediate/intermediate_act_fn/Div_output_0 -> (-1, -1, 1024)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.2/intermediate/intermediate_act_fn/Erf [Erf]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.2/intermediate/intermediate_act_fn/Div_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/intermediate/intermediate_act_fn/Erf [Erf] inputs: [/bert/encoder/layer.2/intermediate/intermediate_act_fn/Div_output_0 -> (-1, -1, 1024)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.2/intermediate/intermediate_act_fn/Erf for ONNX node: /bert/encoder/layer.2/intermediate/intermediate_act_fn/Erf\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.2/intermediate/intermediate_act_fn/Erf_output_0 for ONNX tensor: /bert/encoder/layer.2/intermediate/intermediate_act_fn/Erf_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/intermediate/intermediate_act_fn/Erf [Erf] outputs: [/bert/encoder/layer.2/intermediate/intermediate_act_fn/Erf_output_0 -> (-1, -1, 1024)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.2/intermediate/intermediate_act_fn/Constant_1 [Constant]\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/intermediate/intermediate_act_fn/Constant_1 [Constant] inputs: \n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/intermediate/intermediate_act_fn/Constant_1 [Constant] outputs: [/bert/encoder/layer.2/intermediate/intermediate_act_fn/Constant_1_output_0 -> ()[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.2/intermediate/intermediate_act_fn/Add [Add]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.2/intermediate/intermediate_act_fn/Erf_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.2/intermediate/intermediate_act_fn/Constant_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/intermediate/intermediate_act_fn/Add [Add] inputs: [/bert/encoder/layer.2/intermediate/intermediate_act_fn/Erf_output_0 -> (-1, -1, 1024)[FLOAT]], [/bert/encoder/layer.2/intermediate/intermediate_act_fn/Constant_1_output_0 -> ()[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.2/intermediate/intermediate_act_fn/Constant_1_output_0 for ONNX node: /bert/encoder/layer.2/intermediate/intermediate_act_fn/Constant_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.2/intermediate/intermediate_act_fn/Add for ONNX node: /bert/encoder/layer.2/intermediate/intermediate_act_fn/Add\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.2/intermediate/intermediate_act_fn/Add_output_0 for ONNX tensor: /bert/encoder/layer.2/intermediate/intermediate_act_fn/Add_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/intermediate/intermediate_act_fn/Add [Add] outputs: [/bert/encoder/layer.2/intermediate/intermediate_act_fn/Add_output_0 -> (-1, -1, 1024)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.2/intermediate/intermediate_act_fn/Mul [Mul]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.2/intermediate/dense/Add_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.2/intermediate/intermediate_act_fn/Add_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/intermediate/intermediate_act_fn/Mul [Mul] inputs: [/bert/encoder/layer.2/intermediate/dense/Add_output_0 -> (-1, -1, 1024)[FLOAT]], [/bert/encoder/layer.2/intermediate/intermediate_act_fn/Add_output_0 -> (-1, -1, 1024)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.2/intermediate/intermediate_act_fn/Mul for ONNX node: /bert/encoder/layer.2/intermediate/intermediate_act_fn/Mul\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.2/intermediate/intermediate_act_fn/Mul_output_0 for ONNX tensor: /bert/encoder/layer.2/intermediate/intermediate_act_fn/Mul_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/intermediate/intermediate_act_fn/Mul [Mul] outputs: [/bert/encoder/layer.2/intermediate/intermediate_act_fn/Mul_output_0 -> (-1, -1, 1024)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.2/intermediate/intermediate_act_fn/Constant_2 [Constant]\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/intermediate/intermediate_act_fn/Constant_2 [Constant] inputs: \n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/intermediate/intermediate_act_fn/Constant_2 [Constant] outputs: [/bert/encoder/layer.2/intermediate/intermediate_act_fn/Constant_2_output_0 -> ()[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.2/intermediate/intermediate_act_fn/Mul_1 [Mul]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.2/intermediate/intermediate_act_fn/Mul_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.2/intermediate/intermediate_act_fn/Constant_2_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/intermediate/intermediate_act_fn/Mul_1 [Mul] inputs: [/bert/encoder/layer.2/intermediate/intermediate_act_fn/Mul_output_0 -> (-1, -1, 1024)[FLOAT]], [/bert/encoder/layer.2/intermediate/intermediate_act_fn/Constant_2_output_0 -> ()[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.2/intermediate/intermediate_act_fn/Constant_2_output_0 for ONNX node: /bert/encoder/layer.2/intermediate/intermediate_act_fn/Constant_2_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.2/intermediate/intermediate_act_fn/Mul_1 for ONNX node: /bert/encoder/layer.2/intermediate/intermediate_act_fn/Mul_1\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.2/intermediate/intermediate_act_fn/Mul_1_output_0 for ONNX tensor: /bert/encoder/layer.2/intermediate/intermediate_act_fn/Mul_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/intermediate/intermediate_act_fn/Mul_1 [Mul] outputs: [/bert/encoder/layer.2/intermediate/intermediate_act_fn/Mul_1_output_0 -> (-1, -1, 1024)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.2/output/dense/MatMul [MatMul]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.2/intermediate/intermediate_act_fn/Mul_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: onnx::MatMul_831\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/output/dense/MatMul [MatMul] inputs: [/bert/encoder/layer.2/intermediate/intermediate_act_fn/Mul_1_output_0 -> (-1, -1, 1024)[FLOAT]], [onnx::MatMul_831 -> (1024, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: onnx::MatMul_831 for ONNX node: onnx::MatMul_831\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.2/output/dense/MatMul for ONNX node: /bert/encoder/layer.2/output/dense/MatMul\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.2/output/dense/MatMul_output_0 for ONNX tensor: /bert/encoder/layer.2/output/dense/MatMul_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/output/dense/MatMul [MatMul] outputs: [/bert/encoder/layer.2/output/dense/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.2/output/dense/Add [Add]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: bert.encoder.layer.2.output.dense.bias\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.2/output/dense/MatMul_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/output/dense/Add [Add] inputs: [bert.encoder.layer.2.output.dense.bias -> (256)[FLOAT]], [/bert/encoder/layer.2/output/dense/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: bert.encoder.layer.2.output.dense.bias for ONNX node: bert.encoder.layer.2.output.dense.bias\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.2/output/dense/Add for ONNX node: /bert/encoder/layer.2/output/dense/Add\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.2/output/dense/Add_output_0 for ONNX tensor: /bert/encoder/layer.2/output/dense/Add_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/output/dense/Add [Add] outputs: [/bert/encoder/layer.2/output/dense/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.2/output/Add [Add]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.2/output/dense/Add_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.2/attention/output/LayerNorm/Add_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/output/Add [Add] inputs: [/bert/encoder/layer.2/output/dense/Add_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.2/attention/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.2/output/Add for ONNX node: /bert/encoder/layer.2/output/Add\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.2/output/Add_output_0 for ONNX tensor: /bert/encoder/layer.2/output/Add_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/output/Add [Add] outputs: [/bert/encoder/layer.2/output/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.2/output/LayerNorm/ReduceMean [ReduceMean]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.2/output/Add_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/output/LayerNorm/ReduceMean [ReduceMean] inputs: [/bert/encoder/layer.2/output/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.2/output/LayerNorm/ReduceMean for ONNX node: /bert/encoder/layer.2/output/LayerNorm/ReduceMean\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.2/output/LayerNorm/ReduceMean_output_0 for ONNX tensor: /bert/encoder/layer.2/output/LayerNorm/ReduceMean_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/output/LayerNorm/ReduceMean [ReduceMean] outputs: [/bert/encoder/layer.2/output/LayerNorm/ReduceMean_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.2/output/LayerNorm/Sub [Sub]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.2/output/Add_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.2/output/LayerNorm/ReduceMean_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/output/LayerNorm/Sub [Sub] inputs: [/bert/encoder/layer.2/output/Add_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.2/output/LayerNorm/ReduceMean_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.2/output/LayerNorm/Sub for ONNX node: /bert/encoder/layer.2/output/LayerNorm/Sub\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.2/output/LayerNorm/Sub_output_0 for ONNX tensor: /bert/encoder/layer.2/output/LayerNorm/Sub_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/output/LayerNorm/Sub [Sub] outputs: [/bert/encoder/layer.2/output/LayerNorm/Sub_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.2/output/LayerNorm/Constant [Constant]\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/output/LayerNorm/Constant [Constant] inputs: \n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/output/LayerNorm/Constant [Constant] outputs: [/bert/encoder/layer.2/output/LayerNorm/Constant_output_0 -> ()[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.2/output/LayerNorm/Pow [Pow]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.2/output/LayerNorm/Sub_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.2/output/LayerNorm/Constant_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/output/LayerNorm/Pow [Pow] inputs: [/bert/encoder/layer.2/output/LayerNorm/Sub_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.2/output/LayerNorm/Constant_output_0 -> ()[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.2/output/LayerNorm/Constant_output_0 for ONNX node: /bert/encoder/layer.2/output/LayerNorm/Constant_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.2/output/LayerNorm/Pow for ONNX node: /bert/encoder/layer.2/output/LayerNorm/Pow\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.2/output/LayerNorm/Pow_output_0 for ONNX tensor: /bert/encoder/layer.2/output/LayerNorm/Pow_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/output/LayerNorm/Pow [Pow] outputs: [/bert/encoder/layer.2/output/LayerNorm/Pow_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.2/output/LayerNorm/ReduceMean_1 [ReduceMean]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.2/output/LayerNorm/Pow_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/output/LayerNorm/ReduceMean_1 [ReduceMean] inputs: [/bert/encoder/layer.2/output/LayerNorm/Pow_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.2/output/LayerNorm/ReduceMean_1 for ONNX node: /bert/encoder/layer.2/output/LayerNorm/ReduceMean_1\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.2/output/LayerNorm/ReduceMean_1_output_0 for ONNX tensor: /bert/encoder/layer.2/output/LayerNorm/ReduceMean_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/output/LayerNorm/ReduceMean_1 [ReduceMean] outputs: [/bert/encoder/layer.2/output/LayerNorm/ReduceMean_1_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.2/output/LayerNorm/Constant_1 [Constant]\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/output/LayerNorm/Constant_1 [Constant] inputs: \n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/output/LayerNorm/Constant_1 [Constant] outputs: [/bert/encoder/layer.2/output/LayerNorm/Constant_1_output_0 -> ()[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.2/output/LayerNorm/Add [Add]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.2/output/LayerNorm/ReduceMean_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.2/output/LayerNorm/Constant_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/output/LayerNorm/Add [Add] inputs: [/bert/encoder/layer.2/output/LayerNorm/ReduceMean_1_output_0 -> (-1, -1, 1)[FLOAT]], [/bert/encoder/layer.2/output/LayerNorm/Constant_1_output_0 -> ()[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.2/output/LayerNorm/Constant_1_output_0 for ONNX node: /bert/encoder/layer.2/output/LayerNorm/Constant_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.2/output/LayerNorm/Add for ONNX node: /bert/encoder/layer.2/output/LayerNorm/Add\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.2/output/LayerNorm/Add_output_0 for ONNX tensor: /bert/encoder/layer.2/output/LayerNorm/Add_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/output/LayerNorm/Add [Add] outputs: [/bert/encoder/layer.2/output/LayerNorm/Add_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.2/output/LayerNorm/Sqrt [Sqrt]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.2/output/LayerNorm/Add_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/output/LayerNorm/Sqrt [Sqrt] inputs: [/bert/encoder/layer.2/output/LayerNorm/Add_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.2/output/LayerNorm/Sqrt for ONNX node: /bert/encoder/layer.2/output/LayerNorm/Sqrt\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.2/output/LayerNorm/Sqrt_output_0 for ONNX tensor: /bert/encoder/layer.2/output/LayerNorm/Sqrt_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/output/LayerNorm/Sqrt [Sqrt] outputs: [/bert/encoder/layer.2/output/LayerNorm/Sqrt_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.2/output/LayerNorm/Div [Div]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.2/output/LayerNorm/Sub_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.2/output/LayerNorm/Sqrt_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/output/LayerNorm/Div [Div] inputs: [/bert/encoder/layer.2/output/LayerNorm/Sub_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.2/output/LayerNorm/Sqrt_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.2/output/LayerNorm/Div for ONNX node: /bert/encoder/layer.2/output/LayerNorm/Div\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.2/output/LayerNorm/Div_output_0 for ONNX tensor: /bert/encoder/layer.2/output/LayerNorm/Div_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/output/LayerNorm/Div [Div] outputs: [/bert/encoder/layer.2/output/LayerNorm/Div_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.2/output/LayerNorm/Mul [Mul]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.2/output/LayerNorm/Div_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: bert.encoder.layer.2.output.LayerNorm.weight\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/output/LayerNorm/Mul [Mul] inputs: [/bert/encoder/layer.2/output/LayerNorm/Div_output_0 -> (-1, -1, 256)[FLOAT]], [bert.encoder.layer.2.output.LayerNorm.weight -> (256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: bert.encoder.layer.2.output.LayerNorm.weight for ONNX node: bert.encoder.layer.2.output.LayerNorm.weight\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.2/output/LayerNorm/Mul for ONNX node: /bert/encoder/layer.2/output/LayerNorm/Mul\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.2/output/LayerNorm/Mul_output_0 for ONNX tensor: /bert/encoder/layer.2/output/LayerNorm/Mul_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/output/LayerNorm/Mul [Mul] outputs: [/bert/encoder/layer.2/output/LayerNorm/Mul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.2/output/LayerNorm/Add_1 [Add]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.2/output/LayerNorm/Mul_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: bert.encoder.layer.2.output.LayerNorm.bias\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/output/LayerNorm/Add_1 [Add] inputs: [/bert/encoder/layer.2/output/LayerNorm/Mul_output_0 -> (-1, -1, 256)[FLOAT]], [bert.encoder.layer.2.output.LayerNorm.bias -> (256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: bert.encoder.layer.2.output.LayerNorm.bias for ONNX node: bert.encoder.layer.2.output.LayerNorm.bias\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.2/output/LayerNorm/Add_1 for ONNX node: /bert/encoder/layer.2/output/LayerNorm/Add_1\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.2/output/LayerNorm/Add_1_output_0 for ONNX tensor: /bert/encoder/layer.2/output/LayerNorm/Add_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.2/output/LayerNorm/Add_1 [Add] outputs: [/bert/encoder/layer.2/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/query/MatMul [MatMul]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.2/output/LayerNorm/Add_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: onnx::MatMul_832\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.3/attention/self/query/MatMul [MatMul] inputs: [/bert/encoder/layer.2/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], [onnx::MatMul_832 -> (256, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: onnx::MatMul_832 for ONNX node: onnx::MatMul_832\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/query/MatMul for ONNX node: /bert/encoder/layer.3/attention/self/query/MatMul\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/query/MatMul_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/query/MatMul_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.3/attention/self/query/MatMul [MatMul] outputs: [/bert/encoder/layer.3/attention/self/query/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/query/Add [Add]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: bert.encoder.layer.3.attention.self.query.bias\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/query/MatMul_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.3/attention/self/query/Add [Add] inputs: [bert.encoder.layer.3.attention.self.query.bias -> (256)[FLOAT]], [/bert/encoder/layer.3/attention/self/query/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: bert.encoder.layer.3.attention.self.query.bias for ONNX node: bert.encoder.layer.3.attention.self.query.bias\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/query/Add for ONNX node: /bert/encoder/layer.3/attention/self/query/Add\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/query/Add_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/query/Add_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.3/attention/self/query/Add [Add] outputs: [/bert/encoder/layer.3/attention/self/query/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/key/MatMul [MatMul]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.2/output/LayerNorm/Add_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: onnx::MatMul_833\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.3/attention/self/key/MatMul [MatMul] inputs: [/bert/encoder/layer.2/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], [onnx::MatMul_833 -> (256, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: onnx::MatMul_833 for ONNX node: onnx::MatMul_833\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/key/MatMul for ONNX node: /bert/encoder/layer.3/attention/self/key/MatMul\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/key/MatMul_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/key/MatMul_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.3/attention/self/key/MatMul [MatMul] outputs: [/bert/encoder/layer.3/attention/self/key/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/key/Add [Add]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: bert.encoder.layer.3.attention.self.key.bias\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/key/MatMul_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.3/attention/self/key/Add [Add] inputs: [bert.encoder.layer.3.attention.self.key.bias -> (256)[FLOAT]], [/bert/encoder/layer.3/attention/self/key/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: bert.encoder.layer.3.attention.self.key.bias for ONNX node: bert.encoder.layer.3.attention.self.key.bias\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/key/Add for ONNX node: /bert/encoder/layer.3/attention/self/key/Add\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/key/Add_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/key/Add_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.3/attention/self/key/Add [Add] outputs: [/bert/encoder/layer.3/attention/self/key/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Shape [Shape]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/key/Add_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.3/attention/self/Shape [Shape] inputs: [/bert/encoder/layer.3/attention/self/key/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Shape for ONNX node: /bert/encoder/layer.3/attention/self/Shape\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/Shape_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/Shape_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.3/attention/self/Shape [Shape] outputs: [/bert/encoder/layer.3/attention/self/Shape_output_0 -> (3)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Constant [Constant]\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.3/attention/self/Constant [Constant] inputs: \n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.3/attention/self/Constant [Constant] outputs: [/bert/encoder/layer.3/attention/self/Constant_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Gather [Gather]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Shape_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Constant_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.3/attention/self/Gather [Gather] inputs: [/bert/encoder/layer.3/attention/self/Shape_output_0 -> (3)[INT32]], [/bert/encoder/layer.3/attention/self/Constant_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Constant_output_0 for ONNX node: /bert/encoder/layer.3/attention/self/Constant_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Using Gather axis: 0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Gather for ONNX node: /bert/encoder/layer.3/attention/self/Gather\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/Gather_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/Gather_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.3/attention/self/Gather [Gather] outputs: [/bert/encoder/layer.3/attention/self/Gather_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Shape_1 [Shape]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/key/Add_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.3/attention/self/Shape_1 [Shape] inputs: [/bert/encoder/layer.3/attention/self/key/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Shape_1 for ONNX node: /bert/encoder/layer.3/attention/self/Shape_1\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/Shape_1_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/Shape_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.3/attention/self/Shape_1 [Shape] outputs: [/bert/encoder/layer.3/attention/self/Shape_1_output_0 -> (3)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Constant_1 [Constant]\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.3/attention/self/Constant_1 [Constant] inputs: \n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.3/attention/self/Constant_1 [Constant] outputs: [/bert/encoder/layer.3/attention/self/Constant_1_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Gather_1 [Gather]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Shape_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Constant_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.3/attention/self/Gather_1 [Gather] inputs: [/bert/encoder/layer.3/attention/self/Shape_1_output_0 -> (3)[INT32]], [/bert/encoder/layer.3/attention/self/Constant_1_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Constant_1_output_0 for ONNX node: /bert/encoder/layer.3/attention/self/Constant_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Using Gather axis: 0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Gather_1 for ONNX node: /bert/encoder/layer.3/attention/self/Gather_1\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/Gather_1_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/Gather_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.3/attention/self/Gather_1 [Gather] outputs: [/bert/encoder/layer.3/attention/self/Gather_1_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Unsqueeze [Unsqueeze]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Gather_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.3/attention/self/Unsqueeze [Unsqueeze] inputs: [/bert/encoder/layer.3/attention/self/Gather_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Unsqueeze for ONNX node: /bert/encoder/layer.3/attention/self/Unsqueeze\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/Unsqueeze_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/Unsqueeze_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.3/attention/self/Unsqueeze [Unsqueeze] outputs: [/bert/encoder/layer.3/attention/self/Unsqueeze_output_0 -> (1)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Unsqueeze_1 [Unsqueeze]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Gather_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.3/attention/self/Unsqueeze_1 [Unsqueeze] inputs: [/bert/encoder/layer.3/attention/self/Gather_1_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Unsqueeze_1 for ONNX node: /bert/encoder/layer.3/attention/self/Unsqueeze_1\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/Unsqueeze_1_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/Unsqueeze_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.3/attention/self/Unsqueeze_1 [Unsqueeze] outputs: [/bert/encoder/layer.3/attention/self/Unsqueeze_1_output_0 -> (1)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Constant_2 [Constant]\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.3/attention/self/Constant_2 [Constant] inputs: \n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.3/attention/self/Constant_2 [Constant] outputs: [/bert/encoder/layer.3/attention/self/Constant_2_output_0 -> (1)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Constant_3 [Constant]\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.3/attention/self/Constant_3 [Constant] inputs: \n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.3/attention/self/Constant_3 [Constant] outputs: [/bert/encoder/layer.3/attention/self/Constant_3_output_0 -> (1)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Concat [Concat]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Unsqueeze_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Unsqueeze_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Constant_2_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Constant_3_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.3/attention/self/Concat [Concat] inputs: [/bert/encoder/layer.3/attention/self/Unsqueeze_output_0 -> (1)[INT32]], [/bert/encoder/layer.3/attention/self/Unsqueeze_1_output_0 -> (1)[INT32]], [/bert/encoder/layer.3/attention/self/Constant_2_output_0 -> (1)[INT32]], [/bert/encoder/layer.3/attention/self/Constant_3_output_0 -> (1)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Constant_2_output_0 for ONNX node: /bert/encoder/layer.3/attention/self/Constant_2_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Constant_3_output_0 for ONNX node: /bert/encoder/layer.3/attention/self/Constant_3_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Concat for ONNX node: /bert/encoder/layer.3/attention/self/Concat\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/Concat_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/Concat_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.3/attention/self/Concat [Concat] outputs: [/bert/encoder/layer.3/attention/self/Concat_output_0 -> (4)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Reshape [Reshape]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/key/Add_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Concat_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.3/attention/self/Reshape [Reshape] inputs: [/bert/encoder/layer.3/attention/self/key/Add_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.3/attention/self/Concat_output_0 -> (4)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Reshape for ONNX node: /bert/encoder/layer.3/attention/self/Reshape\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/Reshape_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/Reshape_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.3/attention/self/Reshape [Reshape] outputs: [/bert/encoder/layer.3/attention/self/Reshape_output_0 -> (-1, -1, 8, 32)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/value/MatMul [MatMul]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.2/output/LayerNorm/Add_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: onnx::MatMul_836\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.3/attention/self/value/MatMul [MatMul] inputs: [/bert/encoder/layer.2/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], [onnx::MatMul_836 -> (256, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: onnx::MatMul_836 for ONNX node: onnx::MatMul_836\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/value/MatMul for ONNX node: /bert/encoder/layer.3/attention/self/value/MatMul\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/value/MatMul_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/value/MatMul_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.3/attention/self/value/MatMul [MatMul] outputs: [/bert/encoder/layer.3/attention/self/value/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/value/Add [Add]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: bert.encoder.layer.3.attention.self.value.bias\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/value/MatMul_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.3/attention/self/value/Add [Add] inputs: [bert.encoder.layer.3.attention.self.value.bias -> (256)[FLOAT]], [/bert/encoder/layer.3/attention/self/value/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: bert.encoder.layer.3.attention.self.value.bias for ONNX node: bert.encoder.layer.3.attention.self.value.bias\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/value/Add for ONNX node: /bert/encoder/layer.3/attention/self/value/Add\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/value/Add_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/value/Add_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.3/attention/self/value/Add [Add] outputs: [/bert/encoder/layer.3/attention/self/value/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Shape_2 [Shape]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/value/Add_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.3/attention/self/Shape_2 [Shape] inputs: [/bert/encoder/layer.3/attention/self/value/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Shape_2 for ONNX node: /bert/encoder/layer.3/attention/self/Shape_2\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/Shape_2_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/Shape_2_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.3/attention/self/Shape_2 [Shape] outputs: [/bert/encoder/layer.3/attention/self/Shape_2_output_0 -> (3)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Constant_4 [Constant]\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.3/attention/self/Constant_4 [Constant] inputs: \n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.3/attention/self/Constant_4 [Constant] outputs: [/bert/encoder/layer.3/attention/self/Constant_4_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Gather_2 [Gather]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Shape_2_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Constant_4_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.3/attention/self/Gather_2 [Gather] inputs: [/bert/encoder/layer.3/attention/self/Shape_2_output_0 -> (3)[INT32]], [/bert/encoder/layer.3/attention/self/Constant_4_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Constant_4_output_0 for ONNX node: /bert/encoder/layer.3/attention/self/Constant_4_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Using Gather axis: 0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Gather_2 for ONNX node: /bert/encoder/layer.3/attention/self/Gather_2\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/Gather_2_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/Gather_2_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.3/attention/self/Gather_2 [Gather] outputs: [/bert/encoder/layer.3/attention/self/Gather_2_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Shape_3 [Shape]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/value/Add_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.3/attention/self/Shape_3 [Shape] inputs: [/bert/encoder/layer.3/attention/self/value/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Shape_3 for ONNX node: /bert/encoder/layer.3/attention/self/Shape_3\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/Shape_3_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/Shape_3_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.3/attention/self/Shape_3 [Shape] outputs: [/bert/encoder/layer.3/attention/self/Shape_3_output_0 -> (3)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Constant_5 [Constant]\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.3/attention/self/Constant_5 [Constant] inputs: \n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.3/attention/self/Constant_5 [Constant] outputs: [/bert/encoder/layer.3/attention/self/Constant_5_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Gather_3 [Gather]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Shape_3_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Constant_5_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.3/attention/self/Gather_3 [Gather] inputs: [/bert/encoder/layer.3/attention/self/Shape_3_output_0 -> (3)[INT32]], [/bert/encoder/layer.3/attention/self/Constant_5_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Constant_5_output_0 for ONNX node: /bert/encoder/layer.3/attention/self/Constant_5_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Using Gather axis: 0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Gather_3 for ONNX node: /bert/encoder/layer.3/attention/self/Gather_3\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/Gather_3_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/Gather_3_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.3/attention/self/Gather_3 [Gather] outputs: [/bert/encoder/layer.3/attention/self/Gather_3_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Unsqueeze_2 [Unsqueeze]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Gather_2_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.3/attention/self/Unsqueeze_2 [Unsqueeze] inputs: [/bert/encoder/layer.3/attention/self/Gather_2_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Unsqueeze_2 for ONNX node: /bert/encoder/layer.3/attention/self/Unsqueeze_2\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/Unsqueeze_2_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/Unsqueeze_2_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.3/attention/self/Unsqueeze_2 [Unsqueeze] outputs: [/bert/encoder/layer.3/attention/self/Unsqueeze_2_output_0 -> (1)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Unsqueeze_3 [Unsqueeze]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Gather_3_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.3/attention/self/Unsqueeze_3 [Unsqueeze] inputs: [/bert/encoder/layer.3/attention/self/Gather_3_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Unsqueeze_3 for ONNX node: /bert/encoder/layer.3/attention/self/Unsqueeze_3\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/Unsqueeze_3_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/Unsqueeze_3_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.3/attention/self/Unsqueeze_3 [Unsqueeze] outputs: [/bert/encoder/layer.3/attention/self/Unsqueeze_3_output_0 -> (1)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Constant_6 [Constant]\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.3/attention/self/Constant_6 [Constant] inputs: \n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.3/attention/self/Constant_6 [Constant] outputs: [/bert/encoder/layer.3/attention/self/Constant_6_output_0 -> (1)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Constant_7 [Constant]\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.3/attention/self/Constant_7 [Constant] inputs: \n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.3/attention/self/Constant_7 [Constant] outputs: [/bert/encoder/layer.3/attention/self/Constant_7_output_0 -> (1)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Concat_1 [Concat]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Unsqueeze_2_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Unsqueeze_3_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Constant_6_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Constant_7_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.3/attention/self/Concat_1 [Concat] inputs: [/bert/encoder/layer.3/attention/self/Unsqueeze_2_output_0 -> (1)[INT32]], [/bert/encoder/layer.3/attention/self/Unsqueeze_3_output_0 -> (1)[INT32]], [/bert/encoder/layer.3/attention/self/Constant_6_output_0 -> (1)[INT32]], [/bert/encoder/layer.3/attention/self/Constant_7_output_0 -> (1)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Constant_6_output_0 for ONNX node: /bert/encoder/layer.3/attention/self/Constant_6_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Constant_7_output_0 for ONNX node: /bert/encoder/layer.3/attention/self/Constant_7_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Concat_1 for ONNX node: /bert/encoder/layer.3/attention/self/Concat_1\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/Concat_1_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/Concat_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.3/attention/self/Concat_1 [Concat] outputs: [/bert/encoder/layer.3/attention/self/Concat_1_output_0 -> (4)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Reshape_1 [Reshape]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/value/Add_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Concat_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.3/attention/self/Reshape_1 [Reshape] inputs: [/bert/encoder/layer.3/attention/self/value/Add_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.3/attention/self/Concat_1_output_0 -> (4)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Reshape_1 for ONNX node: /bert/encoder/layer.3/attention/self/Reshape_1\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/Reshape_1_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/Reshape_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.3/attention/self/Reshape_1 [Reshape] outputs: [/bert/encoder/layer.3/attention/self/Reshape_1_output_0 -> (-1, -1, 8, 32)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Transpose [Transpose]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Reshape_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.3/attention/self/Transpose [Transpose] inputs: [/bert/encoder/layer.3/attention/self/Reshape_1_output_0 -> (-1, -1, 8, 32)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Transpose for ONNX node: /bert/encoder/layer.3/attention/self/Transpose\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/Transpose_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/Transpose_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.3/attention/self/Transpose [Transpose] outputs: [/bert/encoder/layer.3/attention/self/Transpose_output_0 -> (-1, 8, -1, 32)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Shape_4 [Shape]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/query/Add_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.3/attention/self/Shape_4 [Shape] inputs: [/bert/encoder/layer.3/attention/self/query/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Shape_4 for ONNX node: /bert/encoder/layer.3/attention/self/Shape_4\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/Shape_4_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/Shape_4_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.3/attention/self/Shape_4 [Shape] outputs: [/bert/encoder/layer.3/attention/self/Shape_4_output_0 -> (3)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Constant_8 [Constant]\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.3/attention/self/Constant_8 [Constant] inputs: \n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.3/attention/self/Constant_8 [Constant] outputs: [/bert/encoder/layer.3/attention/self/Constant_8_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Gather_4 [Gather]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Shape_4_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Constant_8_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.3/attention/self/Gather_4 [Gather] inputs: [/bert/encoder/layer.3/attention/self/Shape_4_output_0 -> (3)[INT32]], [/bert/encoder/layer.3/attention/self/Constant_8_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Constant_8_output_0 for ONNX node: /bert/encoder/layer.3/attention/self/Constant_8_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Using Gather axis: 0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Gather_4 for ONNX node: /bert/encoder/layer.3/attention/self/Gather_4\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/Gather_4_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/Gather_4_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.3/attention/self/Gather_4 [Gather] outputs: [/bert/encoder/layer.3/attention/self/Gather_4_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Shape_5 [Shape]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/query/Add_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.3/attention/self/Shape_5 [Shape] inputs: [/bert/encoder/layer.3/attention/self/query/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Shape_5 for ONNX node: /bert/encoder/layer.3/attention/self/Shape_5\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/Shape_5_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/Shape_5_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.3/attention/self/Shape_5 [Shape] outputs: [/bert/encoder/layer.3/attention/self/Shape_5_output_0 -> (3)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Constant_9 [Constant]\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.3/attention/self/Constant_9 [Constant] inputs: \n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.3/attention/self/Constant_9 [Constant] outputs: [/bert/encoder/layer.3/attention/self/Constant_9_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Gather_5 [Gather]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Shape_5_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Constant_9_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.3/attention/self/Gather_5 [Gather] inputs: [/bert/encoder/layer.3/attention/self/Shape_5_output_0 -> (3)[INT32]], [/bert/encoder/layer.3/attention/self/Constant_9_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Constant_9_output_0 for ONNX node: /bert/encoder/layer.3/attention/self/Constant_9_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Using Gather axis: 0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Gather_5 for ONNX node: /bert/encoder/layer.3/attention/self/Gather_5\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/Gather_5_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/Gather_5_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.3/attention/self/Gather_5 [Gather] outputs: [/bert/encoder/layer.3/attention/self/Gather_5_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Unsqueeze_4 [Unsqueeze]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Gather_4_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.3/attention/self/Unsqueeze_4 [Unsqueeze] inputs: [/bert/encoder/layer.3/attention/self/Gather_4_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Unsqueeze_4 for ONNX node: /bert/encoder/layer.3/attention/self/Unsqueeze_4\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/Unsqueeze_4_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/Unsqueeze_4_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.3/attention/self/Unsqueeze_4 [Unsqueeze] outputs: [/bert/encoder/layer.3/attention/self/Unsqueeze_4_output_0 -> (1)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Unsqueeze_5 [Unsqueeze]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Gather_5_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.3/attention/self/Unsqueeze_5 [Unsqueeze] inputs: [/bert/encoder/layer.3/attention/self/Gather_5_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Unsqueeze_5 for ONNX node: /bert/encoder/layer.3/attention/self/Unsqueeze_5\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/Unsqueeze_5_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/Unsqueeze_5_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.3/attention/self/Unsqueeze_5 [Unsqueeze] outputs: [/bert/encoder/layer.3/attention/self/Unsqueeze_5_output_0 -> (1)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Constant_10 [Constant]\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.3/attention/self/Constant_10 [Constant] inputs: \n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.3/attention/self/Constant_10 [Constant] outputs: [/bert/encoder/layer.3/attention/self/Constant_10_output_0 -> (1)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Constant_11 [Constant]\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.3/attention/self/Constant_11 [Constant] inputs: \n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.3/attention/self/Constant_11 [Constant] outputs: [/bert/encoder/layer.3/attention/self/Constant_11_output_0 -> (1)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Concat_2 [Concat]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Unsqueeze_4_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Unsqueeze_5_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Constant_10_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Constant_11_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.3/attention/self/Concat_2 [Concat] inputs: [/bert/encoder/layer.3/attention/self/Unsqueeze_4_output_0 -> (1)[INT32]], [/bert/encoder/layer.3/attention/self/Unsqueeze_5_output_0 -> (1)[INT32]], [/bert/encoder/layer.3/attention/self/Constant_10_output_0 -> (1)[INT32]], [/bert/encoder/layer.3/attention/self/Constant_11_output_0 -> (1)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Constant_10_output_0 for ONNX node: /bert/encoder/layer.3/attention/self/Constant_10_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Constant_11_output_0 for ONNX node: /bert/encoder/layer.3/attention/self/Constant_11_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Concat_2 for ONNX node: /bert/encoder/layer.3/attention/self/Concat_2\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/Concat_2_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/Concat_2_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.3/attention/self/Concat_2 [Concat] outputs: [/bert/encoder/layer.3/attention/self/Concat_2_output_0 -> (4)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Reshape_2 [Reshape]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/query/Add_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Concat_2_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.3/attention/self/Reshape_2 [Reshape] inputs: [/bert/encoder/layer.3/attention/self/query/Add_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.3/attention/self/Concat_2_output_0 -> (4)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Reshape_2 for ONNX node: /bert/encoder/layer.3/attention/self/Reshape_2\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/Reshape_2_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/Reshape_2_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.3/attention/self/Reshape_2 [Reshape] outputs: [/bert/encoder/layer.3/attention/self/Reshape_2_output_0 -> (-1, -1, 8, 32)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Transpose_1 [Transpose]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Reshape_2_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.3/attention/self/Transpose_1 [Transpose] inputs: [/bert/encoder/layer.3/attention/self/Reshape_2_output_0 -> (-1, -1, 8, 32)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Transpose_1 for ONNX node: /bert/encoder/layer.3/attention/self/Transpose_1\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/Transpose_1_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/Transpose_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.3/attention/self/Transpose_1 [Transpose] outputs: [/bert/encoder/layer.3/attention/self/Transpose_1_output_0 -> (-1, 8, -1, 32)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Transpose_2 [Transpose]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Reshape_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.3/attention/self/Transpose_2 [Transpose] inputs: [/bert/encoder/layer.3/attention/self/Reshape_output_0 -> (-1, -1, 8, 32)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Transpose_2 for ONNX node: /bert/encoder/layer.3/attention/self/Transpose_2\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/Transpose_2_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/Transpose_2_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.3/attention/self/Transpose_2 [Transpose] outputs: [/bert/encoder/layer.3/attention/self/Transpose_2_output_0 -> (-1, 8, 32, -1)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/MatMul [MatMul]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Transpose_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Transpose_2_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.3/attention/self/MatMul [MatMul] inputs: [/bert/encoder/layer.3/attention/self/Transpose_1_output_0 -> (-1, 8, -1, 32)[FLOAT]], [/bert/encoder/layer.3/attention/self/Transpose_2_output_0 -> (-1, 8, 32, -1)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/MatMul for ONNX node: /bert/encoder/layer.3/attention/self/MatMul\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/MatMul_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/MatMul_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.3/attention/self/MatMul [MatMul] outputs: [/bert/encoder/layer.3/attention/self/MatMul_output_0 -> (-1, 8, -1, -1)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Constant_12 [Constant]\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.3/attention/self/Constant_12 [Constant] inputs: \n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.3/attention/self/Constant_12 [Constant] outputs: [/bert/encoder/layer.3/attention/self/Constant_12_output_0 -> ()[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Div [Div]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/MatMul_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Constant_12_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.3/attention/self/Div [Div] inputs: [/bert/encoder/layer.3/attention/self/MatMul_output_0 -> (-1, 8, -1, -1)[FLOAT]], [/bert/encoder/layer.3/attention/self/Constant_12_output_0 -> ()[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Constant_12_output_0 for ONNX node: /bert/encoder/layer.3/attention/self/Constant_12_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Div for ONNX node: /bert/encoder/layer.3/attention/self/Div\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/Div_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/Div_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.3/attention/self/Div [Div] outputs: [/bert/encoder/layer.3/attention/self/Div_output_0 -> (-1, 8, -1, -1)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Add [Add]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Div_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/Mul_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.3/attention/self/Add [Add] inputs: [/bert/encoder/layer.3/attention/self/Div_output_0 -> (-1, 8, -1, -1)[FLOAT]], [/bert/Mul_output_0 -> (-1, 1, 1, -1)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Add for ONNX node: /bert/encoder/layer.3/attention/self/Add\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/Add_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/Add_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.3/attention/self/Add [Add] outputs: [/bert/encoder/layer.3/attention/self/Add_output_0 -> (-1, 8, -1, -1)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Softmax [Softmax]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Add_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.3/attention/self/Softmax [Softmax] inputs: [/bert/encoder/layer.3/attention/self/Add_output_0 -> (-1, 8, -1, -1)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Softmax for ONNX node: /bert/encoder/layer.3/attention/self/Softmax\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/Softmax_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/Softmax_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.3/attention/self/Softmax [Softmax] outputs: [/bert/encoder/layer.3/attention/self/Softmax_output_0 -> (-1, 8, -1, -1)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/MatMul_1 [MatMul]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Softmax_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Transpose_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.3/attention/self/MatMul_1 [MatMul] inputs: [/bert/encoder/layer.3/attention/self/Softmax_output_0 -> (-1, 8, -1, -1)[FLOAT]], [/bert/encoder/layer.3/attention/self/Transpose_output_0 -> (-1, 8, -1, 32)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/MatMul_1 for ONNX node: /bert/encoder/layer.3/attention/self/MatMul_1\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/MatMul_1_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/MatMul_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.3/attention/self/MatMul_1 [MatMul] outputs: [/bert/encoder/layer.3/attention/self/MatMul_1_output_0 -> (-1, 8, -1, 32)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Transpose_3 [Transpose]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/MatMul_1_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.3/attention/self/Transpose_3 [Transpose] inputs: [/bert/encoder/layer.3/attention/self/MatMul_1_output_0 -> (-1, 8, -1, 32)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Transpose_3 for ONNX node: /bert/encoder/layer.3/attention/self/Transpose_3\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/Transpose_3_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/Transpose_3_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.3/attention/self/Transpose_3 [Transpose] outputs: [/bert/encoder/layer.3/attention/self/Transpose_3_output_0 -> (-1, -1, 8, 32)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Shape_6 [Shape]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Transpose_3_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.3/attention/self/Shape_6 [Shape] inputs: [/bert/encoder/layer.3/attention/self/Transpose_3_output_0 -> (-1, -1, 8, 32)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Shape_6 for ONNX node: /bert/encoder/layer.3/attention/self/Shape_6\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/Shape_6_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/Shape_6_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.3/attention/self/Shape_6 [Shape] outputs: [/bert/encoder/layer.3/attention/self/Shape_6_output_0 -> (4)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Constant_13 [Constant]\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.3/attention/self/Constant_13 [Constant] inputs: \n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.3/attention/self/Constant_13 [Constant] outputs: [/bert/encoder/layer.3/attention/self/Constant_13_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Gather_6 [Gather]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Shape_6_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Constant_13_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.3/attention/self/Gather_6 [Gather] inputs: [/bert/encoder/layer.3/attention/self/Shape_6_output_0 -> (4)[INT32]], [/bert/encoder/layer.3/attention/self/Constant_13_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Constant_13_output_0 for ONNX node: /bert/encoder/layer.3/attention/self/Constant_13_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Using Gather axis: 0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Gather_6 for ONNX node: /bert/encoder/layer.3/attention/self/Gather_6\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/Gather_6_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/Gather_6_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.3/attention/self/Gather_6 [Gather] outputs: [/bert/encoder/layer.3/attention/self/Gather_6_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Shape_7 [Shape]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Transpose_3_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.3/attention/self/Shape_7 [Shape] inputs: [/bert/encoder/layer.3/attention/self/Transpose_3_output_0 -> (-1, -1, 8, 32)[FLOAT]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Shape_7 for ONNX node: /bert/encoder/layer.3/attention/self/Shape_7\n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/Shape_7_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/Shape_7_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.3/attention/self/Shape_7 [Shape] outputs: [/bert/encoder/layer.3/attention/self/Shape_7_output_0 -> (4)[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Constant_14 [Constant]\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.3/attention/self/Constant_14 [Constant] inputs: \n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.3/attention/self/Constant_14 [Constant] outputs: [/bert/encoder/layer.3/attention/self/Constant_14_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Gather_7 [Gather]\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Shape_7_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Constant_14_output_0\n",
      "[01/18/2023-20:38:46] [V] [TRT] /bert/encoder/layer.3/attention/self/Gather_7 [Gather] inputs: [/bert/encoder/layer.3/attention/self/Shape_7_output_0 -> (4)[INT32]], [/bert/encoder/layer.3/attention/self/Constant_14_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:46] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Constant_14_output_0 for ONNX node: /bert/encoder/layer.3/attention/self/Constant_14_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Using Gather axis: 0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Gather_7 for ONNX node: /bert/encoder/layer.3/attention/self/Gather_7\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/Gather_7_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/Gather_7_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.3/attention/self/Gather_7 [Gather] outputs: [/bert/encoder/layer.3/attention/self/Gather_7_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Unsqueeze_6 [Unsqueeze]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Gather_6_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.3/attention/self/Unsqueeze_6 [Unsqueeze] inputs: [/bert/encoder/layer.3/attention/self/Gather_6_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Unsqueeze_6 for ONNX node: /bert/encoder/layer.3/attention/self/Unsqueeze_6\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/Unsqueeze_6_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/Unsqueeze_6_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.3/attention/self/Unsqueeze_6 [Unsqueeze] outputs: [/bert/encoder/layer.3/attention/self/Unsqueeze_6_output_0 -> (1)[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Unsqueeze_7 [Unsqueeze]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Gather_7_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.3/attention/self/Unsqueeze_7 [Unsqueeze] inputs: [/bert/encoder/layer.3/attention/self/Gather_7_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Unsqueeze_7 for ONNX node: /bert/encoder/layer.3/attention/self/Unsqueeze_7\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/Unsqueeze_7_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/Unsqueeze_7_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.3/attention/self/Unsqueeze_7 [Unsqueeze] outputs: [/bert/encoder/layer.3/attention/self/Unsqueeze_7_output_0 -> (1)[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Constant_15 [Constant]\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.3/attention/self/Constant_15 [Constant] inputs: \n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.3/attention/self/Constant_15 [Constant] outputs: [/bert/encoder/layer.3/attention/self/Constant_15_output_0 -> (1)[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Concat_3 [Concat]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Unsqueeze_6_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Unsqueeze_7_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Constant_15_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.3/attention/self/Concat_3 [Concat] inputs: [/bert/encoder/layer.3/attention/self/Unsqueeze_6_output_0 -> (1)[INT32]], [/bert/encoder/layer.3/attention/self/Unsqueeze_7_output_0 -> (1)[INT32]], [/bert/encoder/layer.3/attention/self/Constant_15_output_0 -> (1)[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Constant_15_output_0 for ONNX node: /bert/encoder/layer.3/attention/self/Constant_15_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Concat_3 for ONNX node: /bert/encoder/layer.3/attention/self/Concat_3\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/Concat_3_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/Concat_3_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.3/attention/self/Concat_3 [Concat] outputs: [/bert/encoder/layer.3/attention/self/Concat_3_output_0 -> (3)[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/self/Reshape_3 [Reshape]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Transpose_3_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Concat_3_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.3/attention/self/Reshape_3 [Reshape] inputs: [/bert/encoder/layer.3/attention/self/Transpose_3_output_0 -> (-1, -1, 8, 32)[FLOAT]], [/bert/encoder/layer.3/attention/self/Concat_3_output_0 -> (3)[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/self/Reshape_3 for ONNX node: /bert/encoder/layer.3/attention/self/Reshape_3\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/self/Reshape_3_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/self/Reshape_3_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.3/attention/self/Reshape_3 [Reshape] outputs: [/bert/encoder/layer.3/attention/self/Reshape_3_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/output/dense/MatMul [MatMul]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/self/Reshape_3_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: onnx::MatMul_842\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.3/attention/output/dense/MatMul [MatMul] inputs: [/bert/encoder/layer.3/attention/self/Reshape_3_output_0 -> (-1, -1, 256)[FLOAT]], [onnx::MatMul_842 -> (256, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: onnx::MatMul_842 for ONNX node: onnx::MatMul_842\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/output/dense/MatMul for ONNX node: /bert/encoder/layer.3/attention/output/dense/MatMul\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/output/dense/MatMul_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/output/dense/MatMul_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.3/attention/output/dense/MatMul [MatMul] outputs: [/bert/encoder/layer.3/attention/output/dense/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/output/dense/Add [Add]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: bert.encoder.layer.3.attention.output.dense.bias\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/output/dense/MatMul_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.3/attention/output/dense/Add [Add] inputs: [bert.encoder.layer.3.attention.output.dense.bias -> (256)[FLOAT]], [/bert/encoder/layer.3/attention/output/dense/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: bert.encoder.layer.3.attention.output.dense.bias for ONNX node: bert.encoder.layer.3.attention.output.dense.bias\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/output/dense/Add for ONNX node: /bert/encoder/layer.3/attention/output/dense/Add\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/output/dense/Add_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/output/dense/Add_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.3/attention/output/dense/Add [Add] outputs: [/bert/encoder/layer.3/attention/output/dense/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/output/Add [Add]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/output/dense/Add_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.2/output/LayerNorm/Add_1_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.3/attention/output/Add [Add] inputs: [/bert/encoder/layer.3/attention/output/dense/Add_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.2/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/output/Add for ONNX node: /bert/encoder/layer.3/attention/output/Add\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/output/Add_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/output/Add_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.3/attention/output/Add [Add] outputs: [/bert/encoder/layer.3/attention/output/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/output/LayerNorm/ReduceMean [ReduceMean]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/output/Add_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.3/attention/output/LayerNorm/ReduceMean [ReduceMean] inputs: [/bert/encoder/layer.3/attention/output/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/output/LayerNorm/ReduceMean for ONNX node: /bert/encoder/layer.3/attention/output/LayerNorm/ReduceMean\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/output/LayerNorm/ReduceMean_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/output/LayerNorm/ReduceMean_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.3/attention/output/LayerNorm/ReduceMean [ReduceMean] outputs: [/bert/encoder/layer.3/attention/output/LayerNorm/ReduceMean_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/output/LayerNorm/Sub [Sub]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/output/Add_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/output/LayerNorm/ReduceMean_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.3/attention/output/LayerNorm/Sub [Sub] inputs: [/bert/encoder/layer.3/attention/output/Add_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.3/attention/output/LayerNorm/ReduceMean_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/output/LayerNorm/Sub for ONNX node: /bert/encoder/layer.3/attention/output/LayerNorm/Sub\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/output/LayerNorm/Sub_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/output/LayerNorm/Sub_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.3/attention/output/LayerNorm/Sub [Sub] outputs: [/bert/encoder/layer.3/attention/output/LayerNorm/Sub_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/output/LayerNorm/Constant [Constant]\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.3/attention/output/LayerNorm/Constant [Constant] inputs: \n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.3/attention/output/LayerNorm/Constant [Constant] outputs: [/bert/encoder/layer.3/attention/output/LayerNorm/Constant_output_0 -> ()[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/output/LayerNorm/Pow [Pow]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/output/LayerNorm/Sub_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/output/LayerNorm/Constant_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.3/attention/output/LayerNorm/Pow [Pow] inputs: [/bert/encoder/layer.3/attention/output/LayerNorm/Sub_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.3/attention/output/LayerNorm/Constant_output_0 -> ()[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/output/LayerNorm/Constant_output_0 for ONNX node: /bert/encoder/layer.3/attention/output/LayerNorm/Constant_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/output/LayerNorm/Pow for ONNX node: /bert/encoder/layer.3/attention/output/LayerNorm/Pow\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/output/LayerNorm/Pow_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/output/LayerNorm/Pow_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.3/attention/output/LayerNorm/Pow [Pow] outputs: [/bert/encoder/layer.3/attention/output/LayerNorm/Pow_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/output/LayerNorm/ReduceMean_1 [ReduceMean]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/output/LayerNorm/Pow_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.3/attention/output/LayerNorm/ReduceMean_1 [ReduceMean] inputs: [/bert/encoder/layer.3/attention/output/LayerNorm/Pow_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/output/LayerNorm/ReduceMean_1 for ONNX node: /bert/encoder/layer.3/attention/output/LayerNorm/ReduceMean_1\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/output/LayerNorm/ReduceMean_1_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/output/LayerNorm/ReduceMean_1_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.3/attention/output/LayerNorm/ReduceMean_1 [ReduceMean] outputs: [/bert/encoder/layer.3/attention/output/LayerNorm/ReduceMean_1_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/output/LayerNorm/Constant_1 [Constant]\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.3/attention/output/LayerNorm/Constant_1 [Constant] inputs: \n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.3/attention/output/LayerNorm/Constant_1 [Constant] outputs: [/bert/encoder/layer.3/attention/output/LayerNorm/Constant_1_output_0 -> ()[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/output/LayerNorm/Add [Add]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/output/LayerNorm/ReduceMean_1_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/output/LayerNorm/Constant_1_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.3/attention/output/LayerNorm/Add [Add] inputs: [/bert/encoder/layer.3/attention/output/LayerNorm/ReduceMean_1_output_0 -> (-1, -1, 1)[FLOAT]], [/bert/encoder/layer.3/attention/output/LayerNorm/Constant_1_output_0 -> ()[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/output/LayerNorm/Constant_1_output_0 for ONNX node: /bert/encoder/layer.3/attention/output/LayerNorm/Constant_1_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/output/LayerNorm/Add for ONNX node: /bert/encoder/layer.3/attention/output/LayerNorm/Add\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/output/LayerNorm/Add_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/output/LayerNorm/Add_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.3/attention/output/LayerNorm/Add [Add] outputs: [/bert/encoder/layer.3/attention/output/LayerNorm/Add_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/output/LayerNorm/Sqrt [Sqrt]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/output/LayerNorm/Add_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.3/attention/output/LayerNorm/Sqrt [Sqrt] inputs: [/bert/encoder/layer.3/attention/output/LayerNorm/Add_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/output/LayerNorm/Sqrt for ONNX node: /bert/encoder/layer.3/attention/output/LayerNorm/Sqrt\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/output/LayerNorm/Sqrt_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/output/LayerNorm/Sqrt_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.3/attention/output/LayerNorm/Sqrt [Sqrt] outputs: [/bert/encoder/layer.3/attention/output/LayerNorm/Sqrt_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/output/LayerNorm/Div [Div]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/output/LayerNorm/Sub_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/output/LayerNorm/Sqrt_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.3/attention/output/LayerNorm/Div [Div] inputs: [/bert/encoder/layer.3/attention/output/LayerNorm/Sub_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.3/attention/output/LayerNorm/Sqrt_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/output/LayerNorm/Div for ONNX node: /bert/encoder/layer.3/attention/output/LayerNorm/Div\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/output/LayerNorm/Div_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/output/LayerNorm/Div_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.3/attention/output/LayerNorm/Div [Div] outputs: [/bert/encoder/layer.3/attention/output/LayerNorm/Div_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/output/LayerNorm/Mul [Mul]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/output/LayerNorm/Div_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: bert.encoder.layer.3.attention.output.LayerNorm.weight\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.3/attention/output/LayerNorm/Mul [Mul] inputs: [/bert/encoder/layer.3/attention/output/LayerNorm/Div_output_0 -> (-1, -1, 256)[FLOAT]], [bert.encoder.layer.3.attention.output.LayerNorm.weight -> (256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: bert.encoder.layer.3.attention.output.LayerNorm.weight for ONNX node: bert.encoder.layer.3.attention.output.LayerNorm.weight\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/output/LayerNorm/Mul for ONNX node: /bert/encoder/layer.3/attention/output/LayerNorm/Mul\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/output/LayerNorm/Mul_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/output/LayerNorm/Mul_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.3/attention/output/LayerNorm/Mul [Mul] outputs: [/bert/encoder/layer.3/attention/output/LayerNorm/Mul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.3/attention/output/LayerNorm/Add_1 [Add]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/output/LayerNorm/Mul_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: bert.encoder.layer.3.attention.output.LayerNorm.bias\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.3/attention/output/LayerNorm/Add_1 [Add] inputs: [/bert/encoder/layer.3/attention/output/LayerNorm/Mul_output_0 -> (-1, -1, 256)[FLOAT]], [bert.encoder.layer.3.attention.output.LayerNorm.bias -> (256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: bert.encoder.layer.3.attention.output.LayerNorm.bias for ONNX node: bert.encoder.layer.3.attention.output.LayerNorm.bias\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.3/attention/output/LayerNorm/Add_1 for ONNX node: /bert/encoder/layer.3/attention/output/LayerNorm/Add_1\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.3/attention/output/LayerNorm/Add_1_output_0 for ONNX tensor: /bert/encoder/layer.3/attention/output/LayerNorm/Add_1_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.3/attention/output/LayerNorm/Add_1 [Add] outputs: [/bert/encoder/layer.3/attention/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.3/intermediate/dense/MatMul [MatMul]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/output/LayerNorm/Add_1_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: onnx::MatMul_843\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.3/intermediate/dense/MatMul [MatMul] inputs: [/bert/encoder/layer.3/attention/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], [onnx::MatMul_843 -> (256, 1024)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: onnx::MatMul_843 for ONNX node: onnx::MatMul_843\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.3/intermediate/dense/MatMul for ONNX node: /bert/encoder/layer.3/intermediate/dense/MatMul\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.3/intermediate/dense/MatMul_output_0 for ONNX tensor: /bert/encoder/layer.3/intermediate/dense/MatMul_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.3/intermediate/dense/MatMul [MatMul] outputs: [/bert/encoder/layer.3/intermediate/dense/MatMul_output_0 -> (-1, -1, 1024)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.3/intermediate/dense/Add [Add]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: bert.encoder.layer.3.intermediate.dense.bias\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.3/intermediate/dense/MatMul_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.3/intermediate/dense/Add [Add] inputs: [bert.encoder.layer.3.intermediate.dense.bias -> (1024)[FLOAT]], [/bert/encoder/layer.3/intermediate/dense/MatMul_output_0 -> (-1, -1, 1024)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: bert.encoder.layer.3.intermediate.dense.bias for ONNX node: bert.encoder.layer.3.intermediate.dense.bias\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.3/intermediate/dense/Add for ONNX node: /bert/encoder/layer.3/intermediate/dense/Add\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.3/intermediate/dense/Add_output_0 for ONNX tensor: /bert/encoder/layer.3/intermediate/dense/Add_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.3/intermediate/dense/Add [Add] outputs: [/bert/encoder/layer.3/intermediate/dense/Add_output_0 -> (-1, -1, 1024)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.3/intermediate/intermediate_act_fn/Constant [Constant]\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.3/intermediate/intermediate_act_fn/Constant [Constant] inputs: \n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.3/intermediate/intermediate_act_fn/Constant [Constant] outputs: [/bert/encoder/layer.3/intermediate/intermediate_act_fn/Constant_output_0 -> ()[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.3/intermediate/intermediate_act_fn/Div [Div]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.3/intermediate/dense/Add_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.3/intermediate/intermediate_act_fn/Constant_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.3/intermediate/intermediate_act_fn/Div [Div] inputs: [/bert/encoder/layer.3/intermediate/dense/Add_output_0 -> (-1, -1, 1024)[FLOAT]], [/bert/encoder/layer.3/intermediate/intermediate_act_fn/Constant_output_0 -> ()[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.3/intermediate/intermediate_act_fn/Constant_output_0 for ONNX node: /bert/encoder/layer.3/intermediate/intermediate_act_fn/Constant_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.3/intermediate/intermediate_act_fn/Div for ONNX node: /bert/encoder/layer.3/intermediate/intermediate_act_fn/Div\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.3/intermediate/intermediate_act_fn/Div_output_0 for ONNX tensor: /bert/encoder/layer.3/intermediate/intermediate_act_fn/Div_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.3/intermediate/intermediate_act_fn/Div [Div] outputs: [/bert/encoder/layer.3/intermediate/intermediate_act_fn/Div_output_0 -> (-1, -1, 1024)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.3/intermediate/intermediate_act_fn/Erf [Erf]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.3/intermediate/intermediate_act_fn/Div_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.3/intermediate/intermediate_act_fn/Erf [Erf] inputs: [/bert/encoder/layer.3/intermediate/intermediate_act_fn/Div_output_0 -> (-1, -1, 1024)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.3/intermediate/intermediate_act_fn/Erf for ONNX node: /bert/encoder/layer.3/intermediate/intermediate_act_fn/Erf\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.3/intermediate/intermediate_act_fn/Erf_output_0 for ONNX tensor: /bert/encoder/layer.3/intermediate/intermediate_act_fn/Erf_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.3/intermediate/intermediate_act_fn/Erf [Erf] outputs: [/bert/encoder/layer.3/intermediate/intermediate_act_fn/Erf_output_0 -> (-1, -1, 1024)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.3/intermediate/intermediate_act_fn/Constant_1 [Constant]\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.3/intermediate/intermediate_act_fn/Constant_1 [Constant] inputs: \n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.3/intermediate/intermediate_act_fn/Constant_1 [Constant] outputs: [/bert/encoder/layer.3/intermediate/intermediate_act_fn/Constant_1_output_0 -> ()[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.3/intermediate/intermediate_act_fn/Add [Add]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.3/intermediate/intermediate_act_fn/Erf_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.3/intermediate/intermediate_act_fn/Constant_1_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.3/intermediate/intermediate_act_fn/Add [Add] inputs: [/bert/encoder/layer.3/intermediate/intermediate_act_fn/Erf_output_0 -> (-1, -1, 1024)[FLOAT]], [/bert/encoder/layer.3/intermediate/intermediate_act_fn/Constant_1_output_0 -> ()[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.3/intermediate/intermediate_act_fn/Constant_1_output_0 for ONNX node: /bert/encoder/layer.3/intermediate/intermediate_act_fn/Constant_1_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.3/intermediate/intermediate_act_fn/Add for ONNX node: /bert/encoder/layer.3/intermediate/intermediate_act_fn/Add\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.3/intermediate/intermediate_act_fn/Add_output_0 for ONNX tensor: /bert/encoder/layer.3/intermediate/intermediate_act_fn/Add_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.3/intermediate/intermediate_act_fn/Add [Add] outputs: [/bert/encoder/layer.3/intermediate/intermediate_act_fn/Add_output_0 -> (-1, -1, 1024)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.3/intermediate/intermediate_act_fn/Mul [Mul]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.3/intermediate/dense/Add_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.3/intermediate/intermediate_act_fn/Add_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.3/intermediate/intermediate_act_fn/Mul [Mul] inputs: [/bert/encoder/layer.3/intermediate/dense/Add_output_0 -> (-1, -1, 1024)[FLOAT]], [/bert/encoder/layer.3/intermediate/intermediate_act_fn/Add_output_0 -> (-1, -1, 1024)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.3/intermediate/intermediate_act_fn/Mul for ONNX node: /bert/encoder/layer.3/intermediate/intermediate_act_fn/Mul\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.3/intermediate/intermediate_act_fn/Mul_output_0 for ONNX tensor: /bert/encoder/layer.3/intermediate/intermediate_act_fn/Mul_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.3/intermediate/intermediate_act_fn/Mul [Mul] outputs: [/bert/encoder/layer.3/intermediate/intermediate_act_fn/Mul_output_0 -> (-1, -1, 1024)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.3/intermediate/intermediate_act_fn/Constant_2 [Constant]\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.3/intermediate/intermediate_act_fn/Constant_2 [Constant] inputs: \n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.3/intermediate/intermediate_act_fn/Constant_2 [Constant] outputs: [/bert/encoder/layer.3/intermediate/intermediate_act_fn/Constant_2_output_0 -> ()[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.3/intermediate/intermediate_act_fn/Mul_1 [Mul]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.3/intermediate/intermediate_act_fn/Mul_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.3/intermediate/intermediate_act_fn/Constant_2_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.3/intermediate/intermediate_act_fn/Mul_1 [Mul] inputs: [/bert/encoder/layer.3/intermediate/intermediate_act_fn/Mul_output_0 -> (-1, -1, 1024)[FLOAT]], [/bert/encoder/layer.3/intermediate/intermediate_act_fn/Constant_2_output_0 -> ()[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.3/intermediate/intermediate_act_fn/Constant_2_output_0 for ONNX node: /bert/encoder/layer.3/intermediate/intermediate_act_fn/Constant_2_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.3/intermediate/intermediate_act_fn/Mul_1 for ONNX node: /bert/encoder/layer.3/intermediate/intermediate_act_fn/Mul_1\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.3/intermediate/intermediate_act_fn/Mul_1_output_0 for ONNX tensor: /bert/encoder/layer.3/intermediate/intermediate_act_fn/Mul_1_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.3/intermediate/intermediate_act_fn/Mul_1 [Mul] outputs: [/bert/encoder/layer.3/intermediate/intermediate_act_fn/Mul_1_output_0 -> (-1, -1, 1024)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.3/output/dense/MatMul [MatMul]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.3/intermediate/intermediate_act_fn/Mul_1_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: onnx::MatMul_844\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.3/output/dense/MatMul [MatMul] inputs: [/bert/encoder/layer.3/intermediate/intermediate_act_fn/Mul_1_output_0 -> (-1, -1, 1024)[FLOAT]], [onnx::MatMul_844 -> (1024, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: onnx::MatMul_844 for ONNX node: onnx::MatMul_844\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.3/output/dense/MatMul for ONNX node: /bert/encoder/layer.3/output/dense/MatMul\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.3/output/dense/MatMul_output_0 for ONNX tensor: /bert/encoder/layer.3/output/dense/MatMul_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.3/output/dense/MatMul [MatMul] outputs: [/bert/encoder/layer.3/output/dense/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.3/output/dense/Add [Add]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: bert.encoder.layer.3.output.dense.bias\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.3/output/dense/MatMul_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.3/output/dense/Add [Add] inputs: [bert.encoder.layer.3.output.dense.bias -> (256)[FLOAT]], [/bert/encoder/layer.3/output/dense/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: bert.encoder.layer.3.output.dense.bias for ONNX node: bert.encoder.layer.3.output.dense.bias\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.3/output/dense/Add for ONNX node: /bert/encoder/layer.3/output/dense/Add\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.3/output/dense/Add_output_0 for ONNX tensor: /bert/encoder/layer.3/output/dense/Add_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.3/output/dense/Add [Add] outputs: [/bert/encoder/layer.3/output/dense/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.3/output/Add [Add]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.3/output/dense/Add_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.3/attention/output/LayerNorm/Add_1_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.3/output/Add [Add] inputs: [/bert/encoder/layer.3/output/dense/Add_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.3/attention/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.3/output/Add for ONNX node: /bert/encoder/layer.3/output/Add\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.3/output/Add_output_0 for ONNX tensor: /bert/encoder/layer.3/output/Add_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.3/output/Add [Add] outputs: [/bert/encoder/layer.3/output/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.3/output/LayerNorm/ReduceMean [ReduceMean]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.3/output/Add_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.3/output/LayerNorm/ReduceMean [ReduceMean] inputs: [/bert/encoder/layer.3/output/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.3/output/LayerNorm/ReduceMean for ONNX node: /bert/encoder/layer.3/output/LayerNorm/ReduceMean\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.3/output/LayerNorm/ReduceMean_output_0 for ONNX tensor: /bert/encoder/layer.3/output/LayerNorm/ReduceMean_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.3/output/LayerNorm/ReduceMean [ReduceMean] outputs: [/bert/encoder/layer.3/output/LayerNorm/ReduceMean_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.3/output/LayerNorm/Sub [Sub]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.3/output/Add_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.3/output/LayerNorm/ReduceMean_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.3/output/LayerNorm/Sub [Sub] inputs: [/bert/encoder/layer.3/output/Add_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.3/output/LayerNorm/ReduceMean_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.3/output/LayerNorm/Sub for ONNX node: /bert/encoder/layer.3/output/LayerNorm/Sub\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.3/output/LayerNorm/Sub_output_0 for ONNX tensor: /bert/encoder/layer.3/output/LayerNorm/Sub_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.3/output/LayerNorm/Sub [Sub] outputs: [/bert/encoder/layer.3/output/LayerNorm/Sub_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.3/output/LayerNorm/Constant [Constant]\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.3/output/LayerNorm/Constant [Constant] inputs: \n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.3/output/LayerNorm/Constant [Constant] outputs: [/bert/encoder/layer.3/output/LayerNorm/Constant_output_0 -> ()[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.3/output/LayerNorm/Pow [Pow]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.3/output/LayerNorm/Sub_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.3/output/LayerNorm/Constant_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.3/output/LayerNorm/Pow [Pow] inputs: [/bert/encoder/layer.3/output/LayerNorm/Sub_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.3/output/LayerNorm/Constant_output_0 -> ()[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.3/output/LayerNorm/Constant_output_0 for ONNX node: /bert/encoder/layer.3/output/LayerNorm/Constant_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.3/output/LayerNorm/Pow for ONNX node: /bert/encoder/layer.3/output/LayerNorm/Pow\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.3/output/LayerNorm/Pow_output_0 for ONNX tensor: /bert/encoder/layer.3/output/LayerNorm/Pow_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.3/output/LayerNorm/Pow [Pow] outputs: [/bert/encoder/layer.3/output/LayerNorm/Pow_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.3/output/LayerNorm/ReduceMean_1 [ReduceMean]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.3/output/LayerNorm/Pow_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.3/output/LayerNorm/ReduceMean_1 [ReduceMean] inputs: [/bert/encoder/layer.3/output/LayerNorm/Pow_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.3/output/LayerNorm/ReduceMean_1 for ONNX node: /bert/encoder/layer.3/output/LayerNorm/ReduceMean_1\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.3/output/LayerNorm/ReduceMean_1_output_0 for ONNX tensor: /bert/encoder/layer.3/output/LayerNorm/ReduceMean_1_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.3/output/LayerNorm/ReduceMean_1 [ReduceMean] outputs: [/bert/encoder/layer.3/output/LayerNorm/ReduceMean_1_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.3/output/LayerNorm/Constant_1 [Constant]\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.3/output/LayerNorm/Constant_1 [Constant] inputs: \n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.3/output/LayerNorm/Constant_1 [Constant] outputs: [/bert/encoder/layer.3/output/LayerNorm/Constant_1_output_0 -> ()[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.3/output/LayerNorm/Add [Add]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.3/output/LayerNorm/ReduceMean_1_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.3/output/LayerNorm/Constant_1_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.3/output/LayerNorm/Add [Add] inputs: [/bert/encoder/layer.3/output/LayerNorm/ReduceMean_1_output_0 -> (-1, -1, 1)[FLOAT]], [/bert/encoder/layer.3/output/LayerNorm/Constant_1_output_0 -> ()[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.3/output/LayerNorm/Constant_1_output_0 for ONNX node: /bert/encoder/layer.3/output/LayerNorm/Constant_1_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.3/output/LayerNorm/Add for ONNX node: /bert/encoder/layer.3/output/LayerNorm/Add\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.3/output/LayerNorm/Add_output_0 for ONNX tensor: /bert/encoder/layer.3/output/LayerNorm/Add_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.3/output/LayerNorm/Add [Add] outputs: [/bert/encoder/layer.3/output/LayerNorm/Add_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.3/output/LayerNorm/Sqrt [Sqrt]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.3/output/LayerNorm/Add_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.3/output/LayerNorm/Sqrt [Sqrt] inputs: [/bert/encoder/layer.3/output/LayerNorm/Add_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.3/output/LayerNorm/Sqrt for ONNX node: /bert/encoder/layer.3/output/LayerNorm/Sqrt\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.3/output/LayerNorm/Sqrt_output_0 for ONNX tensor: /bert/encoder/layer.3/output/LayerNorm/Sqrt_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.3/output/LayerNorm/Sqrt [Sqrt] outputs: [/bert/encoder/layer.3/output/LayerNorm/Sqrt_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.3/output/LayerNorm/Div [Div]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.3/output/LayerNorm/Sub_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.3/output/LayerNorm/Sqrt_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.3/output/LayerNorm/Div [Div] inputs: [/bert/encoder/layer.3/output/LayerNorm/Sub_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.3/output/LayerNorm/Sqrt_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.3/output/LayerNorm/Div for ONNX node: /bert/encoder/layer.3/output/LayerNorm/Div\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.3/output/LayerNorm/Div_output_0 for ONNX tensor: /bert/encoder/layer.3/output/LayerNorm/Div_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.3/output/LayerNorm/Div [Div] outputs: [/bert/encoder/layer.3/output/LayerNorm/Div_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.3/output/LayerNorm/Mul [Mul]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.3/output/LayerNorm/Div_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: bert.encoder.layer.3.output.LayerNorm.weight\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.3/output/LayerNorm/Mul [Mul] inputs: [/bert/encoder/layer.3/output/LayerNorm/Div_output_0 -> (-1, -1, 256)[FLOAT]], [bert.encoder.layer.3.output.LayerNorm.weight -> (256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: bert.encoder.layer.3.output.LayerNorm.weight for ONNX node: bert.encoder.layer.3.output.LayerNorm.weight\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.3/output/LayerNorm/Mul for ONNX node: /bert/encoder/layer.3/output/LayerNorm/Mul\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.3/output/LayerNorm/Mul_output_0 for ONNX tensor: /bert/encoder/layer.3/output/LayerNorm/Mul_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.3/output/LayerNorm/Mul [Mul] outputs: [/bert/encoder/layer.3/output/LayerNorm/Mul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.3/output/LayerNorm/Add_1 [Add]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.3/output/LayerNorm/Mul_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: bert.encoder.layer.3.output.LayerNorm.bias\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.3/output/LayerNorm/Add_1 [Add] inputs: [/bert/encoder/layer.3/output/LayerNorm/Mul_output_0 -> (-1, -1, 256)[FLOAT]], [bert.encoder.layer.3.output.LayerNorm.bias -> (256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: bert.encoder.layer.3.output.LayerNorm.bias for ONNX node: bert.encoder.layer.3.output.LayerNorm.bias\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.3/output/LayerNorm/Add_1 for ONNX node: /bert/encoder/layer.3/output/LayerNorm/Add_1\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.3/output/LayerNorm/Add_1_output_0 for ONNX tensor: /bert/encoder/layer.3/output/LayerNorm/Add_1_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.3/output/LayerNorm/Add_1 [Add] outputs: [/bert/encoder/layer.3/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/query/MatMul [MatMul]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.3/output/LayerNorm/Add_1_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: onnx::MatMul_845\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/self/query/MatMul [MatMul] inputs: [/bert/encoder/layer.3/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], [onnx::MatMul_845 -> (256, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: onnx::MatMul_845 for ONNX node: onnx::MatMul_845\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/query/MatMul for ONNX node: /bert/encoder/layer.4/attention/self/query/MatMul\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/query/MatMul_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/query/MatMul_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/self/query/MatMul [MatMul] outputs: [/bert/encoder/layer.4/attention/self/query/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/query/Add [Add]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: bert.encoder.layer.4.attention.self.query.bias\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/query/MatMul_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/self/query/Add [Add] inputs: [bert.encoder.layer.4.attention.self.query.bias -> (256)[FLOAT]], [/bert/encoder/layer.4/attention/self/query/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: bert.encoder.layer.4.attention.self.query.bias for ONNX node: bert.encoder.layer.4.attention.self.query.bias\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/query/Add for ONNX node: /bert/encoder/layer.4/attention/self/query/Add\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/query/Add_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/query/Add_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/self/query/Add [Add] outputs: [/bert/encoder/layer.4/attention/self/query/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/key/MatMul [MatMul]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.3/output/LayerNorm/Add_1_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: onnx::MatMul_846\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/self/key/MatMul [MatMul] inputs: [/bert/encoder/layer.3/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], [onnx::MatMul_846 -> (256, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: onnx::MatMul_846 for ONNX node: onnx::MatMul_846\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/key/MatMul for ONNX node: /bert/encoder/layer.4/attention/self/key/MatMul\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/key/MatMul_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/key/MatMul_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/self/key/MatMul [MatMul] outputs: [/bert/encoder/layer.4/attention/self/key/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/key/Add [Add]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: bert.encoder.layer.4.attention.self.key.bias\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/key/MatMul_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/self/key/Add [Add] inputs: [bert.encoder.layer.4.attention.self.key.bias -> (256)[FLOAT]], [/bert/encoder/layer.4/attention/self/key/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: bert.encoder.layer.4.attention.self.key.bias for ONNX node: bert.encoder.layer.4.attention.self.key.bias\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/key/Add for ONNX node: /bert/encoder/layer.4/attention/self/key/Add\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/key/Add_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/key/Add_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/self/key/Add [Add] outputs: [/bert/encoder/layer.4/attention/self/key/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Shape [Shape]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/key/Add_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/self/Shape [Shape] inputs: [/bert/encoder/layer.4/attention/self/key/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Shape for ONNX node: /bert/encoder/layer.4/attention/self/Shape\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/Shape_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/Shape_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/self/Shape [Shape] outputs: [/bert/encoder/layer.4/attention/self/Shape_output_0 -> (3)[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Constant [Constant]\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/self/Constant [Constant] inputs: \n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/self/Constant [Constant] outputs: [/bert/encoder/layer.4/attention/self/Constant_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Gather [Gather]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Shape_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Constant_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/self/Gather [Gather] inputs: [/bert/encoder/layer.4/attention/self/Shape_output_0 -> (3)[INT32]], [/bert/encoder/layer.4/attention/self/Constant_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Constant_output_0 for ONNX node: /bert/encoder/layer.4/attention/self/Constant_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Using Gather axis: 0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Gather for ONNX node: /bert/encoder/layer.4/attention/self/Gather\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/Gather_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/Gather_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/self/Gather [Gather] outputs: [/bert/encoder/layer.4/attention/self/Gather_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Shape_1 [Shape]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/key/Add_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/self/Shape_1 [Shape] inputs: [/bert/encoder/layer.4/attention/self/key/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Shape_1 for ONNX node: /bert/encoder/layer.4/attention/self/Shape_1\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/Shape_1_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/Shape_1_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/self/Shape_1 [Shape] outputs: [/bert/encoder/layer.4/attention/self/Shape_1_output_0 -> (3)[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Constant_1 [Constant]\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/self/Constant_1 [Constant] inputs: \n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/self/Constant_1 [Constant] outputs: [/bert/encoder/layer.4/attention/self/Constant_1_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Gather_1 [Gather]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Shape_1_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Constant_1_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/self/Gather_1 [Gather] inputs: [/bert/encoder/layer.4/attention/self/Shape_1_output_0 -> (3)[INT32]], [/bert/encoder/layer.4/attention/self/Constant_1_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Constant_1_output_0 for ONNX node: /bert/encoder/layer.4/attention/self/Constant_1_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Using Gather axis: 0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Gather_1 for ONNX node: /bert/encoder/layer.4/attention/self/Gather_1\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/Gather_1_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/Gather_1_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/self/Gather_1 [Gather] outputs: [/bert/encoder/layer.4/attention/self/Gather_1_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Unsqueeze [Unsqueeze]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Gather_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/self/Unsqueeze [Unsqueeze] inputs: [/bert/encoder/layer.4/attention/self/Gather_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Unsqueeze for ONNX node: /bert/encoder/layer.4/attention/self/Unsqueeze\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/Unsqueeze_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/Unsqueeze_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/self/Unsqueeze [Unsqueeze] outputs: [/bert/encoder/layer.4/attention/self/Unsqueeze_output_0 -> (1)[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Unsqueeze_1 [Unsqueeze]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Gather_1_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/self/Unsqueeze_1 [Unsqueeze] inputs: [/bert/encoder/layer.4/attention/self/Gather_1_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Unsqueeze_1 for ONNX node: /bert/encoder/layer.4/attention/self/Unsqueeze_1\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/Unsqueeze_1_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/Unsqueeze_1_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/self/Unsqueeze_1 [Unsqueeze] outputs: [/bert/encoder/layer.4/attention/self/Unsqueeze_1_output_0 -> (1)[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Constant_2 [Constant]\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/self/Constant_2 [Constant] inputs: \n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/self/Constant_2 [Constant] outputs: [/bert/encoder/layer.4/attention/self/Constant_2_output_0 -> (1)[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Constant_3 [Constant]\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/self/Constant_3 [Constant] inputs: \n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/self/Constant_3 [Constant] outputs: [/bert/encoder/layer.4/attention/self/Constant_3_output_0 -> (1)[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Concat [Concat]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Unsqueeze_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Unsqueeze_1_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Constant_2_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Constant_3_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/self/Concat [Concat] inputs: [/bert/encoder/layer.4/attention/self/Unsqueeze_output_0 -> (1)[INT32]], [/bert/encoder/layer.4/attention/self/Unsqueeze_1_output_0 -> (1)[INT32]], [/bert/encoder/layer.4/attention/self/Constant_2_output_0 -> (1)[INT32]], [/bert/encoder/layer.4/attention/self/Constant_3_output_0 -> (1)[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Constant_2_output_0 for ONNX node: /bert/encoder/layer.4/attention/self/Constant_2_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Constant_3_output_0 for ONNX node: /bert/encoder/layer.4/attention/self/Constant_3_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Concat for ONNX node: /bert/encoder/layer.4/attention/self/Concat\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/Concat_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/Concat_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/self/Concat [Concat] outputs: [/bert/encoder/layer.4/attention/self/Concat_output_0 -> (4)[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Reshape [Reshape]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/key/Add_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Concat_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/self/Reshape [Reshape] inputs: [/bert/encoder/layer.4/attention/self/key/Add_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.4/attention/self/Concat_output_0 -> (4)[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Reshape for ONNX node: /bert/encoder/layer.4/attention/self/Reshape\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/Reshape_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/Reshape_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/self/Reshape [Reshape] outputs: [/bert/encoder/layer.4/attention/self/Reshape_output_0 -> (-1, -1, 8, 32)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/value/MatMul [MatMul]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.3/output/LayerNorm/Add_1_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: onnx::MatMul_849\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/self/value/MatMul [MatMul] inputs: [/bert/encoder/layer.3/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], [onnx::MatMul_849 -> (256, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: onnx::MatMul_849 for ONNX node: onnx::MatMul_849\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/value/MatMul for ONNX node: /bert/encoder/layer.4/attention/self/value/MatMul\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/value/MatMul_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/value/MatMul_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/self/value/MatMul [MatMul] outputs: [/bert/encoder/layer.4/attention/self/value/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/value/Add [Add]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: bert.encoder.layer.4.attention.self.value.bias\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/value/MatMul_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/self/value/Add [Add] inputs: [bert.encoder.layer.4.attention.self.value.bias -> (256)[FLOAT]], [/bert/encoder/layer.4/attention/self/value/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: bert.encoder.layer.4.attention.self.value.bias for ONNX node: bert.encoder.layer.4.attention.self.value.bias\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/value/Add for ONNX node: /bert/encoder/layer.4/attention/self/value/Add\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/value/Add_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/value/Add_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/self/value/Add [Add] outputs: [/bert/encoder/layer.4/attention/self/value/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Shape_2 [Shape]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/value/Add_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/self/Shape_2 [Shape] inputs: [/bert/encoder/layer.4/attention/self/value/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Shape_2 for ONNX node: /bert/encoder/layer.4/attention/self/Shape_2\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/Shape_2_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/Shape_2_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/self/Shape_2 [Shape] outputs: [/bert/encoder/layer.4/attention/self/Shape_2_output_0 -> (3)[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Constant_4 [Constant]\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/self/Constant_4 [Constant] inputs: \n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/self/Constant_4 [Constant] outputs: [/bert/encoder/layer.4/attention/self/Constant_4_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Gather_2 [Gather]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Shape_2_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Constant_4_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/self/Gather_2 [Gather] inputs: [/bert/encoder/layer.4/attention/self/Shape_2_output_0 -> (3)[INT32]], [/bert/encoder/layer.4/attention/self/Constant_4_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Constant_4_output_0 for ONNX node: /bert/encoder/layer.4/attention/self/Constant_4_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Using Gather axis: 0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Gather_2 for ONNX node: /bert/encoder/layer.4/attention/self/Gather_2\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/Gather_2_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/Gather_2_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/self/Gather_2 [Gather] outputs: [/bert/encoder/layer.4/attention/self/Gather_2_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Shape_3 [Shape]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/value/Add_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/self/Shape_3 [Shape] inputs: [/bert/encoder/layer.4/attention/self/value/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Shape_3 for ONNX node: /bert/encoder/layer.4/attention/self/Shape_3\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/Shape_3_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/Shape_3_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/self/Shape_3 [Shape] outputs: [/bert/encoder/layer.4/attention/self/Shape_3_output_0 -> (3)[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Constant_5 [Constant]\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/self/Constant_5 [Constant] inputs: \n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/self/Constant_5 [Constant] outputs: [/bert/encoder/layer.4/attention/self/Constant_5_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Gather_3 [Gather]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Shape_3_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Constant_5_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/self/Gather_3 [Gather] inputs: [/bert/encoder/layer.4/attention/self/Shape_3_output_0 -> (3)[INT32]], [/bert/encoder/layer.4/attention/self/Constant_5_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Constant_5_output_0 for ONNX node: /bert/encoder/layer.4/attention/self/Constant_5_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Using Gather axis: 0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Gather_3 for ONNX node: /bert/encoder/layer.4/attention/self/Gather_3\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/Gather_3_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/Gather_3_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/self/Gather_3 [Gather] outputs: [/bert/encoder/layer.4/attention/self/Gather_3_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Unsqueeze_2 [Unsqueeze]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Gather_2_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/self/Unsqueeze_2 [Unsqueeze] inputs: [/bert/encoder/layer.4/attention/self/Gather_2_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Unsqueeze_2 for ONNX node: /bert/encoder/layer.4/attention/self/Unsqueeze_2\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/Unsqueeze_2_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/Unsqueeze_2_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/self/Unsqueeze_2 [Unsqueeze] outputs: [/bert/encoder/layer.4/attention/self/Unsqueeze_2_output_0 -> (1)[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Unsqueeze_3 [Unsqueeze]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Gather_3_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/self/Unsqueeze_3 [Unsqueeze] inputs: [/bert/encoder/layer.4/attention/self/Gather_3_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Unsqueeze_3 for ONNX node: /bert/encoder/layer.4/attention/self/Unsqueeze_3\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/Unsqueeze_3_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/Unsqueeze_3_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/self/Unsqueeze_3 [Unsqueeze] outputs: [/bert/encoder/layer.4/attention/self/Unsqueeze_3_output_0 -> (1)[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Constant_6 [Constant]\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/self/Constant_6 [Constant] inputs: \n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/self/Constant_6 [Constant] outputs: [/bert/encoder/layer.4/attention/self/Constant_6_output_0 -> (1)[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Constant_7 [Constant]\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/self/Constant_7 [Constant] inputs: \n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/self/Constant_7 [Constant] outputs: [/bert/encoder/layer.4/attention/self/Constant_7_output_0 -> (1)[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Concat_1 [Concat]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Unsqueeze_2_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Unsqueeze_3_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Constant_6_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Constant_7_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/self/Concat_1 [Concat] inputs: [/bert/encoder/layer.4/attention/self/Unsqueeze_2_output_0 -> (1)[INT32]], [/bert/encoder/layer.4/attention/self/Unsqueeze_3_output_0 -> (1)[INT32]], [/bert/encoder/layer.4/attention/self/Constant_6_output_0 -> (1)[INT32]], [/bert/encoder/layer.4/attention/self/Constant_7_output_0 -> (1)[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Constant_6_output_0 for ONNX node: /bert/encoder/layer.4/attention/self/Constant_6_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Constant_7_output_0 for ONNX node: /bert/encoder/layer.4/attention/self/Constant_7_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Concat_1 for ONNX node: /bert/encoder/layer.4/attention/self/Concat_1\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/Concat_1_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/Concat_1_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/self/Concat_1 [Concat] outputs: [/bert/encoder/layer.4/attention/self/Concat_1_output_0 -> (4)[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Reshape_1 [Reshape]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/value/Add_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Concat_1_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/self/Reshape_1 [Reshape] inputs: [/bert/encoder/layer.4/attention/self/value/Add_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.4/attention/self/Concat_1_output_0 -> (4)[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Reshape_1 for ONNX node: /bert/encoder/layer.4/attention/self/Reshape_1\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/Reshape_1_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/Reshape_1_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/self/Reshape_1 [Reshape] outputs: [/bert/encoder/layer.4/attention/self/Reshape_1_output_0 -> (-1, -1, 8, 32)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Transpose [Transpose]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Reshape_1_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/self/Transpose [Transpose] inputs: [/bert/encoder/layer.4/attention/self/Reshape_1_output_0 -> (-1, -1, 8, 32)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Transpose for ONNX node: /bert/encoder/layer.4/attention/self/Transpose\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/Transpose_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/Transpose_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/self/Transpose [Transpose] outputs: [/bert/encoder/layer.4/attention/self/Transpose_output_0 -> (-1, 8, -1, 32)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Shape_4 [Shape]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/query/Add_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/self/Shape_4 [Shape] inputs: [/bert/encoder/layer.4/attention/self/query/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Shape_4 for ONNX node: /bert/encoder/layer.4/attention/self/Shape_4\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/Shape_4_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/Shape_4_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/self/Shape_4 [Shape] outputs: [/bert/encoder/layer.4/attention/self/Shape_4_output_0 -> (3)[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Constant_8 [Constant]\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/self/Constant_8 [Constant] inputs: \n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/self/Constant_8 [Constant] outputs: [/bert/encoder/layer.4/attention/self/Constant_8_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Gather_4 [Gather]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Shape_4_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Constant_8_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/self/Gather_4 [Gather] inputs: [/bert/encoder/layer.4/attention/self/Shape_4_output_0 -> (3)[INT32]], [/bert/encoder/layer.4/attention/self/Constant_8_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Constant_8_output_0 for ONNX node: /bert/encoder/layer.4/attention/self/Constant_8_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Using Gather axis: 0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Gather_4 for ONNX node: /bert/encoder/layer.4/attention/self/Gather_4\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/Gather_4_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/Gather_4_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/self/Gather_4 [Gather] outputs: [/bert/encoder/layer.4/attention/self/Gather_4_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Shape_5 [Shape]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/query/Add_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/self/Shape_5 [Shape] inputs: [/bert/encoder/layer.4/attention/self/query/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Shape_5 for ONNX node: /bert/encoder/layer.4/attention/self/Shape_5\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/Shape_5_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/Shape_5_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/self/Shape_5 [Shape] outputs: [/bert/encoder/layer.4/attention/self/Shape_5_output_0 -> (3)[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Constant_9 [Constant]\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/self/Constant_9 [Constant] inputs: \n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/self/Constant_9 [Constant] outputs: [/bert/encoder/layer.4/attention/self/Constant_9_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Gather_5 [Gather]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Shape_5_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Constant_9_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/self/Gather_5 [Gather] inputs: [/bert/encoder/layer.4/attention/self/Shape_5_output_0 -> (3)[INT32]], [/bert/encoder/layer.4/attention/self/Constant_9_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Constant_9_output_0 for ONNX node: /bert/encoder/layer.4/attention/self/Constant_9_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Using Gather axis: 0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Gather_5 for ONNX node: /bert/encoder/layer.4/attention/self/Gather_5\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/Gather_5_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/Gather_5_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/self/Gather_5 [Gather] outputs: [/bert/encoder/layer.4/attention/self/Gather_5_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Unsqueeze_4 [Unsqueeze]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Gather_4_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/self/Unsqueeze_4 [Unsqueeze] inputs: [/bert/encoder/layer.4/attention/self/Gather_4_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Unsqueeze_4 for ONNX node: /bert/encoder/layer.4/attention/self/Unsqueeze_4\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/Unsqueeze_4_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/Unsqueeze_4_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/self/Unsqueeze_4 [Unsqueeze] outputs: [/bert/encoder/layer.4/attention/self/Unsqueeze_4_output_0 -> (1)[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Unsqueeze_5 [Unsqueeze]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Gather_5_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/self/Unsqueeze_5 [Unsqueeze] inputs: [/bert/encoder/layer.4/attention/self/Gather_5_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Unsqueeze_5 for ONNX node: /bert/encoder/layer.4/attention/self/Unsqueeze_5\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/Unsqueeze_5_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/Unsqueeze_5_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/self/Unsqueeze_5 [Unsqueeze] outputs: [/bert/encoder/layer.4/attention/self/Unsqueeze_5_output_0 -> (1)[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Constant_10 [Constant]\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/self/Constant_10 [Constant] inputs: \n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/self/Constant_10 [Constant] outputs: [/bert/encoder/layer.4/attention/self/Constant_10_output_0 -> (1)[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Constant_11 [Constant]\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/self/Constant_11 [Constant] inputs: \n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/self/Constant_11 [Constant] outputs: [/bert/encoder/layer.4/attention/self/Constant_11_output_0 -> (1)[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Concat_2 [Concat]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Unsqueeze_4_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Unsqueeze_5_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Constant_10_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Constant_11_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/self/Concat_2 [Concat] inputs: [/bert/encoder/layer.4/attention/self/Unsqueeze_4_output_0 -> (1)[INT32]], [/bert/encoder/layer.4/attention/self/Unsqueeze_5_output_0 -> (1)[INT32]], [/bert/encoder/layer.4/attention/self/Constant_10_output_0 -> (1)[INT32]], [/bert/encoder/layer.4/attention/self/Constant_11_output_0 -> (1)[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Constant_10_output_0 for ONNX node: /bert/encoder/layer.4/attention/self/Constant_10_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Constant_11_output_0 for ONNX node: /bert/encoder/layer.4/attention/self/Constant_11_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Concat_2 for ONNX node: /bert/encoder/layer.4/attention/self/Concat_2\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/Concat_2_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/Concat_2_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/self/Concat_2 [Concat] outputs: [/bert/encoder/layer.4/attention/self/Concat_2_output_0 -> (4)[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Reshape_2 [Reshape]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/query/Add_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Concat_2_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/self/Reshape_2 [Reshape] inputs: [/bert/encoder/layer.4/attention/self/query/Add_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.4/attention/self/Concat_2_output_0 -> (4)[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Reshape_2 for ONNX node: /bert/encoder/layer.4/attention/self/Reshape_2\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/Reshape_2_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/Reshape_2_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/self/Reshape_2 [Reshape] outputs: [/bert/encoder/layer.4/attention/self/Reshape_2_output_0 -> (-1, -1, 8, 32)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Transpose_1 [Transpose]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Reshape_2_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/self/Transpose_1 [Transpose] inputs: [/bert/encoder/layer.4/attention/self/Reshape_2_output_0 -> (-1, -1, 8, 32)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Transpose_1 for ONNX node: /bert/encoder/layer.4/attention/self/Transpose_1\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/Transpose_1_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/Transpose_1_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/self/Transpose_1 [Transpose] outputs: [/bert/encoder/layer.4/attention/self/Transpose_1_output_0 -> (-1, 8, -1, 32)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Transpose_2 [Transpose]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Reshape_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/self/Transpose_2 [Transpose] inputs: [/bert/encoder/layer.4/attention/self/Reshape_output_0 -> (-1, -1, 8, 32)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Transpose_2 for ONNX node: /bert/encoder/layer.4/attention/self/Transpose_2\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/Transpose_2_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/Transpose_2_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/self/Transpose_2 [Transpose] outputs: [/bert/encoder/layer.4/attention/self/Transpose_2_output_0 -> (-1, 8, 32, -1)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/MatMul [MatMul]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Transpose_1_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Transpose_2_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/self/MatMul [MatMul] inputs: [/bert/encoder/layer.4/attention/self/Transpose_1_output_0 -> (-1, 8, -1, 32)[FLOAT]], [/bert/encoder/layer.4/attention/self/Transpose_2_output_0 -> (-1, 8, 32, -1)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/MatMul for ONNX node: /bert/encoder/layer.4/attention/self/MatMul\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/MatMul_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/MatMul_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/self/MatMul [MatMul] outputs: [/bert/encoder/layer.4/attention/self/MatMul_output_0 -> (-1, 8, -1, -1)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Constant_12 [Constant]\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/self/Constant_12 [Constant] inputs: \n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/self/Constant_12 [Constant] outputs: [/bert/encoder/layer.4/attention/self/Constant_12_output_0 -> ()[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Div [Div]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/MatMul_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Constant_12_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/self/Div [Div] inputs: [/bert/encoder/layer.4/attention/self/MatMul_output_0 -> (-1, 8, -1, -1)[FLOAT]], [/bert/encoder/layer.4/attention/self/Constant_12_output_0 -> ()[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Constant_12_output_0 for ONNX node: /bert/encoder/layer.4/attention/self/Constant_12_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Div for ONNX node: /bert/encoder/layer.4/attention/self/Div\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/Div_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/Div_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/self/Div [Div] outputs: [/bert/encoder/layer.4/attention/self/Div_output_0 -> (-1, 8, -1, -1)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Add [Add]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Div_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/Mul_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/self/Add [Add] inputs: [/bert/encoder/layer.4/attention/self/Div_output_0 -> (-1, 8, -1, -1)[FLOAT]], [/bert/Mul_output_0 -> (-1, 1, 1, -1)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Add for ONNX node: /bert/encoder/layer.4/attention/self/Add\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/Add_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/Add_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/self/Add [Add] outputs: [/bert/encoder/layer.4/attention/self/Add_output_0 -> (-1, 8, -1, -1)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Softmax [Softmax]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Add_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/self/Softmax [Softmax] inputs: [/bert/encoder/layer.4/attention/self/Add_output_0 -> (-1, 8, -1, -1)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Softmax for ONNX node: /bert/encoder/layer.4/attention/self/Softmax\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/Softmax_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/Softmax_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/self/Softmax [Softmax] outputs: [/bert/encoder/layer.4/attention/self/Softmax_output_0 -> (-1, 8, -1, -1)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/MatMul_1 [MatMul]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Softmax_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Transpose_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/self/MatMul_1 [MatMul] inputs: [/bert/encoder/layer.4/attention/self/Softmax_output_0 -> (-1, 8, -1, -1)[FLOAT]], [/bert/encoder/layer.4/attention/self/Transpose_output_0 -> (-1, 8, -1, 32)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/MatMul_1 for ONNX node: /bert/encoder/layer.4/attention/self/MatMul_1\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/MatMul_1_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/MatMul_1_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/self/MatMul_1 [MatMul] outputs: [/bert/encoder/layer.4/attention/self/MatMul_1_output_0 -> (-1, 8, -1, 32)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Transpose_3 [Transpose]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/MatMul_1_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/self/Transpose_3 [Transpose] inputs: [/bert/encoder/layer.4/attention/self/MatMul_1_output_0 -> (-1, 8, -1, 32)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Transpose_3 for ONNX node: /bert/encoder/layer.4/attention/self/Transpose_3\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/Transpose_3_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/Transpose_3_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/self/Transpose_3 [Transpose] outputs: [/bert/encoder/layer.4/attention/self/Transpose_3_output_0 -> (-1, -1, 8, 32)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Shape_6 [Shape]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Transpose_3_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/self/Shape_6 [Shape] inputs: [/bert/encoder/layer.4/attention/self/Transpose_3_output_0 -> (-1, -1, 8, 32)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Shape_6 for ONNX node: /bert/encoder/layer.4/attention/self/Shape_6\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/Shape_6_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/Shape_6_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/self/Shape_6 [Shape] outputs: [/bert/encoder/layer.4/attention/self/Shape_6_output_0 -> (4)[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Constant_13 [Constant]\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/self/Constant_13 [Constant] inputs: \n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/self/Constant_13 [Constant] outputs: [/bert/encoder/layer.4/attention/self/Constant_13_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Gather_6 [Gather]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Shape_6_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Constant_13_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/self/Gather_6 [Gather] inputs: [/bert/encoder/layer.4/attention/self/Shape_6_output_0 -> (4)[INT32]], [/bert/encoder/layer.4/attention/self/Constant_13_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Constant_13_output_0 for ONNX node: /bert/encoder/layer.4/attention/self/Constant_13_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Using Gather axis: 0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Gather_6 for ONNX node: /bert/encoder/layer.4/attention/self/Gather_6\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/Gather_6_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/Gather_6_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/self/Gather_6 [Gather] outputs: [/bert/encoder/layer.4/attention/self/Gather_6_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Shape_7 [Shape]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Transpose_3_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/self/Shape_7 [Shape] inputs: [/bert/encoder/layer.4/attention/self/Transpose_3_output_0 -> (-1, -1, 8, 32)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Shape_7 for ONNX node: /bert/encoder/layer.4/attention/self/Shape_7\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/Shape_7_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/Shape_7_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/self/Shape_7 [Shape] outputs: [/bert/encoder/layer.4/attention/self/Shape_7_output_0 -> (4)[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Constant_14 [Constant]\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/self/Constant_14 [Constant] inputs: \n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/self/Constant_14 [Constant] outputs: [/bert/encoder/layer.4/attention/self/Constant_14_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Gather_7 [Gather]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Shape_7_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Constant_14_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/self/Gather_7 [Gather] inputs: [/bert/encoder/layer.4/attention/self/Shape_7_output_0 -> (4)[INT32]], [/bert/encoder/layer.4/attention/self/Constant_14_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Constant_14_output_0 for ONNX node: /bert/encoder/layer.4/attention/self/Constant_14_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Using Gather axis: 0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Gather_7 for ONNX node: /bert/encoder/layer.4/attention/self/Gather_7\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/Gather_7_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/Gather_7_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/self/Gather_7 [Gather] outputs: [/bert/encoder/layer.4/attention/self/Gather_7_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Unsqueeze_6 [Unsqueeze]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Gather_6_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/self/Unsqueeze_6 [Unsqueeze] inputs: [/bert/encoder/layer.4/attention/self/Gather_6_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Unsqueeze_6 for ONNX node: /bert/encoder/layer.4/attention/self/Unsqueeze_6\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/Unsqueeze_6_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/Unsqueeze_6_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/self/Unsqueeze_6 [Unsqueeze] outputs: [/bert/encoder/layer.4/attention/self/Unsqueeze_6_output_0 -> (1)[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Unsqueeze_7 [Unsqueeze]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Gather_7_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/self/Unsqueeze_7 [Unsqueeze] inputs: [/bert/encoder/layer.4/attention/self/Gather_7_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Unsqueeze_7 for ONNX node: /bert/encoder/layer.4/attention/self/Unsqueeze_7\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/Unsqueeze_7_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/Unsqueeze_7_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/self/Unsqueeze_7 [Unsqueeze] outputs: [/bert/encoder/layer.4/attention/self/Unsqueeze_7_output_0 -> (1)[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Constant_15 [Constant]\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/self/Constant_15 [Constant] inputs: \n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/self/Constant_15 [Constant] outputs: [/bert/encoder/layer.4/attention/self/Constant_15_output_0 -> (1)[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Concat_3 [Concat]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Unsqueeze_6_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Unsqueeze_7_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Constant_15_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/self/Concat_3 [Concat] inputs: [/bert/encoder/layer.4/attention/self/Unsqueeze_6_output_0 -> (1)[INT32]], [/bert/encoder/layer.4/attention/self/Unsqueeze_7_output_0 -> (1)[INT32]], [/bert/encoder/layer.4/attention/self/Constant_15_output_0 -> (1)[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Constant_15_output_0 for ONNX node: /bert/encoder/layer.4/attention/self/Constant_15_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Concat_3 for ONNX node: /bert/encoder/layer.4/attention/self/Concat_3\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/Concat_3_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/Concat_3_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/self/Concat_3 [Concat] outputs: [/bert/encoder/layer.4/attention/self/Concat_3_output_0 -> (3)[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/self/Reshape_3 [Reshape]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Transpose_3_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Concat_3_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/self/Reshape_3 [Reshape] inputs: [/bert/encoder/layer.4/attention/self/Transpose_3_output_0 -> (-1, -1, 8, 32)[FLOAT]], [/bert/encoder/layer.4/attention/self/Concat_3_output_0 -> (3)[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/self/Reshape_3 for ONNX node: /bert/encoder/layer.4/attention/self/Reshape_3\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/self/Reshape_3_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/self/Reshape_3_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/self/Reshape_3 [Reshape] outputs: [/bert/encoder/layer.4/attention/self/Reshape_3_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/output/dense/MatMul [MatMul]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/self/Reshape_3_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: onnx::MatMul_855\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/output/dense/MatMul [MatMul] inputs: [/bert/encoder/layer.4/attention/self/Reshape_3_output_0 -> (-1, -1, 256)[FLOAT]], [onnx::MatMul_855 -> (256, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: onnx::MatMul_855 for ONNX node: onnx::MatMul_855\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/output/dense/MatMul for ONNX node: /bert/encoder/layer.4/attention/output/dense/MatMul\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/output/dense/MatMul_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/output/dense/MatMul_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/output/dense/MatMul [MatMul] outputs: [/bert/encoder/layer.4/attention/output/dense/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/output/dense/Add [Add]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: bert.encoder.layer.4.attention.output.dense.bias\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/output/dense/MatMul_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/output/dense/Add [Add] inputs: [bert.encoder.layer.4.attention.output.dense.bias -> (256)[FLOAT]], [/bert/encoder/layer.4/attention/output/dense/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: bert.encoder.layer.4.attention.output.dense.bias for ONNX node: bert.encoder.layer.4.attention.output.dense.bias\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/output/dense/Add for ONNX node: /bert/encoder/layer.4/attention/output/dense/Add\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/output/dense/Add_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/output/dense/Add_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/output/dense/Add [Add] outputs: [/bert/encoder/layer.4/attention/output/dense/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/output/Add [Add]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/output/dense/Add_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.3/output/LayerNorm/Add_1_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/output/Add [Add] inputs: [/bert/encoder/layer.4/attention/output/dense/Add_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.3/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/output/Add for ONNX node: /bert/encoder/layer.4/attention/output/Add\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/output/Add_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/output/Add_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/output/Add [Add] outputs: [/bert/encoder/layer.4/attention/output/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/output/LayerNorm/ReduceMean [ReduceMean]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/output/Add_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/output/LayerNorm/ReduceMean [ReduceMean] inputs: [/bert/encoder/layer.4/attention/output/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/output/LayerNorm/ReduceMean for ONNX node: /bert/encoder/layer.4/attention/output/LayerNorm/ReduceMean\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/output/LayerNorm/ReduceMean_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/output/LayerNorm/ReduceMean_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/output/LayerNorm/ReduceMean [ReduceMean] outputs: [/bert/encoder/layer.4/attention/output/LayerNorm/ReduceMean_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/output/LayerNorm/Sub [Sub]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/output/Add_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/output/LayerNorm/ReduceMean_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/output/LayerNorm/Sub [Sub] inputs: [/bert/encoder/layer.4/attention/output/Add_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.4/attention/output/LayerNorm/ReduceMean_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/output/LayerNorm/Sub for ONNX node: /bert/encoder/layer.4/attention/output/LayerNorm/Sub\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/output/LayerNorm/Sub_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/output/LayerNorm/Sub_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/output/LayerNorm/Sub [Sub] outputs: [/bert/encoder/layer.4/attention/output/LayerNorm/Sub_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/output/LayerNorm/Constant [Constant]\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/output/LayerNorm/Constant [Constant] inputs: \n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/output/LayerNorm/Constant [Constant] outputs: [/bert/encoder/layer.4/attention/output/LayerNorm/Constant_output_0 -> ()[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/output/LayerNorm/Pow [Pow]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/output/LayerNorm/Sub_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/output/LayerNorm/Constant_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/output/LayerNorm/Pow [Pow] inputs: [/bert/encoder/layer.4/attention/output/LayerNorm/Sub_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.4/attention/output/LayerNorm/Constant_output_0 -> ()[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/output/LayerNorm/Constant_output_0 for ONNX node: /bert/encoder/layer.4/attention/output/LayerNorm/Constant_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/output/LayerNorm/Pow for ONNX node: /bert/encoder/layer.4/attention/output/LayerNorm/Pow\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/output/LayerNorm/Pow_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/output/LayerNorm/Pow_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/output/LayerNorm/Pow [Pow] outputs: [/bert/encoder/layer.4/attention/output/LayerNorm/Pow_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/output/LayerNorm/ReduceMean_1 [ReduceMean]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/output/LayerNorm/Pow_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/output/LayerNorm/ReduceMean_1 [ReduceMean] inputs: [/bert/encoder/layer.4/attention/output/LayerNorm/Pow_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/output/LayerNorm/ReduceMean_1 for ONNX node: /bert/encoder/layer.4/attention/output/LayerNorm/ReduceMean_1\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/output/LayerNorm/ReduceMean_1_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/output/LayerNorm/ReduceMean_1_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/output/LayerNorm/ReduceMean_1 [ReduceMean] outputs: [/bert/encoder/layer.4/attention/output/LayerNorm/ReduceMean_1_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/output/LayerNorm/Constant_1 [Constant]\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/output/LayerNorm/Constant_1 [Constant] inputs: \n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/output/LayerNorm/Constant_1 [Constant] outputs: [/bert/encoder/layer.4/attention/output/LayerNorm/Constant_1_output_0 -> ()[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/output/LayerNorm/Add [Add]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/output/LayerNorm/ReduceMean_1_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/output/LayerNorm/Constant_1_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/output/LayerNorm/Add [Add] inputs: [/bert/encoder/layer.4/attention/output/LayerNorm/ReduceMean_1_output_0 -> (-1, -1, 1)[FLOAT]], [/bert/encoder/layer.4/attention/output/LayerNorm/Constant_1_output_0 -> ()[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/output/LayerNorm/Constant_1_output_0 for ONNX node: /bert/encoder/layer.4/attention/output/LayerNorm/Constant_1_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/output/LayerNorm/Add for ONNX node: /bert/encoder/layer.4/attention/output/LayerNorm/Add\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/output/LayerNorm/Add_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/output/LayerNorm/Add_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/output/LayerNorm/Add [Add] outputs: [/bert/encoder/layer.4/attention/output/LayerNorm/Add_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/output/LayerNorm/Sqrt [Sqrt]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/output/LayerNorm/Add_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/output/LayerNorm/Sqrt [Sqrt] inputs: [/bert/encoder/layer.4/attention/output/LayerNorm/Add_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/output/LayerNorm/Sqrt for ONNX node: /bert/encoder/layer.4/attention/output/LayerNorm/Sqrt\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/output/LayerNorm/Sqrt_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/output/LayerNorm/Sqrt_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/output/LayerNorm/Sqrt [Sqrt] outputs: [/bert/encoder/layer.4/attention/output/LayerNorm/Sqrt_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/output/LayerNorm/Div [Div]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/output/LayerNorm/Sub_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/output/LayerNorm/Sqrt_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/output/LayerNorm/Div [Div] inputs: [/bert/encoder/layer.4/attention/output/LayerNorm/Sub_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.4/attention/output/LayerNorm/Sqrt_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/output/LayerNorm/Div for ONNX node: /bert/encoder/layer.4/attention/output/LayerNorm/Div\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/output/LayerNorm/Div_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/output/LayerNorm/Div_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/output/LayerNorm/Div [Div] outputs: [/bert/encoder/layer.4/attention/output/LayerNorm/Div_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/output/LayerNorm/Mul [Mul]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/output/LayerNorm/Div_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: bert.encoder.layer.4.attention.output.LayerNorm.weight\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/output/LayerNorm/Mul [Mul] inputs: [/bert/encoder/layer.4/attention/output/LayerNorm/Div_output_0 -> (-1, -1, 256)[FLOAT]], [bert.encoder.layer.4.attention.output.LayerNorm.weight -> (256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: bert.encoder.layer.4.attention.output.LayerNorm.weight for ONNX node: bert.encoder.layer.4.attention.output.LayerNorm.weight\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/output/LayerNorm/Mul for ONNX node: /bert/encoder/layer.4/attention/output/LayerNorm/Mul\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/output/LayerNorm/Mul_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/output/LayerNorm/Mul_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/output/LayerNorm/Mul [Mul] outputs: [/bert/encoder/layer.4/attention/output/LayerNorm/Mul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.4/attention/output/LayerNorm/Add_1 [Add]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/output/LayerNorm/Mul_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: bert.encoder.layer.4.attention.output.LayerNorm.bias\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/output/LayerNorm/Add_1 [Add] inputs: [/bert/encoder/layer.4/attention/output/LayerNorm/Mul_output_0 -> (-1, -1, 256)[FLOAT]], [bert.encoder.layer.4.attention.output.LayerNorm.bias -> (256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: bert.encoder.layer.4.attention.output.LayerNorm.bias for ONNX node: bert.encoder.layer.4.attention.output.LayerNorm.bias\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.4/attention/output/LayerNorm/Add_1 for ONNX node: /bert/encoder/layer.4/attention/output/LayerNorm/Add_1\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.4/attention/output/LayerNorm/Add_1_output_0 for ONNX tensor: /bert/encoder/layer.4/attention/output/LayerNorm/Add_1_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/attention/output/LayerNorm/Add_1 [Add] outputs: [/bert/encoder/layer.4/attention/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.4/intermediate/dense/MatMul [MatMul]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/output/LayerNorm/Add_1_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: onnx::MatMul_856\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/intermediate/dense/MatMul [MatMul] inputs: [/bert/encoder/layer.4/attention/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], [onnx::MatMul_856 -> (256, 1024)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: onnx::MatMul_856 for ONNX node: onnx::MatMul_856\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.4/intermediate/dense/MatMul for ONNX node: /bert/encoder/layer.4/intermediate/dense/MatMul\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.4/intermediate/dense/MatMul_output_0 for ONNX tensor: /bert/encoder/layer.4/intermediate/dense/MatMul_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/intermediate/dense/MatMul [MatMul] outputs: [/bert/encoder/layer.4/intermediate/dense/MatMul_output_0 -> (-1, -1, 1024)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.4/intermediate/dense/Add [Add]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: bert.encoder.layer.4.intermediate.dense.bias\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.4/intermediate/dense/MatMul_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/intermediate/dense/Add [Add] inputs: [bert.encoder.layer.4.intermediate.dense.bias -> (1024)[FLOAT]], [/bert/encoder/layer.4/intermediate/dense/MatMul_output_0 -> (-1, -1, 1024)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: bert.encoder.layer.4.intermediate.dense.bias for ONNX node: bert.encoder.layer.4.intermediate.dense.bias\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.4/intermediate/dense/Add for ONNX node: /bert/encoder/layer.4/intermediate/dense/Add\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.4/intermediate/dense/Add_output_0 for ONNX tensor: /bert/encoder/layer.4/intermediate/dense/Add_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/intermediate/dense/Add [Add] outputs: [/bert/encoder/layer.4/intermediate/dense/Add_output_0 -> (-1, -1, 1024)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.4/intermediate/intermediate_act_fn/Constant [Constant]\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/intermediate/intermediate_act_fn/Constant [Constant] inputs: \n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/intermediate/intermediate_act_fn/Constant [Constant] outputs: [/bert/encoder/layer.4/intermediate/intermediate_act_fn/Constant_output_0 -> ()[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.4/intermediate/intermediate_act_fn/Div [Div]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.4/intermediate/dense/Add_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.4/intermediate/intermediate_act_fn/Constant_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/intermediate/intermediate_act_fn/Div [Div] inputs: [/bert/encoder/layer.4/intermediate/dense/Add_output_0 -> (-1, -1, 1024)[FLOAT]], [/bert/encoder/layer.4/intermediate/intermediate_act_fn/Constant_output_0 -> ()[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.4/intermediate/intermediate_act_fn/Constant_output_0 for ONNX node: /bert/encoder/layer.4/intermediate/intermediate_act_fn/Constant_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.4/intermediate/intermediate_act_fn/Div for ONNX node: /bert/encoder/layer.4/intermediate/intermediate_act_fn/Div\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.4/intermediate/intermediate_act_fn/Div_output_0 for ONNX tensor: /bert/encoder/layer.4/intermediate/intermediate_act_fn/Div_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/intermediate/intermediate_act_fn/Div [Div] outputs: [/bert/encoder/layer.4/intermediate/intermediate_act_fn/Div_output_0 -> (-1, -1, 1024)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.4/intermediate/intermediate_act_fn/Erf [Erf]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.4/intermediate/intermediate_act_fn/Div_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/intermediate/intermediate_act_fn/Erf [Erf] inputs: [/bert/encoder/layer.4/intermediate/intermediate_act_fn/Div_output_0 -> (-1, -1, 1024)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.4/intermediate/intermediate_act_fn/Erf for ONNX node: /bert/encoder/layer.4/intermediate/intermediate_act_fn/Erf\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.4/intermediate/intermediate_act_fn/Erf_output_0 for ONNX tensor: /bert/encoder/layer.4/intermediate/intermediate_act_fn/Erf_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/intermediate/intermediate_act_fn/Erf [Erf] outputs: [/bert/encoder/layer.4/intermediate/intermediate_act_fn/Erf_output_0 -> (-1, -1, 1024)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.4/intermediate/intermediate_act_fn/Constant_1 [Constant]\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/intermediate/intermediate_act_fn/Constant_1 [Constant] inputs: \n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/intermediate/intermediate_act_fn/Constant_1 [Constant] outputs: [/bert/encoder/layer.4/intermediate/intermediate_act_fn/Constant_1_output_0 -> ()[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.4/intermediate/intermediate_act_fn/Add [Add]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.4/intermediate/intermediate_act_fn/Erf_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.4/intermediate/intermediate_act_fn/Constant_1_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/intermediate/intermediate_act_fn/Add [Add] inputs: [/bert/encoder/layer.4/intermediate/intermediate_act_fn/Erf_output_0 -> (-1, -1, 1024)[FLOAT]], [/bert/encoder/layer.4/intermediate/intermediate_act_fn/Constant_1_output_0 -> ()[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.4/intermediate/intermediate_act_fn/Constant_1_output_0 for ONNX node: /bert/encoder/layer.4/intermediate/intermediate_act_fn/Constant_1_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.4/intermediate/intermediate_act_fn/Add for ONNX node: /bert/encoder/layer.4/intermediate/intermediate_act_fn/Add\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.4/intermediate/intermediate_act_fn/Add_output_0 for ONNX tensor: /bert/encoder/layer.4/intermediate/intermediate_act_fn/Add_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/intermediate/intermediate_act_fn/Add [Add] outputs: [/bert/encoder/layer.4/intermediate/intermediate_act_fn/Add_output_0 -> (-1, -1, 1024)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.4/intermediate/intermediate_act_fn/Mul [Mul]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.4/intermediate/dense/Add_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.4/intermediate/intermediate_act_fn/Add_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/intermediate/intermediate_act_fn/Mul [Mul] inputs: [/bert/encoder/layer.4/intermediate/dense/Add_output_0 -> (-1, -1, 1024)[FLOAT]], [/bert/encoder/layer.4/intermediate/intermediate_act_fn/Add_output_0 -> (-1, -1, 1024)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.4/intermediate/intermediate_act_fn/Mul for ONNX node: /bert/encoder/layer.4/intermediate/intermediate_act_fn/Mul\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.4/intermediate/intermediate_act_fn/Mul_output_0 for ONNX tensor: /bert/encoder/layer.4/intermediate/intermediate_act_fn/Mul_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/intermediate/intermediate_act_fn/Mul [Mul] outputs: [/bert/encoder/layer.4/intermediate/intermediate_act_fn/Mul_output_0 -> (-1, -1, 1024)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.4/intermediate/intermediate_act_fn/Constant_2 [Constant]\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/intermediate/intermediate_act_fn/Constant_2 [Constant] inputs: \n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/intermediate/intermediate_act_fn/Constant_2 [Constant] outputs: [/bert/encoder/layer.4/intermediate/intermediate_act_fn/Constant_2_output_0 -> ()[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.4/intermediate/intermediate_act_fn/Mul_1 [Mul]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.4/intermediate/intermediate_act_fn/Mul_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.4/intermediate/intermediate_act_fn/Constant_2_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/intermediate/intermediate_act_fn/Mul_1 [Mul] inputs: [/bert/encoder/layer.4/intermediate/intermediate_act_fn/Mul_output_0 -> (-1, -1, 1024)[FLOAT]], [/bert/encoder/layer.4/intermediate/intermediate_act_fn/Constant_2_output_0 -> ()[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.4/intermediate/intermediate_act_fn/Constant_2_output_0 for ONNX node: /bert/encoder/layer.4/intermediate/intermediate_act_fn/Constant_2_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.4/intermediate/intermediate_act_fn/Mul_1 for ONNX node: /bert/encoder/layer.4/intermediate/intermediate_act_fn/Mul_1\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.4/intermediate/intermediate_act_fn/Mul_1_output_0 for ONNX tensor: /bert/encoder/layer.4/intermediate/intermediate_act_fn/Mul_1_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/intermediate/intermediate_act_fn/Mul_1 [Mul] outputs: [/bert/encoder/layer.4/intermediate/intermediate_act_fn/Mul_1_output_0 -> (-1, -1, 1024)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.4/output/dense/MatMul [MatMul]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.4/intermediate/intermediate_act_fn/Mul_1_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: onnx::MatMul_857\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/output/dense/MatMul [MatMul] inputs: [/bert/encoder/layer.4/intermediate/intermediate_act_fn/Mul_1_output_0 -> (-1, -1, 1024)[FLOAT]], [onnx::MatMul_857 -> (1024, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: onnx::MatMul_857 for ONNX node: onnx::MatMul_857\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.4/output/dense/MatMul for ONNX node: /bert/encoder/layer.4/output/dense/MatMul\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.4/output/dense/MatMul_output_0 for ONNX tensor: /bert/encoder/layer.4/output/dense/MatMul_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/output/dense/MatMul [MatMul] outputs: [/bert/encoder/layer.4/output/dense/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.4/output/dense/Add [Add]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: bert.encoder.layer.4.output.dense.bias\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.4/output/dense/MatMul_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/output/dense/Add [Add] inputs: [bert.encoder.layer.4.output.dense.bias -> (256)[FLOAT]], [/bert/encoder/layer.4/output/dense/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: bert.encoder.layer.4.output.dense.bias for ONNX node: bert.encoder.layer.4.output.dense.bias\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.4/output/dense/Add for ONNX node: /bert/encoder/layer.4/output/dense/Add\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.4/output/dense/Add_output_0 for ONNX tensor: /bert/encoder/layer.4/output/dense/Add_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/output/dense/Add [Add] outputs: [/bert/encoder/layer.4/output/dense/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.4/output/Add [Add]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.4/output/dense/Add_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.4/attention/output/LayerNorm/Add_1_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/output/Add [Add] inputs: [/bert/encoder/layer.4/output/dense/Add_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.4/attention/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.4/output/Add for ONNX node: /bert/encoder/layer.4/output/Add\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.4/output/Add_output_0 for ONNX tensor: /bert/encoder/layer.4/output/Add_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/output/Add [Add] outputs: [/bert/encoder/layer.4/output/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.4/output/LayerNorm/ReduceMean [ReduceMean]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.4/output/Add_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/output/LayerNorm/ReduceMean [ReduceMean] inputs: [/bert/encoder/layer.4/output/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.4/output/LayerNorm/ReduceMean for ONNX node: /bert/encoder/layer.4/output/LayerNorm/ReduceMean\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.4/output/LayerNorm/ReduceMean_output_0 for ONNX tensor: /bert/encoder/layer.4/output/LayerNorm/ReduceMean_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/output/LayerNorm/ReduceMean [ReduceMean] outputs: [/bert/encoder/layer.4/output/LayerNorm/ReduceMean_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.4/output/LayerNorm/Sub [Sub]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.4/output/Add_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.4/output/LayerNorm/ReduceMean_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/output/LayerNorm/Sub [Sub] inputs: [/bert/encoder/layer.4/output/Add_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.4/output/LayerNorm/ReduceMean_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.4/output/LayerNorm/Sub for ONNX node: /bert/encoder/layer.4/output/LayerNorm/Sub\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.4/output/LayerNorm/Sub_output_0 for ONNX tensor: /bert/encoder/layer.4/output/LayerNorm/Sub_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/output/LayerNorm/Sub [Sub] outputs: [/bert/encoder/layer.4/output/LayerNorm/Sub_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.4/output/LayerNorm/Constant [Constant]\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/output/LayerNorm/Constant [Constant] inputs: \n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/output/LayerNorm/Constant [Constant] outputs: [/bert/encoder/layer.4/output/LayerNorm/Constant_output_0 -> ()[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.4/output/LayerNorm/Pow [Pow]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.4/output/LayerNorm/Sub_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.4/output/LayerNorm/Constant_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/output/LayerNorm/Pow [Pow] inputs: [/bert/encoder/layer.4/output/LayerNorm/Sub_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.4/output/LayerNorm/Constant_output_0 -> ()[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.4/output/LayerNorm/Constant_output_0 for ONNX node: /bert/encoder/layer.4/output/LayerNorm/Constant_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.4/output/LayerNorm/Pow for ONNX node: /bert/encoder/layer.4/output/LayerNorm/Pow\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.4/output/LayerNorm/Pow_output_0 for ONNX tensor: /bert/encoder/layer.4/output/LayerNorm/Pow_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/output/LayerNorm/Pow [Pow] outputs: [/bert/encoder/layer.4/output/LayerNorm/Pow_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.4/output/LayerNorm/ReduceMean_1 [ReduceMean]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.4/output/LayerNorm/Pow_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/output/LayerNorm/ReduceMean_1 [ReduceMean] inputs: [/bert/encoder/layer.4/output/LayerNorm/Pow_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.4/output/LayerNorm/ReduceMean_1 for ONNX node: /bert/encoder/layer.4/output/LayerNorm/ReduceMean_1\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.4/output/LayerNorm/ReduceMean_1_output_0 for ONNX tensor: /bert/encoder/layer.4/output/LayerNorm/ReduceMean_1_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/output/LayerNorm/ReduceMean_1 [ReduceMean] outputs: [/bert/encoder/layer.4/output/LayerNorm/ReduceMean_1_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.4/output/LayerNorm/Constant_1 [Constant]\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/output/LayerNorm/Constant_1 [Constant] inputs: \n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/output/LayerNorm/Constant_1 [Constant] outputs: [/bert/encoder/layer.4/output/LayerNorm/Constant_1_output_0 -> ()[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.4/output/LayerNorm/Add [Add]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.4/output/LayerNorm/ReduceMean_1_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.4/output/LayerNorm/Constant_1_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/output/LayerNorm/Add [Add] inputs: [/bert/encoder/layer.4/output/LayerNorm/ReduceMean_1_output_0 -> (-1, -1, 1)[FLOAT]], [/bert/encoder/layer.4/output/LayerNorm/Constant_1_output_0 -> ()[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.4/output/LayerNorm/Constant_1_output_0 for ONNX node: /bert/encoder/layer.4/output/LayerNorm/Constant_1_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.4/output/LayerNorm/Add for ONNX node: /bert/encoder/layer.4/output/LayerNorm/Add\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.4/output/LayerNorm/Add_output_0 for ONNX tensor: /bert/encoder/layer.4/output/LayerNorm/Add_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/output/LayerNorm/Add [Add] outputs: [/bert/encoder/layer.4/output/LayerNorm/Add_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.4/output/LayerNorm/Sqrt [Sqrt]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.4/output/LayerNorm/Add_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/output/LayerNorm/Sqrt [Sqrt] inputs: [/bert/encoder/layer.4/output/LayerNorm/Add_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.4/output/LayerNorm/Sqrt for ONNX node: /bert/encoder/layer.4/output/LayerNorm/Sqrt\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.4/output/LayerNorm/Sqrt_output_0 for ONNX tensor: /bert/encoder/layer.4/output/LayerNorm/Sqrt_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/output/LayerNorm/Sqrt [Sqrt] outputs: [/bert/encoder/layer.4/output/LayerNorm/Sqrt_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.4/output/LayerNorm/Div [Div]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.4/output/LayerNorm/Sub_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.4/output/LayerNorm/Sqrt_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/output/LayerNorm/Div [Div] inputs: [/bert/encoder/layer.4/output/LayerNorm/Sub_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.4/output/LayerNorm/Sqrt_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.4/output/LayerNorm/Div for ONNX node: /bert/encoder/layer.4/output/LayerNorm/Div\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.4/output/LayerNorm/Div_output_0 for ONNX tensor: /bert/encoder/layer.4/output/LayerNorm/Div_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/output/LayerNorm/Div [Div] outputs: [/bert/encoder/layer.4/output/LayerNorm/Div_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.4/output/LayerNorm/Mul [Mul]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.4/output/LayerNorm/Div_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: bert.encoder.layer.4.output.LayerNorm.weight\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/output/LayerNorm/Mul [Mul] inputs: [/bert/encoder/layer.4/output/LayerNorm/Div_output_0 -> (-1, -1, 256)[FLOAT]], [bert.encoder.layer.4.output.LayerNorm.weight -> (256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: bert.encoder.layer.4.output.LayerNorm.weight for ONNX node: bert.encoder.layer.4.output.LayerNorm.weight\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.4/output/LayerNorm/Mul for ONNX node: /bert/encoder/layer.4/output/LayerNorm/Mul\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.4/output/LayerNorm/Mul_output_0 for ONNX tensor: /bert/encoder/layer.4/output/LayerNorm/Mul_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/output/LayerNorm/Mul [Mul] outputs: [/bert/encoder/layer.4/output/LayerNorm/Mul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.4/output/LayerNorm/Add_1 [Add]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.4/output/LayerNorm/Mul_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: bert.encoder.layer.4.output.LayerNorm.bias\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/output/LayerNorm/Add_1 [Add] inputs: [/bert/encoder/layer.4/output/LayerNorm/Mul_output_0 -> (-1, -1, 256)[FLOAT]], [bert.encoder.layer.4.output.LayerNorm.bias -> (256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: bert.encoder.layer.4.output.LayerNorm.bias for ONNX node: bert.encoder.layer.4.output.LayerNorm.bias\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.4/output/LayerNorm/Add_1 for ONNX node: /bert/encoder/layer.4/output/LayerNorm/Add_1\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.4/output/LayerNorm/Add_1_output_0 for ONNX tensor: /bert/encoder/layer.4/output/LayerNorm/Add_1_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.4/output/LayerNorm/Add_1 [Add] outputs: [/bert/encoder/layer.4/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/query/MatMul [MatMul]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.4/output/LayerNorm/Add_1_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: onnx::MatMul_858\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/self/query/MatMul [MatMul] inputs: [/bert/encoder/layer.4/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], [onnx::MatMul_858 -> (256, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: onnx::MatMul_858 for ONNX node: onnx::MatMul_858\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/query/MatMul for ONNX node: /bert/encoder/layer.5/attention/self/query/MatMul\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/query/MatMul_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/query/MatMul_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/self/query/MatMul [MatMul] outputs: [/bert/encoder/layer.5/attention/self/query/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/query/Add [Add]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: bert.encoder.layer.5.attention.self.query.bias\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/query/MatMul_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/self/query/Add [Add] inputs: [bert.encoder.layer.5.attention.self.query.bias -> (256)[FLOAT]], [/bert/encoder/layer.5/attention/self/query/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: bert.encoder.layer.5.attention.self.query.bias for ONNX node: bert.encoder.layer.5.attention.self.query.bias\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/query/Add for ONNX node: /bert/encoder/layer.5/attention/self/query/Add\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/query/Add_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/query/Add_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/self/query/Add [Add] outputs: [/bert/encoder/layer.5/attention/self/query/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/key/MatMul [MatMul]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.4/output/LayerNorm/Add_1_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: onnx::MatMul_859\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/self/key/MatMul [MatMul] inputs: [/bert/encoder/layer.4/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], [onnx::MatMul_859 -> (256, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: onnx::MatMul_859 for ONNX node: onnx::MatMul_859\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/key/MatMul for ONNX node: /bert/encoder/layer.5/attention/self/key/MatMul\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/key/MatMul_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/key/MatMul_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/self/key/MatMul [MatMul] outputs: [/bert/encoder/layer.5/attention/self/key/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/key/Add [Add]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: bert.encoder.layer.5.attention.self.key.bias\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/key/MatMul_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/self/key/Add [Add] inputs: [bert.encoder.layer.5.attention.self.key.bias -> (256)[FLOAT]], [/bert/encoder/layer.5/attention/self/key/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: bert.encoder.layer.5.attention.self.key.bias for ONNX node: bert.encoder.layer.5.attention.self.key.bias\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/key/Add for ONNX node: /bert/encoder/layer.5/attention/self/key/Add\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/key/Add_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/key/Add_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/self/key/Add [Add] outputs: [/bert/encoder/layer.5/attention/self/key/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Shape [Shape]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/key/Add_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/self/Shape [Shape] inputs: [/bert/encoder/layer.5/attention/self/key/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Shape for ONNX node: /bert/encoder/layer.5/attention/self/Shape\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/Shape_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/Shape_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/self/Shape [Shape] outputs: [/bert/encoder/layer.5/attention/self/Shape_output_0 -> (3)[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Constant [Constant]\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/self/Constant [Constant] inputs: \n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/self/Constant [Constant] outputs: [/bert/encoder/layer.5/attention/self/Constant_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Gather [Gather]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Shape_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Constant_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/self/Gather [Gather] inputs: [/bert/encoder/layer.5/attention/self/Shape_output_0 -> (3)[INT32]], [/bert/encoder/layer.5/attention/self/Constant_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Constant_output_0 for ONNX node: /bert/encoder/layer.5/attention/self/Constant_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Using Gather axis: 0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Gather for ONNX node: /bert/encoder/layer.5/attention/self/Gather\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/Gather_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/Gather_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/self/Gather [Gather] outputs: [/bert/encoder/layer.5/attention/self/Gather_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Shape_1 [Shape]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/key/Add_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/self/Shape_1 [Shape] inputs: [/bert/encoder/layer.5/attention/self/key/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Shape_1 for ONNX node: /bert/encoder/layer.5/attention/self/Shape_1\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/Shape_1_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/Shape_1_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/self/Shape_1 [Shape] outputs: [/bert/encoder/layer.5/attention/self/Shape_1_output_0 -> (3)[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Constant_1 [Constant]\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/self/Constant_1 [Constant] inputs: \n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/self/Constant_1 [Constant] outputs: [/bert/encoder/layer.5/attention/self/Constant_1_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Gather_1 [Gather]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Shape_1_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Constant_1_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/self/Gather_1 [Gather] inputs: [/bert/encoder/layer.5/attention/self/Shape_1_output_0 -> (3)[INT32]], [/bert/encoder/layer.5/attention/self/Constant_1_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Constant_1_output_0 for ONNX node: /bert/encoder/layer.5/attention/self/Constant_1_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Using Gather axis: 0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Gather_1 for ONNX node: /bert/encoder/layer.5/attention/self/Gather_1\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/Gather_1_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/Gather_1_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/self/Gather_1 [Gather] outputs: [/bert/encoder/layer.5/attention/self/Gather_1_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Unsqueeze [Unsqueeze]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Gather_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/self/Unsqueeze [Unsqueeze] inputs: [/bert/encoder/layer.5/attention/self/Gather_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Unsqueeze for ONNX node: /bert/encoder/layer.5/attention/self/Unsqueeze\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/Unsqueeze_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/Unsqueeze_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/self/Unsqueeze [Unsqueeze] outputs: [/bert/encoder/layer.5/attention/self/Unsqueeze_output_0 -> (1)[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Unsqueeze_1 [Unsqueeze]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Gather_1_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/self/Unsqueeze_1 [Unsqueeze] inputs: [/bert/encoder/layer.5/attention/self/Gather_1_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Unsqueeze_1 for ONNX node: /bert/encoder/layer.5/attention/self/Unsqueeze_1\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/Unsqueeze_1_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/Unsqueeze_1_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/self/Unsqueeze_1 [Unsqueeze] outputs: [/bert/encoder/layer.5/attention/self/Unsqueeze_1_output_0 -> (1)[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Constant_2 [Constant]\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/self/Constant_2 [Constant] inputs: \n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/self/Constant_2 [Constant] outputs: [/bert/encoder/layer.5/attention/self/Constant_2_output_0 -> (1)[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Constant_3 [Constant]\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/self/Constant_3 [Constant] inputs: \n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/self/Constant_3 [Constant] outputs: [/bert/encoder/layer.5/attention/self/Constant_3_output_0 -> (1)[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Concat [Concat]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Unsqueeze_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Unsqueeze_1_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Constant_2_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Constant_3_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/self/Concat [Concat] inputs: [/bert/encoder/layer.5/attention/self/Unsqueeze_output_0 -> (1)[INT32]], [/bert/encoder/layer.5/attention/self/Unsqueeze_1_output_0 -> (1)[INT32]], [/bert/encoder/layer.5/attention/self/Constant_2_output_0 -> (1)[INT32]], [/bert/encoder/layer.5/attention/self/Constant_3_output_0 -> (1)[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Constant_2_output_0 for ONNX node: /bert/encoder/layer.5/attention/self/Constant_2_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Constant_3_output_0 for ONNX node: /bert/encoder/layer.5/attention/self/Constant_3_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Concat for ONNX node: /bert/encoder/layer.5/attention/self/Concat\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/Concat_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/Concat_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/self/Concat [Concat] outputs: [/bert/encoder/layer.5/attention/self/Concat_output_0 -> (4)[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Reshape [Reshape]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/key/Add_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Concat_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/self/Reshape [Reshape] inputs: [/bert/encoder/layer.5/attention/self/key/Add_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.5/attention/self/Concat_output_0 -> (4)[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Reshape for ONNX node: /bert/encoder/layer.5/attention/self/Reshape\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/Reshape_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/Reshape_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/self/Reshape [Reshape] outputs: [/bert/encoder/layer.5/attention/self/Reshape_output_0 -> (-1, -1, 8, 32)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/value/MatMul [MatMul]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.4/output/LayerNorm/Add_1_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: onnx::MatMul_862\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/self/value/MatMul [MatMul] inputs: [/bert/encoder/layer.4/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], [onnx::MatMul_862 -> (256, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: onnx::MatMul_862 for ONNX node: onnx::MatMul_862\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/value/MatMul for ONNX node: /bert/encoder/layer.5/attention/self/value/MatMul\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/value/MatMul_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/value/MatMul_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/self/value/MatMul [MatMul] outputs: [/bert/encoder/layer.5/attention/self/value/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/value/Add [Add]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: bert.encoder.layer.5.attention.self.value.bias\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/value/MatMul_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/self/value/Add [Add] inputs: [bert.encoder.layer.5.attention.self.value.bias -> (256)[FLOAT]], [/bert/encoder/layer.5/attention/self/value/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: bert.encoder.layer.5.attention.self.value.bias for ONNX node: bert.encoder.layer.5.attention.self.value.bias\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/value/Add for ONNX node: /bert/encoder/layer.5/attention/self/value/Add\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/value/Add_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/value/Add_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/self/value/Add [Add] outputs: [/bert/encoder/layer.5/attention/self/value/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Shape_2 [Shape]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/value/Add_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/self/Shape_2 [Shape] inputs: [/bert/encoder/layer.5/attention/self/value/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Shape_2 for ONNX node: /bert/encoder/layer.5/attention/self/Shape_2\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/Shape_2_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/Shape_2_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/self/Shape_2 [Shape] outputs: [/bert/encoder/layer.5/attention/self/Shape_2_output_0 -> (3)[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Constant_4 [Constant]\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/self/Constant_4 [Constant] inputs: \n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/self/Constant_4 [Constant] outputs: [/bert/encoder/layer.5/attention/self/Constant_4_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Gather_2 [Gather]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Shape_2_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Constant_4_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/self/Gather_2 [Gather] inputs: [/bert/encoder/layer.5/attention/self/Shape_2_output_0 -> (3)[INT32]], [/bert/encoder/layer.5/attention/self/Constant_4_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Constant_4_output_0 for ONNX node: /bert/encoder/layer.5/attention/self/Constant_4_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Using Gather axis: 0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Gather_2 for ONNX node: /bert/encoder/layer.5/attention/self/Gather_2\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/Gather_2_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/Gather_2_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/self/Gather_2 [Gather] outputs: [/bert/encoder/layer.5/attention/self/Gather_2_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Shape_3 [Shape]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/value/Add_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/self/Shape_3 [Shape] inputs: [/bert/encoder/layer.5/attention/self/value/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Shape_3 for ONNX node: /bert/encoder/layer.5/attention/self/Shape_3\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/Shape_3_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/Shape_3_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/self/Shape_3 [Shape] outputs: [/bert/encoder/layer.5/attention/self/Shape_3_output_0 -> (3)[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Constant_5 [Constant]\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/self/Constant_5 [Constant] inputs: \n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/self/Constant_5 [Constant] outputs: [/bert/encoder/layer.5/attention/self/Constant_5_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Gather_3 [Gather]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Shape_3_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Constant_5_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/self/Gather_3 [Gather] inputs: [/bert/encoder/layer.5/attention/self/Shape_3_output_0 -> (3)[INT32]], [/bert/encoder/layer.5/attention/self/Constant_5_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Constant_5_output_0 for ONNX node: /bert/encoder/layer.5/attention/self/Constant_5_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Using Gather axis: 0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Gather_3 for ONNX node: /bert/encoder/layer.5/attention/self/Gather_3\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/Gather_3_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/Gather_3_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/self/Gather_3 [Gather] outputs: [/bert/encoder/layer.5/attention/self/Gather_3_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Unsqueeze_2 [Unsqueeze]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Gather_2_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/self/Unsqueeze_2 [Unsqueeze] inputs: [/bert/encoder/layer.5/attention/self/Gather_2_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Unsqueeze_2 for ONNX node: /bert/encoder/layer.5/attention/self/Unsqueeze_2\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/Unsqueeze_2_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/Unsqueeze_2_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/self/Unsqueeze_2 [Unsqueeze] outputs: [/bert/encoder/layer.5/attention/self/Unsqueeze_2_output_0 -> (1)[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Unsqueeze_3 [Unsqueeze]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Gather_3_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/self/Unsqueeze_3 [Unsqueeze] inputs: [/bert/encoder/layer.5/attention/self/Gather_3_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Unsqueeze_3 for ONNX node: /bert/encoder/layer.5/attention/self/Unsqueeze_3\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/Unsqueeze_3_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/Unsqueeze_3_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/self/Unsqueeze_3 [Unsqueeze] outputs: [/bert/encoder/layer.5/attention/self/Unsqueeze_3_output_0 -> (1)[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Constant_6 [Constant]\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/self/Constant_6 [Constant] inputs: \n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/self/Constant_6 [Constant] outputs: [/bert/encoder/layer.5/attention/self/Constant_6_output_0 -> (1)[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Constant_7 [Constant]\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/self/Constant_7 [Constant] inputs: \n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/self/Constant_7 [Constant] outputs: [/bert/encoder/layer.5/attention/self/Constant_7_output_0 -> (1)[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Concat_1 [Concat]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Unsqueeze_2_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Unsqueeze_3_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Constant_6_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Constant_7_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/self/Concat_1 [Concat] inputs: [/bert/encoder/layer.5/attention/self/Unsqueeze_2_output_0 -> (1)[INT32]], [/bert/encoder/layer.5/attention/self/Unsqueeze_3_output_0 -> (1)[INT32]], [/bert/encoder/layer.5/attention/self/Constant_6_output_0 -> (1)[INT32]], [/bert/encoder/layer.5/attention/self/Constant_7_output_0 -> (1)[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Constant_6_output_0 for ONNX node: /bert/encoder/layer.5/attention/self/Constant_6_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Constant_7_output_0 for ONNX node: /bert/encoder/layer.5/attention/self/Constant_7_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Concat_1 for ONNX node: /bert/encoder/layer.5/attention/self/Concat_1\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/Concat_1_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/Concat_1_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/self/Concat_1 [Concat] outputs: [/bert/encoder/layer.5/attention/self/Concat_1_output_0 -> (4)[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Reshape_1 [Reshape]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/value/Add_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Concat_1_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/self/Reshape_1 [Reshape] inputs: [/bert/encoder/layer.5/attention/self/value/Add_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.5/attention/self/Concat_1_output_0 -> (4)[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Reshape_1 for ONNX node: /bert/encoder/layer.5/attention/self/Reshape_1\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/Reshape_1_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/Reshape_1_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/self/Reshape_1 [Reshape] outputs: [/bert/encoder/layer.5/attention/self/Reshape_1_output_0 -> (-1, -1, 8, 32)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Transpose [Transpose]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Reshape_1_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/self/Transpose [Transpose] inputs: [/bert/encoder/layer.5/attention/self/Reshape_1_output_0 -> (-1, -1, 8, 32)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Transpose for ONNX node: /bert/encoder/layer.5/attention/self/Transpose\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/Transpose_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/Transpose_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/self/Transpose [Transpose] outputs: [/bert/encoder/layer.5/attention/self/Transpose_output_0 -> (-1, 8, -1, 32)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Shape_4 [Shape]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/query/Add_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/self/Shape_4 [Shape] inputs: [/bert/encoder/layer.5/attention/self/query/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Shape_4 for ONNX node: /bert/encoder/layer.5/attention/self/Shape_4\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/Shape_4_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/Shape_4_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/self/Shape_4 [Shape] outputs: [/bert/encoder/layer.5/attention/self/Shape_4_output_0 -> (3)[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Constant_8 [Constant]\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/self/Constant_8 [Constant] inputs: \n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/self/Constant_8 [Constant] outputs: [/bert/encoder/layer.5/attention/self/Constant_8_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Gather_4 [Gather]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Shape_4_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Constant_8_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/self/Gather_4 [Gather] inputs: [/bert/encoder/layer.5/attention/self/Shape_4_output_0 -> (3)[INT32]], [/bert/encoder/layer.5/attention/self/Constant_8_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Constant_8_output_0 for ONNX node: /bert/encoder/layer.5/attention/self/Constant_8_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Using Gather axis: 0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Gather_4 for ONNX node: /bert/encoder/layer.5/attention/self/Gather_4\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/Gather_4_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/Gather_4_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/self/Gather_4 [Gather] outputs: [/bert/encoder/layer.5/attention/self/Gather_4_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Shape_5 [Shape]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/query/Add_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/self/Shape_5 [Shape] inputs: [/bert/encoder/layer.5/attention/self/query/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Shape_5 for ONNX node: /bert/encoder/layer.5/attention/self/Shape_5\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/Shape_5_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/Shape_5_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/self/Shape_5 [Shape] outputs: [/bert/encoder/layer.5/attention/self/Shape_5_output_0 -> (3)[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Constant_9 [Constant]\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/self/Constant_9 [Constant] inputs: \n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/self/Constant_9 [Constant] outputs: [/bert/encoder/layer.5/attention/self/Constant_9_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Gather_5 [Gather]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Shape_5_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Constant_9_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/self/Gather_5 [Gather] inputs: [/bert/encoder/layer.5/attention/self/Shape_5_output_0 -> (3)[INT32]], [/bert/encoder/layer.5/attention/self/Constant_9_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Constant_9_output_0 for ONNX node: /bert/encoder/layer.5/attention/self/Constant_9_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Using Gather axis: 0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Gather_5 for ONNX node: /bert/encoder/layer.5/attention/self/Gather_5\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/Gather_5_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/Gather_5_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/self/Gather_5 [Gather] outputs: [/bert/encoder/layer.5/attention/self/Gather_5_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Unsqueeze_4 [Unsqueeze]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Gather_4_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/self/Unsqueeze_4 [Unsqueeze] inputs: [/bert/encoder/layer.5/attention/self/Gather_4_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Unsqueeze_4 for ONNX node: /bert/encoder/layer.5/attention/self/Unsqueeze_4\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/Unsqueeze_4_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/Unsqueeze_4_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/self/Unsqueeze_4 [Unsqueeze] outputs: [/bert/encoder/layer.5/attention/self/Unsqueeze_4_output_0 -> (1)[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Unsqueeze_5 [Unsqueeze]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Gather_5_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/self/Unsqueeze_5 [Unsqueeze] inputs: [/bert/encoder/layer.5/attention/self/Gather_5_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Unsqueeze_5 for ONNX node: /bert/encoder/layer.5/attention/self/Unsqueeze_5\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/Unsqueeze_5_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/Unsqueeze_5_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/self/Unsqueeze_5 [Unsqueeze] outputs: [/bert/encoder/layer.5/attention/self/Unsqueeze_5_output_0 -> (1)[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Constant_10 [Constant]\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/self/Constant_10 [Constant] inputs: \n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/self/Constant_10 [Constant] outputs: [/bert/encoder/layer.5/attention/self/Constant_10_output_0 -> (1)[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Constant_11 [Constant]\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/self/Constant_11 [Constant] inputs: \n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/self/Constant_11 [Constant] outputs: [/bert/encoder/layer.5/attention/self/Constant_11_output_0 -> (1)[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Concat_2 [Concat]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Unsqueeze_4_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Unsqueeze_5_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Constant_10_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Constant_11_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/self/Concat_2 [Concat] inputs: [/bert/encoder/layer.5/attention/self/Unsqueeze_4_output_0 -> (1)[INT32]], [/bert/encoder/layer.5/attention/self/Unsqueeze_5_output_0 -> (1)[INT32]], [/bert/encoder/layer.5/attention/self/Constant_10_output_0 -> (1)[INT32]], [/bert/encoder/layer.5/attention/self/Constant_11_output_0 -> (1)[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Constant_10_output_0 for ONNX node: /bert/encoder/layer.5/attention/self/Constant_10_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Constant_11_output_0 for ONNX node: /bert/encoder/layer.5/attention/self/Constant_11_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Concat_2 for ONNX node: /bert/encoder/layer.5/attention/self/Concat_2\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/Concat_2_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/Concat_2_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/self/Concat_2 [Concat] outputs: [/bert/encoder/layer.5/attention/self/Concat_2_output_0 -> (4)[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Reshape_2 [Reshape]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/query/Add_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Concat_2_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/self/Reshape_2 [Reshape] inputs: [/bert/encoder/layer.5/attention/self/query/Add_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.5/attention/self/Concat_2_output_0 -> (4)[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Reshape_2 for ONNX node: /bert/encoder/layer.5/attention/self/Reshape_2\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/Reshape_2_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/Reshape_2_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/self/Reshape_2 [Reshape] outputs: [/bert/encoder/layer.5/attention/self/Reshape_2_output_0 -> (-1, -1, 8, 32)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Transpose_1 [Transpose]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Reshape_2_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/self/Transpose_1 [Transpose] inputs: [/bert/encoder/layer.5/attention/self/Reshape_2_output_0 -> (-1, -1, 8, 32)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Transpose_1 for ONNX node: /bert/encoder/layer.5/attention/self/Transpose_1\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/Transpose_1_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/Transpose_1_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/self/Transpose_1 [Transpose] outputs: [/bert/encoder/layer.5/attention/self/Transpose_1_output_0 -> (-1, 8, -1, 32)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Transpose_2 [Transpose]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Reshape_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/self/Transpose_2 [Transpose] inputs: [/bert/encoder/layer.5/attention/self/Reshape_output_0 -> (-1, -1, 8, 32)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Transpose_2 for ONNX node: /bert/encoder/layer.5/attention/self/Transpose_2\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/Transpose_2_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/Transpose_2_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/self/Transpose_2 [Transpose] outputs: [/bert/encoder/layer.5/attention/self/Transpose_2_output_0 -> (-1, 8, 32, -1)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/MatMul [MatMul]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Transpose_1_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Transpose_2_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/self/MatMul [MatMul] inputs: [/bert/encoder/layer.5/attention/self/Transpose_1_output_0 -> (-1, 8, -1, 32)[FLOAT]], [/bert/encoder/layer.5/attention/self/Transpose_2_output_0 -> (-1, 8, 32, -1)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/MatMul for ONNX node: /bert/encoder/layer.5/attention/self/MatMul\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/MatMul_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/MatMul_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/self/MatMul [MatMul] outputs: [/bert/encoder/layer.5/attention/self/MatMul_output_0 -> (-1, 8, -1, -1)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Constant_12 [Constant]\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/self/Constant_12 [Constant] inputs: \n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/self/Constant_12 [Constant] outputs: [/bert/encoder/layer.5/attention/self/Constant_12_output_0 -> ()[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Div [Div]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/MatMul_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Constant_12_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/self/Div [Div] inputs: [/bert/encoder/layer.5/attention/self/MatMul_output_0 -> (-1, 8, -1, -1)[FLOAT]], [/bert/encoder/layer.5/attention/self/Constant_12_output_0 -> ()[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Constant_12_output_0 for ONNX node: /bert/encoder/layer.5/attention/self/Constant_12_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Div for ONNX node: /bert/encoder/layer.5/attention/self/Div\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/Div_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/Div_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/self/Div [Div] outputs: [/bert/encoder/layer.5/attention/self/Div_output_0 -> (-1, 8, -1, -1)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Add [Add]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Div_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/Mul_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/self/Add [Add] inputs: [/bert/encoder/layer.5/attention/self/Div_output_0 -> (-1, 8, -1, -1)[FLOAT]], [/bert/Mul_output_0 -> (-1, 1, 1, -1)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Add for ONNX node: /bert/encoder/layer.5/attention/self/Add\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/Add_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/Add_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/self/Add [Add] outputs: [/bert/encoder/layer.5/attention/self/Add_output_0 -> (-1, 8, -1, -1)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Softmax [Softmax]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Add_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/self/Softmax [Softmax] inputs: [/bert/encoder/layer.5/attention/self/Add_output_0 -> (-1, 8, -1, -1)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Softmax for ONNX node: /bert/encoder/layer.5/attention/self/Softmax\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/Softmax_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/Softmax_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/self/Softmax [Softmax] outputs: [/bert/encoder/layer.5/attention/self/Softmax_output_0 -> (-1, 8, -1, -1)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/MatMul_1 [MatMul]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Softmax_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Transpose_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/self/MatMul_1 [MatMul] inputs: [/bert/encoder/layer.5/attention/self/Softmax_output_0 -> (-1, 8, -1, -1)[FLOAT]], [/bert/encoder/layer.5/attention/self/Transpose_output_0 -> (-1, 8, -1, 32)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/MatMul_1 for ONNX node: /bert/encoder/layer.5/attention/self/MatMul_1\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/MatMul_1_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/MatMul_1_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/self/MatMul_1 [MatMul] outputs: [/bert/encoder/layer.5/attention/self/MatMul_1_output_0 -> (-1, 8, -1, 32)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Transpose_3 [Transpose]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/MatMul_1_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/self/Transpose_3 [Transpose] inputs: [/bert/encoder/layer.5/attention/self/MatMul_1_output_0 -> (-1, 8, -1, 32)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Transpose_3 for ONNX node: /bert/encoder/layer.5/attention/self/Transpose_3\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/Transpose_3_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/Transpose_3_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/self/Transpose_3 [Transpose] outputs: [/bert/encoder/layer.5/attention/self/Transpose_3_output_0 -> (-1, -1, 8, 32)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Shape_6 [Shape]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Transpose_3_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/self/Shape_6 [Shape] inputs: [/bert/encoder/layer.5/attention/self/Transpose_3_output_0 -> (-1, -1, 8, 32)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Shape_6 for ONNX node: /bert/encoder/layer.5/attention/self/Shape_6\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/Shape_6_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/Shape_6_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/self/Shape_6 [Shape] outputs: [/bert/encoder/layer.5/attention/self/Shape_6_output_0 -> (4)[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Constant_13 [Constant]\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/self/Constant_13 [Constant] inputs: \n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/self/Constant_13 [Constant] outputs: [/bert/encoder/layer.5/attention/self/Constant_13_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Gather_6 [Gather]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Shape_6_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Constant_13_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/self/Gather_6 [Gather] inputs: [/bert/encoder/layer.5/attention/self/Shape_6_output_0 -> (4)[INT32]], [/bert/encoder/layer.5/attention/self/Constant_13_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Constant_13_output_0 for ONNX node: /bert/encoder/layer.5/attention/self/Constant_13_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Using Gather axis: 0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Gather_6 for ONNX node: /bert/encoder/layer.5/attention/self/Gather_6\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/Gather_6_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/Gather_6_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/self/Gather_6 [Gather] outputs: [/bert/encoder/layer.5/attention/self/Gather_6_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Shape_7 [Shape]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Transpose_3_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/self/Shape_7 [Shape] inputs: [/bert/encoder/layer.5/attention/self/Transpose_3_output_0 -> (-1, -1, 8, 32)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Shape_7 for ONNX node: /bert/encoder/layer.5/attention/self/Shape_7\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/Shape_7_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/Shape_7_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/self/Shape_7 [Shape] outputs: [/bert/encoder/layer.5/attention/self/Shape_7_output_0 -> (4)[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Constant_14 [Constant]\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/self/Constant_14 [Constant] inputs: \n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/self/Constant_14 [Constant] outputs: [/bert/encoder/layer.5/attention/self/Constant_14_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Gather_7 [Gather]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Shape_7_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Constant_14_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/self/Gather_7 [Gather] inputs: [/bert/encoder/layer.5/attention/self/Shape_7_output_0 -> (4)[INT32]], [/bert/encoder/layer.5/attention/self/Constant_14_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Constant_14_output_0 for ONNX node: /bert/encoder/layer.5/attention/self/Constant_14_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Using Gather axis: 0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Gather_7 for ONNX node: /bert/encoder/layer.5/attention/self/Gather_7\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/Gather_7_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/Gather_7_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/self/Gather_7 [Gather] outputs: [/bert/encoder/layer.5/attention/self/Gather_7_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Unsqueeze_6 [Unsqueeze]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Gather_6_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/self/Unsqueeze_6 [Unsqueeze] inputs: [/bert/encoder/layer.5/attention/self/Gather_6_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Unsqueeze_6 for ONNX node: /bert/encoder/layer.5/attention/self/Unsqueeze_6\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/Unsqueeze_6_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/Unsqueeze_6_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/self/Unsqueeze_6 [Unsqueeze] outputs: [/bert/encoder/layer.5/attention/self/Unsqueeze_6_output_0 -> (1)[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Unsqueeze_7 [Unsqueeze]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Gather_7_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/self/Unsqueeze_7 [Unsqueeze] inputs: [/bert/encoder/layer.5/attention/self/Gather_7_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Original shape: (), unsqueezing to: (1,)\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Unsqueeze_7 for ONNX node: /bert/encoder/layer.5/attention/self/Unsqueeze_7\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/Unsqueeze_7_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/Unsqueeze_7_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/self/Unsqueeze_7 [Unsqueeze] outputs: [/bert/encoder/layer.5/attention/self/Unsqueeze_7_output_0 -> (1)[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Constant_15 [Constant]\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/self/Constant_15 [Constant] inputs: \n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/self/Constant_15 [Constant] outputs: [/bert/encoder/layer.5/attention/self/Constant_15_output_0 -> (1)[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Concat_3 [Concat]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Unsqueeze_6_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Unsqueeze_7_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Constant_15_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/self/Concat_3 [Concat] inputs: [/bert/encoder/layer.5/attention/self/Unsqueeze_6_output_0 -> (1)[INT32]], [/bert/encoder/layer.5/attention/self/Unsqueeze_7_output_0 -> (1)[INT32]], [/bert/encoder/layer.5/attention/self/Constant_15_output_0 -> (1)[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Constant_15_output_0 for ONNX node: /bert/encoder/layer.5/attention/self/Constant_15_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Concat_3 for ONNX node: /bert/encoder/layer.5/attention/self/Concat_3\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/Concat_3_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/Concat_3_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/self/Concat_3 [Concat] outputs: [/bert/encoder/layer.5/attention/self/Concat_3_output_0 -> (3)[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/self/Reshape_3 [Reshape]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Transpose_3_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Concat_3_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/self/Reshape_3 [Reshape] inputs: [/bert/encoder/layer.5/attention/self/Transpose_3_output_0 -> (-1, -1, 8, 32)[FLOAT]], [/bert/encoder/layer.5/attention/self/Concat_3_output_0 -> (3)[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/self/Reshape_3 for ONNX node: /bert/encoder/layer.5/attention/self/Reshape_3\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/self/Reshape_3_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/self/Reshape_3_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/self/Reshape_3 [Reshape] outputs: [/bert/encoder/layer.5/attention/self/Reshape_3_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/output/dense/MatMul [MatMul]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/self/Reshape_3_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: onnx::MatMul_868\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/output/dense/MatMul [MatMul] inputs: [/bert/encoder/layer.5/attention/self/Reshape_3_output_0 -> (-1, -1, 256)[FLOAT]], [onnx::MatMul_868 -> (256, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: onnx::MatMul_868 for ONNX node: onnx::MatMul_868\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/output/dense/MatMul for ONNX node: /bert/encoder/layer.5/attention/output/dense/MatMul\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/output/dense/MatMul_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/output/dense/MatMul_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/output/dense/MatMul [MatMul] outputs: [/bert/encoder/layer.5/attention/output/dense/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/output/dense/Add [Add]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: bert.encoder.layer.5.attention.output.dense.bias\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/output/dense/MatMul_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/output/dense/Add [Add] inputs: [bert.encoder.layer.5.attention.output.dense.bias -> (256)[FLOAT]], [/bert/encoder/layer.5/attention/output/dense/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: bert.encoder.layer.5.attention.output.dense.bias for ONNX node: bert.encoder.layer.5.attention.output.dense.bias\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/output/dense/Add for ONNX node: /bert/encoder/layer.5/attention/output/dense/Add\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/output/dense/Add_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/output/dense/Add_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/output/dense/Add [Add] outputs: [/bert/encoder/layer.5/attention/output/dense/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/output/Add [Add]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/output/dense/Add_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.4/output/LayerNorm/Add_1_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/output/Add [Add] inputs: [/bert/encoder/layer.5/attention/output/dense/Add_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.4/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/output/Add for ONNX node: /bert/encoder/layer.5/attention/output/Add\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/output/Add_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/output/Add_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/output/Add [Add] outputs: [/bert/encoder/layer.5/attention/output/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/output/LayerNorm/ReduceMean [ReduceMean]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/output/Add_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/output/LayerNorm/ReduceMean [ReduceMean] inputs: [/bert/encoder/layer.5/attention/output/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/output/LayerNorm/ReduceMean for ONNX node: /bert/encoder/layer.5/attention/output/LayerNorm/ReduceMean\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/output/LayerNorm/ReduceMean_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/output/LayerNorm/ReduceMean_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/output/LayerNorm/ReduceMean [ReduceMean] outputs: [/bert/encoder/layer.5/attention/output/LayerNorm/ReduceMean_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/output/LayerNorm/Sub [Sub]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/output/Add_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/output/LayerNorm/ReduceMean_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/output/LayerNorm/Sub [Sub] inputs: [/bert/encoder/layer.5/attention/output/Add_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.5/attention/output/LayerNorm/ReduceMean_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/output/LayerNorm/Sub for ONNX node: /bert/encoder/layer.5/attention/output/LayerNorm/Sub\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/output/LayerNorm/Sub_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/output/LayerNorm/Sub_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/output/LayerNorm/Sub [Sub] outputs: [/bert/encoder/layer.5/attention/output/LayerNorm/Sub_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/output/LayerNorm/Constant [Constant]\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/output/LayerNorm/Constant [Constant] inputs: \n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/output/LayerNorm/Constant [Constant] outputs: [/bert/encoder/layer.5/attention/output/LayerNorm/Constant_output_0 -> ()[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/output/LayerNorm/Pow [Pow]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/output/LayerNorm/Sub_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/output/LayerNorm/Constant_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/output/LayerNorm/Pow [Pow] inputs: [/bert/encoder/layer.5/attention/output/LayerNorm/Sub_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.5/attention/output/LayerNorm/Constant_output_0 -> ()[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/output/LayerNorm/Constant_output_0 for ONNX node: /bert/encoder/layer.5/attention/output/LayerNorm/Constant_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/output/LayerNorm/Pow for ONNX node: /bert/encoder/layer.5/attention/output/LayerNorm/Pow\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/output/LayerNorm/Pow_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/output/LayerNorm/Pow_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/output/LayerNorm/Pow [Pow] outputs: [/bert/encoder/layer.5/attention/output/LayerNorm/Pow_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/output/LayerNorm/ReduceMean_1 [ReduceMean]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/output/LayerNorm/Pow_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/output/LayerNorm/ReduceMean_1 [ReduceMean] inputs: [/bert/encoder/layer.5/attention/output/LayerNorm/Pow_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/output/LayerNorm/ReduceMean_1 for ONNX node: /bert/encoder/layer.5/attention/output/LayerNorm/ReduceMean_1\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/output/LayerNorm/ReduceMean_1_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/output/LayerNorm/ReduceMean_1_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/output/LayerNorm/ReduceMean_1 [ReduceMean] outputs: [/bert/encoder/layer.5/attention/output/LayerNorm/ReduceMean_1_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/output/LayerNorm/Constant_1 [Constant]\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/output/LayerNorm/Constant_1 [Constant] inputs: \n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/output/LayerNorm/Constant_1 [Constant] outputs: [/bert/encoder/layer.5/attention/output/LayerNorm/Constant_1_output_0 -> ()[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/output/LayerNorm/Add [Add]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/output/LayerNorm/ReduceMean_1_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/output/LayerNorm/Constant_1_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/output/LayerNorm/Add [Add] inputs: [/bert/encoder/layer.5/attention/output/LayerNorm/ReduceMean_1_output_0 -> (-1, -1, 1)[FLOAT]], [/bert/encoder/layer.5/attention/output/LayerNorm/Constant_1_output_0 -> ()[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/output/LayerNorm/Constant_1_output_0 for ONNX node: /bert/encoder/layer.5/attention/output/LayerNorm/Constant_1_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/output/LayerNorm/Add for ONNX node: /bert/encoder/layer.5/attention/output/LayerNorm/Add\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/output/LayerNorm/Add_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/output/LayerNorm/Add_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/output/LayerNorm/Add [Add] outputs: [/bert/encoder/layer.5/attention/output/LayerNorm/Add_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/output/LayerNorm/Sqrt [Sqrt]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/output/LayerNorm/Add_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/output/LayerNorm/Sqrt [Sqrt] inputs: [/bert/encoder/layer.5/attention/output/LayerNorm/Add_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/output/LayerNorm/Sqrt for ONNX node: /bert/encoder/layer.5/attention/output/LayerNorm/Sqrt\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/output/LayerNorm/Sqrt_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/output/LayerNorm/Sqrt_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/output/LayerNorm/Sqrt [Sqrt] outputs: [/bert/encoder/layer.5/attention/output/LayerNorm/Sqrt_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/output/LayerNorm/Div [Div]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/output/LayerNorm/Sub_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/output/LayerNorm/Sqrt_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/output/LayerNorm/Div [Div] inputs: [/bert/encoder/layer.5/attention/output/LayerNorm/Sub_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.5/attention/output/LayerNorm/Sqrt_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/output/LayerNorm/Div for ONNX node: /bert/encoder/layer.5/attention/output/LayerNorm/Div\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/output/LayerNorm/Div_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/output/LayerNorm/Div_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/output/LayerNorm/Div [Div] outputs: [/bert/encoder/layer.5/attention/output/LayerNorm/Div_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/output/LayerNorm/Mul [Mul]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/output/LayerNorm/Div_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: bert.encoder.layer.5.attention.output.LayerNorm.weight\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/output/LayerNorm/Mul [Mul] inputs: [/bert/encoder/layer.5/attention/output/LayerNorm/Div_output_0 -> (-1, -1, 256)[FLOAT]], [bert.encoder.layer.5.attention.output.LayerNorm.weight -> (256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: bert.encoder.layer.5.attention.output.LayerNorm.weight for ONNX node: bert.encoder.layer.5.attention.output.LayerNorm.weight\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/output/LayerNorm/Mul for ONNX node: /bert/encoder/layer.5/attention/output/LayerNorm/Mul\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/output/LayerNorm/Mul_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/output/LayerNorm/Mul_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/output/LayerNorm/Mul [Mul] outputs: [/bert/encoder/layer.5/attention/output/LayerNorm/Mul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.5/attention/output/LayerNorm/Add_1 [Add]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/output/LayerNorm/Mul_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: bert.encoder.layer.5.attention.output.LayerNorm.bias\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/output/LayerNorm/Add_1 [Add] inputs: [/bert/encoder/layer.5/attention/output/LayerNorm/Mul_output_0 -> (-1, -1, 256)[FLOAT]], [bert.encoder.layer.5.attention.output.LayerNorm.bias -> (256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: bert.encoder.layer.5.attention.output.LayerNorm.bias for ONNX node: bert.encoder.layer.5.attention.output.LayerNorm.bias\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.5/attention/output/LayerNorm/Add_1 for ONNX node: /bert/encoder/layer.5/attention/output/LayerNorm/Add_1\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.5/attention/output/LayerNorm/Add_1_output_0 for ONNX tensor: /bert/encoder/layer.5/attention/output/LayerNorm/Add_1_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/attention/output/LayerNorm/Add_1 [Add] outputs: [/bert/encoder/layer.5/attention/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.5/intermediate/dense/MatMul [MatMul]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/output/LayerNorm/Add_1_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: onnx::MatMul_869\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/intermediate/dense/MatMul [MatMul] inputs: [/bert/encoder/layer.5/attention/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], [onnx::MatMul_869 -> (256, 1024)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: onnx::MatMul_869 for ONNX node: onnx::MatMul_869\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.5/intermediate/dense/MatMul for ONNX node: /bert/encoder/layer.5/intermediate/dense/MatMul\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.5/intermediate/dense/MatMul_output_0 for ONNX tensor: /bert/encoder/layer.5/intermediate/dense/MatMul_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/intermediate/dense/MatMul [MatMul] outputs: [/bert/encoder/layer.5/intermediate/dense/MatMul_output_0 -> (-1, -1, 1024)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.5/intermediate/dense/Add [Add]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: bert.encoder.layer.5.intermediate.dense.bias\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.5/intermediate/dense/MatMul_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/intermediate/dense/Add [Add] inputs: [bert.encoder.layer.5.intermediate.dense.bias -> (1024)[FLOAT]], [/bert/encoder/layer.5/intermediate/dense/MatMul_output_0 -> (-1, -1, 1024)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: bert.encoder.layer.5.intermediate.dense.bias for ONNX node: bert.encoder.layer.5.intermediate.dense.bias\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.5/intermediate/dense/Add for ONNX node: /bert/encoder/layer.5/intermediate/dense/Add\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.5/intermediate/dense/Add_output_0 for ONNX tensor: /bert/encoder/layer.5/intermediate/dense/Add_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/intermediate/dense/Add [Add] outputs: [/bert/encoder/layer.5/intermediate/dense/Add_output_0 -> (-1, -1, 1024)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.5/intermediate/intermediate_act_fn/Constant [Constant]\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/intermediate/intermediate_act_fn/Constant [Constant] inputs: \n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/intermediate/intermediate_act_fn/Constant [Constant] outputs: [/bert/encoder/layer.5/intermediate/intermediate_act_fn/Constant_output_0 -> ()[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.5/intermediate/intermediate_act_fn/Div [Div]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.5/intermediate/dense/Add_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.5/intermediate/intermediate_act_fn/Constant_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/intermediate/intermediate_act_fn/Div [Div] inputs: [/bert/encoder/layer.5/intermediate/dense/Add_output_0 -> (-1, -1, 1024)[FLOAT]], [/bert/encoder/layer.5/intermediate/intermediate_act_fn/Constant_output_0 -> ()[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.5/intermediate/intermediate_act_fn/Constant_output_0 for ONNX node: /bert/encoder/layer.5/intermediate/intermediate_act_fn/Constant_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.5/intermediate/intermediate_act_fn/Div for ONNX node: /bert/encoder/layer.5/intermediate/intermediate_act_fn/Div\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.5/intermediate/intermediate_act_fn/Div_output_0 for ONNX tensor: /bert/encoder/layer.5/intermediate/intermediate_act_fn/Div_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/intermediate/intermediate_act_fn/Div [Div] outputs: [/bert/encoder/layer.5/intermediate/intermediate_act_fn/Div_output_0 -> (-1, -1, 1024)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.5/intermediate/intermediate_act_fn/Erf [Erf]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.5/intermediate/intermediate_act_fn/Div_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/intermediate/intermediate_act_fn/Erf [Erf] inputs: [/bert/encoder/layer.5/intermediate/intermediate_act_fn/Div_output_0 -> (-1, -1, 1024)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.5/intermediate/intermediate_act_fn/Erf for ONNX node: /bert/encoder/layer.5/intermediate/intermediate_act_fn/Erf\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.5/intermediate/intermediate_act_fn/Erf_output_0 for ONNX tensor: /bert/encoder/layer.5/intermediate/intermediate_act_fn/Erf_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/intermediate/intermediate_act_fn/Erf [Erf] outputs: [/bert/encoder/layer.5/intermediate/intermediate_act_fn/Erf_output_0 -> (-1, -1, 1024)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.5/intermediate/intermediate_act_fn/Constant_1 [Constant]\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/intermediate/intermediate_act_fn/Constant_1 [Constant] inputs: \n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/intermediate/intermediate_act_fn/Constant_1 [Constant] outputs: [/bert/encoder/layer.5/intermediate/intermediate_act_fn/Constant_1_output_0 -> ()[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.5/intermediate/intermediate_act_fn/Add [Add]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.5/intermediate/intermediate_act_fn/Erf_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.5/intermediate/intermediate_act_fn/Constant_1_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/intermediate/intermediate_act_fn/Add [Add] inputs: [/bert/encoder/layer.5/intermediate/intermediate_act_fn/Erf_output_0 -> (-1, -1, 1024)[FLOAT]], [/bert/encoder/layer.5/intermediate/intermediate_act_fn/Constant_1_output_0 -> ()[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.5/intermediate/intermediate_act_fn/Constant_1_output_0 for ONNX node: /bert/encoder/layer.5/intermediate/intermediate_act_fn/Constant_1_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.5/intermediate/intermediate_act_fn/Add for ONNX node: /bert/encoder/layer.5/intermediate/intermediate_act_fn/Add\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.5/intermediate/intermediate_act_fn/Add_output_0 for ONNX tensor: /bert/encoder/layer.5/intermediate/intermediate_act_fn/Add_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/intermediate/intermediate_act_fn/Add [Add] outputs: [/bert/encoder/layer.5/intermediate/intermediate_act_fn/Add_output_0 -> (-1, -1, 1024)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.5/intermediate/intermediate_act_fn/Mul [Mul]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.5/intermediate/dense/Add_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.5/intermediate/intermediate_act_fn/Add_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/intermediate/intermediate_act_fn/Mul [Mul] inputs: [/bert/encoder/layer.5/intermediate/dense/Add_output_0 -> (-1, -1, 1024)[FLOAT]], [/bert/encoder/layer.5/intermediate/intermediate_act_fn/Add_output_0 -> (-1, -1, 1024)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.5/intermediate/intermediate_act_fn/Mul for ONNX node: /bert/encoder/layer.5/intermediate/intermediate_act_fn/Mul\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.5/intermediate/intermediate_act_fn/Mul_output_0 for ONNX tensor: /bert/encoder/layer.5/intermediate/intermediate_act_fn/Mul_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/intermediate/intermediate_act_fn/Mul [Mul] outputs: [/bert/encoder/layer.5/intermediate/intermediate_act_fn/Mul_output_0 -> (-1, -1, 1024)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.5/intermediate/intermediate_act_fn/Constant_2 [Constant]\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/intermediate/intermediate_act_fn/Constant_2 [Constant] inputs: \n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/intermediate/intermediate_act_fn/Constant_2 [Constant] outputs: [/bert/encoder/layer.5/intermediate/intermediate_act_fn/Constant_2_output_0 -> ()[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.5/intermediate/intermediate_act_fn/Mul_1 [Mul]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.5/intermediate/intermediate_act_fn/Mul_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.5/intermediate/intermediate_act_fn/Constant_2_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/intermediate/intermediate_act_fn/Mul_1 [Mul] inputs: [/bert/encoder/layer.5/intermediate/intermediate_act_fn/Mul_output_0 -> (-1, -1, 1024)[FLOAT]], [/bert/encoder/layer.5/intermediate/intermediate_act_fn/Constant_2_output_0 -> ()[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.5/intermediate/intermediate_act_fn/Constant_2_output_0 for ONNX node: /bert/encoder/layer.5/intermediate/intermediate_act_fn/Constant_2_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.5/intermediate/intermediate_act_fn/Mul_1 for ONNX node: /bert/encoder/layer.5/intermediate/intermediate_act_fn/Mul_1\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.5/intermediate/intermediate_act_fn/Mul_1_output_0 for ONNX tensor: /bert/encoder/layer.5/intermediate/intermediate_act_fn/Mul_1_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/intermediate/intermediate_act_fn/Mul_1 [Mul] outputs: [/bert/encoder/layer.5/intermediate/intermediate_act_fn/Mul_1_output_0 -> (-1, -1, 1024)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.5/output/dense/MatMul [MatMul]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.5/intermediate/intermediate_act_fn/Mul_1_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: onnx::MatMul_870\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/output/dense/MatMul [MatMul] inputs: [/bert/encoder/layer.5/intermediate/intermediate_act_fn/Mul_1_output_0 -> (-1, -1, 1024)[FLOAT]], [onnx::MatMul_870 -> (1024, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: onnx::MatMul_870 for ONNX node: onnx::MatMul_870\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.5/output/dense/MatMul for ONNX node: /bert/encoder/layer.5/output/dense/MatMul\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.5/output/dense/MatMul_output_0 for ONNX tensor: /bert/encoder/layer.5/output/dense/MatMul_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/output/dense/MatMul [MatMul] outputs: [/bert/encoder/layer.5/output/dense/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.5/output/dense/Add [Add]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: bert.encoder.layer.5.output.dense.bias\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.5/output/dense/MatMul_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/output/dense/Add [Add] inputs: [bert.encoder.layer.5.output.dense.bias -> (256)[FLOAT]], [/bert/encoder/layer.5/output/dense/MatMul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: bert.encoder.layer.5.output.dense.bias for ONNX node: bert.encoder.layer.5.output.dense.bias\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.5/output/dense/Add for ONNX node: /bert/encoder/layer.5/output/dense/Add\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.5/output/dense/Add_output_0 for ONNX tensor: /bert/encoder/layer.5/output/dense/Add_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/output/dense/Add [Add] outputs: [/bert/encoder/layer.5/output/dense/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.5/output/Add [Add]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.5/output/dense/Add_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.5/attention/output/LayerNorm/Add_1_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/output/Add [Add] inputs: [/bert/encoder/layer.5/output/dense/Add_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.5/attention/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.5/output/Add for ONNX node: /bert/encoder/layer.5/output/Add\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.5/output/Add_output_0 for ONNX tensor: /bert/encoder/layer.5/output/Add_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/output/Add [Add] outputs: [/bert/encoder/layer.5/output/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.5/output/LayerNorm/ReduceMean [ReduceMean]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.5/output/Add_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/output/LayerNorm/ReduceMean [ReduceMean] inputs: [/bert/encoder/layer.5/output/Add_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.5/output/LayerNorm/ReduceMean for ONNX node: /bert/encoder/layer.5/output/LayerNorm/ReduceMean\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.5/output/LayerNorm/ReduceMean_output_0 for ONNX tensor: /bert/encoder/layer.5/output/LayerNorm/ReduceMean_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/output/LayerNorm/ReduceMean [ReduceMean] outputs: [/bert/encoder/layer.5/output/LayerNorm/ReduceMean_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.5/output/LayerNorm/Sub [Sub]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.5/output/Add_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.5/output/LayerNorm/ReduceMean_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/output/LayerNorm/Sub [Sub] inputs: [/bert/encoder/layer.5/output/Add_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.5/output/LayerNorm/ReduceMean_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.5/output/LayerNorm/Sub for ONNX node: /bert/encoder/layer.5/output/LayerNorm/Sub\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.5/output/LayerNorm/Sub_output_0 for ONNX tensor: /bert/encoder/layer.5/output/LayerNorm/Sub_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/output/LayerNorm/Sub [Sub] outputs: [/bert/encoder/layer.5/output/LayerNorm/Sub_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.5/output/LayerNorm/Constant [Constant]\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/output/LayerNorm/Constant [Constant] inputs: \n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/output/LayerNorm/Constant [Constant] outputs: [/bert/encoder/layer.5/output/LayerNorm/Constant_output_0 -> ()[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.5/output/LayerNorm/Pow [Pow]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.5/output/LayerNorm/Sub_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.5/output/LayerNorm/Constant_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/output/LayerNorm/Pow [Pow] inputs: [/bert/encoder/layer.5/output/LayerNorm/Sub_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.5/output/LayerNorm/Constant_output_0 -> ()[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.5/output/LayerNorm/Constant_output_0 for ONNX node: /bert/encoder/layer.5/output/LayerNorm/Constant_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.5/output/LayerNorm/Pow for ONNX node: /bert/encoder/layer.5/output/LayerNorm/Pow\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.5/output/LayerNorm/Pow_output_0 for ONNX tensor: /bert/encoder/layer.5/output/LayerNorm/Pow_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/output/LayerNorm/Pow [Pow] outputs: [/bert/encoder/layer.5/output/LayerNorm/Pow_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.5/output/LayerNorm/ReduceMean_1 [ReduceMean]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.5/output/LayerNorm/Pow_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/output/LayerNorm/ReduceMean_1 [ReduceMean] inputs: [/bert/encoder/layer.5/output/LayerNorm/Pow_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.5/output/LayerNorm/ReduceMean_1 for ONNX node: /bert/encoder/layer.5/output/LayerNorm/ReduceMean_1\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.5/output/LayerNorm/ReduceMean_1_output_0 for ONNX tensor: /bert/encoder/layer.5/output/LayerNorm/ReduceMean_1_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/output/LayerNorm/ReduceMean_1 [ReduceMean] outputs: [/bert/encoder/layer.5/output/LayerNorm/ReduceMean_1_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.5/output/LayerNorm/Constant_1 [Constant]\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/output/LayerNorm/Constant_1 [Constant] inputs: \n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/output/LayerNorm/Constant_1 [Constant] outputs: [/bert/encoder/layer.5/output/LayerNorm/Constant_1_output_0 -> ()[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.5/output/LayerNorm/Add [Add]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.5/output/LayerNorm/ReduceMean_1_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.5/output/LayerNorm/Constant_1_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/output/LayerNorm/Add [Add] inputs: [/bert/encoder/layer.5/output/LayerNorm/ReduceMean_1_output_0 -> (-1, -1, 1)[FLOAT]], [/bert/encoder/layer.5/output/LayerNorm/Constant_1_output_0 -> ()[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.5/output/LayerNorm/Constant_1_output_0 for ONNX node: /bert/encoder/layer.5/output/LayerNorm/Constant_1_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.5/output/LayerNorm/Add for ONNX node: /bert/encoder/layer.5/output/LayerNorm/Add\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.5/output/LayerNorm/Add_output_0 for ONNX tensor: /bert/encoder/layer.5/output/LayerNorm/Add_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/output/LayerNorm/Add [Add] outputs: [/bert/encoder/layer.5/output/LayerNorm/Add_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.5/output/LayerNorm/Sqrt [Sqrt]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.5/output/LayerNorm/Add_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/output/LayerNorm/Sqrt [Sqrt] inputs: [/bert/encoder/layer.5/output/LayerNorm/Add_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.5/output/LayerNorm/Sqrt for ONNX node: /bert/encoder/layer.5/output/LayerNorm/Sqrt\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.5/output/LayerNorm/Sqrt_output_0 for ONNX tensor: /bert/encoder/layer.5/output/LayerNorm/Sqrt_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/output/LayerNorm/Sqrt [Sqrt] outputs: [/bert/encoder/layer.5/output/LayerNorm/Sqrt_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.5/output/LayerNorm/Div [Div]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.5/output/LayerNorm/Sub_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.5/output/LayerNorm/Sqrt_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/output/LayerNorm/Div [Div] inputs: [/bert/encoder/layer.5/output/LayerNorm/Sub_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/encoder/layer.5/output/LayerNorm/Sqrt_output_0 -> (-1, -1, 1)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.5/output/LayerNorm/Div for ONNX node: /bert/encoder/layer.5/output/LayerNorm/Div\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.5/output/LayerNorm/Div_output_0 for ONNX tensor: /bert/encoder/layer.5/output/LayerNorm/Div_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/output/LayerNorm/Div [Div] outputs: [/bert/encoder/layer.5/output/LayerNorm/Div_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.5/output/LayerNorm/Mul [Mul]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.5/output/LayerNorm/Div_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: bert.encoder.layer.5.output.LayerNorm.weight\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/output/LayerNorm/Mul [Mul] inputs: [/bert/encoder/layer.5/output/LayerNorm/Div_output_0 -> (-1, -1, 256)[FLOAT]], [bert.encoder.layer.5.output.LayerNorm.weight -> (256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: bert.encoder.layer.5.output.LayerNorm.weight for ONNX node: bert.encoder.layer.5.output.LayerNorm.weight\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.5/output/LayerNorm/Mul for ONNX node: /bert/encoder/layer.5/output/LayerNorm/Mul\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.5/output/LayerNorm/Mul_output_0 for ONNX tensor: /bert/encoder/layer.5/output/LayerNorm/Mul_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/output/LayerNorm/Mul [Mul] outputs: [/bert/encoder/layer.5/output/LayerNorm/Mul_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/encoder/layer.5/output/LayerNorm/Add_1 [Add]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.5/output/LayerNorm/Mul_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: bert.encoder.layer.5.output.LayerNorm.bias\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/output/LayerNorm/Add_1 [Add] inputs: [/bert/encoder/layer.5/output/LayerNorm/Mul_output_0 -> (-1, -1, 256)[FLOAT]], [bert.encoder.layer.5.output.LayerNorm.bias -> (256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: bert.encoder.layer.5.output.LayerNorm.bias for ONNX node: bert.encoder.layer.5.output.LayerNorm.bias\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/encoder/layer.5/output/LayerNorm/Add_1 for ONNX node: /bert/encoder/layer.5/output/LayerNorm/Add_1\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/encoder/layer.5/output/LayerNorm/Add_1_output_0 for ONNX tensor: /bert/encoder/layer.5/output/LayerNorm/Add_1_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/encoder/layer.5/output/LayerNorm/Add_1 [Add] outputs: [/bert/encoder/layer.5/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/pooler/Gather [Gather]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/encoder/layer.5/output/LayerNorm/Add_1_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/Constant_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/pooler/Gather [Gather] inputs: [/bert/encoder/layer.5/output/LayerNorm/Add_1_output_0 -> (-1, -1, 256)[FLOAT]], [/bert/Constant_output_0 -> ()[INT32]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/Constant_output_0 for ONNX node: /bert/Constant_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Using Gather axis: 1\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/pooler/Gather for ONNX node: /bert/pooler/Gather\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/pooler/Gather_output_0 for ONNX tensor: /bert/pooler/Gather_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/pooler/Gather [Gather] outputs: [/bert/pooler/Gather_output_0 -> (-1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/pooler/dense/Gemm [Gemm]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/pooler/Gather_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: bert.pooler.dense.weight\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: bert.pooler.dense.bias\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/pooler/dense/Gemm [Gemm] inputs: [/bert/pooler/Gather_output_0 -> (-1, 256)[FLOAT]], [bert.pooler.dense.weight -> (256, 256)[FLOAT]], [bert.pooler.dense.bias -> (256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: bert.pooler.dense.weight for ONNX node: bert.pooler.dense.weight\n",
      "[01/18/2023-20:38:47] [V] [TRT] Using opA: 0 opB: 1\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/pooler/dense/Gemm for ONNX node: /bert/pooler/dense/Gemm\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: bert.pooler.dense.bias for ONNX node: bert.pooler.dense.bias\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/pooler/dense/Gemm_output_0 for ONNX tensor: /bert/pooler/dense/Gemm_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/pooler/dense/Gemm [Gemm] outputs: [/bert/pooler/dense/Gemm_output_0 -> (-1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /bert/pooler/activation/Tanh [Tanh]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/pooler/dense/Gemm_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/pooler/activation/Tanh [Tanh] inputs: [/bert/pooler/dense/Gemm_output_0 -> (-1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /bert/pooler/activation/Tanh for ONNX node: /bert/pooler/activation/Tanh\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: /bert/pooler/activation/Tanh_output_0 for ONNX tensor: /bert/pooler/activation/Tanh_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] /bert/pooler/activation/Tanh [Tanh] outputs: [/bert/pooler/activation/Tanh_output_0 -> (-1, 256)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Parsing node: /classifier/Gemm [Gemm]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: /bert/pooler/activation/Tanh_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: classifier.weight\n",
      "[01/18/2023-20:38:47] [V] [TRT] Searching for input: classifier.bias\n",
      "[01/18/2023-20:38:47] [V] [TRT] /classifier/Gemm [Gemm] inputs: [/bert/pooler/activation/Tanh_output_0 -> (-1, 256)[FLOAT]], [classifier.weight -> (6, 256)[FLOAT]], [classifier.bias -> (6)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: classifier.weight for ONNX node: classifier.weight\n",
      "[01/18/2023-20:38:47] [V] [TRT] Using opA: 0 opB: 1\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: /classifier/Gemm for ONNX node: /classifier/Gemm\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering layer: classifier.bias for ONNX node: classifier.bias\n",
      "[01/18/2023-20:38:47] [V] [TRT] Registering tensor: logits_129 for ONNX tensor: logits\n",
      "[01/18/2023-20:38:47] [V] [TRT] /classifier/Gemm [Gemm] outputs: [logits -> (-1, 6)[FLOAT]], \n",
      "[01/18/2023-20:38:47] [V] [TRT] Marking logits_129 as output: logits\n",
      "[01/18/2023-20:38:47] [I] Finish parsing network model\n",
      "[01/18/2023-20:38:47] [V] [TRT] Original: 649 layers\n",
      "[01/18/2023-20:38:47] [V] [TRT] After dead-layer removal: 649 layers\n",
      "[01/18/2023-20:38:47] [V] [TRT] Applying generic optimizations to the graph for inference.\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on /bert/Constant_1_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing /bert/Constant_1_output_0 with (Unnamed Layer* 14) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on /bert/Constant_2_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing /bert/Constant_2_output_0 with (Unnamed Layer* 17) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on /bert/embeddings/LayerNorm/Constant_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing /bert/embeddings/LayerNorm/Constant_output_0 with (Unnamed Layer* 51) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on /bert/embeddings/LayerNorm/Constant_1_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing /bert/embeddings/LayerNorm/Constant_1_output_0 with (Unnamed Layer* 55) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on bert.embeddings.LayerNorm.weight\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing bert.embeddings.LayerNorm.weight with (Unnamed Layer* 60) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on bert.embeddings.LayerNorm.bias\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing bert.embeddings.LayerNorm.bias with (Unnamed Layer* 63) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on onnx::MatMul_793\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing onnx::MatMul_793 with (Unnamed Layer* 66) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.0.attention.self.query.bias\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.0.attention.self.query.bias with (Unnamed Layer* 69) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on onnx::MatMul_794\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing onnx::MatMul_794 with (Unnamed Layer* 72) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.0.attention.self.key.bias\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.0.attention.self.key.bias with (Unnamed Layer* 75) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on onnx::MatMul_797\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing onnx::MatMul_797 with (Unnamed Layer* 90) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.0.attention.self.value.bias\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.0.attention.self.value.bias with (Unnamed Layer* 93) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.0/attention/self/Constant_12_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.0/attention/self/Constant_12_output_0 with (Unnamed Layer* 124) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on onnx::MatMul_803\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing onnx::MatMul_803 with (Unnamed Layer* 156) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.0.attention.output.dense.bias\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.0.attention.output.dense.bias with (Unnamed Layer* 159) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.0/attention/output/LayerNorm/Constant_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.0/attention/output/LayerNorm/Constant_output_0 with (Unnamed Layer* 165) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.0/attention/output/LayerNorm/Constant_1_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.0/attention/output/LayerNorm/Constant_1_output_0 with (Unnamed Layer* 169) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.0.attention.output.LayerNorm.weight\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.0.attention.output.LayerNorm.weight with (Unnamed Layer* 174) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.0.attention.output.LayerNorm.bias\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.0.attention.output.LayerNorm.bias with (Unnamed Layer* 177) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on onnx::MatMul_804\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing onnx::MatMul_804 with (Unnamed Layer* 180) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.0.intermediate.dense.bias\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.0.intermediate.dense.bias with (Unnamed Layer* 183) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.0/intermediate/intermediate_act_fn/Constant_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.0/intermediate/intermediate_act_fn/Constant_output_0 with (Unnamed Layer* 186) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.0/intermediate/intermediate_act_fn/Constant_1_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.0/intermediate/intermediate_act_fn/Constant_1_output_0 with (Unnamed Layer* 190) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.0/intermediate/intermediate_act_fn/Constant_2_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.0/intermediate/intermediate_act_fn/Constant_2_output_0 with (Unnamed Layer* 194) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on onnx::MatMul_805\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing onnx::MatMul_805 with (Unnamed Layer* 197) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.0.output.dense.bias\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.0.output.dense.bias with (Unnamed Layer* 200) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.0/output/LayerNorm/Constant_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.0/output/LayerNorm/Constant_output_0 with (Unnamed Layer* 206) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.0/output/LayerNorm/Constant_1_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.0/output/LayerNorm/Constant_1_output_0 with (Unnamed Layer* 210) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.0.output.LayerNorm.weight\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.0.output.LayerNorm.weight with (Unnamed Layer* 215) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.0.output.LayerNorm.bias\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.0.output.LayerNorm.bias with (Unnamed Layer* 218) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on onnx::MatMul_806\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing onnx::MatMul_806 with (Unnamed Layer* 221) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.1.attention.self.query.bias\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.1.attention.self.query.bias with (Unnamed Layer* 224) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on onnx::MatMul_807\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing onnx::MatMul_807 with (Unnamed Layer* 227) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.1.attention.self.key.bias\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.1.attention.self.key.bias with (Unnamed Layer* 230) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on onnx::MatMul_810\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing onnx::MatMul_810 with (Unnamed Layer* 245) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.1.attention.self.value.bias\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.1.attention.self.value.bias with (Unnamed Layer* 248) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.1/attention/self/Constant_12_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.1/attention/self/Constant_12_output_0 with (Unnamed Layer* 279) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on onnx::MatMul_816\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing onnx::MatMul_816 with (Unnamed Layer* 311) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.1.attention.output.dense.bias\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.1.attention.output.dense.bias with (Unnamed Layer* 314) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.1/attention/output/LayerNorm/Constant_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.1/attention/output/LayerNorm/Constant_output_0 with (Unnamed Layer* 320) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.1/attention/output/LayerNorm/Constant_1_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.1/attention/output/LayerNorm/Constant_1_output_0 with (Unnamed Layer* 324) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.1.attention.output.LayerNorm.weight\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.1.attention.output.LayerNorm.weight with (Unnamed Layer* 329) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.1.attention.output.LayerNorm.bias\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.1.attention.output.LayerNorm.bias with (Unnamed Layer* 332) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on onnx::MatMul_817\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing onnx::MatMul_817 with (Unnamed Layer* 335) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.1.intermediate.dense.bias\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.1.intermediate.dense.bias with (Unnamed Layer* 338) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.1/intermediate/intermediate_act_fn/Constant_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.1/intermediate/intermediate_act_fn/Constant_output_0 with (Unnamed Layer* 341) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.1/intermediate/intermediate_act_fn/Constant_1_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.1/intermediate/intermediate_act_fn/Constant_1_output_0 with (Unnamed Layer* 345) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.1/intermediate/intermediate_act_fn/Constant_2_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.1/intermediate/intermediate_act_fn/Constant_2_output_0 with (Unnamed Layer* 349) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on onnx::MatMul_818\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing onnx::MatMul_818 with (Unnamed Layer* 352) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.1.output.dense.bias\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.1.output.dense.bias with (Unnamed Layer* 355) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.1/output/LayerNorm/Constant_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.1/output/LayerNorm/Constant_output_0 with (Unnamed Layer* 361) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.1/output/LayerNorm/Constant_1_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.1/output/LayerNorm/Constant_1_output_0 with (Unnamed Layer* 365) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.1.output.LayerNorm.weight\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.1.output.LayerNorm.weight with (Unnamed Layer* 370) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.1.output.LayerNorm.bias\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.1.output.LayerNorm.bias with (Unnamed Layer* 373) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on onnx::MatMul_819\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing onnx::MatMul_819 with (Unnamed Layer* 376) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.2.attention.self.query.bias\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.2.attention.self.query.bias with (Unnamed Layer* 379) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on onnx::MatMul_820\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing onnx::MatMul_820 with (Unnamed Layer* 382) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.2.attention.self.key.bias\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.2.attention.self.key.bias with (Unnamed Layer* 385) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on onnx::MatMul_823\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing onnx::MatMul_823 with (Unnamed Layer* 400) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.2.attention.self.value.bias\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.2.attention.self.value.bias with (Unnamed Layer* 403) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.2/attention/self/Constant_12_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.2/attention/self/Constant_12_output_0 with (Unnamed Layer* 434) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on onnx::MatMul_829\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing onnx::MatMul_829 with (Unnamed Layer* 466) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.2.attention.output.dense.bias\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.2.attention.output.dense.bias with (Unnamed Layer* 469) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.2/attention/output/LayerNorm/Constant_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.2/attention/output/LayerNorm/Constant_output_0 with (Unnamed Layer* 475) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.2/attention/output/LayerNorm/Constant_1_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.2/attention/output/LayerNorm/Constant_1_output_0 with (Unnamed Layer* 479) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.2.attention.output.LayerNorm.weight\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.2.attention.output.LayerNorm.weight with (Unnamed Layer* 484) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.2.attention.output.LayerNorm.bias\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.2.attention.output.LayerNorm.bias with (Unnamed Layer* 487) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on onnx::MatMul_830\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing onnx::MatMul_830 with (Unnamed Layer* 490) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.2.intermediate.dense.bias\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.2.intermediate.dense.bias with (Unnamed Layer* 493) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.2/intermediate/intermediate_act_fn/Constant_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.2/intermediate/intermediate_act_fn/Constant_output_0 with (Unnamed Layer* 496) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.2/intermediate/intermediate_act_fn/Constant_1_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.2/intermediate/intermediate_act_fn/Constant_1_output_0 with (Unnamed Layer* 500) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.2/intermediate/intermediate_act_fn/Constant_2_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.2/intermediate/intermediate_act_fn/Constant_2_output_0 with (Unnamed Layer* 504) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on onnx::MatMul_831\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing onnx::MatMul_831 with (Unnamed Layer* 507) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.2.output.dense.bias\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.2.output.dense.bias with (Unnamed Layer* 510) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.2/output/LayerNorm/Constant_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.2/output/LayerNorm/Constant_output_0 with (Unnamed Layer* 516) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.2/output/LayerNorm/Constant_1_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.2/output/LayerNorm/Constant_1_output_0 with (Unnamed Layer* 520) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.2.output.LayerNorm.weight\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.2.output.LayerNorm.weight with (Unnamed Layer* 525) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.2.output.LayerNorm.bias\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.2.output.LayerNorm.bias with (Unnamed Layer* 528) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on onnx::MatMul_832\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing onnx::MatMul_832 with (Unnamed Layer* 531) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.3.attention.self.query.bias\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.3.attention.self.query.bias with (Unnamed Layer* 534) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on onnx::MatMul_833\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing onnx::MatMul_833 with (Unnamed Layer* 537) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.3.attention.self.key.bias\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.3.attention.self.key.bias with (Unnamed Layer* 540) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on onnx::MatMul_836\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing onnx::MatMul_836 with (Unnamed Layer* 555) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.3.attention.self.value.bias\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.3.attention.self.value.bias with (Unnamed Layer* 558) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.3/attention/self/Constant_12_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.3/attention/self/Constant_12_output_0 with (Unnamed Layer* 589) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on onnx::MatMul_842\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing onnx::MatMul_842 with (Unnamed Layer* 621) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.3.attention.output.dense.bias\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.3.attention.output.dense.bias with (Unnamed Layer* 624) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.3/attention/output/LayerNorm/Constant_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.3/attention/output/LayerNorm/Constant_output_0 with (Unnamed Layer* 630) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.3/attention/output/LayerNorm/Constant_1_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.3/attention/output/LayerNorm/Constant_1_output_0 with (Unnamed Layer* 634) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.3.attention.output.LayerNorm.weight\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.3.attention.output.LayerNorm.weight with (Unnamed Layer* 639) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.3.attention.output.LayerNorm.bias\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.3.attention.output.LayerNorm.bias with (Unnamed Layer* 642) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on onnx::MatMul_843\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing onnx::MatMul_843 with (Unnamed Layer* 645) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.3.intermediate.dense.bias\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.3.intermediate.dense.bias with (Unnamed Layer* 648) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.3/intermediate/intermediate_act_fn/Constant_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.3/intermediate/intermediate_act_fn/Constant_output_0 with (Unnamed Layer* 651) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.3/intermediate/intermediate_act_fn/Constant_1_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.3/intermediate/intermediate_act_fn/Constant_1_output_0 with (Unnamed Layer* 655) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.3/intermediate/intermediate_act_fn/Constant_2_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.3/intermediate/intermediate_act_fn/Constant_2_output_0 with (Unnamed Layer* 659) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on onnx::MatMul_844\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing onnx::MatMul_844 with (Unnamed Layer* 662) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.3.output.dense.bias\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.3.output.dense.bias with (Unnamed Layer* 665) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.3/output/LayerNorm/Constant_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.3/output/LayerNorm/Constant_output_0 with (Unnamed Layer* 671) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.3/output/LayerNorm/Constant_1_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.3/output/LayerNorm/Constant_1_output_0 with (Unnamed Layer* 675) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.3.output.LayerNorm.weight\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.3.output.LayerNorm.weight with (Unnamed Layer* 680) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.3.output.LayerNorm.bias\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.3.output.LayerNorm.bias with (Unnamed Layer* 683) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on onnx::MatMul_845\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing onnx::MatMul_845 with (Unnamed Layer* 686) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.4.attention.self.query.bias\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.4.attention.self.query.bias with (Unnamed Layer* 689) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on onnx::MatMul_846\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing onnx::MatMul_846 with (Unnamed Layer* 692) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.4.attention.self.key.bias\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.4.attention.self.key.bias with (Unnamed Layer* 695) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on onnx::MatMul_849\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing onnx::MatMul_849 with (Unnamed Layer* 710) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.4.attention.self.value.bias\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.4.attention.self.value.bias with (Unnamed Layer* 713) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.4/attention/self/Constant_12_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.4/attention/self/Constant_12_output_0 with (Unnamed Layer* 744) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on onnx::MatMul_855\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing onnx::MatMul_855 with (Unnamed Layer* 776) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.4.attention.output.dense.bias\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.4.attention.output.dense.bias with (Unnamed Layer* 779) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.4/attention/output/LayerNorm/Constant_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.4/attention/output/LayerNorm/Constant_output_0 with (Unnamed Layer* 785) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.4/attention/output/LayerNorm/Constant_1_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.4/attention/output/LayerNorm/Constant_1_output_0 with (Unnamed Layer* 789) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.4.attention.output.LayerNorm.weight\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.4.attention.output.LayerNorm.weight with (Unnamed Layer* 794) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.4.attention.output.LayerNorm.bias\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.4.attention.output.LayerNorm.bias with (Unnamed Layer* 797) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on onnx::MatMul_856\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing onnx::MatMul_856 with (Unnamed Layer* 800) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.4.intermediate.dense.bias\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.4.intermediate.dense.bias with (Unnamed Layer* 803) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.4/intermediate/intermediate_act_fn/Constant_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.4/intermediate/intermediate_act_fn/Constant_output_0 with (Unnamed Layer* 806) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.4/intermediate/intermediate_act_fn/Constant_1_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.4/intermediate/intermediate_act_fn/Constant_1_output_0 with (Unnamed Layer* 810) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.4/intermediate/intermediate_act_fn/Constant_2_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.4/intermediate/intermediate_act_fn/Constant_2_output_0 with (Unnamed Layer* 814) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on onnx::MatMul_857\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing onnx::MatMul_857 with (Unnamed Layer* 817) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.4.output.dense.bias\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.4.output.dense.bias with (Unnamed Layer* 820) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.4/output/LayerNorm/Constant_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.4/output/LayerNorm/Constant_output_0 with (Unnamed Layer* 826) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.4/output/LayerNorm/Constant_1_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.4/output/LayerNorm/Constant_1_output_0 with (Unnamed Layer* 830) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.4.output.LayerNorm.weight\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.4.output.LayerNorm.weight with (Unnamed Layer* 835) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.4.output.LayerNorm.bias\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.4.output.LayerNorm.bias with (Unnamed Layer* 838) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on onnx::MatMul_858\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing onnx::MatMul_858 with (Unnamed Layer* 841) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.5.attention.self.query.bias\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.5.attention.self.query.bias with (Unnamed Layer* 844) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on onnx::MatMul_859\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing onnx::MatMul_859 with (Unnamed Layer* 847) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.5.attention.self.key.bias\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.5.attention.self.key.bias with (Unnamed Layer* 850) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on onnx::MatMul_862\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing onnx::MatMul_862 with (Unnamed Layer* 865) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.5.attention.self.value.bias\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.5.attention.self.value.bias with (Unnamed Layer* 868) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.5/attention/self/Constant_12_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.5/attention/self/Constant_12_output_0 with (Unnamed Layer* 899) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ShuffleShuffleFusion on /bert/Unsqueeze\n",
      "[01/18/2023-20:38:47] [V] [TRT] ShuffleShuffleFusion: Fusing /bert/Unsqueeze with /bert/Unsqueeze_1\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ShuffleShuffleFusion on /bert/encoder/layer.0/attention/self/Reshape_2\n",
      "[01/18/2023-20:38:47] [V] [TRT] ShuffleShuffleFusion: Fusing /bert/encoder/layer.0/attention/self/Reshape_2 with /bert/encoder/layer.0/attention/self/Transpose_1\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ShuffleShuffleFusion on /bert/encoder/layer.0/attention/self/Reshape\n",
      "[01/18/2023-20:38:47] [V] [TRT] ShuffleShuffleFusion: Fusing /bert/encoder/layer.0/attention/self/Reshape with /bert/encoder/layer.0/attention/self/Transpose_2\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ShuffleShuffleFusion on /bert/encoder/layer.0/attention/self/Reshape_1\n",
      "[01/18/2023-20:38:47] [V] [TRT] ShuffleShuffleFusion: Fusing /bert/encoder/layer.0/attention/self/Reshape_1 with /bert/encoder/layer.0/attention/self/Transpose\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ShuffleShuffleFusion on /bert/encoder/layer.0/attention/self/Transpose_3\n",
      "[01/18/2023-20:38:47] [V] [TRT] ShuffleShuffleFusion: Fusing /bert/encoder/layer.0/attention/self/Transpose_3 with /bert/encoder/layer.0/attention/self/Reshape_3\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ShuffleShuffleFusion on /bert/encoder/layer.1/attention/self/Reshape_2\n",
      "[01/18/2023-20:38:47] [V] [TRT] ShuffleShuffleFusion: Fusing /bert/encoder/layer.1/attention/self/Reshape_2 with /bert/encoder/layer.1/attention/self/Transpose_1\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ShuffleShuffleFusion on /bert/encoder/layer.1/attention/self/Reshape\n",
      "[01/18/2023-20:38:47] [V] [TRT] ShuffleShuffleFusion: Fusing /bert/encoder/layer.1/attention/self/Reshape with /bert/encoder/layer.1/attention/self/Transpose_2\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ShuffleShuffleFusion on /bert/encoder/layer.1/attention/self/Reshape_1\n",
      "[01/18/2023-20:38:47] [V] [TRT] ShuffleShuffleFusion: Fusing /bert/encoder/layer.1/attention/self/Reshape_1 with /bert/encoder/layer.1/attention/self/Transpose\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ShuffleShuffleFusion on /bert/encoder/layer.1/attention/self/Transpose_3\n",
      "[01/18/2023-20:38:47] [V] [TRT] ShuffleShuffleFusion: Fusing /bert/encoder/layer.1/attention/self/Transpose_3 with /bert/encoder/layer.1/attention/self/Reshape_3\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ShuffleShuffleFusion on /bert/encoder/layer.2/attention/self/Reshape_2\n",
      "[01/18/2023-20:38:47] [V] [TRT] ShuffleShuffleFusion: Fusing /bert/encoder/layer.2/attention/self/Reshape_2 with /bert/encoder/layer.2/attention/self/Transpose_1\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ShuffleShuffleFusion on /bert/encoder/layer.2/attention/self/Reshape\n",
      "[01/18/2023-20:38:47] [V] [TRT] ShuffleShuffleFusion: Fusing /bert/encoder/layer.2/attention/self/Reshape with /bert/encoder/layer.2/attention/self/Transpose_2\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ShuffleShuffleFusion on /bert/encoder/layer.2/attention/self/Reshape_1\n",
      "[01/18/2023-20:38:47] [V] [TRT] ShuffleShuffleFusion: Fusing /bert/encoder/layer.2/attention/self/Reshape_1 with /bert/encoder/layer.2/attention/self/Transpose\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ShuffleShuffleFusion on /bert/encoder/layer.2/attention/self/Transpose_3\n",
      "[01/18/2023-20:38:47] [V] [TRT] ShuffleShuffleFusion: Fusing /bert/encoder/layer.2/attention/self/Transpose_3 with /bert/encoder/layer.2/attention/self/Reshape_3\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ShuffleShuffleFusion on /bert/encoder/layer.3/attention/self/Reshape_2\n",
      "[01/18/2023-20:38:47] [V] [TRT] ShuffleShuffleFusion: Fusing /bert/encoder/layer.3/attention/self/Reshape_2 with /bert/encoder/layer.3/attention/self/Transpose_1\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ShuffleShuffleFusion on /bert/encoder/layer.3/attention/self/Reshape\n",
      "[01/18/2023-20:38:47] [V] [TRT] ShuffleShuffleFusion: Fusing /bert/encoder/layer.3/attention/self/Reshape with /bert/encoder/layer.3/attention/self/Transpose_2\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ShuffleShuffleFusion on /bert/encoder/layer.3/attention/self/Reshape_1\n",
      "[01/18/2023-20:38:47] [V] [TRT] ShuffleShuffleFusion: Fusing /bert/encoder/layer.3/attention/self/Reshape_1 with /bert/encoder/layer.3/attention/self/Transpose\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ShuffleShuffleFusion on /bert/encoder/layer.3/attention/self/Transpose_3\n",
      "[01/18/2023-20:38:47] [V] [TRT] ShuffleShuffleFusion: Fusing /bert/encoder/layer.3/attention/self/Transpose_3 with /bert/encoder/layer.3/attention/self/Reshape_3\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ShuffleShuffleFusion on /bert/encoder/layer.4/attention/self/Reshape_2\n",
      "[01/18/2023-20:38:47] [V] [TRT] ShuffleShuffleFusion: Fusing /bert/encoder/layer.4/attention/self/Reshape_2 with /bert/encoder/layer.4/attention/self/Transpose_1\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ShuffleShuffleFusion on /bert/encoder/layer.4/attention/self/Reshape\n",
      "[01/18/2023-20:38:47] [V] [TRT] ShuffleShuffleFusion: Fusing /bert/encoder/layer.4/attention/self/Reshape with /bert/encoder/layer.4/attention/self/Transpose_2\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ShuffleShuffleFusion on /bert/encoder/layer.4/attention/self/Reshape_1\n",
      "[01/18/2023-20:38:47] [V] [TRT] ShuffleShuffleFusion: Fusing /bert/encoder/layer.4/attention/self/Reshape_1 with /bert/encoder/layer.4/attention/self/Transpose\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ShuffleShuffleFusion on /bert/encoder/layer.4/attention/self/Transpose_3\n",
      "[01/18/2023-20:38:47] [V] [TRT] ShuffleShuffleFusion: Fusing /bert/encoder/layer.4/attention/self/Transpose_3 with /bert/encoder/layer.4/attention/self/Reshape_3\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ShuffleShuffleFusion on /bert/encoder/layer.5/attention/self/Reshape_2\n",
      "[01/18/2023-20:38:47] [V] [TRT] ShuffleShuffleFusion: Fusing /bert/encoder/layer.5/attention/self/Reshape_2 with /bert/encoder/layer.5/attention/self/Transpose_1\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ShuffleShuffleFusion on /bert/encoder/layer.5/attention/self/Reshape\n",
      "[01/18/2023-20:38:47] [V] [TRT] ShuffleShuffleFusion: Fusing /bert/encoder/layer.5/attention/self/Reshape with /bert/encoder/layer.5/attention/self/Transpose_2\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ShuffleShuffleFusion on /bert/encoder/layer.5/attention/self/Reshape_1\n",
      "[01/18/2023-20:38:47] [V] [TRT] ShuffleShuffleFusion: Fusing /bert/encoder/layer.5/attention/self/Reshape_1 with /bert/encoder/layer.5/attention/self/Transpose\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ShuffleShuffleFusion on /bert/encoder/layer.5/attention/self/Transpose_3\n",
      "[01/18/2023-20:38:47] [V] [TRT] ShuffleShuffleFusion: Fusing /bert/encoder/layer.5/attention/self/Transpose_3 with /bert/encoder/layer.5/attention/self/Reshape_3\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on onnx::MatMul_868\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing onnx::MatMul_868 with (Unnamed Layer* 931) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.5.attention.output.dense.bias\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.5.attention.output.dense.bias with (Unnamed Layer* 934) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.5/attention/output/LayerNorm/Constant_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.5/attention/output/LayerNorm/Constant_output_0 with (Unnamed Layer* 940) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.5/attention/output/LayerNorm/Constant_1_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.5/attention/output/LayerNorm/Constant_1_output_0 with (Unnamed Layer* 944) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.5.attention.output.LayerNorm.weight\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.5.attention.output.LayerNorm.weight with (Unnamed Layer* 949) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.5.attention.output.LayerNorm.bias\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.5.attention.output.LayerNorm.bias with (Unnamed Layer* 952) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on onnx::MatMul_869\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing onnx::MatMul_869 with (Unnamed Layer* 955) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.5.intermediate.dense.bias\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.5.intermediate.dense.bias with (Unnamed Layer* 958) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.5/intermediate/intermediate_act_fn/Constant_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.5/intermediate/intermediate_act_fn/Constant_output_0 with (Unnamed Layer* 961) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.5/intermediate/intermediate_act_fn/Constant_1_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.5/intermediate/intermediate_act_fn/Constant_1_output_0 with (Unnamed Layer* 965) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.5/intermediate/intermediate_act_fn/Constant_2_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.5/intermediate/intermediate_act_fn/Constant_2_output_0 with (Unnamed Layer* 969) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on onnx::MatMul_870\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing onnx::MatMul_870 with (Unnamed Layer* 972) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.5.output.dense.bias\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.5.output.dense.bias with (Unnamed Layer* 975) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.5/output/LayerNorm/Constant_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.5/output/LayerNorm/Constant_output_0 with (Unnamed Layer* 981) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on /bert/encoder/layer.5/output/LayerNorm/Constant_1_output_0\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing /bert/encoder/layer.5/output/LayerNorm/Constant_1_output_0 with (Unnamed Layer* 985) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.5.output.LayerNorm.weight\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.5.output.LayerNorm.weight with (Unnamed Layer* 990) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on bert.encoder.layer.5.output.LayerNorm.bias\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing bert.encoder.layer.5.output.LayerNorm.bias with (Unnamed Layer* 993) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on bert.pooler.dense.bias\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing bert.pooler.dense.bias with (Unnamed Layer* 1000) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Running: ConstShuffleFusion on classifier.bias\n",
      "[01/18/2023-20:38:47] [V] [TRT] ConstShuffleFusion: Fusing classifier.bias with (Unnamed Layer* 1006) [Shuffle]\n",
      "[01/18/2023-20:38:47] [V] [TRT] Found /bert/encoder/layer.0/attention/self/query/MatMul to be part of self-attention pattern.\n",
      "[01/18/2023-20:38:47] [V] [TRT] Found /bert/encoder/layer.0/attention/self/key/MatMul to be part of self-attention pattern.\n",
      "[01/18/2023-20:38:47] [V] [TRT] Found /bert/encoder/layer.0/attention/self/value/MatMul to be part of self-attention pattern.\n",
      "[01/18/2023-20:38:47] [V] [TRT] Found /bert/encoder/layer.0/attention/self/MatMul to be part of self-attention pattern.\n",
      "[01/18/2023-20:38:47] [V] [TRT] Found /bert/encoder/layer.0/attention/self/Softmax to be part of self-attention pattern.\n",
      "[01/18/2023-20:38:47] [V] [TRT] Found /bert/encoder/layer.0/attention/self/MatMul_1 to be part of self-attention pattern.\n",
      "[01/18/2023-20:38:47] [V] [TRT] Found /bert/encoder/layer.1/attention/self/query/MatMul to be part of self-attention pattern.\n",
      "[01/18/2023-20:38:47] [V] [TRT] Found /bert/encoder/layer.1/attention/self/key/MatMul to be part of self-attention pattern.\n",
      "[01/18/2023-20:38:47] [V] [TRT] Found /bert/encoder/layer.1/attention/self/value/MatMul to be part of self-attention pattern.\n",
      "[01/18/2023-20:38:47] [V] [TRT] Found /bert/encoder/layer.1/attention/self/MatMul to be part of self-attention pattern.\n",
      "[01/18/2023-20:38:47] [V] [TRT] Found /bert/encoder/layer.1/attention/self/Softmax to be part of self-attention pattern.\n",
      "[01/18/2023-20:38:47] [V] [TRT] Found /bert/encoder/layer.1/attention/self/MatMul_1 to be part of self-attention pattern.\n",
      "[01/18/2023-20:38:47] [V] [TRT] Found /bert/encoder/layer.2/attention/self/query/MatMul to be part of self-attention pattern.\n",
      "[01/18/2023-20:38:47] [V] [TRT] Found /bert/encoder/layer.2/attention/self/key/MatMul to be part of self-attention pattern.\n",
      "[01/18/2023-20:38:47] [V] [TRT] Found /bert/encoder/layer.2/attention/self/value/MatMul to be part of self-attention pattern.\n",
      "[01/18/2023-20:38:47] [V] [TRT] Found /bert/encoder/layer.2/attention/self/MatMul to be part of self-attention pattern.\n",
      "[01/18/2023-20:38:47] [V] [TRT] Found /bert/encoder/layer.2/attention/self/Softmax to be part of self-attention pattern.\n",
      "[01/18/2023-20:38:47] [V] [TRT] Found /bert/encoder/layer.2/attention/self/MatMul_1 to be part of self-attention pattern.\n",
      "[01/18/2023-20:38:47] [V] [TRT] Found /bert/encoder/layer.3/attention/self/query/MatMul to be part of self-attention pattern.\n",
      "[01/18/2023-20:38:47] [V] [TRT] Found /bert/encoder/layer.3/attention/self/key/MatMul to be part of self-attention pattern.\n",
      "[01/18/2023-20:38:47] [V] [TRT] Found /bert/encoder/layer.3/attention/self/value/MatMul to be part of self-attention pattern.\n",
      "[01/18/2023-20:38:47] [V] [TRT] Found /bert/encoder/layer.3/attention/self/MatMul to be part of self-attention pattern.\n",
      "[01/18/2023-20:38:47] [V] [TRT] Found /bert/encoder/layer.3/attention/self/Softmax to be part of self-attention pattern.\n",
      "[01/18/2023-20:38:47] [V] [TRT] Found /bert/encoder/layer.3/attention/self/MatMul_1 to be part of self-attention pattern.\n",
      "[01/18/2023-20:38:47] [V] [TRT] Found /bert/encoder/layer.4/attention/self/query/MatMul to be part of self-attention pattern.\n",
      "[01/18/2023-20:38:47] [V] [TRT] Found /bert/encoder/layer.4/attention/self/key/MatMul to be part of self-attention pattern.\n",
      "[01/18/2023-20:38:47] [V] [TRT] Found /bert/encoder/layer.4/attention/self/value/MatMul to be part of self-attention pattern.\n",
      "[01/18/2023-20:38:47] [V] [TRT] Found /bert/encoder/layer.4/attention/self/MatMul to be part of self-attention pattern.\n",
      "[01/18/2023-20:38:47] [V] [TRT] Found /bert/encoder/layer.4/attention/self/Softmax to be part of self-attention pattern.\n",
      "[01/18/2023-20:38:47] [V] [TRT] Found /bert/encoder/layer.4/attention/self/MatMul_1 to be part of self-attention pattern.\n",
      "[01/18/2023-20:38:47] [V] [TRT] Found /bert/encoder/layer.5/attention/self/query/MatMul to be part of self-attention pattern.\n",
      "[01/18/2023-20:38:47] [V] [TRT] Found /bert/encoder/layer.5/attention/self/key/MatMul to be part of self-attention pattern.\n",
      "[01/18/2023-20:38:47] [V] [TRT] Found /bert/encoder/layer.5/attention/self/value/MatMul to be part of self-attention pattern.\n",
      "[01/18/2023-20:38:47] [V] [TRT] Found /bert/encoder/layer.5/attention/self/MatMul to be part of self-attention pattern.\n",
      "[01/18/2023-20:38:47] [V] [TRT] Found /bert/encoder/layer.5/attention/self/Softmax to be part of self-attention pattern.\n",
      "[01/18/2023-20:38:47] [V] [TRT] Found /bert/encoder/layer.5/attention/self/MatMul_1 to be part of self-attention pattern.\n",
      "[01/18/2023-20:38:47] [V] [TRT] Found and reassigned Myelin backends for Self-Attention nodes\n",
      "[01/18/2023-20:38:47] [V] [TRT] After Myelin optimization: 1 layers\n",
      "[01/18/2023-20:38:47] [V] [TRT] Applying ScaleNodes fusions.\n",
      "[01/18/2023-20:38:47] [V] [TRT] After scale fusion: 1 layers\n",
      "[01/18/2023-20:38:47] [V] [TRT] After dupe layer removal: 1 layers\n",
      "[01/18/2023-20:38:47] [V] [TRT] After final dead-layer removal: 1 layers\n",
      "[01/18/2023-20:38:47] [V] [TRT] After tensor merging: 1 layers\n",
      "[01/18/2023-20:38:47] [V] [TRT] After vertical fusions: 1 layers\n",
      "[01/18/2023-20:38:47] [V] [TRT] After dupe layer removal: 1 layers\n",
      "[01/18/2023-20:38:47] [V] [TRT] After final dead-layer removal: 1 layers\n",
      "[01/18/2023-20:38:47] [V] [TRT] After tensor merging: 1 layers\n",
      "[01/18/2023-20:38:47] [V] [TRT] After slice removal: 1 layers\n",
      "[01/18/2023-20:38:47] [V] [TRT] After concat removal: 1 layers\n",
      "[01/18/2023-20:38:47] [V] [TRT] Trying to split Reshape and strided tensor\n",
      "[01/18/2023-20:38:47] [V] [TRT] Graph construction and optimization completed in 0.200373 seconds.\n",
      "[01/18/2023-20:38:47] [V] [TRT] Trying to load shared library libcublas.so.11\n",
      "[01/18/2023-20:38:47] [V] [TRT] Loaded shared library libcublas.so.11\n",
      "[01/18/2023-20:38:47] [V] [TRT] Using cublas as plugin tactic source\n",
      "[01/18/2023-20:38:47] [V] [TRT] Trying to load shared library libcublasLt.so.11\n",
      "[01/18/2023-20:38:47] [V] [TRT] Loaded shared library libcublasLt.so.11\n",
      "[01/18/2023-20:38:47] [V] [TRT] Using cublasLt as core library tactic source\n",
      "[01/18/2023-20:38:47] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +6, GPU +10, now: CPU 580, GPU 378 (MiB)\n",
      "[01/18/2023-20:38:47] [V] [TRT] Trying to load shared library libcudnn.so.8\n",
      "[01/18/2023-20:38:47] [V] [TRT] Loaded shared library libcudnn.so.8\n",
      "[01/18/2023-20:38:47] [V] [TRT] Using cuDNN as plugin tactic source\n",
      "[01/18/2023-20:38:47] [V] [TRT] Using cuDNN as core library tactic source\n",
      "[01/18/2023-20:38:47] [I] [TRT] [MemUsageChange] Init cuDNN: CPU +2, GPU +10, now: CPU 582, GPU 388 (MiB)\n",
      "[01/18/2023-20:38:47] [I] [TRT] Local timing cache in use. Profiling results in this builder pass will not be stored.\n",
      "[01/18/2023-20:38:47] [V] [TRT] Constructing optimization profile number 0 [1/1].\n",
      "[01/18/2023-20:38:47] [V] [TRT] Reserving memory for host IO tensors. Host: 0 bytes\n",
      "[01/18/2023-20:38:47] [V] [TRT] =============== Computing reformatting costs: \n",
      "[01/18/2023-20:38:47] [V] [TRT] *************** Autotuning Reformat: Half(6,1) -> Float(6,1) ***************\n",
      "[01/18/2023-20:38:47] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> logits) (Reformat)\n",
      "[01/18/2023-20:38:47] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.010045\n",
      "[01/18/2023-20:38:47] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0154478\n",
      "[01/18/2023-20:38:47] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0120434\n",
      "[01/18/2023-20:38:47] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.010045\n",
      "[01/18/2023-20:38:47] [V] [TRT] =============== Computing costs for \n",
      "[01/18/2023-20:38:47] [V] [TRT] *************** Autotuning format combination:  -> Int32() ***************\n",
      "[01/18/2023-20:38:47] [V] [TRT] --------------- Timing Runner: [HostToDeviceCopy 0] (ShapeHostToDevice)\n",
      "[01/18/2023-20:38:47] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0113315\n",
      "[01/18/2023-20:38:47] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.0113315\n",
      "[01/18/2023-20:38:47] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: ShapeHostToDevice Tactic: 0x0000000000000000\n",
      "[01/18/2023-20:38:47] [V] [TRT] =============== Computing costs for \n",
      "[01/18/2023-20:38:47] [V] [TRT] *************** Autotuning format combination: Int32(128,1), Int32(128,1), Int32(128,1), Int32() -> Float(6,1) ***************\n",
      "[01/18/2023-20:38:47] [V] [TRT] --------------- Timing Runner: {ForeignNode[bert.embeddings.position_embeddings.weight...(Unnamed Layer* 1007) [ElementWise]]} (Myelin)\n",
      "[01/18/2023-20:38:51] [V] [TRT]  (foreignNode) Set user's cuda kernel library\n",
      "[01/18/2023-20:38:51] [V] [TRT]  (foreignNode) Pass fuse_conv_padding is currently skipped for dynamic shapes\n",
      "[01/18/2023-20:38:51] [V] [TRT]  (foreignNode) Pass pad_conv_channel is currently skipped for dynamic shapes\n",
      "[01/18/2023-20:38:51] [V] [TRT]  (foreignNode) Pass fuse_conv_padding is currently skipped for dynamic shapes\n",
      "[01/18/2023-20:38:51] [V] [TRT]  (foreignNode) Pass pad_conv_channel is currently skipped for dynamic shapes\n",
      "[01/18/2023-20:38:54] [V] [TRT]  (foreignNode) Set user's cuda kernel library\n",
      "[01/18/2023-20:38:54] [V] [TRT]  (foreignNode) Pass fuse_conv_padding is currently skipped for dynamic shapes\n",
      "[01/18/2023-20:38:54] [V] [TRT]  (foreignNode) Pass pad_conv_channel is currently skipped for dynamic shapes\n",
      "[01/18/2023-20:38:54] [V] [TRT]  (foreignNode) Pass fuse_conv_padding is currently skipped for dynamic shapes\n",
      "[01/18/2023-20:38:54] [V] [TRT]  (foreignNode) Pass pad_conv_channel is currently skipped for dynamic shapes\n",
      "[01/18/2023-20:38:57] [V] [TRT]  (foreignNode) Set user's cuda kernel library\n",
      "[01/18/2023-20:38:57] [V] [TRT]  (foreignNode) Pass fuse_conv_padding is currently skipped for dynamic shapes\n",
      "[01/18/2023-20:38:57] [V] [TRT]  (foreignNode) Pass pad_conv_channel is currently skipped for dynamic shapes\n",
      "[01/18/2023-20:38:57] [V] [TRT]  (foreignNode) Pass fuse_conv_padding is currently skipped for dynamic shapes\n",
      "[01/18/2023-20:38:57] [V] [TRT]  (foreignNode) Pass pad_conv_channel is currently skipped for dynamic shapes\n",
      "[01/18/2023-20:39:00] [V] [TRT]  (foreignNode) Set user's cuda kernel library\n",
      "[01/18/2023-20:39:00] [V] [TRT]  (foreignNode) Pass fuse_conv_padding is currently skipped for dynamic shapes\n",
      "[01/18/2023-20:39:00] [V] [TRT]  (foreignNode) Pass pad_conv_channel is currently skipped for dynamic shapes\n",
      "[01/18/2023-20:39:00] [V] [TRT]  (foreignNode) Pass fuse_conv_padding is currently skipped for dynamic shapes\n",
      "[01/18/2023-20:39:00] [V] [TRT]  (foreignNode) Pass pad_conv_channel is currently skipped for dynamic shapes\n",
      "[01/18/2023-20:39:03] [V] [TRT]  (foreignNode) Set user's cuda kernel library\n",
      "[01/18/2023-20:39:03] [V] [TRT]  (foreignNode) Pass fuse_conv_padding is currently skipped for dynamic shapes\n",
      "[01/18/2023-20:39:03] [V] [TRT]  (foreignNode) Pass pad_conv_channel is currently skipped for dynamic shapes\n",
      "[01/18/2023-20:39:03] [V] [TRT]  (foreignNode) Pass fuse_conv_padding is currently skipped for dynamic shapes\n",
      "[01/18/2023-20:39:03] [V] [TRT]  (foreignNode) Pass pad_conv_channel is currently skipped for dynamic shapes\n",
      "[01/18/2023-20:39:06] [V] [TRT]  (foreignNode) Set user's cuda kernel library\n",
      "[01/18/2023-20:39:06] [V] [TRT]  (foreignNode) Pass fuse_conv_padding is currently skipped for dynamic shapes\n",
      "[01/18/2023-20:39:06] [V] [TRT]  (foreignNode) Pass pad_conv_channel is currently skipped for dynamic shapes\n",
      "[01/18/2023-20:39:06] [V] [TRT]  (foreignNode) Pass fuse_conv_padding is currently skipped for dynamic shapes\n",
      "[01/18/2023-20:39:06] [V] [TRT]  (foreignNode) Pass pad_conv_channel is currently skipped for dynamic shapes\n",
      "[01/18/2023-20:39:09] [V] [TRT]  (foreignNode) Set user's cuda kernel library\n",
      "[01/18/2023-20:39:09] [V] [TRT]  (foreignNode) Pass fuse_conv_padding is currently skipped for dynamic shapes\n",
      "[01/18/2023-20:39:09] [V] [TRT]  (foreignNode) Pass pad_conv_channel is currently skipped for dynamic shapes\n",
      "[01/18/2023-20:39:09] [V] [TRT]  (foreignNode) Pass fuse_conv_padding is currently skipped for dynamic shapes\n",
      "[01/18/2023-20:39:09] [V] [TRT]  (foreignNode) Pass pad_conv_channel is currently skipped for dynamic shapes\n",
      "[01/18/2023-20:39:12] [V] [TRT]  (foreignNode) Set user's cuda kernel library\n",
      "[01/18/2023-20:39:12] [V] [TRT]  (foreignNode) Pass fuse_conv_padding is currently skipped for dynamic shapes\n",
      "[01/18/2023-20:39:12] [V] [TRT]  (foreignNode) Pass pad_conv_channel is currently skipped for dynamic shapes\n",
      "[01/18/2023-20:39:12] [V] [TRT]  (foreignNode) Pass fuse_conv_padding is currently skipped for dynamic shapes\n",
      "[01/18/2023-20:39:12] [V] [TRT]  (foreignNode) Pass pad_conv_channel is currently skipped for dynamic shapes\n",
      "[01/18/2023-20:39:15] [V] [TRT]  (foreignNode) Set user's cuda kernel library\n",
      "[01/18/2023-20:39:15] [V] [TRT]  (foreignNode) Pass fuse_conv_padding is currently skipped for dynamic shapes\n",
      "[01/18/2023-20:39:15] [V] [TRT]  (foreignNode) Pass pad_conv_channel is currently skipped for dynamic shapes\n",
      "[01/18/2023-20:39:15] [V] [TRT]  (foreignNode) Pass fuse_conv_padding is currently skipped for dynamic shapes\n",
      "[01/18/2023-20:39:15] [V] [TRT]  (foreignNode) Pass pad_conv_channel is currently skipped for dynamic shapes\n",
      "[01/18/2023-20:39:16] [V] [TRT]  (foreignNode) Set user's cuda kernel library\n",
      "[01/18/2023-20:39:16] [V] [TRT]  (foreignNode) Pass fuse_conv_padding is currently skipped for dynamic shapes\n",
      "[01/18/2023-20:39:16] [V] [TRT]  (foreignNode) Pass pad_conv_channel is currently skipped for dynamic shapes\n",
      "[01/18/2023-20:39:16] [V] [TRT]  (foreignNode) Pass fuse_conv_padding is currently skipped for dynamic shapes\n",
      "[01/18/2023-20:39:16] [V] [TRT]  (foreignNode) Pass pad_conv_channel is currently skipped for dynamic shapes\n",
      "[01/18/2023-20:39:18] [V] [TRT] Tactic: 0x0000000000000000 Time: 1.91971\n",
      "[01/18/2023-20:39:18] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 1.91971\n",
      "[01/18/2023-20:39:18] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Myelin Tactic: 0x0000000000000000\n",
      "[01/18/2023-20:39:18] [V] [TRT] *************** Autotuning format combination: Int32(128,1), Int32(128,1), Int32(128,1), Int32() -> Half(6,1) ***************\n",
      "[01/18/2023-20:39:18] [V] [TRT] --------------- Timing Runner: {ForeignNode[bert.embeddings.position_embeddings.weight...(Unnamed Layer* 1007) [ElementWise]]} (Myelin)\n",
      "[01/18/2023-20:40:33] [V] [TRT]  (foreignNode) Set user's cuda kernel library\n",
      "[01/18/2023-20:40:33] [V] [TRT]  (foreignNode) Pass fuse_conv_padding is currently skipped for dynamic shapes\n",
      "[01/18/2023-20:40:33] [V] [TRT]  (foreignNode) Pass pad_conv_channel is currently skipped for dynamic shapes\n",
      "[01/18/2023-20:40:33] [V] [TRT]  (foreignNode) Pass fuse_conv_padding is currently skipped for dynamic shapes\n",
      "[01/18/2023-20:40:33] [V] [TRT]  (foreignNode) Pass pad_conv_channel is currently skipped for dynamic shapes\n",
      "[01/18/2023-20:41:47] [V] [TRT]  (foreignNode) Set user's cuda kernel library\n",
      "[01/18/2023-20:41:47] [V] [TRT]  (foreignNode) Pass fuse_conv_padding is currently skipped for dynamic shapes\n",
      "[01/18/2023-20:41:47] [V] [TRT]  (foreignNode) Pass pad_conv_channel is currently skipped for dynamic shapes\n",
      "[01/18/2023-20:41:47] [V] [TRT]  (foreignNode) Pass fuse_conv_padding is currently skipped for dynamic shapes\n",
      "[01/18/2023-20:41:47] [V] [TRT]  (foreignNode) Pass pad_conv_channel is currently skipped for dynamic shapes\n",
      "[01/18/2023-20:42:47] [V] [TRT]  (foreignNode) Set user's cuda kernel library\n",
      "[01/18/2023-20:42:47] [V] [TRT]  (foreignNode) Pass fuse_conv_padding is currently skipped for dynamic shapes\n",
      "[01/18/2023-20:42:47] [V] [TRT]  (foreignNode) Pass pad_conv_channel is currently skipped for dynamic shapes\n",
      "[01/18/2023-20:42:47] [V] [TRT]  (foreignNode) Pass fuse_conv_padding is currently skipped for dynamic shapes\n",
      "[01/18/2023-20:42:47] [V] [TRT]  (foreignNode) Pass pad_conv_channel is currently skipped for dynamic shapes\n",
      "[01/18/2023-20:43:58] [V] [TRT]  (foreignNode) Set user's cuda kernel library\n",
      "[01/18/2023-20:43:58] [V] [TRT]  (foreignNode) Pass fuse_conv_padding is currently skipped for dynamic shapes\n",
      "[01/18/2023-20:43:58] [V] [TRT]  (foreignNode) Pass pad_conv_channel is currently skipped for dynamic shapes\n",
      "[01/18/2023-20:43:58] [V] [TRT]  (foreignNode) Pass fuse_conv_padding is currently skipped for dynamic shapes\n",
      "[01/18/2023-20:43:58] [V] [TRT]  (foreignNode) Pass pad_conv_channel is currently skipped for dynamic shapes\n",
      "[01/18/2023-20:45:00] [V] [TRT]  (foreignNode) Set user's cuda kernel library\n",
      "[01/18/2023-20:45:00] [V] [TRT]  (foreignNode) Pass fuse_conv_padding is currently skipped for dynamic shapes\n",
      "[01/18/2023-20:45:00] [V] [TRT]  (foreignNode) Pass pad_conv_channel is currently skipped for dynamic shapes\n",
      "[01/18/2023-20:45:00] [V] [TRT]  (foreignNode) Pass fuse_conv_padding is currently skipped for dynamic shapes\n",
      "[01/18/2023-20:45:00] [V] [TRT]  (foreignNode) Pass pad_conv_channel is currently skipped for dynamic shapes\n",
      "[01/18/2023-20:46:02] [V] [TRT]  (foreignNode) Set user's cuda kernel library\n",
      "[01/18/2023-20:46:02] [V] [TRT]  (foreignNode) Pass fuse_conv_padding is currently skipped for dynamic shapes\n",
      "[01/18/2023-20:46:02] [V] [TRT]  (foreignNode) Pass pad_conv_channel is currently skipped for dynamic shapes\n",
      "[01/18/2023-20:46:02] [V] [TRT]  (foreignNode) Pass fuse_conv_padding is currently skipped for dynamic shapes\n",
      "[01/18/2023-20:46:02] [V] [TRT]  (foreignNode) Pass pad_conv_channel is currently skipped for dynamic shapes\n",
      "[01/18/2023-20:47:01] [V] [TRT]  (foreignNode) Set user's cuda kernel library\n",
      "[01/18/2023-20:47:01] [V] [TRT]  (foreignNode) Pass fuse_conv_padding is currently skipped for dynamic shapes\n",
      "[01/18/2023-20:47:01] [V] [TRT]  (foreignNode) Pass pad_conv_channel is currently skipped for dynamic shapes\n",
      "[01/18/2023-20:47:01] [V] [TRT]  (foreignNode) Pass fuse_conv_padding is currently skipped for dynamic shapes\n",
      "[01/18/2023-20:47:01] [V] [TRT]  (foreignNode) Pass pad_conv_channel is currently skipped for dynamic shapes\n",
      "[01/18/2023-20:47:58] [V] [TRT]  (foreignNode) Set user's cuda kernel library\n",
      "[01/18/2023-20:47:58] [V] [TRT]  (foreignNode) Pass fuse_conv_padding is currently skipped for dynamic shapes\n",
      "[01/18/2023-20:47:58] [V] [TRT]  (foreignNode) Pass pad_conv_channel is currently skipped for dynamic shapes\n",
      "[01/18/2023-20:47:58] [V] [TRT]  (foreignNode) Pass fuse_conv_padding is currently skipped for dynamic shapes\n",
      "[01/18/2023-20:47:58] [V] [TRT]  (foreignNode) Pass pad_conv_channel is currently skipped for dynamic shapes\n",
      "[01/18/2023-20:48:53] [V] [TRT]  (foreignNode) Set user's cuda kernel library\n",
      "[01/18/2023-20:48:53] [V] [TRT]  (foreignNode) Pass fuse_conv_padding is currently skipped for dynamic shapes\n",
      "[01/18/2023-20:48:53] [V] [TRT]  (foreignNode) Pass pad_conv_channel is currently skipped for dynamic shapes\n",
      "[01/18/2023-20:48:53] [V] [TRT]  (foreignNode) Pass fuse_conv_padding is currently skipped for dynamic shapes\n",
      "[01/18/2023-20:48:53] [V] [TRT]  (foreignNode) Pass pad_conv_channel is currently skipped for dynamic shapes\n",
      "[01/18/2023-20:49:09] [V] [TRT]  (foreignNode) Set user's cuda kernel library\n",
      "[01/18/2023-20:49:09] [V] [TRT]  (foreignNode) Pass fuse_conv_padding is currently skipped for dynamic shapes\n",
      "[01/18/2023-20:49:09] [V] [TRT]  (foreignNode) Pass pad_conv_channel is currently skipped for dynamic shapes\n",
      "[01/18/2023-20:49:09] [V] [TRT]  (foreignNode) Pass fuse_conv_padding is currently skipped for dynamic shapes\n",
      "[01/18/2023-20:49:09] [V] [TRT]  (foreignNode) Pass pad_conv_channel is currently skipped for dynamic shapes\n",
      "[01/18/2023-20:49:10] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.845531\n",
      "[01/18/2023-20:49:10] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.845531\n",
      "[01/18/2023-20:49:10] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Myelin Tactic: 0x0000000000000000\n",
      "[01/18/2023-20:49:10] [V] [TRT] Adding reformat layer: Reformatted Output Tensor 0 to {ForeignNode[bert.embeddings.position_embeddings.weight...(Unnamed Layer* 1007) [ElementWise]]} (logits) from Half(6,1) to Float(6,1)\n",
      "[01/18/2023-20:49:10] [V] [TRT] Formats and tactics selection completed in 623.238 seconds.\n",
      "[01/18/2023-20:49:10] [V] [TRT] After reformat layers: 3 layers\n",
      "[01/18/2023-20:49:10] [V] [TRT] Total number of blocks in pre-optimized block assignment: 3\n",
      "[01/18/2023-20:49:10] [I] [TRT] Total Activation Memory: 24117251584\n",
      "[01/18/2023-20:49:10] [I] [TRT] Detected 3 inputs and 1 output network tensors.\n",
      "[01/18/2023-20:49:12] [V] [TRT] Layer: [HostToDeviceCopy 0] Host Persistent: 4 Device Persistent: 0 Scratch Memory: 0\n",
      "[01/18/2023-20:49:12] [V] [TRT] Layer: {ForeignNode[bert.embeddings.position_embeddings.weight...(Unnamed Layer* 1007) [ElementWise]]} Host Persistent: 240 Device Persistent: 0 Scratch Memory: 191242240\n",
      "[01/18/2023-20:49:12] [V] [TRT] Skipped printing memory information for 1 layers with 0 memory size i.e. Host Persistent + Device Persistent + Scratch Memory == 0.\n",
      "[01/18/2023-20:49:12] [I] [TRT] Total Host Persistent Memory: 256\n",
      "[01/18/2023-20:49:12] [I] [TRT] Total Device Persistent Memory: 0\n",
      "[01/18/2023-20:49:12] [I] [TRT] Total Scratch Memory: 191242240\n",
      "[01/18/2023-20:49:12] [I] [TRT] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 24 MiB, GPU 526 MiB\n",
      "[01/18/2023-20:49:12] [I] [TRT] [BlockAssignment] Started assigning block shifts. This will take 3 steps to complete.\n",
      "[01/18/2023-20:49:12] [I] [TRT] [BlockAssignment] Algorithm ShiftNTopDown took 0.045011ms to assign 3 blocks to 3 nodes requiring 191245824 bytes.\n",
      "[01/18/2023-20:49:12] [V] [TRT] Total number of blocks in optimized block assignment: 3\n",
      "[01/18/2023-20:49:12] [I] [TRT] Total Activation Memory: 191245824\n",
      "[01/18/2023-20:49:12] [V] [TRT] Total number of generated kernels selected for the engine: 0\n",
      "[01/18/2023-20:49:12] [V] [TRT] Disabling unused tactic source: CUDNN\n",
      "[01/18/2023-20:49:12] [V] [TRT] Disabling unused tactic source: CUBLAS, CUBLAS_LT\n",
      "[01/18/2023-20:49:12] [V] [TRT] Disabling unused tactic source: EDGE_MASK_CONVOLUTIONS\n",
      "[01/18/2023-20:49:12] [V] [TRT] Disabling unused tactic source: JIT_CONVOLUTIONS\n",
      "[01/18/2023-20:49:12] [V] [TRT] Engine generation completed in 624.823 seconds.\n",
      "[01/18/2023-20:49:12] [W] [TRT] TensorRT encountered issues when converting weights between types and that could affect accuracy.\n",
      "[01/18/2023-20:49:12] [W] [TRT] If this is not the desired behavior, please modify the weights or retrain with regularization to adjust the magnitude of the weights.\n",
      "[01/18/2023-20:49:12] [W] [TRT] Check verbose logs for the list of affected weights.\n",
      "[01/18/2023-20:49:12] [W] [TRT] - 59 weights are affected by this issue: Detected subnormal FP16 values.\n",
      "[01/18/2023-20:49:12] [W] [TRT] - 18 weights are affected by this issue: Detected values less than smallest positive FP16 subnormal value and converted them to the FP16 minimum subnormalized value.\n",
      "[01/18/2023-20:49:12] [W] [TRT] - 1 weights are affected by this issue: Detected finite FP32 values which would overflow in FP16 and converted them to the closest finite FP16 value.\n",
      "[01/18/2023-20:49:12] [V] [TRT]   List of affected weights: bert_embeddings_position_embeddings_weight_constant, bert_embeddings_token_type_embeddings_weight_constant, bert_embeddings_word_embeddings_weight_constant, bert_encoder_layer_0_attention_self_key_bias _ (Unnamed Layer_ 75) [Shuffle]_constant, bert_encoder_layer_1_attention_self_value_bias _ (Unnamed Layer_ 248) [Shuffle]_constant, bert_encoder_layer_1_intermediate_dense_bias _ (Unnamed Layer_ 338) [Shuffle]_constant, bert_encoder_layer_1_output_dense_bias _ (Unnamed Layer_ 355) [Shuffle]_constant, bert_encoder_layer_2_attention_self_key_bias _ (Unnamed Layer_ 385) [Shuffle]_constant, bert_encoder_layer_2_attention_self_value_bias _ (Unnamed Layer_ 403) [Shuffle]_constant, bert_encoder_layer_2_intermediate_dense_bias _ (Unnamed Layer_ 493) [Shuffle]_constant, bert_encoder_layer_3_attention_self_key_bias _ (Unnamed Layer_ 540) [Shuffle]_constant, bert_encoder_layer_4_attention_self_value_bias _ (Unnamed Layer_ 713) [Shuffle]_constant, bert_encoder_layer_4_intermediate_dense_bias _ (Unnamed Layer_ 803) [Shuffle]_constant, bert_encoder_layer_5_attention_output_LayerNorm_bias _ (Unnamed Layer_ 952) [Shuffle]_constant, bert_encoder_layer_5_attention_output_dense_bias _ (Unnamed Layer_ 934) [Shuffle]_constant, bert_encoder_layer_5_attention_self_key_bias _ (Unnamed Layer_ 850) [Shuffle]_constant, bert_encoder_layer_5_intermediate_dense_bias _ (Unnamed Layer_ 958) [Shuffle]_constant, bert_encoder_layer_5_output_LayerNorm_bias _ (Unnamed Layer_ 993) [Shuffle]_constant, bert_encoder_layer_5_output_dense_bias _ (Unnamed Layer_ 975) [Shuffle]_constant, bert_pooler_dense_bias _ (Unnamed Layer_ 1000) [Shuffle]_constant, bert_pooler_dense_weight_constant, classifier_bias _ (Unnamed Layer_ 1006) [Shuffle]_constant, classifier_weight_constant, onnx__MatMul_793 _ (Unnamed Layer_ 66) [Shuffle]_constant, onnx__MatMul_794 _ (Unnamed Layer_ 72) [Shuffle]_constant, onnx__MatMul_797 _ (Unnamed Layer_ 90) [Shuffle]_constant, onnx__MatMul_803 _ (Unnamed Layer_ 156) [Shuffle]_constant, onnx__MatMul_804 _ (Unnamed Layer_ 180) [Shuffle]_constant, onnx__MatMul_805 _ (Unnamed Layer_ 197) [Shuffle]_constant, onnx__MatMul_806 _ (Unnamed Layer_ 221) [Shuffle]_constant, onnx__MatMul_807 _ (Unnamed Layer_ 227) [Shuffle]_constant, onnx__MatMul_810 _ (Unnamed Layer_ 245) [Shuffle]_constant, onnx__MatMul_816 _ (Unnamed Layer_ 311) [Shuffle]_constant, onnx__MatMul_817 _ (Unnamed Layer_ 335) [Shuffle]_constant, onnx__MatMul_818 _ (Unnamed Layer_ 352) [Shuffle]_constant, onnx__MatMul_819 _ (Unnamed Layer_ 376) [Shuffle]_constant, onnx__MatMul_820 _ (Unnamed Layer_ 382) [Shuffle]_constant, onnx__MatMul_823 _ (Unnamed Layer_ 400) [Shuffle]_constant, onnx__MatMul_829 _ (Unnamed Layer_ 466) [Shuffle]_constant, onnx__MatMul_830 _ (Unnamed Layer_ 490) [Shuffle]_constant, onnx__MatMul_831 _ (Unnamed Layer_ 507) [Shuffle]_constant, onnx__MatMul_832 _ (Unnamed Layer_ 531) [Shuffle]_constant, onnx__MatMul_833 _ (Unnamed Layer_ 537) [Shuffle]_constant, onnx__MatMul_836 _ (Unnamed Layer_ 555) [Shuffle]_constant, onnx__MatMul_842 _ (Unnamed Layer_ 621) [Shuffle]_constant, onnx__MatMul_843 _ (Unnamed Layer_ 645) [Shuffle]_constant, onnx__MatMul_844 _ (Unnamed Layer_ 662) [Shuffle]_constant, onnx__MatMul_845 _ (Unnamed Layer_ 686) [Shuffle]_constant, onnx__MatMul_846 _ (Unnamed Layer_ 692) [Shuffle]_constant, onnx__MatMul_849 _ (Unnamed Layer_ 710) [Shuffle]_constant, onnx__MatMul_855 _ (Unnamed Layer_ 776) [Shuffle]_constant, onnx__MatMul_856 _ (Unnamed Layer_ 800) [Shuffle]_constant, onnx__MatMul_857 _ (Unnamed Layer_ 817) [Shuffle]_constant, onnx__MatMul_858 _ (Unnamed Layer_ 841) [Shuffle]_constant, onnx__MatMul_859 _ (Unnamed Layer_ 847) [Shuffle]_constant, onnx__MatMul_862 _ (Unnamed Layer_ 865) [Shuffle]_constant, onnx__MatMul_868 _ (Unnamed Layer_ 931) [Shuffle]_constant, onnx__MatMul_869 _ (Unnamed Layer_ 955) [Shuffle]_constant, onnx__MatMul_870 _ (Unnamed Layer_ 972) [Shuffle]_constant\n",
      "[01/18/2023-20:49:12] [V] [TRT]   List of affected weights: /bert/embeddings/LayerNorm/Constant_1_output_0 + (Unnamed Layer* 55) [Shuffle], /bert/encoder/layer.0/attention/output/LayerNorm/Constant_1_output_0 + (Unnamed Layer* 169) [Shuffle], /bert/encoder/layer.0/output/LayerNorm/Constant_1_output_0 + (Unnamed Layer* 210) [Shuffle], /bert/encoder/layer.1/attention/output/LayerNorm/Constant_1_output_0 + (Unnamed Layer* 324) [Shuffle], /bert/encoder/layer.1/output/LayerNorm/Constant_1_output_0 + (Unnamed Layer* 365) [Shuffle], /bert/encoder/layer.2/attention/output/LayerNorm/Constant_1_output_0 + (Unnamed Layer* 479) [Shuffle], /bert/encoder/layer.2/output/LayerNorm/Constant_1_output_0 + (Unnamed Layer* 520) [Shuffle], /bert/encoder/layer.3/attention/output/LayerNorm/Constant_1_output_0 + (Unnamed Layer* 634) [Shuffle], /bert/encoder/layer.3/output/LayerNorm/Constant_1_output_0 + (Unnamed Layer* 675) [Shuffle], /bert/encoder/layer.4/attention/output/LayerNorm/Constant_1_output_0 + (Unnamed Layer* 789) [Shuffle], /bert/encoder/layer.4/output/LayerNorm/Constant_1_output_0 + (Unnamed Layer* 830) [Shuffle], /bert/encoder/layer.5/attention/output/LayerNorm/Constant_1_output_0 + (Unnamed Layer* 944) [Shuffle], /bert/encoder/layer.5/output/LayerNorm/Constant_1_output_0 + (Unnamed Layer* 985) [Shuffle], bert_embeddings_word_embeddings_weight_constant, onnx__MatMul_830 _ (Unnamed Layer_ 490) [Shuffle]_constant, onnx__MatMul_845 _ (Unnamed Layer_ 686) [Shuffle]_constant, onnx__MatMul_869 _ (Unnamed Layer_ 955) [Shuffle]_constant, onnx__MatMul_870 _ (Unnamed Layer_ 972) [Shuffle]_constant\n",
      "[01/18/2023-20:49:12] [V] [TRT]   List of affected weights: /bert/Constant_2_output_0 + (Unnamed Layer* 17) [Shuffle]\n",
      "[01/18/2023-20:49:12] [V] [TRT] Deleting timing cache: 1 entries, served 0 hits since creation.\n",
      "[01/18/2023-20:49:12] [V] [TRT] Engine Layer Information:\n",
      "Layer(ShapeHostToDevice): [HostToDeviceCopy 0], Tactic: 0x0000000000000000,  -> token_type_ids[implicit padding mask tensor 0] (Int32[])\n",
      "Layer(Myelin): {ForeignNode[bert.embeddings.position_embeddings.weight...(Unnamed Layer* 1007) [ElementWise]]}, Tactic: 0x0000000000000000, token_type_ids (Int32[-1,128]), input_ids (Int32[-1,128]), attention_mask (Int32[-1,128]), token_type_ids[implicit padding mask tensor 0] (Int32[]) -> Reformatted Output Tensor 0 to {ForeignNode[bert.embeddings.position_embeddings.weight...(Unnamed Layer* 1007) [ElementWise]]} (Half[-1,6])\n",
      "Layer(Reformat): Reformatting CopyNode for Output Tensor 0 to {ForeignNode[bert.embeddings.position_embeddings.weight...(Unnamed Layer* 1007) [ElementWise]]}, Tactic: 0x00000000000003e8, Reformatted Output Tensor 0 to {ForeignNode[bert.embeddings.position_embeddings.weight...(Unnamed Layer* 1007) [ElementWise]]} (Half[-1,6]) -> logits (Float[-1,6])\n",
      "[01/18/2023-20:49:12] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in building engine: CPU +24, GPU +32, now: CPU 24, GPU 32 (MiB)\n",
      "[01/18/2023-20:49:12] [I] Engine built in 629.019 sec.\n",
      "[01/18/2023-20:49:12] [I] [TRT] Loaded engine size: 36 MiB\n",
      "[01/18/2023-20:49:12] [V] [TRT] Deserialization required 11760 microseconds.\n",
      "[01/18/2023-20:49:12] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in engine deserialization: CPU +0, GPU +27, now: CPU 0, GPU 27 (MiB)\n",
      "[01/18/2023-20:49:12] [I] Engine deserialized in 0.0121076 sec.\n",
      "[01/18/2023-20:49:12] [V] [TRT] Total per-runner device persistent memory is 0\n",
      "[01/18/2023-20:49:12] [V] [TRT] Total per-runner host persistent memory is 256\n",
      "[01/18/2023-20:49:12] [V] [TRT] Allocated activation device memory of size 191245824\n",
      "[01/18/2023-20:49:13] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +182, now: CPU 0, GPU 209 (MiB)\n",
      "[01/18/2023-20:49:13] [V] [TRT] CUDA lazy loading is enabled.\n",
      "[01/18/2023-20:49:13] [I] Setting persistentCacheLimit to 0 bytes.\n",
      "[01/18/2023-20:49:13] [V] Using enqueueV3.\n",
      "[01/18/2023-20:49:13] [I] Using random values for input input_ids\n",
      "[01/18/2023-20:49:13] [I] Created input binding for input_ids with dimensions 16x128\n",
      "[01/18/2023-20:49:13] [I] Using random values for input attention_mask\n",
      "[01/18/2023-20:49:13] [I] Created input binding for attention_mask with dimensions 16x128\n",
      "[01/18/2023-20:49:13] [I] Using random values for input token_type_ids\n",
      "[01/18/2023-20:49:13] [I] Created input binding for token_type_ids with dimensions 16x128\n",
      "[01/18/2023-20:49:13] [I] Using random values for output logits\n",
      "[01/18/2023-20:49:13] [I] Created output binding for logits with dimensions 16x6\n",
      "[01/18/2023-20:49:13] [I] Starting inference\n",
      "[01/18/2023-20:49:16] [I] Warmup completed 218 queries over 200 ms\n",
      "[01/18/2023-20:49:16] [I] Timing trace has 3259 queries over 3.00108 s\n",
      "[01/18/2023-20:49:16] [I] \n",
      "[01/18/2023-20:49:16] [I] === Trace details ===\n",
      "[01/18/2023-20:49:16] [I] Trace averages of 10 runs:\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.871613 ms - Host latency: 0.888548 ms (enqueue 0.868321 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.870914 ms - Host latency: 0.891185 ms (enqueue 0.867665 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.874623 ms - Host latency: 0.891515 ms (enqueue 0.871413 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.87182 ms - Host latency: 0.888577 ms (enqueue 0.868359 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.871927 ms - Host latency: 0.888969 ms (enqueue 0.868564 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.872035 ms - Host latency: 0.888664 ms (enqueue 0.868646 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.873352 ms - Host latency: 0.890015 ms (enqueue 0.869806 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.872549 ms - Host latency: 0.889398 ms (enqueue 0.869421 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.876108 ms - Host latency: 0.893436 ms (enqueue 0.873242 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.872458 ms - Host latency: 0.889468 ms (enqueue 0.869199 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.869891 ms - Host latency: 0.886633 ms (enqueue 0.866965 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.871881 ms - Host latency: 0.888837 ms (enqueue 0.868802 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.87341 ms - Host latency: 0.890564 ms (enqueue 0.870279 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.870828 ms - Host latency: 0.887732 ms (enqueue 0.867847 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.871896 ms - Host latency: 0.888876 ms (enqueue 0.86871 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.872244 ms - Host latency: 0.889142 ms (enqueue 0.868964 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.872247 ms - Host latency: 0.888678 ms (enqueue 0.869208 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.871414 ms - Host latency: 0.88797 ms (enqueue 0.868173 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.871906 ms - Host latency: 0.888876 ms (enqueue 0.868613 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.874872 ms - Host latency: 0.891846 ms (enqueue 0.871786 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.87132 ms - Host latency: 0.888223 ms (enqueue 0.86788 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.873062 ms - Host latency: 0.890701 ms (enqueue 0.869846 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.870493 ms - Host latency: 0.887033 ms (enqueue 0.867645 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.871338 ms - Host latency: 0.888101 ms (enqueue 0.868222 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.871432 ms - Host latency: 0.889554 ms (enqueue 0.868341 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.871661 ms - Host latency: 0.888489 ms (enqueue 0.868332 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.872553 ms - Host latency: 0.889642 ms (enqueue 0.86937 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.871405 ms - Host latency: 0.888226 ms (enqueue 0.867966 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.872614 ms - Host latency: 0.889337 ms (enqueue 0.869205 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.8729 ms - Host latency: 0.889926 ms (enqueue 0.869687 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.871628 ms - Host latency: 0.888928 ms (enqueue 0.868463 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.872626 ms - Host latency: 0.89166 ms (enqueue 0.869244 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.871823 ms - Host latency: 0.888541 ms (enqueue 0.868713 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.870697 ms - Host latency: 0.887491 ms (enqueue 0.867789 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.871619 ms - Host latency: 0.888568 ms (enqueue 0.868549 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.871613 ms - Host latency: 0.888574 ms (enqueue 0.868658 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.871423 ms - Host latency: 0.888782 ms (enqueue 0.868121 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.87102 ms - Host latency: 0.887848 ms (enqueue 0.868134 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.871332 ms - Host latency: 0.888129 ms (enqueue 0.868152 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.872577 ms - Host latency: 0.889215 ms (enqueue 0.869165 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.872327 ms - Host latency: 0.889465 ms (enqueue 0.869196 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.870892 ms - Host latency: 0.888867 ms (enqueue 0.867664 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.872125 ms - Host latency: 0.889294 ms (enqueue 0.869092 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.870807 ms - Host latency: 0.887872 ms (enqueue 0.867957 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.871338 ms - Host latency: 0.888153 ms (enqueue 0.868384 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.872125 ms - Host latency: 0.888696 ms (enqueue 0.868793 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.872961 ms - Host latency: 0.890155 ms (enqueue 0.869916 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.871722 ms - Host latency: 0.888458 ms (enqueue 0.868683 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.873474 ms - Host latency: 0.89035 ms (enqueue 0.870203 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.872034 ms - Host latency: 0.888495 ms (enqueue 0.869159 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.870703 ms - Host latency: 0.887231 ms (enqueue 0.86803 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.870398 ms - Host latency: 0.888336 ms (enqueue 0.867657 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.871826 ms - Host latency: 0.888763 ms (enqueue 0.86864 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.871014 ms - Host latency: 0.888696 ms (enqueue 0.868079 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.871521 ms - Host latency: 0.888147 ms (enqueue 0.86875 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.870844 ms - Host latency: 0.887457 ms (enqueue 0.86759 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.8703 ms - Host latency: 0.886847 ms (enqueue 0.867212 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.870508 ms - Host latency: 0.886975 ms (enqueue 0.867157 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.872662 ms - Host latency: 0.889539 ms (enqueue 0.869464 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.871631 ms - Host latency: 0.889215 ms (enqueue 0.868683 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.872351 ms - Host latency: 0.889001 ms (enqueue 0.869171 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.871112 ms - Host latency: 0.888867 ms (enqueue 0.867853 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.871832 ms - Host latency: 0.889441 ms (enqueue 0.868982 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.871228 ms - Host latency: 0.887988 ms (enqueue 0.868488 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.871301 ms - Host latency: 0.887897 ms (enqueue 0.868311 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.870294 ms - Host latency: 0.887146 ms (enqueue 0.867407 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.873346 ms - Host latency: 0.88974 ms (enqueue 0.8685 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.870697 ms - Host latency: 0.888696 ms (enqueue 0.867456 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.870593 ms - Host latency: 0.887567 ms (enqueue 0.867236 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.875696 ms - Host latency: 0.893225 ms (enqueue 0.872424 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.878076 ms - Host latency: 0.89516 ms (enqueue 0.87467 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.873865 ms - Host latency: 0.890564 ms (enqueue 0.870612 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.872046 ms - Host latency: 0.888849 ms (enqueue 0.868829 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.872449 ms - Host latency: 0.889069 ms (enqueue 0.869189 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.870508 ms - Host latency: 0.887683 ms (enqueue 0.867371 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.872235 ms - Host latency: 0.890228 ms (enqueue 0.868756 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.871313 ms - Host latency: 0.888092 ms (enqueue 0.868408 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.869995 ms - Host latency: 0.886615 ms (enqueue 0.867072 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.87337 ms - Host latency: 0.890179 ms (enqueue 0.870233 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.871423 ms - Host latency: 0.888214 ms (enqueue 0.867975 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.873572 ms - Host latency: 0.890857 ms (enqueue 0.870465 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.870514 ms - Host latency: 0.887402 ms (enqueue 0.867395 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.872791 ms - Host latency: 0.889819 ms (enqueue 0.869666 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.873218 ms - Host latency: 0.890131 ms (enqueue 0.870001 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.871527 ms - Host latency: 0.888348 ms (enqueue 0.868555 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.872553 ms - Host latency: 0.889441 ms (enqueue 0.868573 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.87204 ms - Host latency: 0.888617 ms (enqueue 0.869318 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.872736 ms - Host latency: 0.889685 ms (enqueue 0.869635 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.870911 ms - Host latency: 0.887518 ms (enqueue 0.867804 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.871417 ms - Host latency: 0.888397 ms (enqueue 0.868262 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.871924 ms - Host latency: 0.889307 ms (enqueue 0.868787 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.873767 ms - Host latency: 0.890295 ms (enqueue 0.870764 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.870898 ms - Host latency: 0.887805 ms (enqueue 0.868005 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.870996 ms - Host latency: 0.888037 ms (enqueue 0.867895 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.875208 ms - Host latency: 0.892358 ms (enqueue 0.871863 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.873157 ms - Host latency: 0.890088 ms (enqueue 0.870093 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.871472 ms - Host latency: 0.887988 ms (enqueue 0.868274 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.871521 ms - Host latency: 0.888293 ms (enqueue 0.868213 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.870508 ms - Host latency: 0.887671 ms (enqueue 0.867334 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.871533 ms - Host latency: 0.888293 ms (enqueue 0.868152 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.870593 ms - Host latency: 0.887598 ms (enqueue 0.867676 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.872046 ms - Host latency: 0.888599 ms (enqueue 0.867419 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.871704 ms - Host latency: 0.888403 ms (enqueue 0.868787 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.872974 ms - Host latency: 0.890161 ms (enqueue 0.870081 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.877124 ms - Host latency: 0.896069 ms (enqueue 0.873999 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.873291 ms - Host latency: 0.890247 ms (enqueue 0.870251 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.874951 ms - Host latency: 0.892175 ms (enqueue 0.87157 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.877283 ms - Host latency: 0.894336 ms (enqueue 0.874329 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.871851 ms - Host latency: 0.888794 ms (enqueue 0.868579 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.871509 ms - Host latency: 0.889758 ms (enqueue 0.868298 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.872864 ms - Host latency: 0.889355 ms (enqueue 0.87002 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.870496 ms - Host latency: 0.886938 ms (enqueue 0.867468 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.872424 ms - Host latency: 0.889294 ms (enqueue 0.86908 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.87124 ms - Host latency: 0.887866 ms (enqueue 0.868628 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.870605 ms - Host latency: 0.888599 ms (enqueue 0.86781 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.872241 ms - Host latency: 0.889087 ms (enqueue 0.869263 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.871204 ms - Host latency: 0.887842 ms (enqueue 0.868127 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.871655 ms - Host latency: 0.888757 ms (enqueue 0.868591 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.872559 ms - Host latency: 0.889648 ms (enqueue 0.869348 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.87019 ms - Host latency: 0.886597 ms (enqueue 0.867053 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.874194 ms - Host latency: 0.891077 ms (enqueue 0.870996 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.876099 ms - Host latency: 0.89353 ms (enqueue 0.8729 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.872632 ms - Host latency: 0.889465 ms (enqueue 0.869275 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.870801 ms - Host latency: 0.888098 ms (enqueue 0.867957 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.87251 ms - Host latency: 0.889502 ms (enqueue 0.869324 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.871606 ms - Host latency: 0.888135 ms (enqueue 0.868225 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.873364 ms - Host latency: 0.890881 ms (enqueue 0.870032 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.873169 ms - Host latency: 0.89054 ms (enqueue 0.86991 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.871301 ms - Host latency: 0.888232 ms (enqueue 0.868103 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.871216 ms - Host latency: 0.887878 ms (enqueue 0.86792 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.872131 ms - Host latency: 0.888892 ms (enqueue 0.868994 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.873926 ms - Host latency: 0.890955 ms (enqueue 0.870862 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.871313 ms - Host latency: 0.888098 ms (enqueue 0.868286 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.871606 ms - Host latency: 0.888245 ms (enqueue 0.868408 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.871448 ms - Host latency: 0.890112 ms (enqueue 0.868176 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.872778 ms - Host latency: 0.889868 ms (enqueue 0.8698 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.87102 ms - Host latency: 0.888245 ms (enqueue 0.867993 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.873083 ms - Host latency: 0.890454 ms (enqueue 0.86991 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.872241 ms - Host latency: 0.891699 ms (enqueue 0.86908 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.871216 ms - Host latency: 0.888013 ms (enqueue 0.868127 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.87124 ms - Host latency: 0.887927 ms (enqueue 0.867993 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.872668 ms - Host latency: 0.889734 ms (enqueue 0.869336 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.871741 ms - Host latency: 0.888477 ms (enqueue 0.868787 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.870093 ms - Host latency: 0.887549 ms (enqueue 0.866907 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.869788 ms - Host latency: 0.886816 ms (enqueue 0.866736 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.87312 ms - Host latency: 0.889587 ms (enqueue 0.869714 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.871399 ms - Host latency: 0.888184 ms (enqueue 0.868237 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.870508 ms - Host latency: 0.887463 ms (enqueue 0.867566 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.873242 ms - Host latency: 0.890381 ms (enqueue 0.868811 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.871875 ms - Host latency: 0.888647 ms (enqueue 0.868909 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.871008 ms - Host latency: 0.88739 ms (enqueue 0.867895 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.870459 ms - Host latency: 0.887231 ms (enqueue 0.867554 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.873889 ms - Host latency: 0.890942 ms (enqueue 0.870789 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.870178 ms - Host latency: 0.886731 ms (enqueue 0.867139 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.87102 ms - Host latency: 0.88772 ms (enqueue 0.868347 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.869873 ms - Host latency: 0.886487 ms (enqueue 0.866785 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.870374 ms - Host latency: 0.887146 ms (enqueue 0.867297 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.872632 ms - Host latency: 0.889233 ms (enqueue 0.869592 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.872327 ms - Host latency: 0.88877 ms (enqueue 0.86947 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.871948 ms - Host latency: 0.88866 ms (enqueue 0.868726 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.871643 ms - Host latency: 0.888464 ms (enqueue 0.868457 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.870288 ms - Host latency: 0.886999 ms (enqueue 0.867188 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.872046 ms - Host latency: 0.889368 ms (enqueue 0.868762 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.872034 ms - Host latency: 0.889282 ms (enqueue 0.868848 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.870703 ms - Host latency: 0.889478 ms (enqueue 0.867541 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.871155 ms - Host latency: 0.888135 ms (enqueue 0.868372 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.871436 ms - Host latency: 0.888428 ms (enqueue 0.868066 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.873633 ms - Host latency: 0.890332 ms (enqueue 0.870532 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.869897 ms - Host latency: 0.886475 ms (enqueue 0.866834 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.87085 ms - Host latency: 0.88844 ms (enqueue 0.867651 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.8703 ms - Host latency: 0.886926 ms (enqueue 0.867126 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.872595 ms - Host latency: 0.890027 ms (enqueue 0.869604 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.872864 ms - Host latency: 0.889685 ms (enqueue 0.869714 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.871924 ms - Host latency: 0.889063 ms (enqueue 0.868884 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.872363 ms - Host latency: 0.88927 ms (enqueue 0.869324 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.869971 ms - Host latency: 0.888245 ms (enqueue 0.86709 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.873242 ms - Host latency: 0.890393 ms (enqueue 0.869788 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.871802 ms - Host latency: 0.890234 ms (enqueue 0.86875 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.873376 ms - Host latency: 0.890381 ms (enqueue 0.870349 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.877295 ms - Host latency: 0.897168 ms (enqueue 0.873792 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.871887 ms - Host latency: 0.888733 ms (enqueue 0.868567 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.87334 ms - Host latency: 0.890173 ms (enqueue 0.870276 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.871912 ms - Host latency: 0.88894 ms (enqueue 0.868555 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.871411 ms - Host latency: 0.887952 ms (enqueue 0.868286 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.873376 ms - Host latency: 0.891956 ms (enqueue 0.87002 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.872815 ms - Host latency: 0.889368 ms (enqueue 0.869202 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.872839 ms - Host latency: 0.889673 ms (enqueue 0.86947 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.874512 ms - Host latency: 0.890881 ms (enqueue 0.871228 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.870923 ms - Host latency: 0.887744 ms (enqueue 0.867944 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.872266 ms - Host latency: 0.889417 ms (enqueue 0.86925 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.87583 ms - Host latency: 0.892493 ms (enqueue 0.87251 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.872131 ms - Host latency: 0.88855 ms (enqueue 0.869116 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.872961 ms - Host latency: 0.889917 ms (enqueue 0.8698 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.871826 ms - Host latency: 0.888879 ms (enqueue 0.868762 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.872266 ms - Host latency: 0.889307 ms (enqueue 0.869165 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.872681 ms - Host latency: 0.890027 ms (enqueue 0.869373 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.873108 ms - Host latency: 0.891882 ms (enqueue 0.86991 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.873792 ms - Host latency: 0.890784 ms (enqueue 0.870691 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.872668 ms - Host latency: 0.889563 ms (enqueue 0.869751 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.871875 ms - Host latency: 0.888867 ms (enqueue 0.868799 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.873669 ms - Host latency: 0.890735 ms (enqueue 0.870544 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.872437 ms - Host latency: 0.889355 ms (enqueue 0.86897 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.871753 ms - Host latency: 0.888477 ms (enqueue 0.86853 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.871802 ms - Host latency: 0.888574 ms (enqueue 0.868921 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.872314 ms - Host latency: 0.88938 ms (enqueue 0.869165 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.871753 ms - Host latency: 0.889355 ms (enqueue 0.868286 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.872583 ms - Host latency: 0.890186 ms (enqueue 0.869629 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.87041 ms - Host latency: 0.887085 ms (enqueue 0.867212 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.872534 ms - Host latency: 0.889551 ms (enqueue 0.869287 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.873315 ms - Host latency: 0.890601 ms (enqueue 0.869873 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.871826 ms - Host latency: 0.891235 ms (enqueue 0.868604 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.871631 ms - Host latency: 0.890063 ms (enqueue 0.868286 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.871436 ms - Host latency: 0.88811 ms (enqueue 0.868237 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.874072 ms - Host latency: 0.891089 ms (enqueue 0.871094 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.874878 ms - Host latency: 0.892114 ms (enqueue 0.871729 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.870825 ms - Host latency: 0.887427 ms (enqueue 0.868018 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.873242 ms - Host latency: 0.89104 ms (enqueue 0.870068 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.874561 ms - Host latency: 0.892065 ms (enqueue 0.870898 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.876855 ms - Host latency: 0.894531 ms (enqueue 0.873364 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.872925 ms - Host latency: 0.889648 ms (enqueue 0.869629 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.87312 ms - Host latency: 0.88999 ms (enqueue 0.87002 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.872681 ms - Host latency: 0.889233 ms (enqueue 0.869385 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.870435 ms - Host latency: 0.887061 ms (enqueue 0.867285 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.871631 ms - Host latency: 0.888599 ms (enqueue 0.868335 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.873926 ms - Host latency: 0.891455 ms (enqueue 0.870703 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.872266 ms - Host latency: 0.889478 ms (enqueue 0.869214 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.8729 ms - Host latency: 0.889819 ms (enqueue 0.869946 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.875781 ms - Host latency: 0.892871 ms (enqueue 0.872168 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.872681 ms - Host latency: 0.889771 ms (enqueue 0.869263 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.875366 ms - Host latency: 0.892847 ms (enqueue 0.871948 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.875098 ms - Host latency: 0.892163 ms (enqueue 0.872119 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.87146 ms - Host latency: 0.890063 ms (enqueue 0.868164 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.871729 ms - Host latency: 0.888623 ms (enqueue 0.868408 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.87373 ms - Host latency: 0.893774 ms (enqueue 0.870337 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.873486 ms - Host latency: 0.890869 ms (enqueue 0.870093 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.872852 ms - Host latency: 0.891772 ms (enqueue 0.869507 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.875415 ms - Host latency: 0.893018 ms (enqueue 0.872021 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.870386 ms - Host latency: 0.886963 ms (enqueue 0.867334 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.873755 ms - Host latency: 0.892969 ms (enqueue 0.870435 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.873999 ms - Host latency: 0.890991 ms (enqueue 0.870581 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.874829 ms - Host latency: 0.894019 ms (enqueue 0.871655 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.871875 ms - Host latency: 0.888647 ms (enqueue 0.868872 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.870801 ms - Host latency: 0.8875 ms (enqueue 0.867627 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.872827 ms - Host latency: 0.889771 ms (enqueue 0.869556 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.874853 ms - Host latency: 0.891699 ms (enqueue 0.87002 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.871411 ms - Host latency: 0.888403 ms (enqueue 0.86853 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.871094 ms - Host latency: 0.88833 ms (enqueue 0.86814 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.871069 ms - Host latency: 0.889331 ms (enqueue 0.868189 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.872485 ms - Host latency: 0.890039 ms (enqueue 0.86936 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.870483 ms - Host latency: 0.886963 ms (enqueue 0.867505 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.875854 ms - Host latency: 0.893726 ms (enqueue 0.87229 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.872583 ms - Host latency: 0.889966 ms (enqueue 0.86936 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.871265 ms - Host latency: 0.887915 ms (enqueue 0.868286 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.870923 ms - Host latency: 0.887793 ms (enqueue 0.868018 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.871899 ms - Host latency: 0.888403 ms (enqueue 0.868628 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.874146 ms - Host latency: 0.891455 ms (enqueue 0.870898 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.871509 ms - Host latency: 0.888745 ms (enqueue 0.868481 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.872314 ms - Host latency: 0.88894 ms (enqueue 0.868994 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.879907 ms - Host latency: 0.897314 ms (enqueue 0.87666 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.877197 ms - Host latency: 0.89436 ms (enqueue 0.873633 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.871729 ms - Host latency: 0.888525 ms (enqueue 0.868677 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.8771 ms - Host latency: 0.894458 ms (enqueue 0.873584 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.871362 ms - Host latency: 0.888379 ms (enqueue 0.868433 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.871777 ms - Host latency: 0.88855 ms (enqueue 0.868604 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.870972 ms - Host latency: 0.887671 ms (enqueue 0.867871 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.871411 ms - Host latency: 0.887891 ms (enqueue 0.868433 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.874512 ms - Host latency: 0.892261 ms (enqueue 0.871411 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.872168 ms - Host latency: 0.88916 ms (enqueue 0.869312 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.872754 ms - Host latency: 0.889941 ms (enqueue 0.869629 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.872412 ms - Host latency: 0.889111 ms (enqueue 0.868945 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.871509 ms - Host latency: 0.889136 ms (enqueue 0.868408 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.875269 ms - Host latency: 0.892114 ms (enqueue 0.871899 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.874609 ms - Host latency: 0.891479 ms (enqueue 0.871631 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.876343 ms - Host latency: 0.894189 ms (enqueue 0.87312 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.871338 ms - Host latency: 0.889648 ms (enqueue 0.868164 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.87168 ms - Host latency: 0.88894 ms (enqueue 0.868579 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.871924 ms - Host latency: 0.88877 ms (enqueue 0.868848 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.875391 ms - Host latency: 0.892163 ms (enqueue 0.872144 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.872974 ms - Host latency: 0.889648 ms (enqueue 0.869971 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.873047 ms - Host latency: 0.89043 ms (enqueue 0.869849 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.873633 ms - Host latency: 0.890649 ms (enqueue 0.870532 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.87102 ms - Host latency: 0.887891 ms (enqueue 0.86792 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.870581 ms - Host latency: 0.887427 ms (enqueue 0.86748 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.875122 ms - Host latency: 0.892432 ms (enqueue 0.871802 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.873584 ms - Host latency: 0.891064 ms (enqueue 0.870337 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.869775 ms - Host latency: 0.886182 ms (enqueue 0.866748 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.871777 ms - Host latency: 0.888477 ms (enqueue 0.868579 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.870947 ms - Host latency: 0.887866 ms (enqueue 0.867749 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.876245 ms - Host latency: 0.893701 ms (enqueue 0.872876 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.87356 ms - Host latency: 0.890454 ms (enqueue 0.870386 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.871411 ms - Host latency: 0.888428 ms (enqueue 0.868189 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.871436 ms - Host latency: 0.888062 ms (enqueue 0.868408 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.873535 ms - Host latency: 0.890552 ms (enqueue 0.870459 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.874072 ms - Host latency: 0.891284 ms (enqueue 0.870752 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.87898 ms - Host latency: 0.896802 ms (enqueue 0.875317 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.871875 ms - Host latency: 0.888379 ms (enqueue 0.868872 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.873486 ms - Host latency: 0.890674 ms (enqueue 0.870166 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.870679 ms - Host latency: 0.887402 ms (enqueue 0.86748 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.870264 ms - Host latency: 0.886865 ms (enqueue 0.867383 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.870923 ms - Host latency: 0.887793 ms (enqueue 0.867603 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.870874 ms - Host latency: 0.890259 ms (enqueue 0.867773 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.871997 ms - Host latency: 0.889429 ms (enqueue 0.868921 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.872534 ms - Host latency: 0.889429 ms (enqueue 0.869141 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.873413 ms - Host latency: 0.890552 ms (enqueue 0.87002 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.871484 ms - Host latency: 0.888281 ms (enqueue 0.868408 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.872876 ms - Host latency: 0.889941 ms (enqueue 0.869653 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.872314 ms - Host latency: 0.889551 ms (enqueue 0.869092 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.873901 ms - Host latency: 0.891797 ms (enqueue 0.870947 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.87356 ms - Host latency: 0.89104 ms (enqueue 0.870313 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.872461 ms - Host latency: 0.889282 ms (enqueue 0.86936 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.872363 ms - Host latency: 0.889233 ms (enqueue 0.869214 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.871069 ms - Host latency: 0.887891 ms (enqueue 0.867871 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.871924 ms - Host latency: 0.888745 ms (enqueue 0.869019 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.870483 ms - Host latency: 0.887354 ms (enqueue 0.867334 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.872046 ms - Host latency: 0.889209 ms (enqueue 0.868848 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.870605 ms - Host latency: 0.888208 ms (enqueue 0.867603 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.872363 ms - Host latency: 0.889624 ms (enqueue 0.869263 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.87168 ms - Host latency: 0.889038 ms (enqueue 0.868896 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.87063 ms - Host latency: 0.887524 ms (enqueue 0.867456 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.873071 ms - Host latency: 0.889868 ms (enqueue 0.869995 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.870703 ms - Host latency: 0.887598 ms (enqueue 0.867749 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.870483 ms - Host latency: 0.887109 ms (enqueue 0.867065 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.873486 ms - Host latency: 0.890039 ms (enqueue 0.870239 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.873828 ms - Host latency: 0.891016 ms (enqueue 0.870264 ms)\n",
      "[01/18/2023-20:49:16] [I] Average on 10 runs - GPU latency: 0.870947 ms - Host latency: 0.88728 ms (enqueue 0.867773 ms)\n",
      "[01/18/2023-20:49:16] [I] \n",
      "[01/18/2023-20:49:16] [I] === Performance summary ===\n",
      "[01/18/2023-20:49:16] [I] Throughput: 1085.94 qps\n",
      "[01/18/2023-20:49:16] [I] Latency: min = 0.878662 ms, max = 0.973877 ms, mean = 0.889442 ms, median = 0.888428 ms, percentile(90%) = 0.894531 ms, percentile(95%) = 0.898438 ms, percentile(99%) = 0.907959 ms\n",
      "[01/18/2023-20:49:16] [I] Enqueue Time: min = 0.86084 ms, max = 0.950439 ms, mean = 0.869163 ms, median = 0.868408 ms, percentile(90%) = 0.873016 ms, percentile(95%) = 0.875732 ms, percentile(99%) = 0.88501 ms\n",
      "[01/18/2023-20:49:16] [I] H2D Latency: min = 0.0102386 ms, max = 0.0415039 ms, mean = 0.0118721 ms, median = 0.0117188 ms, percentile(90%) = 0.012207 ms, percentile(95%) = 0.0129395 ms, percentile(99%) = 0.0150757 ms\n",
      "[01/18/2023-20:49:16] [I] GPU Compute Time: min = 0.863281 ms, max = 0.954346 ms, mean = 0.872336 ms, median = 0.87146 ms, percentile(90%) = 0.876465 ms, percentile(95%) = 0.879578 ms, percentile(99%) = 0.888794 ms\n",
      "[01/18/2023-20:49:16] [I] D2H Latency: min = 0.00390625 ms, max = 0.0341797 ms, mean = 0.00523314 ms, median = 0.00512695 ms, percentile(90%) = 0.00585938 ms, percentile(95%) = 0.00622559 ms, percentile(99%) = 0.00708008 ms\n",
      "[01/18/2023-20:49:16] [I] Total Host Walltime: 3.00108 s\n",
      "[01[01/18/2023-20:49:16] [I] Total GPU Compute Time: 2.84294 s\n",
      "/18/2023-20:49:16] [W] * Throughput may be bound by Enqueue Time rather than GPU Compute and the GPU may be under-utilized.\n",
      "[01/18/2023-20:49:16] [W]   If not already in use, --useCudaGraph (utilize CUDA graphs where possible) may increase the throughput.\n",
      "[01/18/2023-20:49:16] [I] Explanations of the performance metrics are printed in the verbose logs.\n",
      "[01/18/2023-20:49:16] [V] \n",
      "[01/18/2023-20:49:16] [V] === Explanations of the performance metrics ===\n",
      "[01/18/2023-20:49:16] [V] Total Host Walltime: the host walltime from when the first query (after warmups) is enqueued to when the last query is completed.\n",
      "[01/18/2023-20:49:16] [V] GPU Compute Time: the GPU latency to execute the kernels for a query.\n",
      "[01/18/2023-20:49:16] [V] Total GPU Compute Time: the summation of the GPU Compute Time of all the queries. If this is significantly shorter than Total Host Walltime, the GPU may be under-utilized because of host-side overheads or data transfers.\n",
      "[01/18/2023-20:49:16] [V] Throughput: the observed throughput computed by dividing the number of queries by the Total Host Walltime. If this is significantly lower than the reciprocal of GPU Compute Time, the GPU may be under-utilized because of host-side overheads or data transfers.\n",
      "[01/18/2023-20:49:16] [V] Enqueue Time: the host latency to enqueue a query. If this is longer than GPU Compute Time, the GPU may be under-utilized.\n",
      "[01/18/2023-20:49:16] [V] H2D Latency: the latency for host-to-device data transfers for input tensors of a single query.\n",
      "[01/18/2023-20:49:16] [V] D2H Latency: the latency for device-to-host data transfers for output tensors of a single query.\n",
      "[01/18/2023-20:49:16] [V] Latency: the summation of H2D Latency, GPU Compute Time, and D2H Latency. This is the latency to infer a single query.\n",
      "[01/18/2023-20:49:16] [I] \n",
      "&&&& PASSED TensorRT.trtexec [TensorRT v8501] # trtexec --onnx=/workspace/onnx/model.onnx --saveEngine=/workspace/model.plan --minShapes=input_ids:1x128,attention_mask:1x128,token_type_ids:1x128 --optShapes=input_ids:16x128,attention_mask:16x128,token_type_ids:16x128 --maxShapes=input_ids:224x128,attention_mask:224x128,token_type_ids:224x128 --fp16 --verbose --workspace=23000\n",
      "Finished exporting all models...\n"
     ]
    }
   ],
   "source": [
    "!docker run --gpus=all --rm -it --ipc=host --ulimit memlock=-1 --ulimit stack=67108864 \\\n",
    "            -v `pwd`/workspace:/workspace -w /workspace nvcr.io/nvidia/pytorch:22.12-py3 \\\n",
    "            /bin/bash generate_model_trt.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3610b257-20d2-4f16-8f05-e482d42608a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p model_repository/xdistilbert_trt/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "440d9fdb-b6d0-40fd-bd29-96a53a6a1971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing model_repository/xdistilbert_trt/config.pbtxt\n"
     ]
    }
   ],
   "source": [
    "%%writefile model_repository/xdistilbert_trt/config.pbtxt\n",
    "name: \"xdistilbert_trt\"\n",
    "backend: \"tensorrt\"\n",
    "max_batch_size: 224\n",
    "input [\n",
    "  {\n",
    "    name: \"input_ids\"\n",
    "    data_type: TYPE_INT32\n",
    "    dims: [128]\n",
    "  },\n",
    "  {\n",
    "    name: \"attention_mask\"\n",
    "    data_type: TYPE_INT32\n",
    "    dims: [128]\n",
    "  },\n",
    "  {\n",
    "    name: \"token_type_ids\"\n",
    "    data_type: TYPE_INT32\n",
    "    dims: [128]\n",
    "  }\n",
    "]\n",
    "output [\n",
    "  {\n",
    "    name: \"logits\"\n",
    "    data_type: TYPE_FP32\n",
    "    dims: [6]\n",
    "  }\n",
    "]\n",
    "instance_group {\n",
    "  count: 1\n",
    "  kind: KIND_GPU\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d67ee3-e301-4edb-a6d4-d0b1f35ad2b3",
   "metadata": {},
   "source": [
    "### Export model artifacts to S3 <a class=\"anchor\" id=\"export-to-s3\"></a>\n",
    "\n",
    "SageMaker expects the model artifacts in below format, it should also satisfy Triton container requirements such as model name, version, config.pbtxt files etc. `tar` the folder containing the model file and upload it to s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55fb9432-5c5f-449e-88c3-11d1d842af41",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p model_repository/xdistilbert_pt/1/\n",
    "!cp -f workspace/model.pt model_repository/xdistilbert_pt/1/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5022a48f-5d52-4697-8b12-f00fc297f420",
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -C model_repository -czf $pytorch_model_file_name xdistilbert_pt\n",
    "model_uri_pt = sagemaker_session.upload_data(path=pytorch_model_file_name, key_prefix=prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6f5a7b9-416e-40aa-be62-d956d52146f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Model S3 location: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_pt.tar.gz\n"
     ]
    }
   ],
   "source": [
    "print(f\"PyTorch Model S3 location: {model_uri_pt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f302c9-f4a1-449a-b381-834100100f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p model_repository/xdistilbert_trt/1/\n",
    "!cp -f workspace/model.plan model_repository/xdistilbert_trt/1/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "296c069a-2fad-4e22-891a-cf0a05920327",
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -C model_repository -czf $tensorrt_model_file_name xdistilbert_trt\n",
    "model_uri_trt = sagemaker_session.upload_data(path=tensorrt_model_file_name, key_prefix=prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d49ab86-fcb1-467b-96a9-4ce518914b18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorRT Model S3 location: s3://sagemaker-us-west-2-354625738399/mme-gpu/xdistilbert_trt.tar.gz\n"
     ]
    }
   ],
   "source": [
    "print(f\"TensorRT Model S3 location: {model_uri_trt}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cab8f41-08e5-4999-98e7-92ee2852940d",
   "metadata": {},
   "source": [
    "### Deploy Models with MME <a class=\"anchor\" id=\"deploy-models-with-mme\"></a>\n",
    "\n",
    "We will now deploy xtreme distilBERT model with different framework backends i.e. PyTorch, TensorRT to SageMaker MME.\n",
    "\n",
    "\n",
    "<div class=\"alert alert-info\"> <strong> Note </strong>\n",
    "you can deploy 1000s of models. The models can use same framework. They can also use different frameworks as shown in this note.\n",
    "</div>\n",
    "\n",
    "We will use AWS SDK for Python (Boto) APIs [create_model](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/sagemaker.html#SageMaker.Client.create_model), [create_endpoint_config](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/sagemaker.html#SageMaker.Client.create_endpoint_config) and [create_endpoint](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/sagemaker.html#SageMaker.Client.create_endpoint) to create a mulit-model endpoint."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca1f6b1-c210-484f-8bfb-4c05f84be0d3",
   "metadata": {},
   "source": [
    "### Define the serving container  <a class=\"anchor\" id=\"define-container-def\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400c2773-10f6-4b18-bf8b-6a974ae2daf2",
   "metadata": {},
   "source": [
    " In the container definition, define the `ModelDataUrl` to specify the S3 directory that contains all the models that SageMaker multi-model endpoint will use to load  and serve predictions. Set `Mode` to `MultiModel` to indicates SageMaker would create the endpoint with MME container specifications. We set the container with an image that supports deploying multi-model endpoints with GPU, see MME [container images](https://docs.aws.amazon.com/sagemaker/latest/dg/multi-model-endpoints.html#multi-model-support) for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6379000a-3116-4ed4-851b-a041e4cfb3bf",
   "metadata": {},
   "source": [
    "### SageMaker Triton Container Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25758107-1d7a-4085-8a6a-908844f03ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# account mapping for SageMaker MME Triton Image\n",
    "account_id_map = {\n",
    "    \"us-east-1\": \"785573368785\",\n",
    "    \"us-east-2\": \"007439368137\",\n",
    "    \"us-west-1\": \"710691900526\",\n",
    "    \"us-west-2\": \"301217895009\",\n",
    "    \"eu-west-1\": \"802834080501\",\n",
    "    \"eu-west-2\": \"205493899709\",\n",
    "    \"eu-west-3\": \"254080097072\",\n",
    "    \"eu-north-1\": \"601324751636\",\n",
    "    \"eu-south-1\": \"966458181534\",\n",
    "    \"eu-central-1\": \"746233611703\",\n",
    "    \"ap-east-1\": \"110948597952\",\n",
    "    \"ap-south-1\": \"763008648453\",\n",
    "    \"ap-northeast-1\": \"941853720454\",\n",
    "    \"ap-northeast-2\": \"151534178276\",\n",
    "    \"ap-southeast-1\": \"324986816169\",\n",
    "    \"ap-southeast-2\": \"355873309152\",\n",
    "    \"cn-northwest-1\": \"474822919863\",\n",
    "    \"cn-north-1\": \"472730292857\",\n",
    "    \"sa-east-1\": \"756306329178\",\n",
    "    \"ca-central-1\": \"464438896020\",\n",
    "    \"me-south-1\": \"836785723513\",\n",
    "    \"af-south-1\": \"774647643957\",\n",
    "}\n",
    "\n",
    "region = boto3.Session().region_name\n",
    "if region not in account_id_map.keys():\n",
    "    raise (\"UNSUPPORTED REGION\")\n",
    "\n",
    "base = \"amazonaws.com.cn\" if region.startswith(\"cn-\") else \"amazonaws.com\"\n",
    "mme_triton_image_uri = (\n",
    "    \"{account_id}.dkr.ecr.{region}.{base}/sagemaker-tritonserver:22.12-py3\".format(\n",
    "        account_id=account_id_map[region], region=region, base=base\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53b00914-a237-4455-a08c-d79b3715cac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "container = {\"Image\": mme_triton_image_uri, \"ModelDataUrl\": model_data_url, \"Mode\": \"MultiModel\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e28483-e6cf-4769-b6f3-4ccaa61471ec",
   "metadata": {},
   "source": [
    "### Create a MME object <a class=\"anchor\" id=\"create-mme-model-obj\"></a>\n",
    "\n",
    "Using the SageMaker boto3 client, create the model using [create_model](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/sagemaker.html#SageMaker.Client.create_model) API. We will pass the container definition to the create model API along with ModelName and ExecutionRoleArn.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2077c860-1ef6-42f6-b10b-c77e075d2be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Arn: arn:aws:sagemaker:us-west-2:354625738399:model/mme-gpu-mdl-2023-01-19-23-25-42\n"
     ]
    }
   ],
   "source": [
    "create_model_response = sm_client.create_model(\n",
    "    ModelName=sm_model_name, ExecutionRoleArn=role, PrimaryContainer=container\n",
    ")\n",
    "\n",
    "print(\"Model Arn: \" + create_model_response[\"ModelArn\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a8e07e-1410-471e-9c2c-10e0c23db00f",
   "metadata": {},
   "source": [
    "### Define configuration for the MME<a class=\"anchor\" id=\"config-mme\"></a>\n",
    "\n",
    "Create a multi-model endpoint configuration using [create_endpoint_config](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/sagemaker.html#SageMaker.Client.create_endpoint_config) boto3 API. Specify an accelerated GPU computing instance in InstanceType (we will use the same instance type that we are using to host our SageMaker Notebook). We recommend configuring your endpoints with at least two instances with real-life use-cases. This allows SageMaker to provide a highly available set of predictions across multiple Availability Zones for the models.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b55e160-8aa0-4ef7-84f5-cb975df99f4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint Config Arn: arn:aws:sagemaker:us-west-2:354625738399:endpoint-config/mme-gpu-epc-2023-01-19-23-25-42\n"
     ]
    }
   ],
   "source": [
    "create_endpoint_config_response = sm_client.create_endpoint_config(\n",
    "    EndpointConfigName=endpoint_config_name,\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            \"InstanceType\": instance_type,\n",
    "            \"InitialVariantWeight\": 1,\n",
    "            \"InitialInstanceCount\": 1,\n",
    "            \"ModelName\": sm_model_name,\n",
    "            \"VariantName\": \"AllTraffic\",\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(\"Endpoint Config Arn: \" + create_endpoint_config_response[\"EndpointConfigArn\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21943aee-7692-4048-9a47-256d8e21c112",
   "metadata": {},
   "source": [
    "### Create MME  <a class=\"anchor\" id=\"create-mme\"></a>\n",
    "\n",
    "Using the above endpoint configuration we create a new sagemaker endpoint and wait for the deployment to finish. The status will change to **InService** once the deployment is successful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1fc49275-e1c2-46c3-a8be-9e193c271262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint Arn: arn:aws:sagemaker:us-west-2:354625738399:endpoint/mme-gpu-ep-2023-01-19-23-25-42\n"
     ]
    }
   ],
   "source": [
    "create_endpoint_response = sm_client.create_endpoint(\n",
    "    EndpointName=endpoint_name, EndpointConfigName=endpoint_config_name\n",
    ")\n",
    "\n",
    "print(\"Endpoint Arn: \" + create_endpoint_response[\"EndpointArn\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7404e50c-9f66-4b27-9b9a-714f474cc1d9",
   "metadata": {},
   "source": [
    "### Describe MME <a class=\"anchor\" id=\"describe-mme\"></a>\n",
    "\n",
    "Now, we check the status of the endpoint using `describe_endpoint`. This step will take about 5 mins to complete and you should see \"Status: InService\" message before you proceed to next cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d7ac9f8-8ba9-4f37-a2cb-7dc6d428885d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: InService\n",
      "Arn: arn:aws:sagemaker:us-west-2:354625738399:endpoint/mme-gpu-ep-2023-01-19-23-25-42\n",
      "Status: InService\n"
     ]
    }
   ],
   "source": [
    "resp = sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "status = resp[\"EndpointStatus\"]\n",
    "print(\"Status: \" + status)\n",
    "\n",
    "while status == \"Creating\":\n",
    "    time.sleep(60)\n",
    "    resp = sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "    status = resp[\"EndpointStatus\"]\n",
    "    print(\"Status: \" + status)\n",
    "\n",
    "print(\"Arn: \" + resp[\"EndpointArn\"])\n",
    "print(\"Status: \" + status)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1a0ed6-ff2d-46cb-a396-4beef96b58d9",
   "metadata": {},
   "source": [
    "## Helper functions to prepare Input Payload <a class=\"anchor\" id=\"helper-functions\"></a>\n",
    "\n",
    "The following method transforms a sample image we will be using for inference into the payload that can be sent for inference to the Triton server. These will be used by PyTorch and TensorRT efficientnet_b0 computer vision models.\n",
    "\n",
    "The `tritonclient` package provides utility methods to generate the payload without having to know the details of the specification. We'll use the following methods to convert our inference request into a binary format which provides lower latencies for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "daae74d9-1058-4686-9f36-e297277d26e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tritonclient.http as httpclient\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer_name = \"bergum/xtremedistil-emotion\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "\n",
    "def tokenize_text(tokenizer, text):\n",
    "    MAX_LEN = 128\n",
    "    tokenized_text = tokenizer(text, padding='max_length', max_length=MAX_LEN, add_special_tokens=True, return_tensors='np')\n",
    "    return tokenized_text.input_ids, tokenized_text.attention_mask, tokenized_text.token_type_ids\n",
    "\n",
    "def _get_sample_tokenized_text_binary(text, input_names, output_names):\n",
    "    inputs = []\n",
    "    outputs = []\n",
    "    input_ids, attention_mask, token_type_ids = tokenize_text(tokenizer, text)\n",
    "    inputs.append(httpclient.InferInput(input_names[0], input_ids.shape, \"INT32\"))\n",
    "    inputs.append(httpclient.InferInput(input_names[1], attention_mask.shape, \"INT32\"))\n",
    "    inputs.append(httpclient.InferInput(input_names[2], token_type_ids.shape, \"INT32\"))\n",
    "\n",
    "    inputs[0].set_data_from_numpy(input_ids.astype(np.int32), binary_data=True)\n",
    "    inputs[1].set_data_from_numpy(attention_mask.astype(np.int32), binary_data=True)\n",
    "    inputs[2].set_data_from_numpy(token_type_ids.astype(np.int32), binary_data=True)\n",
    "    \n",
    "    outputs.append(httpclient.InferRequestedOutput(output_names[0], binary_data=True))\n",
    "    request_body, header_length = httpclient.InferenceServerClient.generate_request_body(\n",
    "        inputs, outputs=outputs\n",
    "    )\n",
    "    return request_body, header_length\n",
    "\n",
    "def get_sample_tokenized_text_binary_pt(text):\n",
    "    return _get_sample_tokenized_text_binary(text, [\"INPUT__0\", \"INPUT__1\", \"INPUT__2\"], [\"OUTPUT__0\"])\n",
    "\n",
    "\n",
    "def get_sample_tokenized_text_binary_trt(text):\n",
    "    return _get_sample_tokenized_text_binary(text, [\"input_ids\", \"attention_mask\", \"token_type_ids\"], [\"logits\"])\n",
    "\n",
    "def get_predictions(logits):\n",
    "    CLASSES = [\"SADNESS\", \"JOY\", \"LOVE\", \"ANGER\", \"FEAR\", \"SURPRISE\"]\n",
    "    predictions = []\n",
    "    for i in range(len(logits)):\n",
    "        pred_class_idx = np.argmax(logits[i])\n",
    "        predictions.append(CLASSES[pred_class_idx])\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8887d53d-d9b4-41bf-ab74-07a86cecd04c",
   "metadata": {},
   "source": [
    "### Invoke target model on Multi Model Endpoint\n",
    "\n",
    "Once the endpoint is successfully created, we can send inference request to multi-model endpoint using invoke_enpoint API. We specify the TargetModel in the invocation call and pass in the payload for each model type. Sample invocation for PyTorch model and TensorRT model is shown below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef06a05c-ae58-484c-9fed-4c9584795c7f",
   "metadata": {},
   "source": [
    "### Invoke PyTorch Model <a class=\"anchor\" id=\"invoke-pytorch-model\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f4ab429b-5b9c-4edd-9ff7-5f974dd35924",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = \"I really enjoyed deploying thousands of NLP models using Triton on SageMaker Multi-Model Endpoint\"\n",
    "request_body, header_length = get_sample_tokenized_text_binary_pt(sample_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "72a804a1-216c-4a60-b6fd-403e66581459",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = runtime_sm_client.invoke_endpoint(EndpointName=endpoint_name,\n",
    "                                  ContentType='application/vnd.sagemaker-triton.binary+json;json-header-size={}'.format(header_length),\n",
    "                                  Body=request_body,\n",
    "                                  TargetModel='xdistilbert_pt.tar.gz')\n",
    "\n",
    "# Parse json header size length from the response\n",
    "header_length_prefix = \"application/vnd.sagemaker-triton.binary+json;json-header-size=\"\n",
    "header_length_str = response['ContentType'][len(header_length_prefix):]\n",
    "output_name = \"OUTPUT__0\"\n",
    "# Read response body\n",
    "result = httpclient.InferenceServerClient.parse_response_body(\n",
    "    response['Body'].read(), header_length=int(header_length_str))\n",
    "logits = result.as_numpy(output_name)\n",
    "predictions = get_predictions(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "79bc6330-8b84-4e38-ab5a-f0218c0f0d8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['JOY']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41729b83-9921-4f26-b7cf-74f9f81365fc",
   "metadata": {},
   "source": [
    "### Invoke TensorRT Model <a class=\"anchor\" id=\"invoke-tensorrt-model\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "097ea610-e5c1-431c-8168-1a11c3a1fcb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "request_body, header_length = get_sample_tokenized_text_binary_trt(sample_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "90afb76a-72ac-49b0-ae6d-313976bf94f9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModelError",
     "evalue": "An error occurred (ModelError) when calling the InvokeEndpoint operation: Received client error (400) from primary with message \"{\"error\":\"load failed for model 'c81c0b68c414c80f8b64d39f33e1f541': version 1 is at UNAVAILABLE state: Internal: unable to load plan file to auto complete config: /opt/ml/models/c81c0b68c414c80f8b64d39f33e1f541/model/xdistilbert_trt/1/model.plan;\\n\"}\". See https://us-west-2.console.aws.amazon.com/cloudwatch/home?region=us-west-2#logEventViewer:group=/aws/sagemaker/Endpoints/mme-gpu-ep-2023-01-19-23-25-42 in account 354625738399 for more information.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModelError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4235/1082573473.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m response = runtime_sm_client.invoke_endpoint(EndpointName=endpoint_name,\n\u001b[0m\u001b[1;32m      2\u001b[0m                                   \u001b[0mContentType\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'application/vnd.sagemaker-triton.binary+json;json-header-size={}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheader_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                                   \u001b[0mBody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest_body\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                   TargetModel='xdistilbert_trt.tar.gz')\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    528\u001b[0m                 )\n\u001b[1;32m    529\u001b[0m             \u001b[0;31m# The \"self\" in this scope is referring to the BaseClient.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_api_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0m_api_call\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_operation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    958\u001b[0m             \u001b[0merror_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Code\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m             \u001b[0merror_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 960\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    961\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModelError\u001b[0m: An error occurred (ModelError) when calling the InvokeEndpoint operation: Received client error (400) from primary with message \"{\"error\":\"load failed for model 'c81c0b68c414c80f8b64d39f33e1f541': version 1 is at UNAVAILABLE state: Internal: unable to load plan file to auto complete config: /opt/ml/models/c81c0b68c414c80f8b64d39f33e1f541/model/xdistilbert_trt/1/model.plan;\\n\"}\". See https://us-west-2.console.aws.amazon.com/cloudwatch/home?region=us-west-2#logEventViewer:group=/aws/sagemaker/Endpoints/mme-gpu-ep-2023-01-19-23-25-42 in account 354625738399 for more information."
     ]
    }
   ],
   "source": [
    "response = runtime_sm_client.invoke_endpoint(EndpointName=endpoint_name,\n",
    "                                  ContentType='application/vnd.sagemaker-triton.binary+json;json-header-size={}'.format(header_length),\n",
    "                                  Body=request_body,\n",
    "                                  TargetModel='xdistilbert_trt.tar.gz')\n",
    "\n",
    "# Parse json header size length from the response\n",
    "header_length_prefix = \"application/vnd.sagemaker-triton.binary+json;json-header-size=\"\n",
    "header_length_str = response['ContentType'][len(header_length_prefix):]\n",
    "output_name = \"logits\"\n",
    "# Read response body\n",
    "result = httpclient.InferenceServerClient.parse_response_body(\n",
    "    response['Body'].read(), header_length=int(header_length_str))\n",
    "logits = result.as_numpy(output_name)\n",
    "predictions = get_predictions(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a7bfa5-80ca-477e-9ce5-c6bf545e2a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05aa3d1a-c0f2-4809-a7e2-71056556c864",
   "metadata": {},
   "source": [
    "# Deploying Thousand Models to GPUs using MME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132f67b3-0eb6-4ead-8851-c89b2628cb1c",
   "metadata": {},
   "source": [
    "Let's say you have thousand customer-specific distilBERT models which are a mixture of frequently and infrequently accessed models coming from different frameworks (PyTorch, TensorFlow, ONNX, TensorRT) and let's assume most of which have stringent latency requirements.\n",
    "\n",
    "Deploying these 1000 models on GPU instances like `g5.xlarge` (price: `$1/hr`) using Single-Model Endpoints would take ~1000 instances costing you `$1,000`/hour.\n",
    "\n",
    "By leveraging Triton on SageMaker MME, you can deploy these models behind one MME endpoint which can autoscale the number of GPU instances automatically and end up using ~100x lower instances and thus cost would be reduced by ~100x. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccedb827-b9e7-4b54-98f4-f3effa813bc5",
   "metadata": {},
   "source": [
    "## Create 1000 models to be loaded to SageMaker MME\n",
    "\n",
    "This step will take few minutes to complete as we are copying 1000 files to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd99243-9f2e-4954-8ec8-d9b9c8301ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_MODELS = 1000\n",
    "for i in range(1, NUM_MODELS+1):\n",
    "    customer_model_name = f\"xdistilbert_customer{i}.tar.gz\"\n",
    "    model_copy = f\"{model_data_url}{customer_model_name}\"\n",
    "    !aws s3 cp $model_data_url$tensorrt_model_file_name $model_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d3899f-eaf1-4e65-b213-0c37a0e983e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 ls $model_data_url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f091ec-f438-41c0-b00a-71f50111b546",
   "metadata": {},
   "source": [
    "## Set up MME AutoScaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2eb482-42ee-43f0-a7d9-2bb7328a5dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_scaling_client = boto3.client('application-autoscaling')\n",
    "\n",
    "resource_id='endpoint/' + <ENDPOINT_NAME> + '/variant/' + 'AllTraffic' \n",
    "response = auto_scaling_client.register_scalable_target(\n",
    "    ServiceNamespace='sagemaker',\n",
    "    ResourceId=resource_id,\n",
    "    ScalableDimension='sagemaker:variant:DesiredInstanceCount',\n",
    "    MinCapacity = 1,\n",
    "    MaxCapacity = 13\n",
    ")\n",
    "\n",
    "response = auto_scaling_client.put_scaling_policy(\n",
    "    PolicyName='GPUUtil-ScalingPolicy',\n",
    "    ServiceNamespace='sagemaker',\n",
    "    ResourceId=resource_id,\n",
    "    ScalableDimension='sagemaker:variant:DesiredInstanceCount', \n",
    "    PolicyType='TargetTrackingScaling',\n",
    "    TargetTrackingScalingPolicyConfiguration={\n",
    "        'TargetValue': 85.0, \n",
    "        'CustomizedMetricSpecification':\n",
    "        {\n",
    "            'MetricName': 'GPUMemoryUtilization',\n",
    "            'Namespace': '/aws/sagemaker/Endpoints',\n",
    "            'Dimensions': [\n",
    "                {'Name': 'EndpointName', 'Value': <ENDPOINT_NAME> },\n",
    "                {'Name': 'VariantName','Value': 'AllTraffic'}\n",
    "            ],\n",
    "            'Statistic': 'Average',\n",
    "            'Unit': 'Percent'\n",
    "        },\n",
    "        'ScaleInCooldown': 600,\n",
    "        'ScaleOutCooldown': 1 \n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd09ee3a-7b8e-4bf0-b491-1aa2f16156cd",
   "metadata": {},
   "source": [
    "## Put Load on MME Endpoint to see it scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3976ac2-0c78-4224-a1ff-a40d90e5c9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict_model(text, model_name):\n",
    "    print(f\"Using model {model_name} to predict\")\n",
    "    \n",
    "    request_body, header_length = get_sample_tokenized_text_binary_trt(text)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    response = runtime_sm_client.invoke_endpoint(EndpointName=endpoint_name,\n",
    "                                  ContentType='application/vnd.sagemaker-triton.binary+json;json-header-size={}'.format(header_length),\n",
    "                                  Body=request_body,\n",
    "                                  TargetModel=model_name)\n",
    "    \n",
    "    duration = time.time() - start_time\n",
    "    \n",
    "    # Parse json header size length from the response\n",
    "    header_length_prefix = \"application/vnd.sagemaker-triton.binary+json;json-header-size=\"\n",
    "    header_length_str = response['ContentType'][len(header_length_prefix):]\n",
    "    output_name = \"logits\"\n",
    "    # Read response body\n",
    "    result = httpclient.InferenceServerClient.parse_response_body(\n",
    "        response['Body'].read(), header_length=int(header_length_str))\n",
    "    logits = result.as_numpy(output_name)\n",
    "    predictions = get_predictions(logits)\n",
    "    \n",
    "    print(f\"prediction: {predictions}, took {int(duration * 1000)} ms\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287b1cf7-7aea-4018-868e-7d14ecf25cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "for _ in range(10):\n",
    "    i = random.randint(NUM_MODELS)\n",
    "    customer_model_name = f\"xdistilbert_customer{i}.tar.gz\"\n",
    "    predict_model(sample_text, customer_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27272ff9-28a7-43e6-9e05-2ab52e5f03cb",
   "metadata": {},
   "source": [
    "```\n",
    "xdistilbert_english\n",
    ".\n",
    ".\n",
    ".\n",
    "xdistilbert_chinese \n",
    "xdistilbert_APAC\n",
    ".\n",
    ".\n",
    ".\n",
    "xdistilbert_NALA\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbec88f-cbdb-4567-9048-50c0d9746fae",
   "metadata": {},
   "source": [
    "# Clean Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1081fd3f-48c1-4de1-bbfc-4368ae8e8742",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '70ec55f8-d2d6-4ac4-a3ab-94e073748b0f',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '70ec55f8-d2d6-4ac4-a3ab-94e073748b0f',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '0',\n",
       "   'date': 'Thu, 19 Jan 2023 23:19:17 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm_client.delete_endpoint(EndpointName=endpoint_name)\n",
    "sm_client.delete_endpoint_config(EndpointConfigName=endpoint_config_name)\n",
    "sm_client.delete_model(ModelName=sm_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31407206-2d9e-4cc8-83a7-8d9e8e4748c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
